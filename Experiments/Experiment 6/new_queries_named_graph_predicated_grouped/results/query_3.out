Result of /data/leuven/370/vsc37064/new_queries_named_graph_predicated_grouped/query_3.txt:
OpenLink Virtuoso Interactive SQL (Virtuoso)
Version 07.20.3240 as of Mar 11 2025
Type HELP; for help and EXIT; to exit.
Connected to OpenLink Virtuoso
Driver: 07.20.3240 OpenLink Virtuoso ODBC Driver
work                                                                              title                                                                             abstract
LONG VARCHAR                                                                      LONG VARCHAR                                                                      LONG VARCHAR
_______________________________________________________________________________

http://w3id.org/mlsea/pwc/scientificWork/%24%20text%7BR%7D%5E2%24-Bench%3A%20Benchmarking%20the%20Robustness%20of%20Referring%20Perception%20Models%20under%20Perturbations                                                                                  $ text{R}^2$-Bench: Benchmarking the Robustness of Referring Perception Models under Perturbations                                                                                  Referring perception, which aims at grounding visual objects with multimodal referring guidance, is essential for bridging the gap between humans, who provide instructions, and the environment where intelligent systems perceive. Despite progress in this field, the robustness of referring perception models (RPMs) against disruptive perturbations is not well explored. This work thoroughly assesses the resilience of RPMs against various perturbations in both general and specific contexts. Recognizing the complex nature of referring perception tasks, we present a comprehensive taxonomy of perturbations, and then develop a versatile toolbox for synthesizing and evaluating the effects of composite disturbances. Employing this toolbox, we construct $ text{R}^2$-Bench, a benchmark for assessing the Robustness of Referring perception models under noisy conditions across five key tasks. Moreover, we propose the $ text{R}^2$-Agent, an LLM-based agent that simplifies and automates model evaluation via natural language instructions. Our investigation uncovers the vulnerabilities of current RPMs to various perturbations and provides tools for assessing model robustness, potentially promoting the safe and resilient integration of intelligent systems into complex real-world scenarios.
http://w3id.org/mlsea/pwc/scientificWork/%24%CE%BB%24-models%3A%20Effective%20Decision-Aware%20Reinforcement%20Learning%20with%20Latent%20Models                                                                                  $Î»$-models: Effective Decision-Aware Reinforcement Learning with Latent Models                                                                                  The idea of decision-aware model learning, that models should be accurate where it matters for decision-making, has gained prominence in model-based reinforcement learning. While promising theoretical results have been established, the empirical performance of algorithms leveraging a decision-aware loss has been lacking, especially in continuous control problems. In this paper, we present a study on the necessary components for decision-aware reinforcement learning models and we showcase design choices that enable well-performing algorithms. To this end, we provide a theoretical and empirical investigation into algorithmic ideas in the field. We highlight that empirical design decisions established in the MuZero line of works, most importantly the use of a latent model, are vital to achieving good performance for related algorithms. Furthermore, we show that the MuZero loss function is biased in stochastic environments and establish that this bias has practical consequences. Building on these findings, we present an overview of which decision-aware loss functions are best used in what empirical scenarios, providing actionable insights to practitioners in the field.
http://w3id.org/mlsea/pwc/scientificWork/%24H%24-Consistency%20Guarantees%20for%20Regression                                                                                  $H$-Consistency Guarantees for Regression                                                                                  We present a detailed study of $H$-consistency bounds for regression. We first present new theorems that generalize the tools previously given to establish $H$-consistency bounds. This generalization proves essential for analyzing $H$-consistency bounds specific to regression. Next, we prove a series of novel $H$-consistency bounds for surrogate loss functions of the squared loss, under the assumption of a symmetric distribution and a bounded hypothesis set. This includes positive results for the Huber loss, all $ ell_p$ losses, $p geq 1$, the squared $ epsilon$-insensitive loss, as well as a negative result for the $ epsilon$-insensitive loss used in squared Support Vector Regression (SVR). We further leverage our analysis of $H$-consistency for regression and derive principled surrogate losses for adversarial regression (Section 5). This readily establishes novel algorithms for adversarial regression, for which we report favorable experimental results in Section 6.
http://w3id.org/mlsea/pwc/scientificWork/%24L%5E%2ALM%24%3A%20Learning%20Automata%20from%20Examples%20using%20Natural%20Language%20Oracles                                                                                  $L^*LM$: Learning Automata from Examples using Natural Language Oracles                                                                                  Expert demonstrations have proven an easy way to indirectly specify complex tasks. Recent algorithms even support extracting unambiguous formal specifications, e.g. deterministic finite automata (DFA), from demonstrations. Unfortunately, these techniques are generally not sample efficient. In this work, we introduce $L^*LM$, an algorithm for learning DFAs from both demonstrations and natural language. Due to the expressivity of natural language, we observe a significant improvement in the data efficiency of learning DFAs from expert demonstrations. Technically, $L^*LM$ leverages large language models to answer membership queries about the underlying task. This is then combined with recent techniques for transforming learning from demonstrations into a sequence of labeled example learning problems. In our experiments, we observe the two modalities complement each other, yielding a powerful few-shot learner.
http://w3id.org/mlsea/pwc/scientificWork/%27According%20to%20...%27%3A%20Prompting%20Language%20Models%20Improves%20Quoting%20from%20Pre-Training%20Data                                                                                  'According to ...': Prompting Language Models Improves Quoting from Pre-Training Data                                                                                  Large Language Models (LLMs) may hallucinate and generate fake information, despite pre-training on factual data. Inspired by the journalistic device of 'according to sources', we propose according-to prompting: directing LLMs to ground responses against previously observed text. To quantify this grounding, we propose a novel evaluation metric (QUIP-Score) that measures the extent to which model-produced answers are directly found in underlying text corpora. We illustrate with experiments on three corpora (Wikipedia, PubMed, and the U.S. legal tax code) that these prompts improve grounding under our metrics, with the additional benefit of often improving end-task performance. Furthermore, prompts that ask the model to decrease grounding (or to ground to other corpora) indeed decrease QUIP-Score, indicating the ability of LLMs to increase or decrease grounded generations on request.
http://w3id.org/mlsea/pwc/scientificWork/%27Bayesian%20anchoring%27%20and%20the%20fourfold%20pattern%20of%20risk%20attitudes                                                                                  'Bayesian anchoring' and the fourfold pattern of risk attitudes                                                                                  Experiments on decision making under uncertainty are known to display a classical pattern of risk aversion and risk seeking referred to as 'fourfold pattern' (or 'reflection effect') , but recent experiments varying the speed and order of mental processing have brought to light a more nuanced phenomenology. We model experiments though a Bayesian formalization of the anchor-and-adjust heuristic observed in empirical studies on cognitive bias. Using only elementary assumptions on constrained information processing, we are able to infer three separate effects found in recent observations: (1) the reported enhancement of the fourfold pattern for quicker decision processes; (2) the observed decrease of fluctuations for slower decision-making trials; (3) the reported dependence of the outcome on the order in which options are processed. The application of Bayesian modeling offers a solution to recent empirical riddles by bridging two heretofore separate domains of experimental inquiry on bounded rationality.
http://w3id.org/mlsea/pwc/scientificWork/%27Don%27t%20forget%20to%20put%20the%20milk%20back%21%27%20Dataset%20for%20Enabling%20Embodied%20Agents%20to%20Detect%20Anomalous%20Situations                                                                                  'Don't forget to put the milk back!' Dataset for Enabling Embodied Agents to Detect Anomalous Situations                                                                                  Home robots intend to make their users lives easier. Our work assists in this goal by enabling robots to inform their users of dangerous or unsanitary anomalies in their home. Some examples of these anomalies include the user leaving their milk out, forgetting to turn off the stove, or leaving poison accessible to children. To move towards enabling home robots with these abilities, we have created a new dataset, which we call SafetyDetect. The SafetyDetect dataset consists of 1000 anomalous home scenes, each of which contains unsafe or unsanitary situations for an agent to detect. Our approach utilizes large language models (LLMs) alongside both a graph representation of the scene and the relationships between the objects in the scene. Our key insight is that this connected scene graph and the object relationships it encodes enables the LLM to better reason about the scene -- especially as it relates to detecting dangerous or unsanitary situations. Our most promising approach utilizes GPT-4 and pursues a categorization technique where object relations from the scene graph are classified as normal, dangerous, unsanitary, or dangerous for children. This method is able to correctly identify over 90% of anomalous scenarios in the SafetyDetect Dataset. Additionally, we conduct real world experiments on a ClearPath TurtleBot where we generate a scene graph from visuals of the real world scene, and run our approach with no modification. This setup resulted in little performance loss. The SafetyDetect Dataset and code will be released to the public upon this papers publication.
http://w3id.org/mlsea/pwc/scientificWork/%27In%20Dialogues%20We%20Learn%27%3A%20Towards%20Personalized%20Dialogue%20Without%20Pre-defined%20Profiles%20through%20In-Dialogue%20Learning                                                                                  'In Dialogues We Learn': Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning                                                                                  Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.
http://w3id.org/mlsea/pwc/scientificWork/1st%20Place%20Solution%20for%20ICCV%202023%20OmniObject3D%20Challenge%3A%20Sparse-View%20Reconstruction                                                                                  1st Place Solution for ICCV 2023 OmniObject3D Challenge: Sparse-View Reconstruction                                                                                  In this report, we present the 1st place solution for ICCV 2023 OmniObject3D Challenge: Sparse-View Reconstruction. The challenge aims to evaluate approaches for novel view synthesis and surface reconstruction using only a few posed images of each object. We utilize Pixel-NeRF as the basic model, and apply depth supervision as well as coarse-to-fine positional encoding. The experiments demonstrate the effectiveness of our approach in improving sparse-view reconstruction quality. We ranked first in the final test with a PSNR of 25.44614.
http://w3id.org/mlsea/pwc/scientificWork/2AFC%20Prompting%20of%20Large%20Multimodal%20Models%20for%20Image%20Quality%20Assessment                                                                                  2AFC Prompting of Large Multimodal Models for Image Quality Assessment                                                                                  While abundant research has been conducted on improving high-level visual understanding and reasoning capabilities of large multimodal models~(LMMs), their visual quality assessment~(IQA) ability has been relatively under-explored. Here we take initial steps towards this goal by employing the two-alternative forced choice~(2AFC) prompting, as 2AFC is widely regarded as the most reliable way of collecting human opinions of visual quality. Subsequently, the global quality score of each image estimated by a particular LMM can be efficiently aggregated using the maximum a posterior estimation. Meanwhile, we introduce three evaluation criteria: consistency, accuracy, and correlation, to provide comprehensive quantifications and deeper insights into the IQA capability of five LMMs. Extensive experiments show that existing LMMs exhibit remarkable IQA ability on coarse-grained quality comparison, but there is room for improvement on fine-grained quality discrimination. The proposed dataset sheds light on the future development of IQA models based on LMMs. The codes will be made publicly available at https://github.com/h4nwei/2AFC-LMMs.
http://w3id.org/mlsea/pwc/scientificWork/360%C2%B0REA%3A%20Towards%20A%20Reusable%20Experience%20Accumulation%20with%20360%C2%B0%20Assessment%20for%20Multi-Agent%20System                                                                                  360Â°REA: Towards A Reusable Experience Accumulation with 360Â° Assessment for Multi-Agent System                                                                                  Large language model agents have demonstrated remarkable advancements across various complex tasks. Recent works focus on optimizing the agent team or employing self-reflection to iteratively solve complex tasks. Since these agents are all based on the same LLM, only conducting self-evaluation or removing underperforming agents does not substantively enhance the capability of the agents. We argue that a comprehensive evaluation and accumulating experience from evaluation feedback is an effective approach to improving system performance. In this paper, we propose Reusable Experience Accumulation with 360{ deg} Assessment (360{ deg}REA), a hierarchical multi-agent framework inspired by corporate organizational practices. The framework employs a novel 360{ deg} performance assessment method for multi-perspective performance evaluation with fine-grained assessment. To enhance the capability of agents in addressing complex tasks, we introduce dual-level experience pool for agents to accumulate experience through fine-grained assessment. Extensive experiments on complex task datasets demonstrate the effectiveness of 360{ deg}REA.
http://w3id.org/mlsea/pwc/scientificWork/360DVD%3A%20Controllable%20Panorama%20Video%20Generation%20with%20360-Degree%20Video%20Diffusion%20Model                                                                                  360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model                                                                                  360-degree panoramic videos recently attract more interest in both studies and applications, courtesy of the heightened immersive experiences they engender. Due to the expensive cost of capturing 360-degree panoramic videos, generating desirable panoramic videos by given prompts is urgently required. Recently, the emerging text-to-video (T2V) diffusion methods demonstrate notable effectiveness in standard video generation. However, due to the significant gap in content and motion patterns between panoramic and standard videos, these methods encounter challenges in yielding satisfactory 360-degree panoramic videos. In this paper, we propose a controllable panorama video generation pipeline named 360-Degree Video Diffusion model (360DVD) for generating panoramic videos based on the given prompts and motion conditions. Concretely, we introduce a lightweight module dubbed 360-Adapter and assisted 360 Enhancement Techniques to transform pre-trained T2V models for 360-degree video generation. We further propose a new panorama dataset named WEB360 consisting of 360-degree video-text pairs for training 360DVD, addressing the absence of captioned panoramic video datasets. Extensive experiments demonstrate the superiority and effectiveness of 360DVD for panorama video generation. The code and dataset will be released soon.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Cooperative%20Localization%20in%20UAV%20Systems%3A%20CRLB%20Analysis%20and%20Security%20Solutions                                                                                  3D Cooperative Localization in UAV Systems: CRLB Analysis and Security Solutions                                                                                  This paper presents a robust and secure framework for achieving accurate and reliable cooperative localization in multiple unmanned aerial vehicle (UAV) systems. The Cramer-Rao low bound (CRLB) for the three-dimensional (3D) cooperative localization network is derived, with particular attention given to the non-uniform spatial distribution of anchor nodes. Challenges of mobility and security threats are addressed, corresponding solutions are brought forth and numerically assessed . The proposed solution incorporates two key components: the Mobility Adaptive Gradient Descent (MAGD) and Time-evolving Anomaly Detection (TAD). The MAGD adapts the gradient descent algorithm to handle the configuration changes in cooperative localization systems, ensuring accurate localization in dynamic scenarios. The TAD cooperates with reputation propagation (RP) scheme to detect and mitigate potential attacks by identifying malicious data, enhancing the security and resilience of the cooperative localization.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Directed%20Formation%20Control%20with%20Global%20Shape%20Convergence%20using%20Bispherical%20Coordinates                                                                                  3D Directed Formation Control with Global Shape Convergence using Bispherical Coordinates                                                                                  In this paper, we present a novel 3D formation control scheme for directed graphs in a leader-follower configuration, achieving (almost) global convergence to the desired shape. Specifically, we introduce three controlled variables representing bispherical coordinates that uniquely describe the formation in 3D. Acyclic triangulated directed graphs (a class of minimally acyclic persistent graphs) are used to model the inter-agent sensing topology, while the agents' dynamics are governed by single-integrator model. Our analysis demonstrates that the proposed decentralized formation controller ensures (almost) global asymptotic stability while avoiding potential shape ambiguities in the final formation. Furthermore, the control laws are implementable in arbitrarily oriented local coordinate frames of follower agents using only low-cost onboard vision sensors, making it suitable for practical applications. Finally, we validate our formation control approach by a simulation study.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Face%20Reconstruction%20Using%20A%20Spectral-Based%20Graph%20Convolution%20Encoder                                                                                  3D Face Reconstruction Using A Spectral-Based Graph Convolution Encoder                                                                                  Monocular 3D face reconstruction plays a crucial role in avatar generation, with significant demand in web-related applications such as generating virtual financial advisors in FinTech. Current reconstruction methods predominantly rely on deep learning techniques and employ 2D self-supervision as a means to guide model learning. However, these methods encounter challenges in capturing the comprehensive 3D structural information of the face due to the utilization of 2D images for model training purposes. To overcome this limitation and enhance the reconstruction of 3D structural features, we propose an innovative approach that integrates existing 2D features with 3D features to guide the model learning process. Specifically, we introduce the 3D-ID Loss, which leverages the high-dimensional structure features extracted from a Spectral-Based Graph Convolution Encoder applied to the facial mesh. This approach surpasses the sole reliance on the 3D information provided by the facial mesh vertices coordinates. Our model is trained using 2D-3D data pairs from a combination of datasets and achieves state-of-the-art performance on the NoW benchmark.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Landmark%20Detection%20on%20Human%20Point%20Clouds%3A%20A%20Benchmark%20and%20A%20Dual%20Cascade%20Point%20Transformer%20Framework                                                                                  3D Landmark Detection on Human Point Clouds: A Benchmark and A Dual Cascade Point Transformer Framework                                                                                  3D landmark detection plays a pivotal role in various applications such as 3D registration, pose estimation, and virtual try-on. While considerable success has been achieved in 2D human landmark detection or pose estimation, there is a notable scarcity of reported works on landmark detection in unordered 3D point clouds. This paper introduces a novel challenge, namely 3D landmark detection on human point clouds, presenting two primary contributions. Firstly, we establish a comprehensive human point cloud dataset, named HPoint103, designed to support the 3D landmark detection community. This dataset comprises 103 human point clouds created with commercial software and actors, each manually annotated with 11 stable landmarks. Secondly, we propose a Dual Cascade Point Transformer (D-CPT) model for precise point-based landmark detection. D-CPT gradually refines the landmarks through cascade Transformer decoder layers across the entire point cloud stream, simultaneously enhancing landmark coordinates with a RefineNet over local regions. Comparative evaluations with popular point-based methods on HPoint103 and the public dataset DHP19 demonstrate the dramatic outperformance of our D-CPT. Additionally, the integration of our RefineNet into existing methods consistently improves performance.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Semantic%20MapNet%3A%20Building%20Maps%20for%20Multi-Object%20Re-Identification%20in%203D                                                                                  3D Semantic MapNet: Building Maps for Multi-Object Re-Identification in 3D                                                                                  We study the task of 3D multi-object re-identification from embodied tours. Specifically, an agent is given two tours of an environment (e.g. an apartment) under two different layouts (e.g. arrangements of furniture). Its task is to detect and re-identify objects in 3D - e.g. a 'sofa' moved from location A to B, a new 'chair' in the second layout at location C, or a 'lamp' from location D in the first layout missing in the second. To support this task, we create an automated infrastructure to generate paired egocentric tours of initial/modified layouts in the Habitat simulator using Matterport3D scenes, YCB and Google-scanned objects. We present 3D Semantic MapNet (3D-SMNet) - a two-stage re-identification model consisting of (1) a 3D object detector that operates on RGB-D videos with known pose, and (2) a differentiable object matching module that solves correspondence estimation between two sets of 3D bounding boxes. Overall, 3D-SMNet builds object-based maps of each layout and then uses a differentiable matcher to re-identify objects across the tours. After training 3D-SMNet on our generated episodes, we demonstrate zero-shot transfer to real-world rearrangement scenarios by instantiating our task in Replica, Active Vision, and RIO environments depicting rearrangements. On all datasets, we find 3D-SMNet outperforms competitive baselines. Further, we show jointly training on real and generated episodes can lead to significant improvements over training on real data alone.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Semantic%20Segmentation-Driven%20Representations%20for%203D%20Object%20Detection                                                                                  3D Semantic Segmentation-Driven Representations for 3D Object Detection                                                                                  In autonomous driving, 3D detection provides more precise information to downstream tasks, including path planning and motion estimation, compared to 2D detection. Therefore, the need for 3D detection research has emerged. However, although single and multi-view images and depth maps obtained from the camera were used, detection accuracy was relatively low compared to other modality-based detectors due to the lack of geometric information. The proposed multi-modal 3D object detection combines semantic features obtained from images and geometric features obtained from point clouds, but there are difficulties in defining unified representation to fuse data existing in different domains and synchronization between them. In this paper, we propose SeSame : point-wise semantic feature as a new presentation to ensure sufficient semantic information of the existing LiDAR-only based 3D detection. Experiments show that our approach outperforms previous state-of-the-art at different levels of difficulty in car and performance improvement on the KITTI object detection benchmark. Our code is available at https://github.com/HAMA-DL-dev/SeSame
http://w3id.org/mlsea/pwc/scientificWork/3D%20Small%20Object%20Detection%20with%20Dynamic%20Spatial%20Pruning                                                                                  3D Small Object Detection with Dynamic Spatial Pruning                                                                                  In this paper, we propose an efficient feature pruning strategy for 3D small object detection. Conventional 3D object detection methods struggle on small objects due to the weak geometric information from a small number of points. Although increasing the spatial resolution of feature representations can improve the detection performance on small objects, the additional computational overhead is unaffordable. With in-depth study, we observe the growth of computation mainly comes from the upsampling operation in the decoder of 3D detector. Motivated by this, we present a multi-level 3D detector named DSPDet3D which benefits from high spatial resolution to achieves high accuracy on small object detection, while reducing redundant computation by only focusing on small object areas. Specifically, we theoretically derive a dynamic spatial pruning (DSP) strategy to prune the redundant spatial representation of 3D scene in a cascade manner according to the distribution of objects. Then we design DSP module following this strategy and construct DSPDet3D with this efficient module. On ScanNet and TO-SCENE dataset, our method achieves leading performance on small object detection. Moreover, DSPDet3D trained with only ScanNet rooms can generalize well to scenes in larger scale. It takes less than 2s to directly process a whole building consisting of more than 4500k points while detecting out almost all objects, ranging from cups to beds, on a single RTX 3090 GPU. Project page: https://xuxw98.github.io/DSPDet3D/.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Spectrum%20Mapping%20and%20Reconstruction%20under%20Multi-Radiation%20Source%20Scenarios                                                                                  3D Spectrum Mapping and Reconstruction under Multi-Radiation Source Scenarios                                                                                  Spectrum map construction, which is crucial in cognitive radio (CR) system, visualizes the invisible space of the electromagnetic spectrum for spectrum-resource management and allocation. Traditional reconstruction methods are generally for two-dimensional (2D) spectrum map and driven by abundant sampling data. In this paper, we propose a data-model-knowledge-driven reconstruction scheme to construct the three-dimensional (3D) spectrum map under multi-radiation source scenarios. We firstly design a maximum and minimum path loss difference (MMPLD) clustering algorithm to detect the number of radiation sources in a 3D space. Then, we develop a joint location-power estimation method based on the heuristic population evolutionary optimization algorithm. Considering the variation of electromagnetic environment, we self-learn the path loss (PL) model based on the sampling data. Finally, the 3D spectrum is reconstructed according to the self-learned PL model and the extracted knowledge of radiation sources. Simulations show that the proposed 3D spectrum map reconstruction scheme not only has splendid adaptability to the environment, but also achieves high spectrum construction accuracy even when the sampling rate is very low.
http://w3id.org/mlsea/pwc/scientificWork/3D%20high-resolution%20imaging%20algorithm%20using%201D%20MIMO%20array%20for%20autonomous%20driving%20application                                                                                  3D high-resolution imaging algorithm using 1D MIMO array for autonomous driving application                                                                                  The problem of 3D high-resolution imaging in automotive multiple-input multiple-output (MIMO) side-looking radar using a 1D array is considered. The concept of motion-enhanced snapshots is introduced for generating larger apertures in the azimuth dimension. For the first time, 3D imaging capabilities can be achieved with high angular resolution using a 1D MIMO antenna array, which can alleviate the requirement for large radar systems in autonomous vehicles. The robustness to variations in the vehicle's movement trajectory is also considered and addressed with relevant compensations in the steering vector. The available degrees of freedom as well as the Signal to Noise Ratio (SNR) are shown to increase with the proposed method compared to conventional imaging approaches. The performance of the algorithm has been studied in simulations, and validated with experimental data collected in a realistic driving scenario.
http://w3id.org/mlsea/pwc/scientificWork/3D%20scene%20generation%20from%20scene%20graphs%20and%20self-attention                                                                                  3D scene generation from scene graphs and self-attention                                                                                  Synthesizing realistic and diverse indoor 3D scene layouts in a controllable fashion opens up applications in simulated navigation and virtual reality. As concise and robust representations of a scene, scene graphs have proven to be well-suited as the semantic control on the generated layout. We present a variant of the conditional variational autoencoder (cVAE) model to synthesize 3D scenes from scene graphs and floor plans. We exploit the properties of self-attention layers to capture high-level relationships between objects in a scene, and use these as the building blocks of our model. Our model, leverages graph transformers to estimate the size, dimension and orientation of the objects in a room while satisfying relationships in the given scene graph. Our experiments shows self-attention layers leads to sparser (7.9x compared to Graphto3D) and more diverse scenes (16%).
http://w3id.org/mlsea/pwc/scientificWork/3D-Speaker-Toolkit%3A%20An%20Open%20Source%20Toolkit%20for%20Multi-modal%20Speaker%20Verification%20and%20Diarization                                                                                  3D-Speaker-Toolkit: An Open Source Toolkit for Multi-modal Speaker Verification and Diarization                                                                                  This paper introduces 3D-Speaker-Toolkit, an open source toolkit for multi-modal speaker verification and diarization. It is designed for the needs of academic researchers and industrial practitioners. The 3D-Speaker-Toolkit adeptly leverages the combined strengths of acoustic, semantic, and visual data, seamlessly fusing these modalities to offer robust speaker recognition capabilities. The acoustic module extracts speaker embeddings from acoustic features, employing both fully-supervised and self-supervised learning approaches. The semantic module leverages advanced language models to apprehend the substance and context of spoken language, thereby augmenting the system's proficiency in distinguishing speakers through linguistic patterns. Finally, the visual module applies image processing technologies to scrutinize facial features, which bolsters the precision of speaker diarization in multi-speaker environments. Collectively, these modules empower the 3D-Speaker-Toolkit to attain elevated levels of accuracy and dependability in executing speaker-related tasks, establishing a new benchmark in multi-modal speaker analysis. The 3D-Speaker project also includes a handful of open-sourced state-of-the-art models and a large dataset containing over 10,000 speakers. The toolkit is publicly available at https://github.com/alibaba-damo-academy/3D-Speaker.
http://w3id.org/mlsea/pwc/scientificWork/3D-TransUNet%20for%20Brain%20Metastases%20Segmentation%20in%20the%20BraTS2023%20Challenge                                                                                  3D-TransUNet for Brain Metastases Segmentation in the BraTS2023 Challenge                                                                                  Segmenting brain tumors is complex due to their diverse appearances and scales. Brain metastases, the most common type of brain tumor, are a frequent complication of cancer. Therefore, an effective segmentation model for brain metastases must adeptly capture local intricacies to delineate small tumor regions while also integrating global context to understand broader scan features. The TransUNet model, which combines Transformer self-attention with U-Net's localized information, emerges as a promising solution for this task. In this report, we address brain metastases segmentation by training the 3D-TransUNet model on the Brain Tumor Segmentation (BraTS-METS) 2023 challenge dataset. Specifically, we explored two architectural configurations: the Encoder-only 3D-TransUNet, employing Transformers solely in the encoder, and the Decoder-only 3D-TransUNet, utilizing Transformers exclusively in the decoder. For Encoder-only 3D-TransUNet, we note that Masked-Autoencoder pre-training is required for a better initialization of the Transformer Encoder and thus accelerates the training process. We identify that the Decoder-only 3D-TransUNet model should offer enhanced efficacy in the segmentation of brain metastases, as indicated by our 5-fold cross-validation on the training set. However, our use of the Encoder-only 3D-TransUNet model already yield notable results, with an average lesion-wise Dice score of 59.8 % on the test set, securing second place in the BraTS-METS 2023 challenge.
http://w3id.org/mlsea/pwc/scientificWork/3DFIRES%3A%20Few%20Image%203D%20REconstruction%20for%20Scenes%20with%20Hidden%20Surface                                                                                  3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surface                                                                                  This paper introduces 3DFIRES, a novel system for scene-level 3D reconstruction from posed images. Designed to work with as few as one view, 3DFIRES reconstructs the complete geometry of unseen scenes, including hidden surfaces. With multiple view inputs, our method produces full reconstruction within all camera frustums. A key feature of our approach is the fusion of multi-view information at the feature level, enabling the production of coherent and comprehensive 3D reconstruction. We train our system on non-watertight scans from large-scale real scene dataset. We show it matches the efficacy of single-view reconstruction methods with only one input and surpasses existing techniques in both quantitative and qualitative measures for sparse-view 3D reconstruction.
http://w3id.org/mlsea/pwc/scientificWork/7T%20MRI%20Synthesization%20from%203T%20Acquisitions                                                                                  7T MRI Synthesization from 3T Acquisitions                                                                                  Supervised deep learning techniques can be used to generate synthetic 7T MRIs from 3T MRI inputs. This image enhancement process leverages the advantages of ultra-high-field MRI to improve the signal-to-noise and contrast-to-noise ratios of 3T acquisitions. In this paper, we introduce multiple novel 7T synthesization algorithms based on custom-designed variants of the V-Net convolutional neural network. We demonstrate that the V-Net based model has superior performance in enhancing both single-site and multi-site MRI datasets compared to the existing benchmark model. When trained on 3T-7T MRI pairs from 8 subjects with mild Traumatic Brain Injury (TBI), our model achieves state-of-the-art 7T synthesization performance. Compared to previous works, synthetic 7T images generated from our pipeline also display superior enhancement of pathological tissue. Additionally, we implement and test a data augmentation scheme for training models that are robust to variations in the input distribution. This allows synthetic 7T models to accommodate intra-scanner and inter-scanner variability in multisite datasets. On a harmonized dataset consisting of 18 3T-7T MRI pairs from two institutions, including both healthy subjects and those with mild TBI, our model maintains its performance and can generalize to 3T MRI inputs with lower resolution. Our findings demonstrate the promise of V-Net based models for MRI enhancement and offer a preliminary probe into improving the generalizability of synthetic 7T models with data augmentation.
http://w3id.org/mlsea/pwc/scientificWork/A%20Backpack%20Full%20of%20Skills%3A%20Egocentric%20Video%20Understanding%20with%20Diverse%20Task%20Perspectives                                                                                  A Backpack Full of Skills: Egocentric Video Understanding with Diverse Task Perspectives                                                                                  Human comprehension of a video stream is naturally broad: in a few instants, we are able to understand what is happening, the relevance and relationship of objects, and forecast what will follow in the near future, everything all at once. We believe that - to effectively transfer such an holistic perception to intelligent machines - an important role is played by learning to correlate concepts and to abstract knowledge coming from different tasks, to synergistically exploit them when learning novel skills. To accomplish this, we seek for a unified approach to video understanding which combines shared temporal modelling of human actions with minimal overhead, to support multiple downstream tasks and enable cooperation when learning novel skills. We then propose EgoPack, a solution that creates a collection of task perspectives that can be carried across downstream tasks and used as a potential source of additional insights, as a backpack of skills that a robot can carry around and use when needed. We demonstrate the effectiveness and efficiency of our approach on four Ego4D benchmarks, outperforming current state-of-the-art methods.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bayesian%20Committee%20Machine%20Potential%20for%20Oxygen-containing%20Organic%20Compounds                                                                                  A Bayesian Committee Machine Potential for Oxygen-containing Organic Compounds                                                                                  Understanding the pivotal role of oxygen-containing organic compounds in serving as an energy source for living organisms and contributing to protein formation is crucial in the field of biochemistry. This study addresses the challenge of comprehending protein-protein interactions (PPI) and developing predicitive models for proteins and organic compounds, with a specific focus on quantifying their binding affinity. Here, we introduce the active Bayesian Committee Machine (BCM) potential, specifically designed to predict oxygen-containing organic compounds within eight groups of CHO. The BCM potential adopts a committee-based approach to tackle scalability issues associated with kernel regressors, particularly when dealing with large datasets. Its adaptable structure allows for efficient and cost-effective expansion, maintaing both transferability and scalability. Through systematic benchmarking, we position the sparse BCM potential as a promising contender in the pursuit of a universal machine learning potential.
http://w3id.org/mlsea/pwc/scientificWork/A%20Benchmark%20of%20Domain-Adapted%20Large%20Language%20Models%20for%20Generating%20Brief%20Hospital%20Course%20Summaries                                                                                  A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries                                                                                  Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performance of these LLMs across varying context-length inputs using conventional natural language similarity metrics. We further perform a qualitative study where five diverse clinicians blindly compare clinician-written BHCs and two LLM-generated BHCs for 30 samples across metrics of comprehensiveness, conciseness, factual correctness, and fluency. Overall, we present a new benchmark and pre-processed dataset for using LLMs in BHC synthesis from clinical notes. We observe high-quality summarization performance for both in-context proprietary and fine-tuned open-source LLMs using both quantitative metrics and a qualitative clinical reader study. We propose our work as a benchmark to motivate future works to adapt and assess the performance of LLMs in BHC synthesis.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bias-Variance%20Decomposition%20for%20Ensembles%20over%20Multiple%20Synthetic%20Datasets                                                                                  A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets                                                                                  Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets. Our theory predicts multiple synthetic datasets to be especially beneficial for high-variance downstream predictors, and yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice by evaluating the performance of an ensemble over many synthetic datasets for several real datasets and downstream predictors. The results follow our theory, showing that our insights are also practically relevant.
http://w3id.org/mlsea/pwc/scientificWork/A%20Block-Coordinate%20Descent%20EMO%20Algorithm%3A%20Theoretical%20and%20Empirical%20Analysis                                                                                  A Block-Coordinate Descent EMO Algorithm: Theoretical and Empirical Analysis                                                                                  We consider whether conditions exist under which block-coordinate descent is asymptotically efficient in evolutionary multi-objective optimization, addressing an open problem. Block-coordinate descent, where an optimization problem is decomposed into $k$ blocks of decision variables and each of the blocks is optimized (with the others fixed) in a sequence, is a technique used in some large-scale optimization problems such as airline scheduling, however its use in multi-objective optimization is less studied. We propose a block-coordinate version of GSEMO and compare its running time to the standard GSEMO algorithm. Theoretical and empirical results on a bi-objective test function, a variant of LOTZ, serve to demonstrate the existence of cases where block-coordinate descent is faster. The result may yield wider insights into this class of algorithms.
http://w3id.org/mlsea/pwc/scientificWork/A%20Brain-inspired%20Computational%20Model%20for%20Human-like%20Concept%20Learning                                                                                  A Brain-inspired Computational Model for Human-like Concept Learning                                                                                  Concept learning is a fundamental aspect of human cognition and plays a critical role in mental processes such as categorization, reasoning, memory, and decision-making. Researchers across various disciplines have shown consistent interest in the process of concept acquisition in individuals. To elucidate the mechanisms involved in human concept learning, this study examines the findings from computational neuroscience and cognitive psychology. These findings indicate that the brain's representation of concepts relies on two essential components: multisensory representation and text-derived representation. These two types of representations are coordinated by a semantic control system, ultimately leading to the acquisition of concepts. Drawing inspiration from this mechanism, the study develops a human-like computational model for concept learning based on spiking neural networks. By effectively addressing the challenges posed by diverse sources and imbalanced dimensionality of the two forms of concept representations, the study successfully attains human-like concept representations. Tests involving similar concepts demonstrate that our model, which mimics the way humans learn concepts, yields representations that closely align with human cognition.
http://w3id.org/mlsea/pwc/scientificWork/A%20Call%20for%20Clarity%20in%20Beam%20Search%3A%20How%20It%20Works%20and%20When%20It%20Stops                                                                                  A Call for Clarity in Beam Search: How It Works and When It Stops                                                                                  Text generation with beam search has proven successful in a wide range of applications. We point out that, though largely overlooked in the literature, the commonly-used implementation of beam decoding (e.g., Hugging Face Transformers and fairseq) uses a first come, first served heuristic: it keeps a set of already completed sequences over time steps and stops when the size of this set reaches the beam size. Based on this finding, we introduce a patience factor, a simple modification to this beam decoding implementation, that generalizes the stopping criterion and provides flexibility to the depth of search. Empirical results demonstrate that adjusting this patience factor improves decoding performance of strong pretrained models on news text summarization and machine translation over diverse language pairs, with a negligible inference slowdown. Our approach only modifies one line of code and can be thus readily incorporated in any implementation. Further, we find that different versions of beam decoding result in large performance differences in summarization, demonstrating the need for clarity in specifying the beam search implementation in research work. Our code will be available upon publication.
http://w3id.org/mlsea/pwc/scientificWork/A%20Chain-of-Thought%20Prompting%20Approach%20with%20LLMs%20for%20Evaluating%20Students%27%20Formative%20Assessment%20Responses%20in%20Science                                                                                  A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science                                                                                  This paper explores the use of large language models (LLMs) to score and explain short-answer assessments in K-12 science. While existing methods can score more structured math and computer science assessments, they often do not provide explanations for the scores. Our study focuses on employing GPT-4 for automated assessment in middle school Earth Science, combining few-shot and active learning with chain-of-thought reasoning. Using a human-in-the-loop approach, we successfully score and provide meaningful explanations for formative assessment responses. A systematic analysis of our method's pros and cons sheds light on the potential for human-in-the-loop techniques to enhance automated grading for open-ended science assessments.
http://w3id.org/mlsea/pwc/scientificWork/A%20Channel-ensemble%20Approach%3A%20Unbiased%20and%20Low-variance%20Pseudo-labels%20is%20Critical%20for%20Semi-supervised%20Classification                                                                                  A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is Critical for Semi-supervised Classification                                                                                  Semi-supervised learning (SSL) is a practical challenge in computer vision. Pseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of The Art (SOTA) performances in SSL. These approaches employ a threshold-to-pseudo-label (T2L) process to generate PLs by truncating the confidence scores of unlabeled data predicted by the self-training method. However, self-trained models typically yield biased and high-variance predictions, especially in the scenarios when a little labeled data are supplied. To address this issue, we propose a lightweight channel-based ensemble method to effectively consolidate multiple inferior PLs into the theoretically guaranteed unbiased and low-variance one. Importantly, our approach can be readily extended to any SSL framework, such as FixMatch or FreeMatch. Experimental results demonstrate that our method significantly outperforms state-of-the-art techniques on CIFAR10/100 in terms of effectiveness and efficiency.
http://w3id.org/mlsea/pwc/scientificWork/A%20Closer%20Look%20at%20Wav2Vec2%20Embeddings%20for%20On-Device%20Single-Channel%20Speech%20Enhancement                                                                                  A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement                                                                                  Self-supervised learned models have been found to be very effective for certain speech tasks such as automatic speech recognition, speaker identification, keyword spotting and others. While the features are undeniably useful in speech recognition and associated tasks, their utility in speech enhancement systems is yet to be firmly established, and perhaps not properly understood. In this paper, we investigate the uses of SSL representations for single-channel speech enhancement in challenging conditions and find that they add very little value for the enhancement task. Our constraints are designed around on-device real-time speech enhancement -- model is causal, the compute footprint is small. Additionally, we focus on low SNR conditions where such models struggle to provide good enhancement. In order to systematically examine how SSL representations impact performance of such enhancement models, we propose a variety of techniques to utilize these embeddings which include different forms of knowledge-distillation and pre-training.
http://w3id.org/mlsea/pwc/scientificWork/A%20Cluster-Based%20Statistical%20Channel%20Model%20for%20Integrated%20Sensing%20and%20Communication%20Channels                                                                                  A Cluster-Based Statistical Channel Model for Integrated Sensing and Communication Channels                                                                                  The emerging 6G network envisions integrated sensing and communication (ISAC) as a promising solution to meet growing demand for native perception ability. To optimize and evaluate ISAC systems and techniques, it is crucial to have an accurate and realistic wireless channel model. However, some important features of ISAC channels have not been well characterized, for example, most existing ISAC channel models consider communication channels and sensing channels independently, whereas ignoring correlation under the consistent environment. Moreover, sensing channels have not been well modeled in the existing standard-level channel models. Therefore, in order to better model ISAC channel, a cluster-based statistical channel model is proposed in this paper, which is based on measurements conducted at 28 GHz. In the proposed model, a new framework based on 3GPP standard is proposed, which includes communication clusters and sensing clusters. Clustering and tracking algorithms are used to extract and analyze ISAC channel characteristics. Furthermore, some special sensing cluster structures such as shared sensing cluster, newborn sensing cluster, etc., are defined to model correlation and difference between communication and sensing channels. Finally, accuracy of the proposed model is validated based on measurements and simulations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Compact%20LSTM-SVM%20Fusion%20Model%20for%20Long-Duration%20Cardiovascular%20Diseases%20Detection                                                                                  A Compact LSTM-SVM Fusion Model for Long-Duration Cardiovascular Diseases Detection                                                                                  Globally, cardiovascular diseases (CVDs) are the leading cause of mortality, accounting for an estimated 17.9 million deaths annually. One critical clinical objective is the early detection of CVDs using electrocardiogram (ECG) data, an area that has received significant attention from the research community. Recent advancements based on machine learning and deep learning have achieved great progress in this domain. However, existing methodologies exhibit inherent limitations, including inappropriate model evaluations and instances of data leakage. In this study, we present a streamlined workflow paradigm for preprocessing ECG signals into consistent 10-second durations, eliminating the need for manual feature extraction/beat detection. We also propose a hybrid model of Long Short-Term Memory (LSTM) with Support Vector Machine (SVM) for fraud detection. This architecture consists of two LSTM layers and an SVM classifier, which achieves a SOTA results with an Average precision score of 0.9402 on the MIT-BIH arrhythmia dataset and 0.9563 on the MIT-BIH atrial fibrillation dataset. Based on the results, we believe our method can significantly benefit the early detection and management of CVDs.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comparative%20Analysis%20of%20Noise%20Reduction%20Methods%20in%20Sentiment%20Analysis%20on%20Noisy%20Bangla%20Texts                                                                                  A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bangla Texts                                                                                  While Bangla is considered a language with limited resources, sentiment analysis has been a subject of extensive research in the literature. Nevertheless, there is a scarcity of exploration into sentiment analysis specifically in the realm of noisy Bangla texts. In this paper, we introduce a dataset (NC-SentNoB) that we annotated manually to identify ten different types of noise found in a pre-existing sentiment analysis dataset comprising of around 15K noisy Bangla texts. At first, given an input noisy text, we identify the noise type, addressing this as a multi-label classification task. Then, we introduce baseline noise reduction methods to alleviate noise prior to conducting sentiment analysis. Finally, we assess the performance of fine-tuned sentiment analysis models with both noisy and noise-reduced texts to make comparisons. The experimental findings indicate that the noise reduction methods utilized are not satisfactory, highlighting the need for more suitable noise reduction methods in future research endeavors. We have made the implementation and dataset presented in this paper publicly available at https://github.com/ktoufiquee/A-Comparative-Analysis-of-Noise-Reduction-Methods-in-Sentiment-Analysis-on-Noisy-Bangla-Texts
http://w3id.org/mlsea/pwc/scientificWork/A%20Comparative%20Analysis%20on%20Metaheuristic%20Algorithms%20Based%20Vision%20Transformer%20Model%20for%20Early%20Detection%20of%20Alzheimer%27s%20Disease                                                                                  A Comparative Analysis on Metaheuristic Algorithms Based Vision Transformer Model for Early Detection of Alzheimer's Disease                                                                                  A number of life threatening neuro-degenerative disorders had degraded the quality of life for the older generation in particular. Dementia is one such symptom which may lead to a severe condition called Alzheimer's disease if not detected at an early stage. It has been reported that the progression of such disease from a normal stage is due to the change in several parameters inside the human brain. In this paper, an innovative metaheuristic algorithms based ViT model has been proposed for the identification of dementia at different stage. A sizeable number of test data have been utilized for the validation of the proposed scheme. It has also been demonstrated that our model exhibits superior performance in terms of accuracy, precision, recall as well as F1-score.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comparative%20Study%20of%20Sensitivity%20Computations%20in%20ESDIRK-Based%20Optimal%20Control%20Problems                                                                                  A Comparative Study of Sensitivity Computations in ESDIRK-Based Optimal Control Problems                                                                                  In this paper, we compare the impact of iterated and direct approaches to sensitivity computation in fixed-step explicit singly diagonally-implicit Runge-Kutta (ESDIRK) methods when applied to optimal control problems (OCPs). We use the principle of internal numerical differentiation (IND) strictly for the iterated approach, i.e., reusing the iteration matrix factorizations, the number of Newton-type iterations, and Newton iterates, to compute the sensitivities. The direct method computes the sensitivities without using the Newton schemes. We compare the impact of the iterated and direct sensitivity computations in OCPs for the quadruple tank system. We benchmark the iterated and direct approaches with a base case. This base case is an OCP that applies an ESDIRK method that refactorizes the iteration matrix in every Newton iteration and uses a direct approach for sensitivity computations. In these OCPs, we vary the number of integration steps between control intervals and we evaluate the performance based on the number of SQP and QPs iterations, KKT violations, and the total number of function evaluations, Jacobian updates, and iteration matrix factorizations. The results indicate that the iterated approach outperforms the direct approach but yields similar performance to the base case.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Approach%20to%20Diagnosing%20Temporomandibular%20Joint%20Diseases%3A%20AI-driven%20TMD%20Diagnostic%20System                                                                                  A Comprehensive Approach to Diagnosing Temporomandibular Joint Diseases: AI-driven TMD Diagnostic System                                                                                  AI-driven TMD diagnostic system uses AI segmentation method to diagnose Temporomandibular Joint Disorders (TMD). By using segmentation, three important parts: temporal bone, temporomandibular joint (TMJ) disc and the condyle can be identified. The location and the size of each segment are used as the basic information to determine if the patient has a high chance of having Temporomandibular Joint Disorders (TMD).
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Study%20of%20the%20Current%20State-of-the-Art%20in%20Nepali%20Automatic%20Speech%20Recognition%20Systems                                                                                  A Comprehensive Study of the Current State-of-the-Art in Nepali Automatic Speech Recognition Systems                                                                                  In this paper, we examine the research conducted in the field of Nepali Automatic Speech Recognition (ASR). The primary objective of this survey is to conduct a comprehensive review of the works on Nepali Automatic Speech Recognition Systems completed to date, explore the different datasets used, examine the technology utilized, and take account of the obstacles encountered in implementing the Nepali ASR system. In tandem with the global trends of ever-increasing research on speech recognition based research, the number of Nepalese ASR-related projects are also growing. Nevertheless, the investigation of language and acoustic models of the Nepali language has not received adequate attention compared to languages that possess ample resources. In this context, we provide a framework as well as directions for future investigations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Survey%20of%20Federated%20Transfer%20Learning%3A%20Challenges%2C%20Methods%20and%20Applications                                                                                  A Comprehensive Survey of Federated Transfer Learning: Challenges, Methods and Applications                                                                                  Federated learning (FL) is a novel distributed machine learning paradigm that enables participants to collaboratively train a centralized model with privacy preservation by eliminating the requirement of data sharing. In practice, FL often involves multiple participants and requires the third party to aggregate global information to guide the update of the target participant. Therefore, many FL methods do not work well due to the training and test data of each participant may not be sampled from the same feature space and the same underlying distribution. Meanwhile, the differences in their local devices (system heterogeneity), the continuous influx of online data (incremental data), and labeled data scarcity may further influence the performance of these methods. To solve this problem, federated transfer learning (FTL), which integrates transfer learning (TL) into FL, has attracted the attention of numerous researchers. However, since FL enables a continuous share of knowledge among participants with each communication round while not allowing local data to be accessed by other participants, FTL faces many unique challenges that are not present in TL. In this survey, we focus on categorizing and reviewing the current progress on federated transfer learning, and outlining corresponding solutions and applications. Furthermore, the common setting of FTL scenarios, available datasets, and significant related research are summarized in this survey.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20System%20for%20Secondary%20Structure%20Analysis%20of%20Protein%20Models                                                                                  A Comprehensive System for Secondary Structure Analysis of Protein Models                                                                                  In protein structure analysis, the accurate characterization of secondary structure elements is crucial for understanding protein function and dynamics. This paper presents a software system designed for the comprehensive analysis of the secondary structure of protein models. Leveraging phi ({ phi}) and psi ({ psi}) torsion angles, the system utilises K-means clustering and outlier detection techniques to identify and classify folding structures within protein models. Through the visualisation of the Ramachandran plot, the software enables the differentiation of various secondary structure motifs, including alpha-helices, beta-sheets, and other structural elements. The incorporation of customisable threshold values facilitates the identification of outliers, providing insights into potential structural anomalies or misalignments within protein models. Overall, this software system offers researchers a powerful tool for comprehensive secondary structure analysis, to aid in enhancing understanding of protein structures created using both traditional methods such as X-Ray Diffraction and contemporary methods such as Artificial Intelligence.
http://w3id.org/mlsea/pwc/scientificWork/A%20Concept%20for%20Reconstructing%20Stucco%20Statues%20from%20historic%20Sketches%20using%20synthetic%20Data%20only                                                                                  A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic Data only                                                                                  In medieval times, stuccoworkers used a red color, called sinopia, to first create a sketch of the to-be-made statue on the wall. Today, many of these statues are destroyed, but using the original drawings, deriving from the red color also called sinopia, we can reconstruct how the final statue might have looked.We propose a fully-automated approach to reconstruct a point cloud and show preliminary results by generating a color-image, a depth-map, as well as surface normals requiring only a single sketch, and without requiring a collection of other, similar samples. Our proposed solution allows real-time reconstruction on-site, for instance, within an exhibition, or to generate a useful starting point for an expert, trying to manually reconstruct the statue, all while using only synthetic data for training.
http://w3id.org/mlsea/pwc/scientificWork/A%20Concept-based%20Interpretable%20Model%20for%20the%20Diagnosis%20of%20Choroid%20Neoplasias%20using%20Multimodal%20Data                                                                                  A Concept-based Interpretable Model for the Diagnosis of Choroid Neoplasias using Multimodal Data                                                                                  Diagnosing rare diseases presents a common challenge in clinical practice, necessitating the expertise of specialists for accurate identification. The advent of machine learning offers a promising solution, while the development of such technologies is hindered by the scarcity of data on rare conditions and the demand for models that are both interpretable and trustworthy in a clinical context. Interpretable AI, with its capacity for human-readable outputs, can facilitate validation by clinicians and contribute to medical education. In the current work, we focus on choroid neoplasias, the most prevalent form of eye cancer in adults, albeit rare with 5.1 per million. We built the so-far largest dataset consisting of 750 patients, incorporating three distinct imaging modalities collected from 2004 to 2022. Our work introduces a concept-based interpretable model that distinguishes between three types of choroidal tumors, integrating insights from domain experts via radiological reports. Remarkably, this model not only achieves an F1 score of 0.91, rivaling that of black-box models, but also boosts the diagnostic accuracy of junior doctors by 42%. This study highlights the significant potential of interpretable machine learning in improving the diagnosis of rare diseases, laying a groundwork for future breakthroughs in medical AI that could tackle a wider array of complex health scenarios.
http://w3id.org/mlsea/pwc/scientificWork/A%20Concise%20Tiling%20Strategy%20for%20Preserving%20Spatial%20Context%20in%20Earth%20Observation%20Imagery                                                                                  A Concise Tiling Strategy for Preserving Spatial Context in Earth Observation Imagery                                                                                  We propose a new tiling strategy, Flip-n-Slide, which has been developed for specific use with large Earth observation satellite images when the location of objects-of-interest (OoI) is unknown and spatial context can be necessary for class disambiguation. Flip-n-Slide is a concise and minimalistic approach that allows OoI to be represented at multiple tile positions and orientations. This strategy introduces multiple views of spatio-contextual information, without introducing redundancies into the training set. By maintaining distinct transformation permutations for each tile overlap, we enhance the generalizability of the training set without misrepresenting the true data distribution. Our experiments validate the effectiveness of Flip-n-Slide in the task of semantic segmentation, a necessary data product in geophysical studies. We find that Flip-n-Slide outperforms the previous state-of-the-art augmentation routines for tiled data in all evaluation metrics. For underrepresented classes, Flip-n-Slide increases precision by as much as 15.8%.
http://w3id.org/mlsea/pwc/scientificWork/A%20Continued%20Pretrained%20LLM%20Approach%20for%20Automatic%20Medical%20Note%20Generation                                                                                  A Continued Pretrained LLM Approach for Automatic Medical Note Generation                                                                                  LLMs are revolutionizing NLP tasks. However, the use of the most advanced LLMs, such as GPT-4, is often prohibitively expensive for most specialized fields. We introduce HEAL, the first continuously trained 13B LLaMA2-based LLM that is purpose-built for medical conversations and measured on automated scribing. Our results demonstrate that HEAL outperforms GPT-4 and PMC-LLaMA in PubMedQA, with an accuracy of 78.4 %. It also achieves parity with GPT-4 in generating medical notes. Remarkably, HEAL surpasses GPT-4 and Med-PaLM 2 in identifying more correct medical concepts and exceeds the performance of human scribes and other comparable models in correctness and completeness.
http://w3id.org/mlsea/pwc/scientificWork/A%20Contrast%20Based%20Feature%20Selection%20Algorithm%20for%20High-dimensional%20Data%20set%20in%20Machine%20Learning                                                                                  A Contrast Based Feature Selection Algorithm for High-dimensional Data set in Machine Learning                                                                                  Feature selection is an important process in machine learning and knowledge discovery. By selecting the most informative features and eliminating irrelevant ones, the performance of learning algorithms can be improved and the extraction of meaningful patterns and insights from data can be facilitated. However, most existing feature selection methods, when applied to large datasets, encountered the bottleneck of high computation costs. To address this problem, we propose a novel filter feature selection method, ContrastFS, which selects discriminative features based on the discrepancies features shown between different classes. We introduce a dimensionless quantity as a surrogate representation to summarize the distributional individuality of certain classes, based on this quantity we evaluate features and study the correlation among them. We validate effectiveness and efficiency of our approach on several widely studied benchmark datasets, results show that the new method performs favorably with negligible computation in comparison with other state-of-the-art feature selection methods.
http://w3id.org/mlsea/pwc/scientificWork/A%20Controlled%20Reevaluation%20of%20Coreference%20Resolution%20Models                                                                                  A Controlled Reevaluation of Coreference Resolution Models                                                                                  All state-of-the-art coreference resolution (CR) models involve finetuning a pretrained language model. Whether the superior performance of one CR model over another is due to the choice of language model or other factors, such as the task-specific architecture, is difficult or impossible to determine due to lack of a standardized experimental setup. To resolve this ambiguity, we systematically evaluate five CR models and control for certain design decisions including the pretrained language model used by each. When controlling for language model size, encoder-based CR models outperform more recent decoder-based models in terms of both accuracy and inference speed. Surprisingly, among encoder-based CR models, more recent models are not always more accurate, and the oldest CR model that we test generalizes the best to out-of-domain textual genres. We conclude that controlling for the choice of language model reduces most, but not all, of the increase in F1 score reported in the past five years.
http://w3id.org/mlsea/pwc/scientificWork/A%20Data-Driven%20Predictive%20Analysis%20on%20Cyber%20Security%20Threats%20with%20Key%20Risk%20Factors                                                                                  A Data-Driven Predictive Analysis on Cyber Security Threats with Key Risk Factors                                                                                  Cyber risk refers to the risk of defacing reputation, monetary losses, or disruption of an organization or individuals, and this situation usually occurs by the unconscious use of cyber systems. The cyber risk is unhurriedly increasing day by day and it is right now a global threat. Developing countries like Bangladesh face major cyber risk challenges. The growing cyber threat worldwide focuses on the need for effective modeling to predict and manage the associated risk. This paper exhibits a Machine Learning(ML) based model for predicting individuals who may be victims of cyber attacks by analyzing socioeconomic factors. We collected the dataset from victims and non-victims of cyberattacks based on socio-demographic features. The study involved the development of a questionnaire to gather data, which was then used to measure the significance of features. Through data augmentation, the dataset was expanded to encompass 3286 entries, setting the stage for our investigation and modeling. Among several ML models with 19, 20, 21, and 26 features, we proposed a novel Pertinent Features Random Forest (RF) model, which achieved maximum accuracy with 20 features (95.95 %) and also demonstrated the association among the selected features using the Apriori algorithm with Confidence (above 80 %) according to the victim. We generated 10 important association rules and presented the framework that is rigorously evaluated on real-world datasets, demonstrating its potential to predict cyberattacks and associated risk factors effectively. Looking ahead, future efforts will be directed toward refining the predictive model's precision and delving into additional risk factors, to fortify the proposed framework's efficacy in navigating the complex terrain of cybersecurity threats.
http://w3id.org/mlsea/pwc/scientificWork/A%20Data-driven%20Approach%20for%20Rapid%20Detection%20of%20Aeroelastic%20Modes%20from%20Flutter%20Flight%20Test%20Based%20on%20Limited%20Sensor%20Measurements                                                                                  A Data-driven Approach for Rapid Detection of Aeroelastic Modes from Flutter Flight Test Based on Limited Sensor Measurements                                                                                  Flutter flight test involves the evaluation of the airframes aeroelastic stability by applying artificial excitation on the aircraft lifting surfaces. The subsequent responses are captured and analyzed to extract the frequencies and damping characteristics of the system. However, noise contamination, turbulence, non-optimal excitation of modes, and sensor malfunction in one or more sensors make it time-consuming and corrupt the extraction process. In order to expedite the process of identifying and analyzing aeroelastic modes, this study implements a time-delay embedded Dynamic Mode Decomposition technique. This approach is complemented by Robust Principal Component Analysis methodology, and a sparsity promoting criterion which enables the automatic and optimal selection of sparse modes. The anonymized flutter flight test data, provided by the fifth author of this research paper, is utilized in this implementation. The methodology assumes no knowledge of the input excitation, only deals with the responses captured by accelerometer channels, and rapidly identifies the aeroelastic modes. By incorporating a compressed sensing algorithm, the methodology gains the ability to identify aeroelastic modes, even when the number of available sensors is limited. This augmentation greatly enhances the methodology's robustness and effectiveness, making it an excellent choice for real-time implementation during flutter test campaigns.
http://w3id.org/mlsea/pwc/scientificWork/A%20Data-to-Product%20Multimodal%20Conceptual%20Framework%20to%20Achieve%20Automated%20Software%20Evolution%20for%20Context-rich%20Intelligent%20Applications                                                                                  A Data-to-Product Multimodal Conceptual Framework to Achieve Automated Software Evolution for Context-rich Intelligent Applications                                                                                  While AI is extensively transforming Software Engineering (SE) fields, SE is still in need of a framework to overall consider all phases to facilitate Automated Software Evolution (ASEv), particularly for intelligent applications that are context-rich, instead of conquering each division independently. Its complexity comes from the intricacy of the intelligent applications, the heterogeneity of the data sources, and the constant changes in the context. This study proposes a conceptual framework for achieving automated software evolution, emphasizing the importance of multimodality learning. A Selective Sequential Scope Model (3S) model is developed based on the conceptual framework, and it can be used to categorize existing and future research when it covers different SE phases and multimodal learning tasks. This research is a preliminary step toward the blueprint of a higher-level ASEv. The proposed conceptual framework can act as a practical guideline for practitioners to prepare themselves for diving into this area. Although the study is about intelligent applications, the framework and analysis methods may be adapted for other types of software as AI brings more intelligence into their life cycles.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dataset%20and%20Benchmark%20for%20Copyright%20Protection%20from%20Text-to-Image%20Diffusion%20Models                                                                                  A Dataset and Benchmark for Copyright Protection from Text-to-Image Diffusion Models                                                                                  Copyright is a legal right that grants creators the exclusive authority to reproduce, distribute, and profit from their creative works. However, the recent advancements in text-to-image generation techniques have posed significant challenges to copyright protection, as these methods have facilitated the learning of unauthorized content, artistic creations, and portraits, which are subsequently utilized to generate and disseminate uncontrolled content. Especially, the use of stable diffusion, an emerging model for text-to-image generation, poses an increased risk of unauthorized copyright infringement and distribution. Currently, there is a lack of systematic studies evaluating the potential correlation between content generated by stable diffusion and those under copyright protection. Conducting such studies faces several challenges, including i) the intrinsic ambiguity related to copyright infringement in text-to-image models, ii) the absence of a comprehensive large-scale dataset, and iii) the lack of standardized metrics for defining copyright infringement. This work provides the first large-scale standardized dataset and benchmark on copyright protection. Specifically, we propose a pipeline to coordinate CLIP, ChatGPT, and diffusion models to generate a dataset that contains anchor images, corresponding prompts, and images generated by text-to-image models, reflecting the potential abuses of copyright. Furthermore, we explore a suite of evaluation metrics to judge the effectiveness of copyright protection methods. The proposed dataset, benchmark library, and evaluation metrics will be open-sourced to facilitate future research and application. The website and dataset can be accessed website dataset.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dataset%20of%20Open-Domain%20Question%20Answering%20with%20Multiple-Span%20Answers                                                                                  A Dataset of Open-Domain Question Answering with Multiple-Span Answers                                                                                  Multi-span answer extraction, also known as the task of multi-span question answering (MSQA), is critical for real-world applications, as it requires extracting multiple pieces of information from a text to answer complex questions. Despite the active studies and rapid progress in English MSQA research, there is a notable lack of publicly available MSQA benchmark in Chinese. Previous efforts for constructing MSQA datasets predominantly emphasized entity-centric contextualization, resulting in a bias towards collecting factoid questions and potentially overlooking questions requiring more detailed descriptive responses. To overcome these limitations, we present CLEAN, a comprehensive Chinese multi-span question answering dataset that involves a wide range of open-domain subjects with a substantial number of instances requiring descriptive answers. Additionally, we provide established models from relevant literature as baselines for CLEAN. Experimental results and analysis show the characteristics and challenge of the newly proposed CLEAN dataset for the community. Our dataset, CLEAN, will be publicly released at zhiyiluo.site/misc/clean_v1.0_ sample.json.
http://w3id.org/mlsea/pwc/scientificWork/A%20Decade%20of%20Privacy-Relevant%20Android%20App%20Reviews%3A%20Large%20Scale%20Trends                                                                                  A Decade of Privacy-Relevant Android App Reviews: Large Scale Trends                                                                                  We present an analysis of 12 million instances of privacy-relevant reviews publicly visible on the Google Play Store that span a 10 year period. By leveraging state of the art NLP techniques, we examine what users have been writing about privacy along multiple dimensions: time, countries, app types, diverse privacy topics, and even across a spectrum of emotions. We find consistent growth of privacy-relevant reviews, and explore topics that are trending (such as Data Deletion and Data Theft), as well as those on the decline (such as privacy-relevant reviews on sensitive permissions). We find that although privacy reviews come from more than 200 countries, 33 countries provide 90% of privacy reviews. We conduct a comparison across countries by examining the distribution of privacy topics a country's users write about, and find that geographic proximity is not a reliable indicator that nearby countries have similar privacy perspectives. We uncover some countries with unique patterns and explore those herein. Surprisingly, we uncover that it is not uncommon for reviews that discuss privacy to be positive (32%); many users express pleasure about privacy features within apps or privacy-focused apps. We also uncover some unexpected behaviors, such as the use of reviews to deliver privacy disclaimers to developers. Finally, we demonstrate the value of analyzing app reviews with our approach as a complement to existing methods for understanding users' perspectives about privacy
http://w3id.org/mlsea/pwc/scientificWork/A%20Deep%20Learning%20Approach%20to%20Radar-based%20QPE                                                                                  A Deep Learning Approach to Radar-based QPE                                                                                  In this study, we propose a volume-to-point framework for quantitative precipitation estimation (QPE) based on the Quantitative Precipitation Estimation and Segregation Using Multiple Sensor (QPESUMS) Mosaic Radar data set. With a data volume consisting of the time series of gridded radar reflectivities over the Taiwan area, we used machine learning algorithms to establish a statistical model for QPE in weather stations. The model extracts spatial and temporal features from the input data volume and then associates these features with the location-specific precipitations. In contrast to QPE methods based on the Z-R relation, we leverage the machine learning algorithms to automatically detect the evolution and movement of weather systems and associate these patterns to a location with specific topographic attributes. Specifically, we evaluated this framework with the hourly precipitation data of 45 weather stations in Taipei during 2013-2016. In comparison to the operational QPE scheme used by the Central Weather Bureau, the volume-to-point framework performed comparably well in general cases and excelled in detecting heavy-rainfall events. By using the current results as the reference benchmark, the proposed method can integrate the heterogeneous data sources and potentially improve the forecast in extreme precipitation scenarios.
http://w3id.org/mlsea/pwc/scientificWork/A%20Deep%20Learning%20Representation%20of%20Spatial%20Interaction%20Model%20for%20Resilient%20Spatial%20Planning%20of%20Community%20Business%20Clusters                                                                                  A Deep Learning Representation of Spatial Interaction Model for Resilient Spatial Planning of Community Business Clusters                                                                                  Existing Spatial Interaction Models (SIMs) are limited in capturing the complex and context-aware interactions between business clusters and trade areas. To address the limitation, we propose a SIM-GAT model to predict spatiotemporal visitation flows between community business clusters and their trade areas. The model innovatively represents the integrated system of business clusters, trade areas, and transportation infrastructure within an urban region using a connected graph. Then, a graph-based deep learning model, i.e., Graph AttenTion network (GAT), is used to capture the complexity and interdependencies of business clusters. We developed this model with data collected from the Miami metropolitan area in Florida. We then demonstrated its effectiveness in capturing varying attractiveness of business clusters to different residential neighborhoods and across scenarios with an eXplainable AI approach. We contribute a novel method supplementing conventional SIMs to predict and analyze the dynamics of inter-connected community business clusters. The analysis results can inform data-evidenced and place-specific planning strategies helping community business clusters better accommodate their customers across scenarios, and hence improve the resilience of community businesses.
http://w3id.org/mlsea/pwc/scientificWork/A%20Deep%20Look%20Into%20--%20Automated%20Lung%20X-Ray%20Abnormality%20Detection%20System                                                                                  A Deep Look Into -- Automated Lung X-Ray Abnormality Detection System                                                                                  Introduction: Automated Lung X-Ray Abnormality Detection System is the application which distinguish the normal x-ray images from infected x-ray images and highlight area considered for prediction, with the recent pandemic a need to have a non-conventional method and faster detecting diseases, for which X ray serves the purpose. Obectives: As of current situation any viral disease that is infectious is potential pandemic, so there is need for cheap and early detection system. Methods: This research will help to eases the work of expert to do further analysis. Accuracy of three different preexisting models such as DenseNet, MobileNet and VGG16 were high but models over-fitted primarily due to black and white images. Results: This led to building up new method such as as V-BreathNet which gave more than 96% percent accuracy. Conclusion: Thus, it can be stated that not all state-of art CNN models can be used on B/W images. In conclusion not all state-of-art CNN models can be used on B/W images.
http://w3id.org/mlsea/pwc/scientificWork/A%20Density-Guided%20Temporal%20Attention%20Transformer%20for%20Indiscernible%20Object%20Counting%20in%20Underwater%20Video                                                                                  A Density-Guided Temporal Attention Transformer for Indiscernible Object Counting in Underwater Video                                                                                  Dense object counting or crowd counting has come a long way thanks to the recent development in the vision community. However, indiscernible object counting, which aims to count the number of targets that are blended with respect to their surroundings, has been a challenge. Image-based object counting datasets have been the mainstream of the current publicly available datasets. Therefore, we propose a large-scale dataset called YoutubeFish-35, which contains a total of 35 sequences of high-definition videos with high frame-per-second and more than 150,000 annotated center points across a selected variety of scenes. For benchmarking purposes, we select three mainstream methods for dense object counting and carefully evaluate them on the newly collected dataset. We propose TransVidCount, a new strong baseline that combines density and regression branches along the temporal domain in a unified framework and can effectively tackle indiscernible object counting with state-of-the-art performance on YoutubeFish-35 dataset.
http://w3id.org/mlsea/pwc/scientificWork/A%20Directional%20Diffusion%20Graph%20Transformer%20for%20Recommendation                                                                                  A Directional Diffusion Graph Transformer for Recommendation                                                                                  In real-world recommender systems, implicitly collected user feedback, while abundant, often includes noisy false-positive and false-negative interactions. The possible misinterpretations of the user-item interactions pose a significant challenge for traditional graph neural recommenders. These approaches aggregate the users' or items' neighbours based on implicit user-item interactions in order to accurately capture the users' profiles. To account for and model possible noise in the users' interactions in graph neural recommenders, we propose a novel Diffusion Graph Transformer (DiffGT) model for top-k recommendation. Our DiffGT model employs a diffusion process, which includes a forward phase for gradually introducing noise to implicit interactions, followed by a reverse process to iteratively refine the representations of the users' hidden preferences (i.e., a denoising process). In our proposed approach, given the inherent anisotropic structure observed in the user-item interaction graph, we specifically use anisotropic and directional Gaussian noises in the forward diffusion process. Our approach differs from the sole use of isotropic Gaussian noises in existing diffusion models. In the reverse diffusion process, to reverse the effect of noise added earlier and recover the true users' preferences, we integrate a graph transformer architecture with a linear attention module to denoise the noisy user/item embeddings in an effective and efficient manner. In addition, such a reverse diffusion process is further guided by personalised information (e.g., interacted items) to enable the accurate estimation of the users' preferences on items. Our extensive experiments conclusively demonstrate the superiority of our proposed graph diffusion model over ten existing state-of-the-art approaches across three benchmark datasets.
http://w3id.org/mlsea/pwc/scientificWork/A%20Discrete-time%20Dynamical%20Model%20for%20Optimal%20Dispatching%20and%20Rebalancing%20of%20Autonomous%20Mobility-on-Demand%20Systems                                                                                  A Discrete-time Dynamical Model for Optimal Dispatching and Rebalancing of Autonomous Mobility-on-Demand Systems                                                                                  Autonomous vehicles are rapidly evolving and will soon enable the application of large-scale mobility-on-demand (MoD) systems. Managing the fleets of available vehicles, commonly known as 'rebalancing,' is crucial to ensure that vehicles are distributed properly to meet customer demands. This paper presents an optimal control approach to optimize vehicle scheduling and rebalancing in an autonomous mobility-on-demand (AMoD) system. We use graph theory to model a city partitioned into virtual zones. Zones represent small areas of the city where vehicles can stop and pick up/drop off customers, whereas links denote corridors of the city along which autonomous vehicles can move. They are considered vertices and edges in the graph. Vehicles employed in the AMoD scheme are autonomous, and rebalancing can be executed by dispatching available empty vehicles to areas undersupplied. Rebalancing is performed on the graph's vertices, i.e., between city areas. We propose a linear, discrete-time model of an AMoD system using a transformed network. After acquiring the model, the desired number of rebalancing vehicles for the AMoD model is derived through an optimization problem. Moreover, the well-posedness of the model is illustrated. To leverage the proposed model, we implemented the model predictive control (MPC) framework to find the optimal rebalancing and scheduling policy. We show the MPC's effectiveness and how the MPC framework can be implemented in real-time for a real-world case study. The numerical results show that the MPC with a linear cost function and linear reference, which it tracks, is effective, outperforming other MPC-based and state-of-the-art algorithms across all evaluation criteria.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dual-domain%20Regularization%20Method%20for%20Ring%20Artifact%20Removal%20of%20X-ray%20CT                                                                                  A Dual-domain Regularization Method for Ring Artifact Removal of X-ray CT                                                                                  Ring artifacts in computed tomography images, arising from the undesirable responses of detector units, significantly degrade image quality and diagnostic reliability. To address this challenge, we propose a dual-domain regularization model to effectively remove ring artifacts, while maintaining the integrity of the original CT image. The proposed model corrects the vertical stripe artifacts on the sinogram by innovatively updating the response inconsistency compensation coefficients of detector units, which is achieved by employing the group sparse constraint and the projection-view direction sparse constraint on the stripe artifacts. Simultaneously, we apply the sparse constraint on the reconstructed image to further rectified ring artifacts in the image domain. The key advantage of the proposed method lies in considering the relationship between the response inconsistency compensation coefficients of the detector units and the projection views, which enables a more accurate correction of the response of the detector units. An alternating minimization method is designed to solve the model. Comparative experiments on real photon counting detector data demonstrate that the proposed method not only surpasses existing methods in removing ring artifacts but also excels in preserving structural details and image fidelity.
http://w3id.org/mlsea/pwc/scientificWork/A%20Duality%20Analysis%20of%20Kernel%20Ridge%20Regression%20in%20the%20Noiseless%20Regime                                                                                  A Duality Analysis of Kernel Ridge Regression in the Noiseless Regime                                                                                  In this paper, we conduct a comprehensive analysis of generalization properties of Kernel Ridge Regression (KRR) in the noiseless regime, a scenario crucial to scientific computing, where data are often generated via computer simulations. We prove that KRR can attain the minimax optimal rate, which depends on both the eigenvalue decay of the associated kernel and the relative smoothness of target functions. Particularly, when the eigenvalue decays exponentially fast, KRR achieves the spectral accuracy, i.e., a convergence rate faster than any polynomial. Moreover, the numerical experiments well corroborate our theoretical findings. Our proof leverages a novel extension of the duality framework introduced by Chen et al. (2023), which could be useful in analyzing kernel-based methods beyond the scope of this work.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dynamical%20View%20of%20the%20Question%20of%20Why                                                                                  A Dynamical View of the Question of Why                                                                                  We address causal reasoning in multivariate time series data generated by stochastic processes. Existing approaches are largely restricted to static settings, ignoring the continuity and emission of variations across time. In contrast, we propose a learning paradigm that directly establishes causation between events in the course of time. We present two key lemmas to compute causal contributions and frame them as reinforcement learning problems. Our approach offers formal and computational tools for uncovering and quantifying causal relationships in diffusion processes, subsuming various important settings such as discrete-time Markov decision processes. Finally, in fairly intricate experiments and through sheer learning, our framework reveals and quantifies causal links, which otherwise seem inexplicable.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dynamically%20Weighted%20Loss%20Function%20for%20Unsupervised%20Image%20Segmentation                                                                                  A Dynamically Weighted Loss Function for Unsupervised Image Segmentation                                                                                  Image segmentation is the foundation of several computer vision tasks, where pixel-wise knowledge is a prerequisite for achieving the desired target. Deep learning has shown promising performance in supervised image segmentation. However, supervised segmentation algorithms require a massive amount of data annotated at a pixel level, thus limiting their applicability and scalability. Therefore, there is a need to invest in unsupervised learning for segmentation. This work presents an improved version of an unsupervised Convolutional Neural Network (CNN) based algorithm that uses a constant weight factor to balance between the segmentation criteria of feature similarity and spatial continuity, and it requires continuous manual adjustment of parameters depending on the degree of detail in the image and the dataset. In contrast, we propose a novel dynamic weighting scheme that leads to a flexible update of the parameters and an automatic tuning of the balancing weight between the two criteria above to bring out the details in the images in a genuinely unsupervised manner. We present quantitative and qualitative results on four datasets, which show that the proposed scheme outperforms the current unsupervised segmentation approaches without requiring manual adjustment.
http://w3id.org/mlsea/pwc/scientificWork/A%20Fast%2C%20Performant%2C%20Secure%20Distributed%20Training%20Framework%20For%20Large%20Language%20Model                                                                                  A Fast, Performant, Secure Distributed Training Framework For Large Language Model                                                                                  The distributed (federated) LLM is an important method for co-training the domain-specific LLM using siloed data. However, maliciously stealing model parameters and data from the server or client side has become an urgent problem to be solved. In this paper, we propose a secure distributed LLM based on model slicing. In this case, we deploy the Trusted Execution Environment (TEE) on both the client and server side, and put the fine-tuned structure (LoRA or embedding of P-tuning v2) into the TEE. Then, secure communication is executed in the TEE and general environments through lightweight encryption. In order to further reduce the equipment cost as well as increase the model performance and accuracy, we propose a split fine-tuning scheme. In particular, we split the LLM by layers and place the latter layers in a server-side TEE (the client does not need a TEE). We then combine the proposed Sparsification Parameter Fine-tuning (SPF) with the LoRA part to improve the accuracy of the downstream task. Numerous experiments have shown that our method guarantees accuracy while maintaining security.
http://w3id.org/mlsea/pwc/scientificWork/A%20Feature%20Matching%20Method%20Based%20on%20Multi-Level%20Refinement%20Strategy                                                                                  A Feature Matching Method Based on Multi-Level Refinement Strategy                                                                                  Feature matching is a fundamental and crucial process in visual SLAM, and precision has always been a challenging issue in feature matching. In this paper, based on a multi-level fine matching strategy, we propose a new feature matching method called KTGP-ORB. This method utilizes the similarity of local appearance in the Hamming space generated by feature descriptors to establish initial correspondences. It combines the constraint of local image motion smoothness, uses the GMS algorithm to enhance the accuracy of initial matches, and finally employs the PROSAC algorithm to optimize matches, achieving precise matching based on global grayscale information in Euclidean space. Experimental results demonstrate that the KTGP-ORB method reduces the error by an average of 29.92% compared to the ORB algorithm in complex scenes with illumination variations and blur.
http://w3id.org/mlsea/pwc/scientificWork/A%20Framework%20for%20Digital%20Currencies%20for%20Financial%20Inclusion%20in%20Latin%20America%20and%20the%20Caribbean                                                                                  A Framework for Digital Currencies for Financial Inclusion in Latin America and the Caribbean                                                                                  This research aims to provide a framework to assess the contribution of digital currencies to promote financial inclusion, based on a diagnosis of the landscape of financial inclusion and domestic and cross-border payments in Latin America and the Caribbean. It also provides insights from central banks in the region on key aspects regarding a possible implementation of central bank digital currencies. Findings show that although digital currencies development is at an early stage, a well-designed system could reduce the cost of domestic and cross-border payments, improve the settlement of transactions to achieve real-time payments, expand the accessibility of central bank money, incorporate programmable payments and achieve system performance demands.
http://w3id.org/mlsea/pwc/scientificWork/A%20Framework%20for%20Portrait%20Stylization%20with%20Skin-Tone%20Awareness%20and%20Nudity%20Identification                                                                                  A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity Identification                                                                                  Portrait stylization is a challenging task involving the transformation of an input portrait image into a specific style while preserving its inherent characteristics. The recent introduction of Stable Diffusion (SD) has significantly improved the quality of outcomes in this field. However, a practical stylization framework that can effectively filter harmful input content and preserve the distinct characteristics of an input, such as skin-tone, while maintaining the quality of stylization remains lacking. These challenges have hindered the wide deployment of such a framework. To address these issues, this study proposes a portrait stylization framework that incorporates a nudity content identification module (NCIM) and a skin-tone-aware portrait stylization module (STAPSM). In experiments, NCIM showed good performance in enhancing explicit content filtering, and STAPSM accurately represented a diverse range of skin tones. Our proposed framework has been successfully deployed in practice, and it has effectively satisfied critical requirements of real-world applications.
http://w3id.org/mlsea/pwc/scientificWork/A%20Framework%20for%20Strategic%20Discovery%20of%20Credible%20Neural%20Network%20Surrogate%20Models%20under%20Uncertainty                                                                                  A Framework for Strategic Discovery of Credible Neural Network Surrogate Models under Uncertainty                                                                                  The widespread integration of deep neural networks in developing data-driven surrogate models for high-fidelity simulations of complex physical systems highlights the critical necessity for robust uncertainty quantification techniques and credibility assessment methodologies, ensuring the reliable deployment of surrogate models in consequential decision-making. This study presents the Occam Plausibility Algorithm for surrogate models (OPAL-surrogate), providing a systematic framework to uncover predictive neural network-based surrogate models within the large space of potential models, including various neural network classes and choices of architecture and hyperparameters. The framework is grounded in hierarchical Bayesian inferences and employs model validation tests to evaluate the credibility and prediction reliability of the surrogate models under uncertainty. Leveraging these principles, OPAL-surrogate introduces a systematic and efficient strategy for balancing the trade-off between model complexity, accuracy, and prediction uncertainty. The effectiveness of OPAL-surrogate is demonstrated through two modeling problems, including the deformation of porous materials for building insulation and turbulent combustion flow for the ablation of solid fuels within hybrid rocket motors.
http://w3id.org/mlsea/pwc/scientificWork/A%20Fully%20Adaptive%20DRO%20Multistage%20Framework%20Based%20on%20MDR%20for%20Generation%20Scheduling%20under%20Uncertainty                                                                                  A Fully Adaptive DRO Multistage Framework Based on MDR for Generation Scheduling under Uncertainty                                                                                  AbstractâThe growing proliferation of wind power into the power grid achieves a low-cost sustainable electricity supply while introducing technical challenges with associ-ated intermittency. This paper proposes a fully adaptive distributionally robust multistage framework based on mixed decision rules (MDR) for generation scheduling un-der uncertainty to adapt wind power respecting non-anticipativity in quick-start unit status decision and dispatch process. Compared with existing multistage mod-els, the proposed framework introduces improved MDR to handle all decision variables to expand the feasible region. Therefore, our model can find a feasible solution to some problems that are not feasible in the traditional models while finding a better solution to feasible problems, so as to better exploit wind energy and accordingly fall consump-tion of fossil fuels. Besides, the proposed model is refor-mulated with advanced optimization methods and im-proved MDR to the mixed integer linear programming (MILP) to address computational intractability. The effec-tiveness and superiority of the proposed model have been validated with case studies using IEEE benchmark systems.
http://w3id.org/mlsea/pwc/scientificWork/A%20Gaze-grounded%20Visual%20Question%20Answering%20Dataset%20for%20Clarifying%20Ambiguous%20Japanese%20Questions                                                                                  A Gaze-grounded Visual Question Answering Dataset for Clarifying Ambiguous Japanese Questions                                                                                  Situated conversations, which refer to visual information as visual question answering (VQA), often contain ambiguities caused by reliance on directive information. This problem is exacerbated because some languages, such as Japanese, often omit subjective or objective terms. Such ambiguities in questions are often clarified by the contexts in conversational situations, such as joint attention with a user or user gaze information. In this study, we propose the Gaze-grounded VQA dataset (GazeVQA) that clarifies ambiguous questions using gaze information by focusing on a clarification process complemented by gaze information. We also propose a method that utilizes gaze target estimation results to improve the accuracy of GazeVQA tasks. Our experimental results showed that the proposed method improved the performance in some cases of a VQA system on GazeVQA and identified some typical problems of GazeVQA tasks that need to be improved.
http://w3id.org/mlsea/pwc/scientificWork/A%20General%20Approach%20for%20Computing%20a%20Consensus%20in%20Group%20Decision%20Making%20That%20Integrates%20Multiple%20Ethical%20Principles                                                                                  A General Approach for Computing a Consensus in Group Decision Making That Integrates Multiple Ethical Principles                                                                                  We tackle the problem of computing a consensus according to multiple ethical principles -- which can include, for example, the principle of maximum freedom associated with the Benthamite doctrine and the principle of maximum fairness associated with the Rawlsian principles -- among the preferences of different individuals in the context of Group-Decision-Making. More formally, we put forward a novel formalisation of the above-mentioned problem based on a multinorm approximation problem that aims at minimising multiple p-metric distance functions, where each parameter p represents a given ethical principle. Our contribution incurs obvious benefits from a social-choice perspective. Firstly, our approach significantly generalises state-of-the-art approaches that were limited to only two ethical principles (p set to one, for maximum freedom, and p set to infinity, for maximum fairness). Secondly, our experimental results considering an established test case demonstrate that our approach is capable, thanks to a novel re-weighting scheme, to compute a multi-norm consensus that takes into account each ethical principle in a balanced way, in contrast with state-of-the-art approaches that were heavily biased towards the p=1 ethical principle
http://w3id.org/mlsea/pwc/scientificWork/A%20General%20and%20Efficient%20Federated%20Split%20Learning%20with%20Pre-trained%20Image%20Transformers%20for%20Heterogeneous%20Data                                                                                  A General and Efficient Federated Split Learning with Pre-trained Image Transformers for Heterogeneous Data                                                                                  Federated Split Learning (FSL) is a promising distributed learning paradigm in practice, which gathers the strengths of both Federated Learning (FL) and Split Learning (SL) paradigms, to ensure model privacy while diminishing the resource overhead of each client, especially on large transformer models in a resource-constrained environment, e.g., Internet of Things (IoT). However, almost all works merely investigate the performance with simple neural network models in FSL. Despite the minor efforts focusing on incorporating Vision Transformers (ViT) as model architectures, they train ViT from scratch, thereby leading to enormous training overhead in each device with limited resources. Therefore, in this paper, we harness Pre-trained Image Transformers (PITs) as the initial model, coined FES-PIT, to accelerate the training process and improve model robustness. Furthermore, we propose FES-PTZO to hinder the gradient inversion attack, especially having the capability compatible with black-box scenarios, where the gradient information is unavailable. Concretely, FES-PTZO approximates the server gradient by utilizing a zeroth-order (ZO) optimization, which replaces the backward propagation with just one forward process. Empirically, we are the first to provide a systematic evaluation of FSL methods with PITs in real-world datasets, different partial device participations, and heterogeneous data splits. Our experiments verify the effectiveness of our algorithms.
http://w3id.org/mlsea/pwc/scientificWork/A%20Generalized%20Approach%20to%20Online%20Convex%20Optimization                                                                                  A Generalized Approach to Online Convex Optimization                                                                                  In this paper, we analyze the problem of online convex optimization in different settings. We show that any algorithm for online linear optimization with fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, such full-information feedback, bandit feedback, stochastic regret, adversarial regret and various forms of non-stationary regret. Using our analysis, we provide the first efficient projection-free online convex optimization algorithm using linear optimization oracles.
http://w3id.org/mlsea/pwc/scientificWork/A%20Generative%20Approach%20to%20Surrogate-based%20Black-box%20Attacks                                                                                  A Generative Approach to Surrogate-based Black-box Attacks                                                                                  Surrogate-based black-box attacks have exposed the heightened vulnerability of DNNs. These attacks are designed to craft adversarial examples for any samples with black-box target feedback for only a given set of samples. State-of-the-art surrogate-based attacks involve training a discriminative surrogate that mimics the target's outputs. The goal is to learn the decision boundaries of the target. The surrogate is then attacked by white-box attacks to craft adversarial examples similar to the original samples but belong to other classes. With limited samples, the discriminative surrogate fails to accurately learn the target's decision boundaries, and these surrogate-based attacks suffer from low success rates. Different from the discriminative approach, we propose a generative surrogate that learns the distribution of samples residing on or close to the target's decision boundaries. The distribution learned by the generative surrogate can be used to craft adversarial examples that have imperceptible differences from the original samples but belong to other classes. The proposed generative approach results in attacks with remarkably high attack success rates on various targets and datasets.
http://w3id.org/mlsea/pwc/scientificWork/A%20Generative%20Model%20of%20Symmetry%20Transformations                                                                                  A Generative Model of Symmetry Transformations                                                                                  Correctly capturing the symmetry transformations of data can lead to efficient models with strong generalization capabilities, though methods incorporating symmetries often require prior knowledge. While recent advancements have been made in learning those symmetries directly from the dataset, most of this work has focused on the discriminative setting. In this paper, we construct a generative model that explicitly aims to capture symmetries in the data, resulting in a model that learns which symmetries are present in an interpretable way. We provide a simple algorithm for efficiently learning our generative model and demonstrate its ability to capture symmetries under affine and color transformations. Combining our symmetry model with existing generative models results in higher marginal test-log-likelihoods and robustness to data sparsification.
http://w3id.org/mlsea/pwc/scientificWork/A%20Geometric%20Explanation%20of%20the%20Likelihood%20OOD%20Detection%20Paradox                                                                                  A Geometric Explanation of the Likelihood OOD Detection Paradox                                                                                  Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling behaviour: when trained on a relatively complex dataset, they assign higher likelihood values to out-of-distribution (OOD) data from simpler sources. Adding to the mystery, OOD samples are never generated by these DGMs despite having higher likelihoods. This two-pronged paradox has yet to be conclusively explained, making likelihood-based OOD detection unreliable. Our primary observation is that high-likelihood regions will not be generated if they contain minimal probability mass. We demonstrate how this seeming contradiction of large densities yet low probability mass can occur around data confined to low-dimensional manifolds. We also show that this scenario can be identified through local intrinsic dimension (LID) estimation, and propose a method for OOD detection which pairs the likelihoods and LID estimates obtained from a pre-trained DGM. Our method can be applied to normalizing flows and score-based diffusion models, and obtains results which match or surpass state-of-the-art OOD detection benchmarks using the same DGM backbones. Our code is available at https://github.com/layer6ai-labs/dgm_ood_detection.
http://w3id.org/mlsea/pwc/scientificWork/A%20Hard-to-Beat%20Baseline%20for%20Training-free%20CLIP-based%20Adaptation                                                                                  A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation                                                                                  Contrastive Language-Image Pretraining (CLIP) has gained popularity for its remarkable zero-shot capacity. Recent research has focused on developing efficient fine-tuning methods, such as prompt learning and adapter, to enhance CLIP's performance in downstream tasks. However, these methods still require additional training time and computational resources, which is undesirable for devices with limited resources. In this paper, we revisit a classical algorithm, Gaussian Discriminant Analysis (GDA), and apply it to the downstream classification of CLIP. Typically, GDA assumes that features of each class follow Gaussian distributions with identical covariance. By leveraging Bayes' formula, the classifier can be expressed in terms of the class means and covariance, which can be estimated from the data without the need for training. To integrate knowledge from both visual and textual modalities, we ensemble it with the original zero-shot classifier within CLIP. Extensive results on 17 datasets validate that our method surpasses or achieves comparable results with state-of-the-art methods on few-shot classification, imbalanced learning, and out-of-distribution generalization. In addition, we extend our method to base-to-new generalization and unsupervised learning, once again demonstrating its superiority over competing approaches. Our code is publicly available at url{https://github.com/mrflogs/ICLR24}.
http://w3id.org/mlsea/pwc/scientificWork/A%20Human-Machine%20Collaboration%20Framework%20for%20the%20Development%20of%20Schemas                                                                                  A Human-Machine Collaboration Framework for the Development of Schemas                                                                                  The Winograd Schema Challenge (WSC), a seemingly well-thought-out test for machine intelligence, has been proposed to shed light on developing systems that exhibit human behavior. Since its introduction, it aimed to pivot the focus of the AI community from the technology to the science of AI. While common and trivial for humans, studies show that it is still challenging for machines, especially when they have to deal with novel schemas, that is, well-designed sentences that require the resolving of definite pronouns. As researchers have become increasingly interested in the challenge itself, this presumably necessitates the availability of an extensive collection of Winograd schemas, which goes beyond what human experts can reasonably develop themselves, especially after proposed ways of utilizing them as novel forms of CAPTCHAs. To address this necessity, we propose a novel framework that explicitly focuses on how humans and machines can collaborate as teammates to design novel schemas from scratch. This is being accomplished by combining two recent studies from the literature: i) Winventor, a machine-driven approach for the development of large amounts of Winograd schemas, albeit not of high quality, and ii) WinoFlexi, an online crowdsourcing system that allows crowd workers to develop a limited number of schemas often of similar quality to that of experts. Our proposal crafts a new road map toward developing a novel collaborative platform that amplifies human and machine intelligence by combining their complementary strengths.
http://w3id.org/mlsea/pwc/scientificWork/A%20Hybrid%20Intelligence%20Method%20for%20Argument%20Mining                                                                                  A Hybrid Intelligence Method for Argument Mining                                                                                  Large-scale survey tools enable the collection of citizen feedback in opinion corpora. Extracting the key arguments from a large and noisy set of opinions helps in understanding the opinions quickly and accurately. Fully automated methods can extract arguments but (1) require large labeled datasets that induce large annotation costs and (2) work well for known viewpoints, but not for novel points of view. We propose HyEnA, a hybrid (human + AI) method for extracting arguments from opinionated texts, combining the speed of automated processing with the understanding and reasoning capabilities of humans. We evaluate HyEnA on three citizen feedback corpora. We find that, on the one hand, HyEnA achieves higher coverage and precision than a state-of-the-art automated method when compared to a common set of diverse opinions, justifying the need for human insight. On the other hand, HyEnA requires less human effort and does not compromise quality compared to (fully manual) expert analysis, demonstrating the benefit of combining human and artificial intelligence.
http://w3id.org/mlsea/pwc/scientificWork/A%20Hybrid%20Model%20for%20Traffic%20Incident%20Detection%20based%20on%20Generative%20Adversarial%20Networks%20and%20Transformer%20Model                                                                                  A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model                                                                                  In addition to enhancing traffic safety and facilitating prompt emergency response, traffic incident detection plays an indispensable role in intelligent transportation systems by providing real-time traffic status information. This enables the realization of intelligent traffic control and management. Previous research has identified that apart from employing advanced algorithmic models, the effectiveness of detection is also significantly influenced by challenges related to acquiring large datasets and addressing dataset imbalances. A hybrid model combining transformer and generative adversarial networks (GANs) is proposed to address these challenges. Experiments are conducted on four real datasets to validate the superiority of the transformer in traffic incident detection. Additionally, GANs are utilized to expand the dataset and achieve a balanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against the baseline model. The results demonstrate that the proposed model enhances the dataset size, balances the dataset, and improves the performance of traffic incident detection in various aspects.
http://w3id.org/mlsea/pwc/scientificWork/A%20Hybrid%20Transformer-Sequencer%20approach%20for%20Age%20and%20Gender%20classification%20from%20in-wild%20facial%20images                                                                                  A Hybrid Transformer-Sequencer approach for Age and Gender classification from in-wild facial images                                                                                  The advancements in computer vision and image processing techniques have led to emergence of new application in the domain of visual surveillance, targeted advertisement, content-based searching, and human-computer interaction etc. Out of the various techniques in computer vision, face analysis, in particular, has gained much attention. Several previous studies have tried to explore different applications of facial feature processing for a variety of tasks, including age and gender classification. However, despite several previous studies having explored the problem, the age and gender classification of in-wild human faces is still far from the achieving the desired levels of accuracy required for real-world applications. This paper, therefore, attempts to bridge this gap by proposing a hybrid model that combines self-attention and BiLSTM approaches for age and gender classification problems. The proposed models performance is compared with several state-of-the-art model proposed so far. An improvement of approximately 10percent and 6percent over the state-of-the-art implementations for age and gender classification, respectively, are noted for the proposed model. The proposed model is thus found to achieve superior performance and is found to provide a more generalized learning. The model can, therefore, be applied as a core classification component in various image processing and computer vision problems.
http://w3id.org/mlsea/pwc/scientificWork/A%20Hypernetwork%20Based%20Framework%20for%20Non-Stationary%20Channel%20Prediction                                                                                  A Hypernetwork Based Framework for Non-Stationary Channel Prediction                                                                                  In order to break through the development bottleneck of modern wireless communication networks, a critical issue is the out-of-date channel state information (CSI) in high mobility scenarios. In general, non-stationary CSI has statistical properties which vary with time, implying that the data distribution changes continuously over time. This temporal distribution shift behavior undermines the accurate channel prediction and it is still an open problem in the related literature. In this paper, a hypernetwork based framework is proposed for non-stationary channel prediction. The framework aims to dynamically update the neural network (NN) parameters as the wireless channel changes to automatically adapt to various input CSI distributions. Based on this framework, we focus on low-complexity hypernetwork design and present a deep learning (DL) based channel prediction method, termed as LPCNet, which improves the CSI prediction accuracy with acceptable complexity. Moreover, to maximize the achievable downlink spectral efficiency (SE), a joint channel prediction and beamforming (BF) method is developed, termed as JLPCNet, which seeks to predict the BF vector. Our numerical results showcase the effectiveness and flexibility of the proposed framework, and demonstrate the superior performance of LPCNet and JLPCNet in various scenarios for fixed and varying user speeds.
http://w3id.org/mlsea/pwc/scientificWork/A%20Hypothesis-Driven%20Framework%20for%20the%20Analysis%20of%20Self-Rationalising%20Models                                                                                  A Hypothesis-Driven Framework for the Analysis of Self-Rationalising Models                                                                                  The self-rationalising capabilities of LLMs are appealing because the generated explanations can give insights into the plausibility of the predictions. However, how faithful the explanations are to the predictions is questionable, raising the need to explore the patterns behind them further. To this end, we propose a hypothesis-driven statistical framework. We use a Bayesian network to implement a hypothesis about how a task (in our example, natural language inference) is solved, and its internal states are translated into natural language with templates. Those explanations are then compared to LLM-generated free-text explanations using automatic and human evaluations. This allows us to judge how similar the LLM's and the Bayesian network's decision processes are. We demonstrate the usage of our framework with an example hypothesis and two realisations in Bayesian networks. The resulting models do not exhibit a strong similarity to GPT-3.5. We discuss the implications of this as well as the framework's potential to approximate LLM decisions better in future work.
http://w3id.org/mlsea/pwc/scientificWork/A%20Korean%20Legal%20Judgment%20Prediction%20Dataset%20for%20Insurance%20Disputes                                                                                  A Korean Legal Judgment Prediction Dataset for Insurance Disputes                                                                                  This paper introduces a Korean legal judgment prediction (LJP) dataset for insurance disputes. Successful LJP models on insurance disputes can benefit insurance companies and their customers. It can save both sides' time and money by allowing them to predict how the result would come out if they proceed to the dispute mediation process. As is often the case with low-resource languages, there is a limitation on the amount of data available for this specific task. To mitigate this issue, we investigate how one can achieve a good performance despite the limitation in data. In our experiment, we demonstrate that Sentence Transformer Fine-tuning (SetFit, Tunstall et al., 2022) is a good alternative to standard fine-tuning when training data are limited. The models fine-tuned with the SetFit approach on our data show similar performance to the Korean LJP benchmark models (Hwang et al., 2022) despite the much smaller data size.
http://w3id.org/mlsea/pwc/scientificWork/A%20Landmark-Aware%20Visual%20Navigation%20Dataset                                                                                  A Landmark-Aware Visual Navigation Dataset                                                                                  Map representation learned by expert demonstrations has shown promising research value. However, recent advancements in the visual navigation field face challenges due to the lack of human datasets in the real world for efficient supervised representation learning of the environments. We present a Landmark-Aware Visual Navigation (LAVN) dataset to allow for supervised learning of human-centric exploration policies and map building. We collect RGB observation and human point-click pairs as a human annotator explores virtual and real-world environments with the goal of full coverage exploration of the space. The human annotators also provide distinct landmark examples along each trajectory, which we intuit will simplify the task of map or graph building and localization. These human point-clicks serve as direct supervision for waypoint prediction when learning to explore in environments. Our dataset covers a wide spectrum of scenes, including rooms in indoor environments, as well as walkways outdoors. Dataset is available at DOI: 10.5281/zenodo.10608067.
http://w3id.org/mlsea/pwc/scientificWork/A%20Language%20Model%20based%20Framework%20for%20New%20Concept%20Placement%20in%20Ontologies                                                                                  A Language Model based Framework for New Concept Placement in Ontologies                                                                                  We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our framework use fine-tuned PLM for search and a multi-label Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate for the task, and we propose explainable instruction tuning of LLMs for improved performance. Our study shows the advantages of PLMs and highlights the encouraging performance of LLMs that motivates future studies.
http://w3id.org/mlsea/pwc/scientificWork/A%20Large%20Language%20Model%20Enhanced%20Sequential%20Recommender%20for%20Joint%20Video%20and%20Comment%20Recommendation                                                                                  A Large Language Model Enhanced Sequential Recommender for Joint Video and Comment Recommendation                                                                                  In online video platforms, reading or writing comments on interesting videos has become an essential part of the video watching experience. However, existing video recommender systems mainly model users' interaction behaviors with videos, lacking consideration of comments in user behavior modeling. In this paper, we propose a novel recommendation approach called LSVCR by leveraging user interaction histories with both videos and comments, so as to jointly conduct personalized video and comment recommendation. Specifically, our approach consists of two key components, namely sequential recommendation (SR) model and supplemental large language model (LLM) recommender. The SR model serves as the primary recommendation backbone (retained in deployment) of our approach, allowing for efficient user preference modeling. Meanwhile, we leverage the LLM recommender as a supplemental component (discarded in deployment) to better capture underlying user preferences from heterogeneous interaction behaviors. In order to integrate the merits of the SR model and the supplemental LLM recommender, we design a twostage training paradigm. The first stage is personalized preference alignment, which aims to align the preference representations from both components, thereby enhancing the semantics of the SR model. The second stage is recommendation-oriented fine-tuning, in which the alignment-enhanced SR model is fine-tuned according to specific objectives. Extensive experiments in both video and comment recommendation tasks demonstrate the effectiveness of LSVCR. Additionally, online A/B testing on the KuaiShou platform verifies the actual benefits brought by our approach. In particular, we achieve a significant overall gain of 4.13% in comment watch time.
http://w3id.org/mlsea/pwc/scientificWork/A%20LayoutLMv3-Based%20Model%20for%20Enhanced%20Relation%20Extraction%20in%20Visually-Rich%20Documents                                                                                  A LayoutLMv3-Based Model for Enhanced Relation Extraction in Visually-Rich Documents                                                                                  Document Understanding is an evolving field in Natural Language Processing (NLP). In particular, visual and spatial features are essential in addition to the raw text itself and hence, several multimodal models were developed in the field of Visual Document Understanding (VDU). However, while research is mainly focused on Key Information Extraction (KIE), Relation Extraction (RE) between identified entities is still under-studied. For instance, RE is crucial to regroup entities or obtain a comprehensive hierarchy of data in a document. In this paper, we present a model that, initialized from LayoutLMv3, can match or outperform the current state-of-the-art results in RE applied to Visually-Rich Documents (VRD) on FUNSD and CORD datasets, without any specific pre-training and with fewer parameters. We also report an extensive ablation study performed on FUNSD, highlighting the great impact of certain features and modelization choices on the performances.
http://w3id.org/mlsea/pwc/scientificWork/A%20Learning-to-Rank%20Formulation%20of%20Clustering-Based%20Approximate%20Nearest%20Neighbor%20Search                                                                                  A Learning-to-Rank Formulation of Clustering-Based Approximate Nearest Neighbor Search                                                                                  A critical piece of the modern information retrieval puzzle is approximate nearest neighbor search. Its objective is to return a set of $k$ data points that are closest to a query point, with its accuracy measured by the proportion of exact nearest neighbors captured in the returned set. One popular approach to this question is clustering: The indexing algorithm partitions data points into non-overlapping subsets and represents each partition by a point such as its centroid. The query processing algorithm first identifies the nearest clusters -- a process known as routing -- then performs a nearest neighbor search over those clusters only. In this work, we make a simple observation: The routing function solves a ranking problem. Its quality can therefore be assessed with a ranking metric, making the function amenable to learning-to-rank. Interestingly, ground-truth is often freely available: Given a query distribution in a top-$k$ configuration, the ground-truth is the set of clusters that contain the exact top-$k$ vectors. We develop this insight and apply it to Maximum Inner Product Search (MIPS). As we demonstrate empirically on various datasets, learning a simple linear function consistently improves the accuracy of clustering-based MIPS.
http://w3id.org/mlsea/pwc/scientificWork/A%20Lightweight%20Attention-based%20Deep%20Network%20via%20Multi-Scale%20Feature%20Fusion%20for%20Multi-View%20Facial%20Expression%20Recognition                                                                                  A Lightweight Attention-based Deep Network via Multi-Scale Feature Fusion for Multi-View Facial Expression Recognition                                                                                  Convolutional neural networks (CNNs) and their variations have shown effectiveness in facial expression recognition (FER). However, they face challenges when dealing with high computational complexity and multi-view head poses in real-world scenarios. We introduce a lightweight attentional network incorporating multi-scale feature fusion (LANMSFF) to tackle these issues. For the first challenge, we have carefully designed a lightweight fully convolutional network (FCN). We address the second challenge by presenting two novel components, namely mass attention (MassAtt) and point wise feature selection (PWFS) blocks. The MassAtt block simultaneously generates channel and spatial attention maps to recalibrate feature maps by emphasizing important features while suppressing irrelevant ones. On the other hand, the PWFS block employs a feature selection mechanism that discards less meaningful features prior to the fusion process. This mechanism distinguishes it from previous methods that directly fuse multi-scale features. Our proposed approach achieved results comparable to state-of-the-art methods in terms of parameter counts and robustness to pose variation, with accuracy rates of 90.77% on KDEF, 70.44% on FER-2013, and 86.96% on FERPlus datasets. The code for LANMSFF is available at https://github.com/AE-1129/LANMSFF.
http://w3id.org/mlsea/pwc/scientificWork/A%20Lightweight%20Energy%20Management%20Method%20for%20Hybrid%20PV%2FBattery%2FLoad%20Systems                                                                                  A Lightweight Energy Management Method for Hybrid PV/Battery/Load Systems                                                                                  In this paper, a computationally lightweight algorithm is introduced for hybrid PV/Battery/Load systems that is price responsive, responds fast, does not require powerful hardware, and considers the operational limitations of the system. The method is applied to two buildings equipped with PV and battery. Simulation results show that the method can give results that are up to 3.9% more expensive than the Model predictive control (MPC) approach while the runtime of the program is up to 1000 times less than the MPC. Also, while the runtime of the proposed method is in the range of the self-consumption maximization (SCM) approach as the fastest method, its electricity cost is about 3.2% cheaper than the SCM method. Simulation results also show that in case of providing grid services by the battery the difference between electricity cost of the proposed approach and MPC can reduce which makes the method good for such applications.
http://w3id.org/mlsea/pwc/scientificWork/A%20Lightweight%20FPGA-based%20IDS-ECU%20Architecture%20for%20Automotive%20CAN                                                                                  A Lightweight FPGA-based IDS-ECU Architecture for Automotive CAN                                                                                  Recent years have seen an exponential rise in complex software-driven functionality in vehicles, leading to a rising number of electronic control units (ECUs), network capabilities, and interfaces. These expanded capabilities also bring-in new planes of vulnerabilities making intrusion detection and management a critical capability; however, this can often result in more ECUs and network elements due to the high computational overheads. In this paper, we present a consolidated ECU architecture incorporating an Intrusion Detection System (IDS) for Automotive Controller Area Network (CAN) along with traditional ECU functionality on an off-the-shelf hybrid FPGA device, with near-zero overhead for the ECU functionality. We propose two quantised multi-layer perceptrons (QMLP's) as isolated IDSs for detecting a range of attack vectors including Denial-of-Service, Fuzzing and Spoofing, which are accelerated using off-the-shelf deep-learning processing unit (DPU) IP block from Xilinx, operating fully transparently to the software on the ECU. The proposed models achieve the state-of-the-art classification accuracy for all the attacks, while we observed a 15x reduction in power consumption when compared against the GPU-based implementation of the same models quantised using Nvidia libraries. We also achieved a 2.3x speed up in per-message processing latency (at 0.24 ms from the arrival of a CAN message) to meet the strict end-to-end latency on critical CAN nodes and a 2.6x reduction in power consumption for inference when compared to the state-of-the-art IDS models on embedded IDS and loosely coupled IDS accelerators (GPUs) discussed in the literature.
http://w3id.org/mlsea/pwc/scientificWork/A%20Linear%20Time%20and%20Space%20Local%20Point%20Cloud%20Geometry%20Encoder%20via%20Vectorized%20Kernel%20Mixture%20%28VecKM%29                                                                                  A Linear Time and Space Local Point Cloud Geometry Encoder via Vectorized Kernel Mixture (VecKM)                                                                                  We propose VecKM, a novel local point cloud geometry encoder that is descriptive, efficient and robust to noise. VecKM leverages a unique approach by vectorizing a kernel mixture to represent the local point clouds. Such representation is descriptive and robust to noise, which is supported by two theorems that confirm its ability to reconstruct and preserve the similarity of the local shape. Moreover, VecKM is the first successful attempt to reduce the computation and memory costs from $O(n^2+nKd)$ to $O(nd)$ by sacrificing a marginal constant factor, where $n$ is the size of the point cloud and $K$ is neighborhood size. The efficiency is primarily due to VecKM's unique factorizable property that eliminates the need of explicitly grouping points into neighborhoods. In the normal estimation task, VecKM demonstrates not only 100x faster inference speed but also strongest descriptiveness and robustness compared with existing popular encoders. In classification and segmentation tasks, integrating VecKM as a preprocessing module achieves consistently better performance than the PointNet, PointNet++, and point transformer baselines, and runs consistently faster by up to 10x.
http://w3id.org/mlsea/pwc/scientificWork/A%20Logical%20Approach%20to%20Criminal%20Case%20Investigation                                                                                  A Logical Approach to Criminal Case Investigation                                                                                  XAI (eXplanable AI) techniques that have the property of explaining the reasons for their conclusions, i.e. explainability or interpretability, are attracting attention. XAI is expected to be used in the development of forensic science and the justice system. In today's forensic and criminal investigation environment, experts face many challenges due to large amounts of data, small pieces of evidence in a chaotic and complex environment, traditional laboratory structures and sometimes inadequate knowledge. All these can lead to failed investigations and miscarriages of justice. In this paper, we describe the application of one logical approach to crime scene investigation. The subject of the application is ``The Adventure of the Speckled Band'' from the Sherlock Holmes short stories. The applied data is the knowledge graph created for the Knowledge Graph Reasoning Challenge. We tried to find the murderer by inferring each person with the motive, opportunity, and method. We created an ontology of motives and methods of murder from dictionaries and dictionaries, added it to the knowledge graph of ``The Adventure of the Speckled Band'', and applied scripts to determine motives, opportunities, and methods.
http://w3id.org/mlsea/pwc/scientificWork/A%20Machine%20Learning%20Approach%20for%20Optimizing%20Hybrid%20Quantum%20Noise%20Clusters%20for%20Gaussian%20Quantum%20Channel%20Capacity                                                                                  A Machine Learning Approach for Optimizing Hybrid Quantum Noise Clusters for Gaussian Quantum Channel Capacity                                                                                  This work contributes to the advancement of quantum communication by visualizing hybrid quantum noise in higher dimensions and optimizing the capacity of the quantum channel by using machine learning (ML). Employing the expectation maximization (EM) algorithm, the quantum channel parameters are iteratively adjusted to estimate the channel capacity, facilitating the categorization of quantum noise data in higher dimensions into a finite number of clusters. In contrast to previous investigations that represented the model in lower dimensions, our work describes the quantum noise as a Gaussian Mixture Model (GMM) with mixing weights derived from a Poisson distribution. The objective was to model the quantum noise using a finite mixture of Gaussian components while preserving the mixing coefficients from the Poisson distribution. Approximating the infinite Gaussian mixture with a finite number of components makes it feasible to visualize clusters of quantum noise data without modifying the original probability density function. By implementing the EM algorithm, the research fine-tuned the channel parameters, identified optimal clusters, improved channel capacity estimation, and offered insights into the characteristics of quantum noise within an ML framework.
http://w3id.org/mlsea/pwc/scientificWork/A%20Material%20Sensing-Assisted%20Initial%20Beam%20Establishment%20Method%20for%20JCAS%20Systems                                                                                  A Material Sensing-Assisted Initial Beam Establishment Method for JCAS Systems                                                                                  Communication systems operating at high frequency bands must use narrow beams to compensate the high path loss. However, it is incredibly time-consuming to achieve beam alignment between the transmitter and receiver due to the large volume of beam space with narrow beams. The high latency of initial beam establishment will challenge the implementation of future 6G networks at high frequency bands. To tackle this problem, this paper proposes an initial beam establishment method using the material sensing results from joint communications and sensing (JCAS) systems. The reflection loss (RL) induced by each reflector can be predicted by exploiting the pre-identified material information of reflectors in the environment. The base station (BS) first scans the beam directions with low RL and establishes the connection immediately without sweeping the rest of the beam directions. In this way, the latency of initial beam establishment is significantly reduced.
http://w3id.org/mlsea/pwc/scientificWork/A%20Mathematical%20Theory%20for%20Learning%20Semantic%20Languages%20by%20Abstract%20Learners                                                                                  A Mathematical Theory for Learning Semantic Languages by Abstract Learners                                                                                  Recent advances in Large Language Models (LLMs) have demonstrated the emergence of capabilities (learned skills) when the number of system parameters and the size of training data surpass certain thresholds. The exact mechanisms behind such phenomena are not fully understood and remain a topic of active research. Inspired by the skill-text bipartite graph model presented in [1] for modeling semantic language, we develop a mathematical theory to explain the emergence of learned skills, taking the learning (or training) process into account. Our approach models the learning process for skills in the skill-text bipartite graph as an iterative decoding process in Low-Density Parity Check (LDPC) codes and Irregular Repetition Slotted ALOHA (IRSA). Using density evolution analysis, we demonstrate the emergence of learned skills when the ratio of the size of training texts to the number of skills exceeds a certain threshold. Our analysis also yields a scaling law for testing errors relative to the size of training texts. Upon completion of the training, we propose a method for semantic compression and discuss its application in semantic communication.
http://w3id.org/mlsea/pwc/scientificWork/A%20Method%20for%20Target%20Detection%20Based%20on%20Mmw%20Radar%20and%20Vision%20Fusion                                                                                  A Method for Target Detection Based on Mmw Radar and Vision Fusion                                                                                  An efficient and accurate traffic monitoring system often takes advantages of multi-sensor detection to ensure the safety of urban traffic, promoting the accuracy and robustness of target detection and tracking. A method for target detection using Radar-Vision Fusion Path Aggregation Fully Convolutional One-Stage Network (RV-PAFCOS) is proposed in this paper, which is extended from Fully Convolutional One-Stage Network (FCOS) by introducing the modules of radar image processing branches, radar-vision fusion and path aggregation. The radar image processing branch mainly focuses on the image modeling based on the spatiotemporal calibration of millimeter-wave (mmw) radar and cameras, taking the conversion of radar point clouds to radar images. The fusion module extracts features of radar and optical images based on the principle of spatial attention stitching criterion. The path aggregation module enhances the reuse of feature layers, combining the positional information of shallow feature maps with deep semantic information, to obtain better detection performance for both large and small targets. Through the experimental analysis, the method proposed in this paper can effectively fuse the mmw radar and vision perceptions, showing good performance in traffic target detection.
http://w3id.org/mlsea/pwc/scientificWork/A%20Methodology%20to%20Study%20the%20Impact%20of%20Spiking%20Neural%20Network%20Parameters%20considering%20Event-Based%20Automotive%20Data                                                                                  A Methodology to Study the Impact of Spiking Neural Network Parameters considering Event-Based Automotive Data                                                                                  Autonomous Driving (AD) systems are considered as the future of human mobility and transportation. Solving computer vision tasks such as image classification and object detection/segmentation, with high accuracy and low power/energy consumption, is highly needed to realize AD systems in real life. These requirements can potentially be satisfied by Spiking Neural Networks (SNNs). However, the state-of-the-art works in SNN-based AD systems still focus on proposing network models that can achieve high accuracy, and they have not systematically studied the roles of SNN parameters when used for learning event-based automotive data. Therefore, we still lack understanding of how to effectively develop SNN models for AD systems. Toward this, we propose a novel methodology to systematically study and analyze the impact of SNN parameters considering event-based automotive data, then leverage this analysis for enhancing SNN developments. To do this, we first explore different settings of SNN parameters that directly affect the learning mechanism (i.e., batch size, learning rate, neuron threshold potential, and weight decay), then analyze the accuracy results. Afterward, we propose techniques that jointly improve SNN accuracy and reduce training time. Experimental results show that our methodology can improve the SNN models for AD systems than the state-of-the-art, as it achieves higher accuracy (i.e., 86%) for the NCARS dataset, and it can also achieve iso-accuracy (i.e., ~85% with standard deviation less than 0.5%) while speeding up the training time by 1.9x. In this manner, our research work provides a set of guidelines for SNN parameter enhancements, thereby enabling the practical developments of SNN-based AD systems.
http://w3id.org/mlsea/pwc/scientificWork/A%20Model-Based%20Framework%20for%20Assessing%20the%20Physiologic%20Structure%20of%20Electrodermal%20Activity                                                                                  A Model-Based Framework for Assessing the Physiologic Structure of Electrodermal Activity                                                                                  Objective: We present a statistical model for extracting physiologic characteristics from electrodermal activity (EDA) data in observational settings. Methods: We based our model on the integrate-and-fire physiology of sweat gland bursts, which predicts inverse Gaussian (IG) inter-pulse interval structure. At the core of our model-based paradigm is a subject-specific amplitude threshold selection process for EDA pulses based on the statistical properties of four right-skewed models including the IG. By performing a sensitivity analysis across thresholds and fitting all four models, we selected for IG-like structure and verified the pulse selection with a goodness-of-fit analysis, maximizing capture of physiology at the time scale of EDA responses. Results: We tested the model-based paradigm on simulated EDA time series and data from two different experimental cohorts recorded during different experimental conditions, using different equipment. In both the simulated and experimental data, our model-based method robustly recovered pulses that captured the IG-like structure predicted by physiology, despite large differences in noise level. In contrast, established EDA analysis tools, which attempted to estimate neural activity from slower EDA responses, did not provide physiological validation and were susceptible to noise. Conclusion: We present a computationally efficient, statistically rigorous, and physiology-informed paradigm for pulse selection from EDA data that is robust across individuals and experimental conditions, yet adaptable to varying noise level. Significance: The robustness of the model-based paradigm and its physiological basis provide empirical support for the use of EDA as a clinical marker for sympathetic activity in conditions such as pain, anxiety, depression, and sleep states.
http://w3id.org/mlsea/pwc/scientificWork/A%20Modular%20Approach%20to%20Automatic%20Cyber%20Threat%20Attribution%20using%20Opinion%20Pools                                                                                  A Modular Approach to Automatic Cyber Threat Attribution using Opinion Pools                                                                                  Cyber threat attribution can play an important role in increasing resilience against digital threats. Recent research focuses on automating the threat attribution process and on integrating it with other efforts, such as threat hunting. To support increasing automation of the cyber threat attribution process, this paper proposes a modular architecture as an alternative to current monolithic automated approaches. The modular architecture can utilize opinion pools to combine the output of concrete attributors. The proposed solution increases the tractability of the threat attribution problem and offers increased usability and interpretability, as opposed to monolithic alternatives. In addition, a Pairing Aggregator is proposed as an aggregation method that forms pairs of attributors based on distinct features to produce intermediary results before finally producing a single Probability Mass Function (PMF) as output. The Pairing Aggregator sequentially applies both the logarithmic opinion pool and the linear opinion pool. An experimental validation suggests that the modular approach does not result in decreased performance and can even enhance precision and recall compared to monolithic alternatives. The results also suggest that the Pairing Aggregator can improve precision over the linear and logarithmic opinion pools. Furthermore, the improved k-accuracy in the experiment suggests that forensic experts can leverage the resulting PMF during their manual attribution processes to enhance their efficiency.
http://w3id.org/mlsea/pwc/scientificWork/A%20Moral%20Imperative%3A%20The%20Need%20for%20Continual%20Superalignment%20of%20Large%20Language%20Models                                                                                  A Moral Imperative: The Need for Continual Superalignment of Large Language Models                                                                                  This paper examines the challenges associated with achieving life-long superalignment in AI systems, particularly large language models (LLMs). Superalignment is a theoretical framework that aspires to ensure that superintelligent AI systems act in accordance with human values and goals. Despite its promising vision, we argue that achieving superalignment requires substantial changes in the current LLM architectures due to their inherent limitations in comprehending and adapting to the dynamic nature of these human ethics and evolving global scenarios. We dissect the challenges of encoding an ever-changing spectrum of human values into LLMs, highlighting the discrepancies between static AI models and the dynamic nature of human societies. To illustrate these challenges, we analyze two distinct examples: one demonstrates a qualitative shift in human values, while the other presents a quantifiable change. Through these examples, we illustrate how LLMs, constrained by their training data, fail to align with contemporary human values and scenarios. The paper concludes by exploring potential strategies to address and possibly mitigate these alignment discrepancies, suggesting a path forward in the pursuit of more adaptable and responsive AI systems.
http://w3id.org/mlsea/pwc/scientificWork/A%20Moreau%20Envelope%20Approach%20for%20LQR%20Meta-Policy%20Estimation                                                                                  A Moreau Envelope Approach for LQR Meta-Policy Estimation                                                                                  We study the problem of policy estimation for the Linear Quadratic Regulator (LQR) in discrete-time linear time-invariant uncertain dynamical systems. We propose a Moreau Envelope-based surrogate LQR cost, built from a finite set of realizations of the uncertain system, to define a meta-policy efficiently adjustable to new realizations. Moreover, we design an algorithm to find an approximate first-order stationary point of the meta-LQR cost function. Numerical results show that the proposed approach outperforms naive averaging of controllers on new realizations of the linear system. We also provide empirical evidence that our method has better sample complexity than Model-Agnostic Meta-Learning (MAML) approaches.
http://w3id.org/mlsea/pwc/scientificWork/A%20Morphologically-Aware%20Dictionary-based%20Data%20Augmentation%20Technique%20for%20Machine%20Translation%20of%20Under-Represented%20Languages                                                                                  A Morphologically-Aware Dictionary-based Data Augmentation Technique for Machine Translation of Under-Represented Languages                                                                                  The availability of parallel texts is crucial to the performance of machine translation models. However, most of the world's languages face the predominant challenge of data scarcity. In this paper, we propose strategies to synthesize parallel data relying on morpho-syntactic information and using bilingual lexicons along with a small amount of seed parallel data. Our methodology adheres to a realistic scenario backed by the small parallel seed data. It is linguistically informed, as it aims to create augmented data that is more likely to be grammatically correct. We analyze how our synthetic data can be combined with raw parallel data and demonstrate a consistent improvement in performance in our experiments on 14 languages (28 English <-> X pairs) ranging from well- to very low-resource ones. Our method leads to improvements even when using only five seed sentences and a bilingual lexicon.
http://w3id.org/mlsea/pwc/scientificWork/A%20Morphology-Based%20Investigation%20of%20Positional%20Encodings                                                                                  A Morphology-Based Investigation of Positional Encodings                                                                                  How does the importance of positional encoding in pre-trained language models (PLMs) vary across languages with different morphological complexity? In this paper, we offer the first study addressing this question, encompassing 23 morphologically diverse languages and 5 different downstream tasks. We choose two categories of tasks: syntactic tasks (part-of-speech tagging, named entity recognition, dependency parsing) and semantic tasks (natural language inference, paraphrasing). We consider language-specific BERT models trained on monolingual corpus for our investigation. The main experiment consists of nullifying the effect of positional encoding during fine-tuning and investigating its impact across various tasks and languages. Our findings demonstrate that the significance of positional encoding diminishes as the morphological complexity of a language increases. Across all experiments, we observe clustering of languages according to their morphological typology - with analytic languages at one end and synthetic languages at the opposite end.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multi-Branched%20Radial%20Basis%20Network%20Approach%20to%20Predicting%20Complex%20Chaotic%20Behaviours                                                                                  A Multi-Branched Radial Basis Network Approach to Predicting Complex Chaotic Behaviours                                                                                  In this study, we propose a multi branched network approach to predict the dynamics of a physics attractor characterized by intricate and chaotic behavior. We introduce a unique neural network architecture comprised of Radial Basis Function (RBF) layers combined with an attention mechanism designed to effectively capture nonlinear inter-dependencies inherent in the attractor's temporal evolution. Our results demonstrate successful prediction of the attractor's trajectory across 100 predictions made using a real-world dataset of 36,700 time-series observations encompassing approximately 28 minutes of activity. To further illustrate the performance of our proposed technique, we provide comprehensive visualizations depicting the attractor's original and predicted behaviors alongside quantitative measures comparing observed versus estimated outcomes. Overall, this work showcases the potential of advanced machine learning algorithms in elucidating hidden structures in complex physical systems while offering practical applications in various domains requiring accurate short-term forecasting capabilities.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multi-Task%20Oriented%20Semantic%20Communication%20Framework%20for%20Autonomous%20Vehicles                                                                                  A Multi-Task Oriented Semantic Communication Framework for Autonomous Vehicles                                                                                  Task-oriented semantic communication is an emerging technology that transmits only the relevant semantics of a message instead of the whole message to achieve a specific task. It reduces latency, compresses the data, and is more robust in low SNR scenarios. This work presents a multi-task-oriented semantic communication framework for connected and autonomous vehicles (CAVs). We propose a convolutional autoencoder (CAE) that performs the semantic encoding of the road traffic signs. These encoded images are then transmitted from one CAV to another CAV through satellite in challenging weather conditions where visibility is impaired. In addition, we propose task-oriented semantic decoders for image reconstruction and classification tasks. Simulation results show that the proposed framework outperforms the conventional schemes, such as QAM-16, regarding the reconstructed image's similarity and the classification's accuracy. In addition, it can save up to 89 % of the bandwidth by sending fewer bits.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multimodal%20In-Context%20Tuning%20Approach%20for%20E-Commerce%20Product%20Description%20Generation                                                                                  A Multimodal In-Context Tuning Approach for E-Commerce Product Description Generation                                                                                  In this paper, we propose a new setting for generating product descriptions from images, augmented by marketing keywords. It leverages the combined power of visual and textual information to create descriptions that are more tailored to the unique features of products. For this setting, previous methods utilize visual and textual encoders to encode the image and keywords and employ a language model-based decoder to generate the product description. However, the generated description is often inaccurate and generic since same-category products have similar copy-writings, and optimizing the overall framework on large-scale samples makes models concentrate on common words yet ignore the product features. To alleviate the issue, we present a simple and effective Multimodal In-Context Tuning approach, named ModICT, which introduces a similar product sample as the reference and utilizes the in-context learning capability of language models to produce the description. During training, we keep the visual encoder and language model frozen, focusing on optimizing the modules responsible for creating multimodal in-context references and dynamic prompts. This approach preserves the language generation prowess of large language models (LLMs), facilitating a substantial increase in description diversity. To assess the effectiveness of ModICT across various language model scales and types, we collect data from three distinct product categories within the E-commerce domain. Extensive experiments demonstrate that ModICT significantly improves the accuracy (by up to 3.3% on Rouge-L) and diversity (by up to 9.4% on D-5) of generated results compared to conventional methods. Our findings underscore the potential of ModICT as a valuable tool for enhancing automatic generation of product descriptions in a wide range of applications. Code is at: https://github.com/HITsz-TMG/Multimodal-In-Context-Tuning
http://w3id.org/mlsea/pwc/scientificWork/A%20Neuro-Symbolic%20Approach%20to%20Monitoring%20Salt%20Content%20in%20Food                                                                                  A Neuro-Symbolic Approach to Monitoring Salt Content in Food                                                                                  We propose a dialogue system that enables heart failure patients to inquire about salt content in foods and help them monitor and reduce salt intake. Addressing the lack of specific datasets for food-based salt content inquiries, we develop a template-based conversational dataset. The dataset is structured to ask clarification questions to identify food items and their salt content. Our findings indicate that while fine-tuning transformer-based models on the dataset yields limited performance, the integration of Neuro-Symbolic Rules significantly enhances the system's performance. Our experiments show that by integrating neuro-symbolic rules, our system achieves an improvement in joint goal accuracy of over 20% across different data sizes compared to naively fine-tuning transformer-based models.
http://w3id.org/mlsea/pwc/scientificWork/A%20Neuro-Symbolic%20Approach%20to%20Multi-Agent%20RL%20for%20Interpretability%20and%20Probabilistic%20Decision%20Making                                                                                  A Neuro-Symbolic Approach to Multi-Agent RL for Interpretability and Probabilistic Decision Making                                                                                  Multi-agent reinforcement learning (MARL) is well-suited for runtime decision-making in optimizing the performance of systems where multiple agents coexist and compete for shared resources. However, applying common deep learning-based MARL solutions to real-world problems suffers from issues of interpretability, sample efficiency, partial observability, etc. To address these challenges, we present an event-driven formulation, where decision-making is handled by distributed co-operative MARL agents using neuro-symbolic methods. The recently introduced neuro-symbolic Logical Neural Networks (LNN) framework serves as a function approximator for the RL, to train a rules-based policy that is both logical and interpretable by construction. To enable decision-making under uncertainty and partial observability, we developed a novel probabilistic neuro-symbolic framework, Probabilistic Logical Neural Networks (PLNN), which combines the capabilities of logical reasoning with probabilistic graphical models. In PLNN, the upward/downward inference strategy, inherited from LNN, is coupled with belief bounds by setting the activation function for the logical operator associated with each neural network node to a probability-respecting generalization of the Fr 'echet inequalities. These PLNN nodes form the unifying element that combines probabilistic logic and Bayes Nets, permitting inference for variables with unobserved states. We demonstrate our contributions by addressing key MARL challenges for power sharing in a system-on-chip application.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Era%20in%20LLM%20Security%3A%20Exploring%20Security%20Concerns%20in%20Real-World%20LLM-based%20Systems                                                                                  A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems                                                                                  Large Language Model (LLM) systems are inherently compositional, with individual LLM serving as the core foundation with additional layers of objects such as plugins, sandbox, and so on. Along with the great potential, there are also increasing concerns over the security of such probabilistic intelligent systems. However, existing studies on LLM security often focus on individual LLM, but without examining the ecosystem through the lens of LLM systems with other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we systematically analyze the security of LLM systems, instead of focusing on the individual LLMs. To do so, we build on top of the information flow and formulate the security of LLM systems as constraints on the alignment of the information flow within LLM and between LLM and other objects. Based on this construction and the unique probabilistic nature of LLM, the attack surface of the LLM system can be decomposed into three key components: (1) multi-layer security analysis, (2) analysis of the existence of constraints, and (3) analysis of the robustness of these constraints. To ground this new attack surface, we propose a multi-layer and multi-step approach and apply it to the state-of-art LLM system, OpenAI GPT4. Our investigation exposes several security issues, not just within the LLM model itself but also in its integration with other components. We found that although the OpenAI GPT4 has designed numerous safety constraints to improve its safety features, these safety constraints are still vulnerable to attackers. To further demonstrate the real-world threats of our discovered vulnerabilities, we construct an end-to-end attack where an adversary can illicitly acquire the user's chat history, all without the need to manipulate the user's input or gain direct access to OpenAI GPT4. Our demo is in the link: https://fzwark.github.io/LLM-System-Attack-Demo/
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Massive%20Multilingual%20Dataset%20for%20High-Performance%20Language%20Technologies                                                                                  A New Massive Multilingual Dataset for High-Performance Language Technologies                                                                                  We present the HPLT (High Performance Language Technologies) language resources, a new massive multilingual dataset including both monolingual and bilingual corpora extracted from CommonCrawl and previously unused web crawls from the Internet Archive. We describe our methods for data acquisition, management and processing of large corpora, which rely on open-source software tools and high-performance computing. Our monolingual collection focuses on low- to medium-resourced languages and covers 75 languages and a total of ~5.6 trillion word tokens de-duplicated on the document level. Our English-centric parallel corpus is derived from its monolingual counterpart and covers 18 language pairs and more than 96 million aligned sentence pairs with roughly 1.4 billion English tokens. The HPLT language resources are one of the largest open text corpora ever released, providing a great resource for language modeling and machine translation training. We publicly release the corpora, the software, and the tools used in this work.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Sentence%20Extraction%20Strategy%20for%20Unsupervised%20Extractive%20Summarization%20Methods                                                                                  A New Sentence Extraction Strategy for Unsupervised Extractive Summarization Methods                                                                                  In recent years, text summarization methods have attracted much attention again thanks to the researches on neural network models. Most of the current text summarization methods based on neural network models are supervised methods which need large-scale datasets. However, large-scale datasets are difficult to obtain in practical applications. In this paper, we model the task of extractive text summarization methods from the perspective of Information Theory, and then describe the unsupervised extractive methods with a uniform framework. To improve the feature distribution and to decrease the mutual information of summarization sentences, we propose a new sentence extraction strategy which can be applied to existing unsupervised extractive methods. Experiments are carried out on different datasets, and results show that our strategy is indeed effective and in line with expectations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Nonlinear%20Observer%20Design%20for%20the%20Discrete-time%20Systems%3A%20Exploiting%20Matrix-Multiplier-based%20LMI%20Approach                                                                                  A Nonlinear Observer Design for the Discrete-time Systems: Exploiting Matrix-Multiplier-based LMI Approach                                                                                  This letter focuses on the $ mathcal{H}_ infty$ observer design for a class of nonlinear discrete systems under the presence of measurement noise or external disturbances. A novel Linear Matrix Inequality (LMI) condition is developed in this method through the utilisation of the reformulated Lipschitz property, a new variant of Young inequality and the well-known Linear Parameter Varying (LPV) approach. One of the key components of the proposed LMI is the generalised matrix multipliers. The deliberate use of these multipliers enables us to introduce more numbers of decision variables inside LMIs than the one illustrated in the literature. It aids in adding some extra degrees of freedom from a feasibility point of view, thus enhancing the LMI conditions. Thus, the proposed LMIs are less conservative than existing ones. Later on, the effectiveness of the developed LMIs and observer is highlighted through the numerical example and an application of state of charge (SoC) estimation in the Li-ion battery model.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Corpus%20of%20Annotated%20Medical%20Imaging%20Reports%20and%20Information%20Extraction%20Results%20Using%20BERT-based%20Language%20Models                                                                                  A Novel Corpus of Annotated Medical Imaging Reports and Information Extraction Results Using BERT-based Language Models                                                                                  Medical imaging is critical to the diagnosis, surveillance, and treatment of many health conditions, including oncological, neurological, cardiovascular, and musculoskeletal disorders, among others. Radiologists interpret these complex, unstructured images and articulate their assessments through narrative reports that remain largely unstructured. This unstructured narrative must be converted into a structured semantic representation to facilitate secondary applications such as retrospective analyses or clinical decision support. Here, we introduce the Corpus of Annotated Medical Imaging Reports (CAMIR), which includes 609 annotated radiology reports from three imaging modality types: Computed Tomography, Magnetic Resonance Imaging, and Positron Emission Tomography-Computed Tomography. Reports were annotated using an event-based schema that captures clinical indications, lesions, and medical problems. Each event consists of a trigger and multiple arguments, and a majority of the argument types, including anatomy, normalize the spans to pre-defined concepts to facilitate secondary use. CAMIR uniquely combines a granular event structure and concept normalization. To extract CAMIR events, we explored two BERT (Bi-directional Encoder Representation from Transformers)-based architectures, including an existing architecture (mSpERT) that jointly extracts all event information and a multi-step approach (PL-Marker++) that we augmented for the CAMIR schema.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Feature%20Learning-based%20Bio-inspired%20Neural%20Network%20for%20Real-time%20Collision-free%20Rescue%20of%20Multi-Robot%20Systems                                                                                  A Novel Feature Learning-based Bio-inspired Neural Network for Real-time Collision-free Rescue of Multi-Robot Systems                                                                                  Natural disasters and urban accidents drive the demand for rescue robots to provide safer, faster, and more efficient rescue trajectories. In this paper, a feature learning-based bio-inspired neural network (FLBBINN) is proposed to quickly generate a heuristic rescue path in complex and dynamic environments, as traditional approaches usually cannot provide a satisfactory solution to real-time responses to sudden environmental changes. The neurodynamic model is incorporated into the feature learning method that can use environmental information to improve path planning strategies. Task assignment and collision-free rescue trajectory are generated through robot poses and the dynamic landscape of neural activity. A dual-channel scale filter, a neural activity channel, and a secondary distance fusion are employed to extract and filter feature neurons. After completion of the feature learning process, a neurodynamics-based feature matrix is established to quickly generate the new heuristic rescue paths with parameter-driven topological adaptability. The proposed FLBBINN aims to reduce the computational complexity of the neural network-based approach and enable the feature learning method to achieve real-time responses to environmental changes. Several simulations and experiments have been conducted to evaluate the performance of the proposed FLBBINN. The results show that the proposed FLBBINN would significantly improve the speed, efficiency, and optimality for rescue operations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Framework%20for%20Multi-Person%20Temporal%20Gaze%20Following%20and%20Social%20Gaze%20Prediction                                                                                  A Novel Framework for Multi-Person Temporal Gaze Following and Social Gaze Prediction                                                                                  Gaze following and social gaze prediction are fundamental tasks providing insights into human communication behaviors, intent, and social interactions. Most previous approaches addressed these tasks separately, either by designing highly specialized social gaze models that do not generalize to other social gaze tasks or by considering social gaze inference as an ad-hoc post-processing of the gaze following task. Furthermore, the vast majority of gaze following approaches have proposed static models that can handle only one person at a time, therefore failing to take advantage of social interactions and temporal dynamics. In this paper, we address these limitations and introduce a novel framework to jointly predict the gaze target and social gaze label for all people in the scene. The framework comprises of: (i) a temporal, transformer-based architecture that, in addition to image tokens, handles person-specific tokens capturing the gaze information related to each individual; (ii) a new dataset, VSGaze, that unifies annotation types across multiple gaze following and social gaze datasets. We show that our model trained on VSGaze can address all tasks jointly, and achieves state-of-the-art results for multi-person gaze following and social gaze prediction.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Geometric%20Solution%20for%20Moving%20Target%20Localization%20through%20Multistatic%20Sensing%20in%20the%20ISAC%20System                                                                                  A Novel Geometric Solution for Moving Target Localization through Multistatic Sensing in the ISAC System                                                                                  This paper proposes a novel geometric solution for tracking a moving target through multistatic sensing. In contrast to existing two-step weighted least square (2SWLS) methods which use the bistatic range (BR) and bistatic range rate (BRR) measurements, the proposed method incorporates an additional direction of arrival (DOA) measurement of the target obtained from a communication receiver in an integrated sensing and communication (ISAC) system. Unlike the existing 2SWLS methods that require at least three transmitter-receiver (TX-RX) pairs to operate, the proposed algorithm can conduct location estimation with a single TX-RX pair and velocity estimation with two TX-RX pairs. Simulations reveal that the proposed method exhibits superior performance compared to existing 2SWLS methods, particularly when dealing with moderate levels of noise in DOA measurements.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Hybrid%20Feature%20Importance%20and%20Feature%20Interaction%20Detection%20Framework%20for%20Predictive%20Optimization%20in%20Industry%204.0%20Applications                                                                                  A Novel Hybrid Feature Importance and Feature Interaction Detection Framework for Predictive Optimization in Industry 4.0 Applications                                                                                  Advanced machine learning algorithms are increasingly utilized to provide data-based prediction and decision-making support in Industry 4.0. However, the prediction accuracy achieved by the existing models is insufficient to warrant practical implementation in real-world applications. This is because not all features present in real-world datasets possess a direct relevance to the predictive analysis being conducted. Consequently, the careful incorporation of select features has the potential to yield a substantial positive impact on the outcome. To address the research gap, this paper proposes a novel hybrid framework that combines the feature importance detector - local interpretable model-agnostic explanations (LIME) and the feature interaction detector - neural interaction detection (NID), to improve prediction accuracy. By applying the proposed framework, unnecessary features can be eliminated, and interactions are encoded to generate a more conducive dataset for predictive purposes. Subsequently, the proposed model is deployed to refine the prediction of electricity consumption in foundry processing. The experimental outcomes reveal an augmentation of up to 9.56% in the R2 score, and a diminution of up to 24.05% in the root mean square error.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Method%20for%20Clustering%20Cellular%20Data%20to%20Improve%20Classification                                                                                  A Novel Method for Clustering Cellular Data to Improve Classification                                                                                  Many fields, such as neuroscience, are experiencing the vast proliferation of cellular data, underscoring the need for organizing and interpreting large datasets. A popular approach partitions data into manageable subsets via hierarchical clustering, but objective methods to determine the appropriate classification granularity are missing. We recently introduced a technique to systematically identify when to stop subdividing clusters based on the fundamental principle that cells must differ more between than within clusters. Here we present the corresponding protocol to classify cellular datasets by combining data-driven unsupervised hierarchical clustering with statistical testing. These general-purpose functions are applicable to any cellular dataset that can be organized as two-dimensional matrices of numerical values, including molecular, physiological, and anatomical datasets. We demonstrate the protocol using cellular data from the Janelia MouseLight project to characterize morphological aspects of neurons.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Observer-Centric%20Approach%20for%20Detecting%20Faults%20in%20Islanded%20AC%20Microgrids%20with%20Uncertainties                                                                                  A Novel Observer-Centric Approach for Detecting Faults in Islanded AC Microgrids with Uncertainties                                                                                  Fault detection is vital in ensuring AC microgrids' reliable and resilient operation. Its importance lies in swiftly identifying and isolating faults, preventing cascading failures, and enabling rapid power restoration. This paper proposes a strategy based on observers and residuals for detecting internal faults in grid-forming inverters with power-sharing coordination. The dynamics of the inverters are captured through a nonlinear state space model. The design of our observers and residuals considers $H_{-}/H_{ infty}$ conditions to ensure robustness against disturbances and responsiveness to faults. The proposed design is less restrictive than existing observer-based fault detection schemes by leveraging the properties of quadratic inner-boundedness and one-sided Lipschitz conditions. The internal faults considered in this paper include actuator faults, busbar faults, and inverter bridge faults, which are modeled using vector-matrix representations that modify the state space model of the inverters. One significant advantage of the proposed approach is its cost-effectiveness, as it does not require additional sensors. Experiments are conducted on an islanded AC microgrid with three inductive lines, four inductive loads, and four grid-forming inverters to validate the merits of the proposed fault detection strategy. The results demonstrate that our design outperforms existing methods in the field.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Steganography%20Technique%20for%20Digital%20Images%20Using%20the%20Least%20Significant%20Bit%20Substitution%20Method                                                                                  A Novel Steganography Technique for Digital Images Using the Least Significant Bit Substitution Method                                                                                  Communication has become a lot easier in this era of technology, development of high-speed computer networks, and the inexpensive uses of Internet. Therefore, data transmission has become vulnerable to and unsafe from different external attacks. Every communication body wants to secure their data while communicating over the Internet. The internet has various bene ts but the main demerit is the privacy and security and the transmission of data over insecure network or channel may happen. Various techniques used for secure communication in order to address these issues, steganography plays an important role. Steganography is the process of obfuscation that makes something incomprehensible and unclear. Different image steganography research methods are proposed recently but each has their advantages and disadvantages and still have necessity to develop some better image steganography mechanisms to achieve the reliability between the basics criteria of image steganography. Therefore, the proposedwork, in this paper, is based on the Least Signi cant Bit (LSB) substitution method. The LSB substitution method can minimize the error rate in embedding process and can achieve greater reliability in criteria, using novel algorithm based on value difference. In this paper, we proposed a novel technique in steganography within the digital images such is RGB, Gray Scale, Texture, Aerial images to achieve higher security, imperceptibility, capacity, and robustness as compared with existing methods. The experimental outcomes of the suggested approach prove further developed strength and justify the feasibility of our research. Through numerical simulations, we observed that the proposed strategy outperformed the next-best current methodology by 5.561 percent in terms of PSNR Correlation score. Additionally, the proposed approach achieved a 6.43 percent better score in PSNR with a variable measure of code inserted in similar images with distinct dimensions. Furthermore, encrypting the same amount of information in images of varying sizes resulted in approximately 6.77 percent improvements. Embedding different sizes of a particular secret message in a different image (such as Gray, Texture, Aerial and RGB images) came out with about 5.466 percent of better score.
http://w3id.org/mlsea/pwc/scientificWork/A%20Parameter%20Privacy-Preserving%20Strategy%20for%20Mixed-Autonomy%20Platoon%20Control                                                                                  A Parameter Privacy-Preserving Strategy for Mixed-Autonomy Platoon Control                                                                                  It has been demonstrated that leading cruise control (LCC) can improve the operation of mixed-autonomy platoons by allowing connected and automated vehicles (CAVs) to make longitudinal control decisions based on the information provided by surrounding vehicles. However, LCC generally requires surrounding human-driven vehicles (HDVs) to share their real-time states, which can be used by adversaries to infer drivers' car-following behavior, potentially leading to financial losses or safety concerns. This paper aims to address such privacy concerns and protect the behavioral characteristics of HDVs by devising a parameter privacy-preserving approach for mixed-autonomy platoon control. First, we integrate a parameter privacy filter into LCC to protect sensitive car-following parameters. The privacy filter allows each vehicle to generate seemingly realistic pseudo states by distorting the true parameters to pseudo parameters, which can protect drivers' privacy in behavioral parameters without significantly influencing the control performance. Second, to enhance the practicality and reliability of the privacy filter within LCC, we first extend the current approach to accommodate continuous parameter spaces through a neural network estimator. Subsequently, we introduce an individual-level parameter privacy preservation constraint, focusing on the privacy level of each individual parameter pair, further enhancing the approach's reliability. Third, analysis of head-to-tail string stability reveals the potential impact of privacy filters in degrading mixed traffic flow performance. Simulation shows that this approach can effectively trade off privacy and control performance in LCC. We further demonstrate the benefit of such an approach in networked systems, i.e., by applying the privacy filter to a proceeding vehicle, one can also achieve a certain level of privacy for the following vehicle.
http://w3id.org/mlsea/pwc/scientificWork/A%20Path%20Towards%20Legal%20Autonomy%3A%20An%20interoperable%20and%20explainable%20approach%20to%20extracting%2C%20transforming%2C%20loading%20and%20computing%20legal%20information%20using%20large%20language%20models%2C%20expert%20systems%20and%20Bayesian%20networks                                                                                  A Path Towards Legal Autonomy: An interoperable and explainable approach to extracting, transforming, loading and computing legal information using large language models, expert systems and Bayesian networks                                                                                  Legal autonomy - the lawful activity of artificial intelligence agents - can be achieved in one of two ways. It can be achieved either by imposing constraints on AI actors such as developers, deployers and users, and on AI resources such as data, or by imposing constraints on the range and scope of the impact that AI agents can have on the environment. The latter approach involves encoding extant rules concerning AI driven devices into the software of AI agents controlling those devices (e.g., encoding rules about limitations on zones of operations into the agent software of an autonomous drone device). This is a challenge since the effectivity of such an approach requires a method of extracting, loading, transforming and computing legal information that would be both explainable and legally interoperable, and that would enable AI agents to reason about the law. In this paper, we sketch a proof of principle for such a method using large language models (LLMs), expert legal systems known as legal decision paths, and Bayesian networks. We then show how the proposed method could be applied to extant regulation in matters of autonomous cars, such as the California Vehicle Code.
http://w3id.org/mlsea/pwc/scientificWork/A%20Personalized%20Framework%20for%20Consumer%20and%20Producer%20Group%20Fairness%20Optimization%20in%20Recommender%20Systems                                                                                  A Personalized Framework for Consumer and Producer Group Fairness Optimization in Recommender Systems                                                                                  In recent years, there has been an increasing recognition that when machine learning (ML) algorithms are used to automate decisions, they may mistreat individuals or groups, with legal, ethical, or economic implications. Recommender systems are prominent examples of these machine learning (ML) systems that aid users in making decisions. The majority of past literature research on RS fairness treats user and item fairness concerns independently, ignoring the fact that recommender systems function in a two-sided marketplace. In this paper, we propose CP-FairRank, an optimization-based re-ranking algorithm that seamlessly integrates fairness constraints from both the consumer and producer side in a joint objective framework. The framework is generalizable and may take into account varied fairness settings based on group segmentation, recommendation model selection, and domain, which is one of its key characteristics. For instance, we demonstrate that the system may jointly increase consumer and producer fairness when (un)protected consumer groups are defined on the basis of their activity level and main-streamness, while producer groups are defined according to their popularity level. For empirical validation, through large-scale on eight datasets and four mainstream collaborative filtering (CF) recommendation models, we demonstrate that our proposed strategy is able to improve both consumer and producer fairness without compromising or very little overall recommendation quality, demonstrating the role algorithms may play in avoiding data biases.
http://w3id.org/mlsea/pwc/scientificWork/A%20Perspective%20on%20Individualized%20Treatment%20Effects%20Estimation%20from%20Time-series%20Health%20Data                                                                                  A Perspective on Individualized Treatment Effects Estimation from Time-series Health Data                                                                                  The burden of diseases is rising worldwide, with unequal treatment efficacy for patient populations that are underrepresented in clinical trials. Healthcare, however, is driven by the average population effect of medical treatments and, therefore, operates in a 'one-size-fits-all' approach, not necessarily what best fits each patient. These facts suggest a pressing need for methodologies to study individualized treatment effects (ITE) to drive personalized treatment. Despite the increased interest in machine-learning-driven ITE estimation models, the vast majority focus on tabular data with limited review and understanding of methodologies proposed for time-series electronic health records (EHRs). To this end, this work provides an overview of ITE works for time-series data and insights into future research. The work summarizes the latest work in the literature and reviews it in light of theoretical assumptions, types of treatment settings, and computational frameworks. Furthermore, this work discusses challenges and future research directions for ITEs in a time-series setting. We hope this work opens new directions and serves as a resource for understanding one of the exciting yet under-studied research areas.
http://w3id.org/mlsea/pwc/scientificWork/A%20Phone-based%20Distributed%20Ambient%20Temperature%20Measurement%20System%20with%20An%20Efficient%20Label-free%20Automated%20Training%20Strategy                                                                                  A Phone-based Distributed Ambient Temperature Measurement System with An Efficient Label-free Automated Training Strategy                                                                                  Enhancing the energy efficiency of buildings significantly relies on monitoring indoor ambient temperature. The potential limitations of conventional temperature measurement techniques, together with the omnipresence of smartphones, have redirected researchers' attention towards the exploration of phone-based ambient temperature estimation technology. Nevertheless, numerous obstacles remain to be addressed in order to achieve a practical implementation of this technology. This study proposes a distributed phone-based ambient temperature estimation system which enables collaboration between multiple phones to accurately measure the ambient temperature in each small area of an indoor space. Besides, it offers a secure, efficient, and cost-effective training strategy to train a new estimation model for each newly added phone, eliminating the need for manual collection of labeled data. This innovative training strategy can yield a high-performing estimation model for a new phone with just 5 data points, requiring only a few iterations. Meanwhile, by crowdsourcing, our system automatically provides accurate inferred labels for all newly collected data. We also highlight the potential of integrating federated learning into our system to ensure privacy protection at the end of this study. We believe this study has the potential to advance the practical application of phone-based ambient temperature measurement, facilitating energy-saving efforts in buildings.
http://w3id.org/mlsea/pwc/scientificWork/A%20Photonic%20Physically%20Unclonable%20Function%27s%20Resilience%20to%20Multiple-Valued%20Machine%20Learning%20Attacks                                                                                  A Photonic Physically Unclonable Function's Resilience to Multiple-Valued Machine Learning Attacks                                                                                  Physically unclonable functions (PUFs) identify integrated circuits using nonlinearly-related challenge-response pairs (CRPs). Ideally, the relationship between challenges and corresponding responses is unpredictable, even if a subset of CRPs is known. Previous work developed a photonic PUF offering improved security compared to non-optical counterparts. Here, we investigate this PUF's susceptibility to Multiple-Valued-Logic-based machine learning attacks. We find that approximately 1,000 CRPs are necessary to train models that predict response bits better than random chance. Given the significant challenge of acquiring a vast number of CRPs from a photonic PUF, our results demonstrate photonic PUF resilience against such attacks.
http://w3id.org/mlsea/pwc/scientificWork/A%20Physics-embedded%20Deep%20Learning%20Framework%20for%20Cloth%20Simulation                                                                                  A Physics-embedded Deep Learning Framework for Cloth Simulation                                                                                  Delicate cloth simulations have long been desired in computer graphics. Various methods were proposed to improve engaged force interactions, collision handling, and numerical integrations. Deep learning has the potential to achieve fast and real-time simulation, but common neural network structures often demand many parameters to capture cloth dynamics. This paper proposes a physics-embedded learning framework that directly encodes physical features of cloth simulation. The convolutional neural network is used to represent spatial correlations of the mass-spring system, after which three branches are designed to learn linear, nonlinear, and time derivate features of cloth physics. The framework can also integrate with other external forces and collision handling through either traditional simulators or sub neural networks. The model is tested across different cloth animation cases, without training with new data. Agreement with baselines and predictive realism successfully validate its generalization ability. Inference efficiency of the proposed model also defeats traditional physics simulation. This framework is also designed to easily integrate with other visual refinement techniques like wrinkle carving, which leaves significant chances to incorporate prevailing macing learning techniques in 3D cloth amination.
http://w3id.org/mlsea/pwc/scientificWork/A%20Practical%20and%20Online%20Trajectory%20Planner%20for%20Autonomous%20Ships%27%20Berthing%2C%20Incorporating%20Speed%20Control                                                                                  A Practical and Online Trajectory Planner for Autonomous Ships' Berthing, Incorporating Speed Control                                                                                  Autonomous ships are essentially designed and equipped to perceive their internal and external environment and subsequently perform appropriate actions depending on the predetermined objective(s) without human intervention. Consequently, trajectory planning algorithms for autonomous berthing must consider factors such as system dynamics, ship actuators, environmental disturbances, and the safety of the ship, other ships, and port structures, among others. In this study, basing the ship dynamics on the low-speed MMG model, trajectory planning for an autonomous ship is modeled as an optimal control problem (OCP) that is transcribed into a nonlinear programming problem (NLP) using the direct multiple shooting technique. To enhance berthing safety, besides considering wind disturbances, speed control, actuators' limitations, and collision avoidance features are incorporated as constraints in the NLP, which is then solved using the Sequential Quadratic Programming (SQP) algorithm in MATLAB. Finally, the performance of the proposed planner is evaluated through (i) comparison with solutions obtained using CMA-ES for two different model ships, (ii) trajectory planning for different harbor entry and berth approach scenarios, and (iii) feasibility study using stochastically generated initial conditions and positions within the port boundaries. Simulation results indicate enhanced berthing safety as well as practical and computational feasibility making the planner suitable for real-time applications.
http://w3id.org/mlsea/pwc/scientificWork/A%20Probabilistic%20Approach%20for%20Alignment%20with%20Human%20Comparisons                                                                                  A Probabilistic Approach for Alignment with Human Comparisons                                                                                  A growing trend involves integrating human knowledge into learning frameworks, leveraging subtle human feedback to refine AI models. Despite these advances, no comprehensive theoretical framework describing the specific conditions under which human comparisons improve the traditional supervised fine-tuning process has been developed. To bridge this gap, this paper studies the effective use of human comparisons to address limitations arising from noisy data and high-dimensional models. We propose a two-stage 'Supervised Fine Tuning+Human Comparison' (SFT+HC) framework connecting machine learning with human feedback through a probabilistic bisection approach. The two-stage framework first learns low-dimensional representations from noisy-labeled data via an SFT procedure, and then uses human comparisons to improve the model alignment. To examine the efficacy of the alignment phase, we introduce a novel concept termed the 'label-noise-to-comparison-accuracy' (LNCA) ratio. This paper theoretically identifies the conditions under which the 'SFT+HC' framework outperforms pure SFT approach, leveraging this ratio to highlight the advantage of incorporating human evaluators in reducing sample complexity. We validate that the proposed conditions for the LNCA ratio are met in a case study conducted via an Amazon Mechanical Turk experiment.
http://w3id.org/mlsea/pwc/scientificWork/A%20Quadrature%20Approach%20for%20General-Purpose%20Batch%20Bayesian%20Optimization%20via%20Probabilistic%20Lifting                                                                                  A Quadrature Approach for General-Purpose Batch Bayesian Optimization via Probabilistic Lifting                                                                                  Parallelisation in Bayesian optimisation is a common strategy but faces several challenges: the need for flexibility in acquisition functions and kernel choices, flexibility dealing with discrete and continuous variables simultaneously, model misspecification, and lastly fast massive parallelisation. To address these challenges, we introduce a versatile and modular framework for batch Bayesian optimisation via probabilistic lifting with kernel quadrature, called SOBER, which we present as a Python library based on GPyTorch/BoTorch. Our framework offers the following unique benefits: (1) Versatility in downstream tasks under a unified approach. (2) A gradient-free sampler, which does not require the gradient of acquisition functions, offering domain-agnostic sampling (e.g., discrete and mixed variables, non-Euclidean space). (3) Flexibility in domain prior distribution. (4) Adaptive batch size (autonomous determination of the optimal batch size). (5) Robustness against a misspecified reproducing kernel Hilbert space. (6) Natural stopping criterion.
http://w3id.org/mlsea/pwc/scientificWork/A%20Quasi-Stationary%20Approach%20to%20Metastability%20in%20a%20System%20of%20Spiking%20Neurons%20with%20Synaptic%20Plasticity                                                                                  A Quasi-Stationary Approach to Metastability in a System of Spiking Neurons with Synaptic Plasticity                                                                                  After reviewing the behavioral studies of working memory and of the cellular substrate of the latter, we argue that metastable states constitute candidates for the type of transient information storage required by working memory. We then present a simple neural network model made of stochastic units whose synapses exhibit short-term facilitation. The Markov process dynamics of this model was specifically designed to be analytically tractable, simple to simulate numerically and to exhibit a quasi-stationary distribution (QSD). Since the state space is finite this QSD is also a Yaglom limit, which allows us to bridge the gap between quasi-stationarity and metastability by considering the relative orders of magnitude of the relaxation and absorption times. We present first analytical results: characterization of the absorbing region of the Markov process, irreducibility outside this absorbing region and consequently existence and uniqueness of a QSD. We then apply Perron-Frobenius spectral analysis to obtain any specific QSD, and design an approximate method for the first moments of this QSD when the exact method is intractable. Finally we use these methods to study the relaxation time toward the QSD and establish numerically the memorylessness of the time of extinction.
http://w3id.org/mlsea/pwc/scientificWork/A%20Question%20Answering%20Based%20Pipeline%20for%20Comprehensive%20Chinese%20EHR%20Information%20Extraction                                                                                  A Question Answering Based Pipeline for Comprehensive Chinese EHR Information Extraction                                                                                  Electronic health records (EHRs) hold significant value for research and applications. As a new way of information extraction, question answering (QA) can extract more flexible information than conventional methods and is more accessible to clinical researchers, but its progress is impeded by the scarcity of annotated data. In this paper, we propose a novel approach that automatically generates training data for transfer learning of QA models. Our pipeline incorporates a preprocessing module to handle challenges posed by extraction types that are not readily compatible with extractive QA frameworks, including cases with discontinuous answers and many-to-one relationships. The obtained QA model exhibits excellent performance on subtasks of information extraction in EHRs, and it can effectively handle few-shot or zero-shot settings involving yes-no questions. Case studies and ablation studies demonstrate the necessity of each component in our design, and the resulting model is deemed suitable for practical use.
http://w3id.org/mlsea/pwc/scientificWork/A%20Real-Time%20Rescheduling%20Algorithm%20for%20Multi-robot%20Plan%20Execution                                                                                  A Real-Time Rescheduling Algorithm for Multi-robot Plan Execution                                                                                  One area of research in multi-agent path finding is to determine how replanning can be efficiently achieved in the case of agents being delayed during execution. One option is to reschedule the passing order of agents, i.e., the sequence in which agents visit the same location. In response, we propose Switchable-Edge Search (SES), an A*-style algorithm designed to find optimal passing orders. We prove the optimality of SES and evaluate its efficiency via simulations. The best variant of SES takes less than 1 second for small- and medium-sized problems and runs up to 4 times faster than baselines for large-sized problems.
http://w3id.org/mlsea/pwc/scientificWork/A%20Recipe%20for%20CAC%3A%20Mosaic-based%20Generalized%20Loss%20for%20Improved%20Class-Agnostic%20Counting                                                                                  A Recipe for CAC: Mosaic-based Generalized Loss for Improved Class-Agnostic Counting                                                                                  Class agnostic counting (CAC) is a vision task that can be used to count the total occurrence number of any given reference objects in the query image. The task is usually formulated as a density map estimation problem through similarity computation among a few image samples of the reference object and the query image. In this paper, we point out a severe issue of the existing CAC framework: Given a multi-class setting, models don't consider reference images and instead blindly match all dominant objects in the query image. Moreover, the current evaluation metrics and dataset cannot be used to faithfully assess the model's generalization performance and robustness. To this end, we discover that the combination of mosaic augmentation with generalized loss is essential for addressing the aforementioned issue of CAC models to count objects of majority (i.e. dominant objects) regardless of the references. Furthermore, we introduce a new evaluation protocol and metrics for resolving the problem behind the existing CAC evaluation scheme and better benchmarking CAC models in a more fair manner. Besides, extensive evaluation results demonstrate that our proposed recipe can consistently improve the performance of different CAC models. The code will be released upon acceptance.
http://w3id.org/mlsea/pwc/scientificWork/A%20Recommender%20System%20for%20NFT%20Collectibles%20with%20Item%20Feature                                                                                  A Recommender System for NFT Collectibles with Item Feature                                                                                  Recommender systems have been actively studied and applied in various domains to deal with information overload. Although there are numerous studies on recommender systems for movies, music, and e-commerce, comparatively less attention has been paid to the recommender system for NFTs despite the continuous growth of the NFT market. This paper presents a recommender system for NFTs that utilizes a variety of data sources, from NFT transaction records to external item features, to generate precise recommendations that cater to individual preferences. We develop a data-efficient graph-based recommender system to efficiently capture the complex relationship between each item and users and generate node(item) embeddings which incorporate both node feature information and graph structure. Furthermore, we exploit inputs beyond user-item interactions, such as image feature, text feature, and price feature. Numerical experiments verify the performance of the graph-based recommender system improves significantly after utilizing all types of item features as side information, thereby outperforming all other baselines.
http://w3id.org/mlsea/pwc/scientificWork/A%20Reinforcement%20Learning%20Approach%20for%20Dynamic%20Rebalancing%20in%20Bike-Sharing%20System                                                                                  A Reinforcement Learning Approach for Dynamic Rebalancing in Bike-Sharing System                                                                                  Bike-Sharing Systems provide eco-friendly urban mobility, contributing to the alleviation of traffic congestion and to healthier lifestyles. Efficiently operating such systems and maintaining high customer satisfaction is challenging due to the stochastic nature of trip demand, leading to full or empty stations. Devising effective rebalancing strategies using vehicles to redistribute bikes among stations is therefore of uttermost importance for operators. As a promising alternative to classical mathematical optimization, reinforcement learning is gaining ground to solve sequential decision-making problems. This paper introduces a spatio-temporal reinforcement learning algorithm for the dynamic rebalancing problem with multiple vehicles. We first formulate the problem as a Multi-agent Markov Decision Process in a continuous time framework. This allows for independent and cooperative vehicle rebalancing, eliminating the impractical restriction of time-discretized models where vehicle departures are synchronized. A comprehensive simulator under the first-arrive-first-serve rule is then developed to facilitate the learning process by computing immediate rewards under diverse demand scenarios. To estimate the value function and learn the rebalancing policy, various Deep Q-Network configurations are tested, minimizing the lost demand. Experiments are carried out on various datasets generated from historical data, affected by both temporal and weather factors. The proposed algorithms outperform benchmarks, including a multi-period Mixed-Integer Programming model, in terms of lost demand. Once trained, it yields immediate decisions, making it suitable for real-time applications. Our work offers practical insights for operators and enriches the integration of reinforcement learning into dynamic rebalancing problems, paving the way for more intelligent and robust urban mobility solutions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Reinforcement%20Learning%20Based%20Controller%20to%20Minimize%20Forces%20on%20the%20Crutches%20of%20a%20Lower-Limb%20Exoskeleton                                                                                  A Reinforcement Learning Based Controller to Minimize Forces on the Crutches of a Lower-Limb Exoskeleton                                                                                  Metabolic energy consumption of a powered lower-limb exoskeleton user mainly comes from the upper body effort since the lower body is considered to be passive. However, the upper body effort of the users is largely ignored in the literature when designing motion controllers. In this work, we use deep reinforcement learning to develop a locomotion controller that minimizes ground reaction forces (GRF) on crutches. The rationale for minimizing GRF is to reduce the upper body effort of the user. Accordingly, we design a model and a learning framework for a human-exoskeleton system with crutches. We formulate a reward function to encourage the forward displacement of a human-exoskeleton system while satisfying the predetermined constraints of a physical robot. We evaluate our new framework using Proximal Policy Optimization, a state-of-the-art deep reinforcement learning (RL) method, on the MuJoCo physics simulator with different hyperparameters and network architectures over multiple trials. We empirically show that our learning model can generate joint torques based on the joint angle, velocities, and the GRF on the feet and crutch tips. The resulting exoskeleton model can directly generate joint torques from states in line with the RL framework. Finally, we empirically show that policy trained using our method can generate a gait with a 35% reduction in GRF with respect to the baseline.
http://w3id.org/mlsea/pwc/scientificWork/A%20Reinforcement%20Learning%20based%20Reset%20Policy%20for%20CDCL%20SAT%20Solvers                                                                                  A Reinforcement Learning based Reset Policy for CDCL SAT Solvers                                                                                  Restart policy is an important technique used in modern Conflict-Driven Clause Learning (CDCL) solvers, wherein some parts of the solver state are erased at certain intervals during the run of the solver. In most solvers, variable activities are preserved across restart boundaries, resulting in solvers continuing to search parts of the assignment tree that are not far from the one immediately prior to a restart. To enable the solver to search possibly 'distant' parts of the assignment tree, we study the effect of resets, a variant of restarts which not only erases the assignment trail, but also randomizes the activity scores of the variables of the input formula after reset, thus potentially enabling a better global exploration of the search space. In this paper, we model the problem of whether to trigger reset as a multi-armed bandit (MAB) problem, and propose two reinforcement learning (RL) based adaptive reset policies using the Upper Confidence Bound (UCB) and Thompson sampling algorithms. These two algorithms balance the exploration-exploitation tradeoff by adaptively choosing arms (reset vs. no reset) based on their estimated rewards during the solver's run. We implement our reset policies in four baseline SOTA CDCL solvers and compare the baselines against the reset versions on Satcoin benchmarks and SAT Competition instances. Our results show that RL-based reset versions outperform the corresponding baseline solvers on both Satcoin and the SAT competition instances, suggesting that our RL policy helps to dynamically and profitably adapt the reset frequency for any given input instance. We also introduce the concept of a partial reset, where at least a constant number of variable activities are retained across reset boundaries. Building on previous results, we show that there is an exponential separation between O(1) vs. $ Omega(n)$-length partial resets.
http://w3id.org/mlsea/pwc/scientificWork/A%20Review%20of%20Carsickness%20Mitigation%3A%20Navigating%20Challenges%20and%20Exploiting%20Opportunities%20in%20the%20Era%20of%20Intelligent%20Vehicles                                                                                  A Review of Carsickness Mitigation: Navigating Challenges and Exploiting Opportunities in the Era of Intelligent Vehicles                                                                                  Motion sickness (MS) has long been a common complaint in road transportation. However, in the era of driving automation, MS has become an increasingly significant issue. The future intelligent vehicle is envisioned as a mobile space for work or entertainment, but unfortunately passengers' engagement in non-driving tasks may exacerbate MS. Finding effective MS countermeasures is crucial to ensure a pleasant passenger experience. Nevertheless, due to the complex mechanism of MS, there are numerous challenges in mitigating it, hindering the development of practical countermeasures. To address this, we first review two prevalent theories explaining the mechanism of MS. Subsequently, this paper provides a summary of current subjective and objective approaches for quantifying motion sickness levels. Then, it surveys existing methods for alleviating MS, including passenger adjustment, intelligent vehicle solutions, and motion cues of various modalities. Furthermore, we outline the limitations and remaining challenges of current research and highlight novel opportunities in the context of intelligent vehicles. Finally, we propose an integrated framework for alleviating MS. The findings of this review will enhance our understanding of carsickness and offer valuable insights for future research and practice in MS mitigation within modern vehicles.
http://w3id.org/mlsea/pwc/scientificWork/A%20Review%20on%20Knowledge%20Graphs%20for%20Healthcare%3A%20Resources%2C%20Applications%2C%20and%20Promises                                                                                  A Review on Knowledge Graphs for Healthcare: Resources, Applications, and Promises                                                                                  Healthcare knowledge graphs (HKGs) are valuable tools for organizing biomedical concepts and their relationships with interpretable structures. The recent advent of large language models (LLMs) has paved the way for building more comprehensive and accurate HKGs. This, in turn, can improve the reliability of generated content and enable better evaluation of LLMs. However, the challenges of HKGs such as regarding data heterogeneity and limited coverage are not fully understood, highlighting the need for detailed reviews. This work provides the first comprehensive review of HKGs. It summarizes the pipeline and key techniques for HKG construction, as well as the common utilization approaches, i.e., model-free and model-based. The existing HKG resources are also organized based on the data types they capture and application domains they cover, along with relevant statistical information (Resource available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase). At the application level, we delve into the successful integration of HKGs across various health domains, ranging from fine-grained basic science research to high-level clinical decision support and public health. Lastly, the paper highlights the opportunities for HKGs in the era of LLMs. This work aims to serve as a valuable resource for understanding the potential and opportunities of HKG in health research.
http://w3id.org/mlsea/pwc/scientificWork/A%20Roadmap%20Towards%20Automated%20and%20Regulated%20Robotic%20Systems                                                                                  A Roadmap Towards Automated and Regulated Robotic Systems                                                                                  The rapid development of generative technology opens up possibility for higher level of automation, and artificial intelligence (AI) embodiment in robotic systems is imminent. However, due to the blackbox nature of the generative technology, the generation of the knowledge and workflow scheme is uncontrolled, especially in a dynamic environment and a complex scene. This poses challenges to regulations in safety-demanding applications such as medical scenes. We argue that the unregulated generative processes from AI is fitted for low level end tasks, but intervention in the form of manual or automated regulation should happen post-workflow-generation and pre-robotic-execution. To address this, we propose a roadmap that can lead to fully automated and regulated robotic systems. In this paradigm, the high level policies are generated as structured graph data, enabling regulatory oversight and reusability, while the code base for lower level tasks is generated by generative models. Our approach aims the transitioning from expert knowledge to regulated action, akin to the iterative processes of study, practice, scrutiny, and execution in human tasks. We identify the generative and deterministic processes in a design cycle, where generative processes serve as a text-based world simulator and the deterministic processes generate the executable system. We propose State Machine Seralization Language (SMSL) to be the conversion point between text simulator and executable workflow control. From there, we analyze the modules involved based on the current literature, and discuss human in the loop. As a roadmap, this work identifies the current possible implementation and future work. This work does not provide an implemented system but envisions to inspire the researchers working on the direction in the roadmap. We implement the SMSL and D-SFO paradigm that serve as the starting point of the roadmap.
http://w3id.org/mlsea/pwc/scientificWork/A%20Safe%20Harbor%20for%20AI%20Evaluation%20and%20Red%20Teaming                                                                                  A Safe Harbor for AI Evaluation and Red Teaming                                                                                  Independent evaluation and red teaming are critical for identifying the risks posed by generative AI systems. However, the terms of service and enforcement strategies used by prominent AI companies to deter model misuse have disincentives on good faith safety evaluations. This causes some researchers to fear that conducting such research or releasing their findings will result in account suspensions or legal reprisal. Although some companies offer researcher access programs, they are an inadequate substitute for independent research access, as they have limited community representation, receive inadequate funding, and lack independence from corporate incentives. We propose that major AI developers commit to providing a legal and technical safe harbor, indemnifying public interest safety research and protecting it from the threat of account suspensions or legal reprisal. These proposals emerged from our collective experience conducting safety, privacy, and trustworthiness research on generative AI systems, where norms and incentives could be better aligned with public interests, without exacerbating model misuse. We believe these commitments are a necessary step towards more inclusive and unimpeded community efforts to tackle the risks of generative AI.
http://w3id.org/mlsea/pwc/scientificWork/A%20Saliency%20Enhanced%20Feature%20Fusion%20based%20multiscale%20RGB-D%20Salient%20Object%20Detection%20Network                                                                                  A Saliency Enhanced Feature Fusion based multiscale RGB-D Salient Object Detection Network                                                                                  Multiscale convolutional neural network (CNN) has demonstrated remarkable capabilities in solving various vision problems. However, fusing features of different scales alwaysresults in large model sizes, impeding the application of multiscale CNNs in RGB-D saliency detection. In this paper, we propose a customized feature fusion module, called Saliency Enhanced Feature Fusion (SEFF), for RGB-D saliency detection. SEFF utilizes saliency maps of the neighboring scales to enhance the necessary features for fusing, resulting in more representative fused features. Our multiscale RGB-D saliency detector uses SEFF and processes images with three different scales. SEFF is used to fuse the features of RGB and depth images, as well as the features of decoders at different scales. Extensive experiments on five benchmark datasets have demonstrated the superiority of our method over ten SOTA saliency detectors.
http://w3id.org/mlsea/pwc/scientificWork/A%20Sampling%20Theory%20Perspective%20on%20Activations%20for%20Implicit%20Neural%20Representations                                                                                  A Sampling Theory Perspective on Activations for Implicit Neural Representations                                                                                  Implicit Neural Representations (INRs) have gained popularity for encoding signals as compact, differentiable entities. While commonly using techniques like Fourier positional encodings or non-traditional activation functions (e.g., Gaussian, sinusoid, or wavelets) to capture high-frequency content, their properties lack exploration within a unified theoretical framework. Addressing this gap, we conduct a comprehensive analysis of these activations from a sampling theory perspective. Our investigation reveals that sinc activations, previously unused in conjunction with INRs, are theoretically optimal for signal encoding. Additionally, we establish a connection between dynamical systems and INRs, leveraging sampling theory to bridge these two paradigms.
http://w3id.org/mlsea/pwc/scientificWork/A%20Sampling-based%20Framework%20for%20Hypothesis%20Testing%20on%20Large%20Attributed%20Graphs                                                                                  A Sampling-based Framework for Hypothesis Testing on Large Attributed Graphs                                                                                  Hypothesis testing is a statistical method used to draw conclusions about populations from sample data, typically represented in tables. With the prevalence of graph representations in real-life applications, hypothesis testing in graphs is gaining importance. In this work, we formalize node, edge, and path hypotheses in attributed graphs. We develop a sampling-based hypothesis testing framework, which can accommodate existing hypothesis-agnostic graph sampling methods. To achieve accurate and efficient sampling, we then propose a Path-Hypothesis-Aware SamplEr, PHASE, an m- dimensional random walk that accounts for the paths specified in a hypothesis. We further optimize its time efficiency and propose PHASEopt. Experiments on real datasets demonstrate the ability of our framework to leverage common graph sampling methods for hypothesis testing, and the superiority of hypothesis-aware sampling in terms of accuracy and time efficiency.
http://w3id.org/mlsea/pwc/scientificWork/A%20Scalable%20Algorithm%20for%20Individually%20Fair%20K-means%20Clustering                                                                                  A Scalable Algorithm for Individually Fair K-means Clustering                                                                                  We present a scalable algorithm for the individually fair ($p$, $k$)-clustering problem introduced by Jung et al. and Mahabadi et al. Given $n$ points $P$ in a metric space, let $ delta(x)$ for $x in P$ be the radius of the smallest ball around $x$ containing at least $n / k$ points. A clustering is then called individually fair if it has centers within distance $ delta(x)$ of $x$ for each $x in P$. While good approximation algorithms are known for this problem no efficient practical algorithms with good theoretical guarantees have been presented. We design the first fast local-search algorithm that runs in ~$O(nk^2)$ time and obtains a bicriteria $(O(1), 6)$ approximation. Then we show empirically that not only is our algorithm much faster than prior work, but it also produces lower-cost solutions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Secure%20and%20Trustworthy%20Network%20Architecture%20for%20Federated%20Learning%20Healthcare%20Applications                                                                                  A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications                                                                                  Federated Learning (FL) has emerged as a promising approach for privacy-preserving machine learning, particularly in sensitive domains such as healthcare. In this context, the TRUSTroke project aims to leverage FL to assist clinicians in ischemic stroke prediction. This paper provides an overview of the TRUSTroke FL network infrastructure. The proposed architecture adopts a client-server model with a central Parameter Server (PS). We introduce a Docker-based design for the client nodes, offering a flexible solution for implementing FL processes in clinical settings. The impact of different communication protocols (HTTP or MQTT) on FL network operation is analyzed, with MQTT selected for its suitability in FL scenarios. A control plane to support the main operations required by FL processes is also proposed. The paper concludes with an analysis of security aspects of the FL architecture, addressing potential threats and proposing mitigation strategies to increase the trustworthiness level.
http://w3id.org/mlsea/pwc/scientificWork/A%20Sentiment%20Analysis%20of%20Medical%20Text%20Based%20on%20Deep%20Learning                                                                                  A Sentiment Analysis of Medical Text Based on Deep Learning                                                                                  The field of natural language processing (NLP) has made significant progress with the rapid development of deep learning technologies. One of the research directions in text sentiment analysis is sentiment analysis of medical texts, which holds great potential for application in clinical diagnosis. However, the medical field currently lacks sufficient text datasets, and the effectiveness of sentiment analysis is greatly impacted by different model design approaches, which presents challenges. Therefore, this paper focuses on the medical domain, using bidirectional encoder representations from transformers (BERT) as the basic pre-trained model and experimenting with modules such as convolutional neural network (CNN), fully connected network (FCN), and graph convolutional networks (GCN) at the output layer. Experiments and analyses were conducted on the METS-CoV dataset to explore the training performance after integrating different deep learning networks. The results indicate that CNN models outperform other networks when trained on smaller medical text datasets in combination with pre-trained models like BERT. This study highlights the significance of model selection in achieving effective sentiment analysis in the medical domain and provides a reference for future research to develop more efficient model architectures.
http://w3id.org/mlsea/pwc/scientificWork/A%20Simple%20Baseline%20for%20Efficient%20Hand%20Mesh%20Reconstruction                                                                                  A Simple Baseline for Efficient Hand Mesh Reconstruction                                                                                  3D hand pose estimation has found broad application in areas such as gesture recognition and human-machine interaction tasks. As performance improves, the complexity of the systems also increases, which can limit the comparative analysis and practical implementation of these methods. In this paper, we propose a simple yet effective baseline that not only surpasses state-of-the-art (SOTA) methods but also demonstrates computational efficiency. To establish this baseline, we abstract existing work into two components: a token generator and a mesh regressor, and then examine their core structures. A core structure, in this context, is one that fulfills intrinsic functions, brings about significant improvements, and achieves excellent performance without unnecessary complexities. Our proposed approach is decoupled from any modifications to the backbone, making it adaptable to any modern models. Our method outperforms existing solutions, achieving state-of-the-art (SOTA) results across multiple datasets. On the FreiHAND dataset, our approach produced a PA-MPJPE of 5.7mm and a PA-MPVPE of 6.0mm. Similarly, on the Dexycb dataset, we observed a PA-MPJPE of 5.5mm and a PA-MPVPE of 5.0mm. As for performance speed, our method reached up to 33 frames per second (fps) when using HRNet and up to 70 fps when employing FastViT-MA36
http://w3id.org/mlsea/pwc/scientificWork/A%20Simple%20Detection%20and%20Identification%20Scheme%20For%20Reconfigurable%20Intelligent%20Surfaces                                                                                  A Simple Detection and Identification Scheme For Reconfigurable Intelligent Surfaces                                                                                  Reconfigurable intelligent surface (RIS)-empowered communication is one of the promising physical layer enabling technologies for the sixth generation (6G) wireless networks due to their unprecedented capabilities in shaping the wireless communication environment. RISs are modeled as passive objects that can not transmit or receive wireless signals. While the passiveness of these surfaces is a key advantage in terms of power consumption and implementation complexity, it limits their capability to interact with the other active components in the network. Specifically, unlike conventional base stations (BSs), which actively identify themselves to user equipment (UEs) by periodically sending pilot signals, RISs need to be detected from the UE side. This paper proposes a novel RIS identification (RIS- ID) scheme, enabling UEs to detect and uniquely identify RISs in their surrounding environment. Furthermore, to assess the proposed RIS-ID scheme, we propose two performance metrics: the false and miss detection probabilities. These probabilities are analytically derived and verified through computer simulations, revealing the effectiveness of the proposed RIS-ID scheme under different operating scenarios.
http://w3id.org/mlsea/pwc/scientificWork/A%20Simple%20and%20Model-Free%20Path%20Filtering%20Algorithm%20for%20Smoothing%20and%20Accuracy                                                                                  A Simple and Model-Free Path Filtering Algorithm for Smoothing and Accuracy                                                                                  Predominantly, complex optimization techniques are used for path reconstruction given noisy measurements. However, optimization techniques often require the selection of suitable models, tedious parameter tuning and typically fail to generalize to higher-level tasks. In this paper, we present a model-free path filtering method based on the popular moving average method, namely the Curvature Corrected Moving Average (CCMA), which convinces by its simplicity and broad applicability. The moving average is characterized by its unique noise suppression property, albeit curves are bent inwards, which adversely affects its accuracy. By utilizing the relation between both curvatures, the original curvature can be inferred based on the curvature of filtered points. Extending the symmetric filtering not only succeeds in minimizing noise but retains the original shape of the path, making it a suitable algorithm for a variety of robotic applications. We demonstrate the practicality of the approach in a real-world convoy scenario: The accumulated estimates of the leader vehicleâs position, originating from an Extended Kalman filter, are smoothed using our novel approach to generate proper inputs for the Model Predictive Controller (MPC). This cascade structure of filtering provides both responsiveness and smoothness. Furthermore, we successfully applied this method in the off-road convoy scenario for the ELROB 2022, where we won first place. The source code is publicly available.
http://w3id.org/mlsea/pwc/scientificWork/A%20Simple%20but%20Effective%20Approach%20to%20Improve%20Structured%20Language%20Model%20Output%20for%20Information%20Extraction                                                                                  A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction                                                                                  Large language models (LLMs) have demonstrated impressive abilities in generating unstructured natural language according to instructions. However, their performance can be inconsistent when tasked with producing text that adheres to specific structured formats, which is crucial in applications like named entity recognition (NER) or relation extraction (RE). To address this issue, this paper introduces an efficient method, G&O, to enhance their structured text generation capabilities. It breaks the generation into a two-step pipeline: initially, LLMs generate answers in natural language as intermediate responses. Subsequently, LLMs are asked to organize the output into the desired structure, using the intermediate responses as context. G&O effectively separates the generation of content from the structuring process, reducing the pressure of completing two orthogonal tasks simultaneously. Tested on zero-shot NER and RE, the results indicate a significant improvement in LLM performance with minimal additional efforts. This straightforward and adaptable prompting technique can also be combined with other strategies, like self-consistency, to further elevate LLM capabilities in various structured text generation tasks.
http://w3id.org/mlsea/pwc/scientificWork/A%20Simple%20yet%20Effective%20Network%20based%20on%20Vision%20Transformer%20for%20Camouflaged%20Object%20and%20Salient%20Object%20Detection                                                                                  A Simple yet Effective Network based on Vision Transformer for Camouflaged Object and Salient Object Detection                                                                                  Camouflaged object detection (COD) and salient object detection (SOD) are two distinct yet closely-related computer vision tasks widely studied during the past decades. Though sharing the same purpose of segmenting an image into binary foreground and background regions, their distinction lies in the fact that COD focuses on concealed objects hidden in the image, while SOD concentrates on the most prominent objects in the image. Previous works achieved good performance by stacking various hand-designed modules and multi-scale features. However, these carefully-designed complex networks often performed well on one task but not on another. In this work, we propose a simple yet effective network (SENet) based on vision Transformer (ViT), by employing a simple design of an asymmetric ViT-based encoder-decoder structure, we yield competitive results on both tasks, exhibiting greater versatility than meticulously crafted ones. Furthermore, to enhance the Transformer's ability to model local information, which is important for pixel-level binary segmentation tasks, we propose a local information capture module (LICM). We also propose a dynamic weighted loss (DW loss) based on Binary Cross-Entropy (BCE) and Intersection over Union (IoU) loss, which guides the network to pay more attention to those smaller and more difficult-to-find target objects according to their size. Moreover, we explore the issue of joint training of SOD and COD, and propose a preliminary solution to the conflict in joint training, further improving the performance of SOD. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of our method. The code is available at https://github.com/linuxsino/SENet.
http://w3id.org/mlsea/pwc/scientificWork/A%20Sinkhorn-type%20Algorithm%20for%20Constrained%20Optimal%20Transport                                                                                  A Sinkhorn-type Algorithm for Constrained Optimal Transport                                                                                  Entropic optimal transport (OT) and the Sinkhorn algorithm have made it practical for machine learning practitioners to perform the fundamental task of calculating transport distance between statistical distributions. In this work, we focus on a general class of OT problems under a combination of equality and inequality constraints. We derive the corresponding entropy regularization formulation and introduce a Sinkhorn-type algorithm for such constrained OT problems supported by theoretical guarantees. We first bound the approximation error when solving the problem through entropic regularization, which reduces exponentially with the increase of the regularization parameter. Furthermore, we prove a sublinear first-order convergence rate of the proposed Sinkhorn-type algorithm in the dual space by characterizing the optimization procedure with a Lyapunov function. To achieve fast and higher-order convergence under weak entropy regularization, we augment the Sinkhorn-type algorithm with dynamic regularization scheduling and second-order acceleration. Overall, this work systematically combines recent theoretical and numerical advances in entropic optimal transport with the constrained case, allowing practitioners to derive approximate transport plans in complex scenarios.
http://w3id.org/mlsea/pwc/scientificWork/A%20Spectrum-based%20Image%20Denoising%20Method%20with%20Edge%20Feature%20Enhancement                                                                                  A Spectrum-based Image Denoising Method with Edge Feature Enhancement                                                                                  Image denoising stands as a critical challenge in image processing and computer vision, aiming to restore the original image from noise-affected versions caused by various intrinsic and extrinsic factors. This process is essential for applications that rely on the high quality and clarity of visual information, such as image restoration, visual tracking, and image registration, where the original content is vital for performance. Despite the development of numerous denoising algorithms, effectively suppressing noise, particularly under poor capture conditions with high noise levels, remains a challenge. Image denoising's practical importance spans multiple domains, notably medical imaging for enhanced diagnostic precision, as well as surveillance and satellite imagery where it improves image quality and usability. Techniques like the Fourier transform, which excels in noise reduction and edge preservation, along with phase congruency-based methods, offer promising results for enhancing noisy and low-contrast images common in modern imaging scenarios.
http://w3id.org/mlsea/pwc/scientificWork/A%20Stationary%20Equilibrium%20Model%20of%20Green%20Technology%20Adoption%20with%20Endogenous%20Carbon%20Price                                                                                  A Stationary Equilibrium Model of Green Technology Adoption with Endogenous Carbon Price                                                                                  This paper proposes and analyzes a stationary equilibrium model for a competitive industry which endogenously determines the carbon price necessary to achieve a given emission target. In the model, firms are identified by their level of technology and make production, entry, and abatement decisions. Polluting firms are subject to a carbon price and abatement is formulated as an irreversible investment, which entails a sunk cost and results in the firms switching to a carbon neutral technology. In equilibrium, we identify a carbon price and a stationary distribution of incumbent, polluting firms, that guarantee the compliance with a certain emission target. Our general theoretical framework is complemented with a case study with Brownian technology shocks, in which we discuss some implications of our model. We observe that a carbon pricing system alongside installation subsidies and tax benefits for green firms trigger earlier investment, while higher income taxes for polluting firms may be distorting. Moreover, we discuss the role of a welfare maximizing regulator, who, by optimally setting the emission target, may mitigate or revert some parameters' effects observed in the model with fixed limit.
http://w3id.org/mlsea/pwc/scientificWork/A%20Structure-Guided%20Gauss-Newton%20Method%20for%20Shallow%20ReLU%20Neural%20Network                                                                                  A Structure-Guided Gauss-Newton Method for Shallow ReLU Neural Network                                                                                  In this paper, we propose a structure-guided Gauss-Newton (SgGN) method for solving least squares problems using a shallow ReLU neural network. The method effectively takes advantage of both the least squares structure and the neural network structure of the objective function. By categorizing the weights and biases of the hidden and output layers of the network as nonlinear and linear parameters, respectively, the method iterates back and forth between the nonlinear and linear parameters. The nonlinear parameters are updated by a damped Gauss-Newton method and the linear ones are updated by a linear solver. Moreover, at the Gauss-Newton step, a special form of the Gauss-Newton matrix is derived for the shallow ReLU neural network and is used for efficient iterations. It is shown that the corresponding mass and Gauss-Newton matrices in the respective linear and nonlinear steps are symmetric and positive definite under reasonable assumptions. Thus, the SgGN method naturally produces an effective search direction without the need of additional techniques like shifting in the Levenberg-Marquardt method to achieve invertibility of the Gauss-Newton matrix. The convergence and accuracy of the method are demonstrated numerically for several challenging function approximation problems, especially those with discontinuities or sharp transition layers that pose significant challenges for commonly used training algorithms in machine learning.
http://w3id.org/mlsea/pwc/scientificWork/A%20Study%20of%20Acquisition%20Functions%20for%20Medical%20Imaging%20Deep%20Active%20Learning                                                                                  A Study of Acquisition Functions for Medical Imaging Deep Active Learning                                                                                  The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that textit{bald} performs on average better than other acquisition functions. Our extended analyses however revealed that all acquisition functions perform badly on the positive (cancerous) samples, suggesting exploitation of class unbalance, which could be crucial in real-world settings. We finish by suggesting future work directions that would be useful to improve this current work. The code of our implementation is open-sourced at url{https://github.com/bonaventuredossou/ece526_course_project}
http://w3id.org/mlsea/pwc/scientificWork/A%20Study%20of%20Shape%20Modeling%20Against%20Noise                                                                                  A Study of Shape Modeling Against Noise                                                                                  Shape modeling is a challenging task with many potential applications in computer vision and medical imaging. There are many shape modeling methods in the literature, each with its advantages and applications. However, many shape modeling methods have difficulties handling shapes that have missing pieces or outliers. In this regard, this paper introduces shape denoising, a fundamental problem in shape modeling that lies at the core of many computer vision and medical imaging applications and has not received enough attention in the literature. The paper introduces six types of noise that can be used to perturb shapes as well as an objective measure for the noise level and for comparing methods on their shape denoising capabilities. Finally, the paper evaluates seven methods capable of accomplishing this task, of which six are based on deep learning, including some generative models.
http://w3id.org/mlsea/pwc/scientificWork/A%20Study%20of%20Vulnerability%20Repair%20in%20JavaScript%20Programs%20with%20Large%20Language%20Models                                                                                  A Study of Vulnerability Repair in JavaScript Programs with Large Language Models                                                                                  In recent years, JavaScript has become the most widely used programming language, especially in web development. However, writing secure JavaScript code is not trivial, and programmers often make mistakes that lead to security vulnerabilities in web applications. Large Language Models (LLMs) have demonstrated substantial advancements across multiple domains, and their evolving capabilities indicate their potential for automatic code generation based on a required specification, including automatic bug fixing. In this study, we explore the accuracy of LLMs, namely ChatGPT and Bard, in finding and fixing security vulnerabilities in JavaScript programs. We also investigate the impact of context in a prompt on directing LLMs to produce a correct patch of vulnerable JavaScript code. Our experiments on real-world software vulnerabilities show that while LLMs are promising in automatic program repair of JavaScript code, achieving a correct bug fix often requires an appropriate amount of context in the prompt.
http://w3id.org/mlsea/pwc/scientificWork/A%20Study%20on%20Domain%20Generalization%20for%20Failure%20Detection%20through%20Human%20Reactions%20in%20HRI                                                                                  A Study on Domain Generalization for Failure Detection through Human Reactions in HRI                                                                                  Machine learning models are commonly tested in-distribution (same dataset); performance almost always drops in out-of-distribution settings. For HRI research, the goal is often to develop generalized models. This makes domain generalization - retaining performance in different settings - a critical issue. In this study, we present a concise analysis of domain generalization in failure detection models trained on human facial expressions. Using two distinct datasets of humans reacting to videos where error occurs, one from a controlled lab setting and another collected online, we trained deep learning models on each dataset. When testing these models on the alternate dataset, we observed a significant performance drop. We reflect on the causes for the observed model behavior and leave recommendations. This work emphasizes the need for HRI research focusing on improving model robustness and real-life applicability.
http://w3id.org/mlsea/pwc/scientificWork/A%20Study%20on%20How%20Attention%20Scores%20in%20the%20BERT%20Model%20are%20Aware%20of%20Lexical%20Categories%20in%20Syntactic%20and%20Semantic%20Tasks%20on%20the%20GLUE%20Benchmark                                                                                  A Study on How Attention Scores in the BERT Model are Aware of Lexical Categories in Syntactic and Semantic Tasks on the GLUE Benchmark                                                                                  This study examines whether the attention scores between tokens in the BERT model significantly vary based on lexical categories during the fine-tuning process for downstream tasks. Drawing inspiration from the notion that in human language processing, syntactic and semantic information is parsed differently, we categorize tokens in sentences according to their lexical categories and focus on changes in attention scores among these categories. Our hypothesis posits that in downstream tasks that prioritize semantic information, attention scores centered on content words are enhanced, while in cases emphasizing syntactic information, attention scores centered on function words are intensified. Through experimentation conducted on six tasks from the GLUE benchmark dataset, we substantiate our hypothesis regarding the fine-tuning process. Furthermore, our additional investigations reveal the presence of BERT layers that consistently assign more bias to specific lexical categories, irrespective of the task, highlighting the existence of task-agnostic lexical category preferences.
http://w3id.org/mlsea/pwc/scientificWork/A%20Subspace-Constrained%20Tyler%27s%20Estimator%20and%20its%20Applications%20to%20Structure%20from%20Motion                                                                                  A Subspace-Constrained Tyler's Estimator and its Applications to Structure from Motion                                                                                  We present the subspace-constrained Tyler's estimator (STE) designed for recovering a low-dimensional subspace within a dataset that may be highly corrupted with outliers. STE is a fusion of the Tyler's M-estimator (TME) and a variant of the fast median subspace. Our theoretical analysis suggests that, under a common inlier-outlier model, STE can effectively recover the underlying subspace, even when it contains a smaller fraction of inliers relative to other methods in the field of robust subspace recovery. We apply STE in the context of Structure from Motion (SfM) in two ways: for robust estimation of the fundamental matrix and for the removal of outlying cameras, enhancing the robustness of the SfM pipeline. Numerical experiments confirm the state-of-the-art performance of our method in these applications. This research makes significant contributions to the field of robust subspace recovery, particularly in the context of computer vision and 3D reconstruction.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20AI-generated%20Text%20Forensic%20Systems%3A%20Detection%2C%20Attribution%2C%20and%20Characterization                                                                                  A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization                                                                                  We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text. While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale. This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses. We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization. These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization). Furthermore, we explore available resources for AI-generated text forensics research and discuss the evolving challenges and future directions of forensic systems in an AI era.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20IMU%20Based%20Cross-Modal%20Transfer%20Learning%20in%20Human%20Activity%20Recognition                                                                                  A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition                                                                                  Despite living in a multi-sensory world, most AI models are limited to textual and visual understanding of human motion and behavior. In fact, full situational awareness of human motion could best be understood through a combination of sensors. In this survey we investigate how knowledge can be transferred and utilized amongst modalities for Human Activity/Action Recognition (HAR), i.e. cross-modality transfer learning. We motivate the importance and potential of IMU data and its applicability in cross-modality learning as well as the importance of studying the HAR problem. We categorize HAR related tasks by time and abstractness and then compare various types of multimodal HAR datasets. We also distinguish and expound on many related but inconsistently used terms in the literature, such as transfer learning, domain adaptation, representation learning, sensor fusion, and multimodal learning, and describe how cross-modal learning fits with all these concepts. We then review the literature in IMU-based cross-modal transfer for HAR. The two main approaches for cross-modal transfer are instance-based transfer, where instances of one modality are mapped to another (e.g. knowledge is transferred in the input space), or feature-based transfer, where the model relates the modalities in an intermediate latent space (e.g. knowledge is transferred in the feature space). Finally, we discuss future research directions and applications in cross-modal HAR.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Music%20Generation%20in%20the%20Context%20of%20Interaction                                                                                  A Survey of Music Generation in the Context of Interaction                                                                                  In recent years, machine learning, and in particular generative adversarial neural networks (GANs) and attention-based neural networks (transformers), have been successfully used to compose and generate music, both melodies and polyphonic pieces. Current research focuses foremost on style replication (eg. generating a Bach-style chorale) or style transfer (eg. classical to jazz) based on large amounts of recorded or transcribed music, which in turn also allows for fairly straight-forward 'performance' evaluation. However, most of these models are not suitable for human-machine co-creation through live interaction, neither is clear, how such models and resulting creations would be evaluated. This article presents a thorough review of music representation, feature analysis, heuristic algorithms, statistical and parametric modelling, and human and automatic evaluation measures, along with a discussion of which approaches and models seem most suitable for live interaction.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20using%20Large%20Language%20Models%20for%20Generating%20Infrastructure%20as%20Code                                                                                  A Survey of using Large Language Models for Generating Infrastructure as Code                                                                                  Infrastructure as Code (IaC) is a revolutionary approach which has gained significant prominence in the Industry. IaC manages and provisions IT infrastructure using machine-readable code by enabling automation, consistency across the environments, reproducibility, version control, error reduction and enhancement in scalability. However, IaC orchestration is often a painstaking effort which requires specialised skills as well as a lot of manual effort. Automation of IaC is a necessity in the present conditions of the Industry and in this survey, we study the feasibility of applying Large Language Models (LLM) to address this problem. LLMs are large neural network-based models which have demonstrated significant language processing abilities and shown to be capable of following a range of instructions within a broad scope. Recently, they have also been adapted for code understanding and generation tasks successfully, which makes them a promising choice for the automatic generation of IaC configurations. In this survey, we delve into the details of IaC, usage of IaC in different platforms, their challenges, LLMs in terms of code-generation aspects and the importance of LLMs in IaC along with our own experiments. Finally, we conclude by presenting the challenges in this area and highlighting the scope for future research.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20African%20Computer%20Vision%20Datasets%2C%20Topics%20and%20Researchers                                                                                  A Survey on African Computer Vision Datasets, Topics and Researchers                                                                                  Computer vision encompasses a range of tasks such as object detection, semantic segmentation, and 3D reconstruction. Despite its relevance to African communities, research in this field within Africa represents only 0.06% of top-tier publications over the past decade. This study undertakes a thorough analysis of 63,000 Scopus-indexed computer vision publications from Africa, spanning from 2012 to 2022. The aim is to provide a survey of African computer vision topics, datasets and researchers. A key aspect of our study is the identification and categorization of African Computer Vision datasets using large language models that automatically parse abstracts of these publications. We also provide a compilation of unofficial African Computer Vision datasets distributed through challenges or data hosting platforms, and provide a full taxonomy of dataset categories. Our survey also pinpoints computer vision topics trends specific to different African regions, indicating their unique focus areas. Additionally, we carried out an extensive survey to capture the views of African researchers on the current state of computer vision research in the continent and the structural barriers they believe need urgent attention. In conclusion, this study catalogs and categorizes Computer Vision datasets and topics contributed or initiated by African institutions and identifies barriers to publishing in top-tier Computer Vision venues. This survey underscores the importance of encouraging African researchers and institutions in advancing computer vision research in the continent. It also stresses on the need for research topics to be more aligned with the needs of African communities.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Consumer%20IoT%20Traffic%3A%20Security%20and%20Privacy                                                                                  A Survey on Consumer IoT Traffic: Security and Privacy                                                                                  For the past few years, the Consumer Internet of Things (CIoT) has entered public lives. While CIoT has improved the convenience of people's daily lives, it has also brought new security and privacy concerns. In this survey, we try to figure out what researchers can learn about the security and privacy of CIoT by traffic analysis, a popular method in the security community. From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved. We collected 310 papers from January 2018 to December 2023 related to CIoT traffic analysis from the security and privacy perspective and summarized the process of CIoT traffic analysis in which the new characteristics of CIoT are identified. Then, we detail existing works based on five application goals: device fingerprinting, user activity inference, malicious traffic analysis, security analysis, and measurement. At last, we discuss the new challenges and future research directions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Data%20Selection%20for%20Language%20Models                                                                                  A Survey on Data Selection for Language Models                                                                                  A major factor in the recent success of large language models is the use of enormous and ever-growing text datasets for unsupervised pre-training. However, naively training a model on all available data may not be optimal (or feasible), as the quality of available text data can vary. Filtering out data can also decrease the carbon footprint and financial costs of training models by reducing the amount of training required. Data selection methods aim to determine which candidate data points to include in the training dataset and how to appropriately sample from the selected data points. The promise of improved data selection methods has caused the volume of research in the area to rapidly expand. However, because deep learning is mostly driven by empirical evidence and experimentation on large-scale data is expensive, few organizations have the resources for extensive data selection research. Consequently, knowledge of effective data selection practices has become concentrated within a few organizations, many of which do not openly share their findings and methodologies. To narrow this gap in knowledge, we present a comprehensive review of existing literature on data selection methods and related research areas, providing a taxonomy of existing approaches. By describing the current landscape of research, this work aims to accelerate progress in data selection by establishing an entry point for new and established researchers. Additionally, throughout this review we draw attention to noticeable holes in the literature and conclude the paper by proposing promising avenues for future research.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Data-Driven%20Fault%20Diagnostic%20Techniques%20for%20Marine%20Diesel%20Engines                                                                                  A Survey on Data-Driven Fault Diagnostic Techniques for Marine Diesel Engines                                                                                  Fault diagnosis in marine diesel engines is vital for maritime safety and operational efficiency.These engines are integral to marine vessels, and their reliable performance is crucial for safenavigation. Swift identification and resolution of faults are essential to prevent breakdowns,enhance safety, and reduce the risk of catastrophic failures at sea. Proactive fault diagnosisfacilitates timely maintenance, minimizes downtime, and ensures the overall reliability andlongevity of marine diesel engines. This paper explores the importance of fault diagnosis,emphasizing subsystems, common faults, and recent advancements in data-driven approachesfor effective marine diesel engine maintenance
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Human-AI%20Teaming%20with%20Large%20Pre-Trained%20Models                                                                                  A Survey on Human-AI Teaming with Large Pre-Trained Models                                                                                  In the rapidly evolving landscape of artificial intelligence (AI), the collaboration between human intelligence and AI systems, known as Human-AI (HAI) Teaming, has emerged as a cornerstone for advancing problem-solving and decision-making processes. The advent of Large Pre-trained Models (LPtM) has significantly transformed this landscape, offering unprecedented capabilities by leveraging vast amounts of data to understand and predict complex patterns. This paper surveys the pivotal integration of LPtMs with HAI, emphasizing how these models enhance collaborative intelligence beyond traditional approaches. It examines the synergistic potential of LPtMs in augmenting human capabilities, discussing this collaboration for AI model improvements, effective teaming, ethical considerations, and their broad applied implications in various sectors. Through this exploration, the study sheds light on the transformative impact of LPtM-enhanced HAI Teaming, providing insights for future research, policy development, and strategic implementations aimed at harnessing the full potential of this collaboration for research and societal benefit.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Knowledge%20Distillation%20of%20Large%20Language%20Models                                                                                  A Survey on Knowledge Distillation of Large Language Models                                                                                  In the era of Large Language Models (LLMs), Knowledge Distillation (KD) emerges as a pivotal methodology for transferring advanced capabilities from leading proprietary LLMs, such as GPT-4, to their open-source counterparts like LLaMA and Mistral. Additionally, as open-source LLMs flourish, KD plays a crucial role in both compressing these models, and facilitating their self-improvement by employing themselves as teachers. This paper presents a comprehensive survey of KD's role within the realm of LLM, highlighting its critical function in imparting advanced knowledge to smaller models and its utility in model compression and self-improvement. Our survey is meticulously structured around three foundational pillars: textit{algorithm}, textit{skill}, and textit{verticalization} -- providing a comprehensive examination of KD mechanisms, the enhancement of specific cognitive abilities, and their practical implications across diverse fields. Crucially, the survey navigates the intricate interplay between data augmentation (DA) and KD, illustrating how DA emerges as a powerful paradigm within the KD framework to bolster LLMs' performance. By leveraging DA to generate context-rich, skill-specific training data, KD transcends traditional boundaries, enabling open-source models to approximate the contextual adeptness, ethical alignment, and deep semantic insights characteristic of their proprietary counterparts. This work aims to provide an insightful guide for researchers and practitioners, offering a detailed overview of current methodologies in KD and proposing future research directions. Importantly, we firmly advocate for compliance with the legal terms that regulate the use of LLMs, ensuring ethical and lawful application of KD of LLMs. An associated Github repository is available at https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Long%20Video%20Generation%3A%20Challenges%2C%20Methods%2C%20and%20Prospects                                                                                  A Survey on Long Video Generation: Challenges, Methods, and Prospects                                                                                  Video generation is a rapidly advancing research area, garnering significant attention due to its broad range of applications. One critical aspect of this field is the generation of long-duration videos, which presents unique challenges and opportunities. This paper presents the first survey of recent advancements in long video generation and summarises them into two key paradigms: divide and conquer temporal autoregressive. We delve into the common models employed in each paradigm, including aspects of network design and conditioning techniques. Furthermore, we offer a comprehensive overview and classification of the datasets and evaluation metrics which are crucial for advancing long video generation research. Concluding with a summary of existing studies, we also discuss the emerging challenges and future directions in this dynamic field. We hope that this survey will serve as an essential reference for researchers and practitioners in the realm of long video generation.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Semantic%20Modeling%20for%20Building%20Energy%20Management                                                                                  A Survey on Semantic Modeling for Building Energy Management                                                                                  Buildings account for a substantial portion of global energy consumption. Reducing buildings' energy usage primarily involves obtaining data from building systems and environment, which are instrumental in assessing and optimizing the building's performance. However, as devices from various manufacturers represent their data in unique ways, this disparity introduces challenges for semantic interoperability and creates obstacles in developing scalable building applications. This survey explores the leading semantic modeling techniques deployed for energy management in buildings. Furthermore, it aims to offer tangible use cases for applying semantic models, shedding light on the pivotal concepts and limitations intrinsic to each model. Our findings will assist researchers in discerning the appropriate circumstances and methodologies for employing these models in various use cases.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Statistical%20Theory%20of%20Deep%20Learning%3A%20Approximation%2C%20Training%20Dynamics%2C%20and%20Generative%20Models                                                                                  A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models                                                                                  In this article, we review the literature on statistical theories of neural networks from three perspectives. In the first part, results on excess risks for neural networks are reviewed in the nonparametric framework of regression or classification. These results rely on explicit constructions of neural networks, leading to fast convergence rates of excess risks, in that tools from the approximation theory are adopted. Through these constructions, the width and depth of the networks can be expressed in terms of sample size, data dimension, and function smoothness. Nonetheless, their underlying analysis only applies to the global minimizer in the highly non-convex landscape of deep neural networks. This motivates us to review the training dynamics of neural networks in the second part. Specifically, we review papers that attempt to answer ``how the neural network trained via gradient-based methods finds the solution that can generalize well on unseen data.'' In particular, two well-known paradigms are reviewed: the Neural Tangent Kernel (NTK) paradigm, and Mean-Field (MF) paradigm. In the last part, we review the most recent theoretical advancements in generative models including Generative Adversarial Networks (GANs), diffusion models, and in-context learning (ICL) in the Large Language Models (LLMs). The former two models are known to be the main pillars of the modern generative AI era, while ICL is a strong capability of LLMs in learning from a few examples in the context. Finally, we conclude the paper by suggesting several promising directions for deep learning theory.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Transformer%20Compression                                                                                  A Survey on Transformer Compression                                                                                  Transformer plays a vital role in the realms of natural language processing (NLP) and computer vision (CV), specially for constructing large language models (LLM) and large vision models (LVM). Model compression methods reduce the memory and computational cost of Transformer, which is a necessary step to implement large language/vision models on practical devices. Given the unique architecture of Transformer, featuring alternative attention and feedforward neural network (FFN) modules, specific compression techniques are usually required. The efficiency of these compression methods is also paramount, as retraining large models on the entire training dataset is usually impractical. This survey provides a comprehensive review of recent compression methods, with a specific focus on their application to Transformer-based models. The compression methods are primarily categorized into pruning, quantization, knowledge distillation, and efficient architecture design (Mamba, RetNet, RWKV, etc.). In each category, we discuss compression methods for both language and vision tasks, highlighting common underlying principles. Finally, we delve into the relation between various compression methods, and discuss further directions in this domain.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20the%20Densest%20Subgraph%20Problem%20and%20Its%20Variants                                                                                  A Survey on the Densest Subgraph Problem and Its Variants                                                                                  The Densest Subgraph Problem requires to find, in a given graph, a subset of vertices whose induced subgraph maximizes a measure of density. The problem has received a great deal of attention in the algorithmic literature since the early 1970s, with many variants proposed and many applications built on top of this basic definition. Recent years have witnessed a revival of research interest in this problem with several important contributions, including some groundbreaking results, published in 2022 and 2023. This survey provides a deep overview of the fundamental results and an exhaustive coverage of the many variants proposed in the literature, with a special attention to the most recent results. The survey also presents a comprehensive overview of applications and discusses some interesting open problems for this evergreen research topic.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20the%20Robustness%20of%20Computer%20Vision%20Models%20against%20Common%20Corruptions                                                                                  A Survey on the Robustness of Computer Vision Models against Common Corruptions                                                                                  The performance of computer vision models are susceptible to unexpected changes in input images, known as common corruptions (e.g. noise, blur, illumination changes, etc.), that can hinder their reliability when deployed in real scenarios. These corruptions are not always considered to test model generalization and robustness. In this survey, we present a comprehensive overview of methods that improve the robustness of computer vision models against common corruptions. We categorize methods into four groups based on the model part and training method addressed: data augmentation, representation learning, knowledge distillation, and network components. We also cover indirect methods for generalization and mitigation of shortcut learning, potentially useful for corruption robustness. We release a unified benchmark framework to compare robustness performance on several datasets, and address the inconsistencies of evaluation in the literature. We provide an experimental overview of the base corruption robustness of popular vision backbones, and show that corruption robustness does not necessarily scale with model size. The very large models (above 100M parameters) gain negligible robustness, considering the increased computational requirements. To achieve generalizable and robust computer vision models, we foresee the need of developing new learning strategies to efficiently exploit limited data and mitigate unwanted or unreliable learning behaviors.
http://w3id.org/mlsea/pwc/scientificWork/A%20Systematic%20Evaluation%20of%20Euclidean%20Alignment%20with%20Deep%20Learning%20for%20EEG%20Decoding                                                                                  A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding                                                                                  Electroencephalography (EEG) signals are frequently used for various Brain-Computer Interface (BCI) tasks. While Deep Learning (DL) techniques have shown promising results, they are hindered by the substantial data requirements. By leveraging data from multiple subjects, transfer learning enables more effective training of DL models. A technique that is gaining popularity is Euclidean Alignment (EA) due to its ease of use, low computational complexity, and compatibility with Deep Learning models. However, few studies evaluate its impact on the training performance of shared and individual DL models. In this work, we systematically evaluate the effect of EA combined with DL for decoding BCI signals. We used EA to train shared models with data from multiple subjects and evaluated its transferability to new subjects. Our experimental results show that it improves decoding in the target subject by 4.33% and decreases convergence time by more than 70%. We also trained individual models for each subject to use as a majority-voting ensemble classifier. In this scenario, using EA improved the 3-model ensemble accuracy by 3.7%. However, when compared to the shared model with EA, the ensemble accuracy was 3.62% lower.
http://w3id.org/mlsea/pwc/scientificWork/A%20Systematic%20Overview%20of%20Single-Cell%20Transcriptomics%20Databases%2C%20their%20Use%20cases%2C%20and%20Limitations                                                                                  A Systematic Overview of Single-Cell Transcriptomics Databases, their Use cases, and Limitations                                                                                  Rapid advancements in high-throughput single-cell RNA-seq (scRNA-seq) technologies and experimental protocols have led to the generation of vast amounts of genomic data that populates several online databases and repositories. Here, we systematically examined large-scale scRNA-seq databases, categorizing them based on their scope and purpose such as general, tissue-specific databases, disease-specific databases, cancer-focused databases, and cell type-focused databases. Next, we discuss the technical and methodological challenges associated with curating large-scale scRNA-seq databases, along with current computational solutions. We argue that understanding scRNA-seq databases, including their limitations and assumptions, is crucial for effectively utilizing this data to make robust discoveries and identify novel biological insights. Furthermore, we propose that bridging the gap between computational and wet lab scientists through user-friendly web-based platforms is needed for democratizing access to single-cell data. These platforms would facilitate interdisciplinary research, enabling researchers from various disciplines to collaborate effectively. This review underscores the importance of leveraging computational approaches to unravel the complexities of single-cell data and offers a promising direction for future research in the field.
http://w3id.org/mlsea/pwc/scientificWork/A%20Systematic%20Review%20of%20Low-Rank%20and%20Local%20Low-Rank%20Matrix%20Approximation%20in%20Big%20Data%20Medical%20Imaging                                                                                  A Systematic Review of Low-Rank and Local Low-Rank Matrix Approximation in Big Data Medical Imaging                                                                                  The large volume and complexity of medical imaging datasets are bottlenecks for storage, transmission, and processing. To tackle these challenges, the application of low-rank matrix approximation (LRMA) and its derivative, local LRMA (LLRMA) has demonstrated potential. A detailed analysis of the literature identifies LRMA and LLRMA methods applied to various imaging modalities, and the challenges and limitations associated with existing LRMA and LLRMA methods are addressed. We note a significant shift towards a preference for LLRMA in the medical imaging field since 2015, demonstrating its potential and effectiveness in capturing complex structures in medical data compared to LRMA. Acknowledging the limitations of shallow similarity methods used with LLRMA, we suggest advanced semantic image segmentation for similarity measure, explaining in detail how it can measure similar patches and their feasibility. We note that LRMA and LLRMA are mainly applied to unstructured medical data, and we propose extending their application to different medical data types, including structured and semi-structured. This paper also discusses how LRMA and LLRMA can be applied to regular data with missing entries and the impact of inaccuracies in predicting missing values and their effects. We discuss the impact of patch size and propose the use of random search (RS) to determine the optimal patch size. To enhance feasibility, a hybrid approach using Bayesian optimization and RS is proposed, which could improve the application of LRMA and LLRMA in medical imaging.
http://w3id.org/mlsea/pwc/scientificWork/A%20Task-Driven%20Multi-UAV%20Coalition%20Formation%20Mechanism                                                                                  A Task-Driven Multi-UAV Coalition Formation Mechanism                                                                                  With the rapid advancement of UAV technology, the problem of UAV coalition formation has become a hotspot. Therefore, designing task-driven multi-UAV coalition formation mechanism has become a challenging problem. However, existing coalition formation mechanisms suffer from low relevance between UAVs and task requirements, resulting in overall low coalition utility and unstable coalition structures. To address these problems, this paper proposed a novel multi-UAV coalition network collaborative task completion model, considering both coalition work capacity and task-requirement relationships. This model stimulated the formation of coalitions that match task requirements by using a revenue function based on the coalition's revenue threshold. Subsequently, an algorithm for coalition formation based on marginal utility was proposed. Specifically, the algorithm utilized Shapley value to achieve fair utility distribution within the coalition, evaluated coalition values based on marginal utility preference order, and achieved stable coalition partition through a limited number of iterations. Additionally, we theoretically proved that this algorithm has Nash equilibrium solution. Finally, experimental results demonstrated that the proposed algorithm, compared to currently classical algorithms, not only forms more stable coalitions but also further enhances the overall utility of coalitions effectively.
http://w3id.org/mlsea/pwc/scientificWork/A%20Taxmans%20guide%20to%20taxation%20of%20crypto%20assets                                                                                  A Taxmans guide to taxation of crypto assets                                                                                  The Financial system has witnessed rapid technological changes. The rise of Bitcoin and other crypto assets based on Distributed Ledger Technology mark a fundamental change in the way people transact and transmit value over a decentralized network, spread across geographies. This has created regulatory and tax policy blind spots, as governments and tax administrations take time to understand and provide policy responses to this innovative, revolutionary, and fast-paced technology. Due to the breakneck speed of innovation in blockchain technology and advent of Decentralized Finance, Decentralized Autonomous Organizations and the Metaverse, it is unlikely that the policy interventions and guidance by regulatory authorities or tax administrations would be ahead or in sync with the pace of innovation. This paper tries to explain the principles on which crypto assets function, their underlying technology and relates them to the tax issues and taxable events which arise within this ecosystem. It also provides instances of tax and regulatory policy responses already in effect in various jurisdictions, including the recent changes in reporting standards by the FATF and the OECD. This paper tries to explain the rationale behind existing laws and policies and the challenges in their implementation. It also attempts to present a ballpark estimate of tax potential of this asset class and suggests creation of global public digital infrastructure that can address issues related to pseudonymity and extra-territoriality. The paper analyses both direct and indirect taxation issues related to crypto assets and discusses more recent aspects like proof-of-stake and maximal extractable value in greater detail.
http://w3id.org/mlsea/pwc/scientificWork/A%20Taxonomy%20of%20Foundation%20Model%20based%20Systems%20through%20the%20Lens%20of%20Software%20Architecture                                                                                  A Taxonomy of Foundation Model based Systems through the Lens of Software Architecture                                                                                  The recent release of large language model (LLM) based chatbots, such as ChatGPT, has attracted huge interest in foundation models. It is widely believed that foundation models will serve as the fundamental building blocks for future AI systems. As foundation models are in their early stages, the design of foundation model based systems has not yet been systematically explored. There is limited understanding about the impact of introducing foundation models in software architecture. Therefore, in this paper, we propose a taxonomy of foundation model based systems, which classifies and compares the characteristics of foundation models and design options of foundation model based systems. Our taxonomy comprises three categories: the pretraining and adaptation of foundation models, the architecture design of foundation model based systems, and responsible-AI-by-design. This taxonomy can serve as concrete guidance for making major architectural design decisions when designing foundation model based systems and highlights trade-offs arising from design decisions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Temporal%20Graph%20Network%20Framework%20for%20Dynamic%20Recommendation                                                                                  A Temporal Graph Network Framework for Dynamic Recommendation                                                                                  Recommender systems, crucial for user engagement on platforms like e-commerce and streaming services, often lag behind users' evolving preferences due to static data reliance. After Temporal Graph Networks (TGNs) were proposed, various studies have shown that TGN can significantly improve situations where the features of nodes and edges dynamically change over time. However, despite its promising capabilities, it has not been directly applied in recommender systems to date. Our study bridges this gap by directly implementing Temporal Graph Networks (TGN) in recommender systems, a first in this field. Using real-world datasets and a range of graph and history embedding methods, we show TGN's adaptability, confirming its effectiveness in dynamic recommendation scenarios.
http://w3id.org/mlsea/pwc/scientificWork/A%20Theoretical%20Result%20on%20the%20Inductive%20Bias%20of%20RNN%20Language%20Models                                                                                  A Theoretical Result on the Inductive Bias of RNN Language Models                                                                                  Recent work by Hewitt et al. (2020) provides a possible interpretation of the empirical success of recurrent neural networks (RNNs) as language models (LMs). It shows that RNNs can efficiently represent bounded hierarchical structures that are prevalent in human language. This suggests that RNNs' success might be linked to their ability to model hierarchy. However, a closer inspection of Hewitt et al.'s (2020) construction shows that it is not limited to hierarchical LMs, posing the question of what emph{other classes} of LMs can be efficiently represented by RNNs. To this end, we generalize their construction to show that RNNs can efficiently represent a larger class of LMs: Those that can be represented by a pushdown automaton with a bounded stack and a generalized stack update function. This is analogous to an automaton that keeps a memory of a fixed number of symbols and updates the memory with a simple update mechanism. Altogether, the efficiency in representing a diverse class of non-hierarchical LMs posits a lack of concrete cognitive and human-language-centered inductive biases in RNNs.
http://w3id.org/mlsea/pwc/scientificWork/A%20Theory%20for%20Length%20Generalization%20in%20Learning%20to%20Reason                                                                                  A Theory for Length Generalization in Learning to Reason                                                                                  Length generalization (LG) is a challenging problem in learning to reason. It refers to the phenomenon that when trained on reasoning problems of smaller lengths or sizes, the resulting model struggles with problems of larger sizes or lengths. Although LG has been studied by many researchers, the challenge remains. This paper proposes a theoretical study of LG for problems whose reasoning processes can be modeled as DAGs (directed acyclic graphs). The paper first identifies and proves the conditions under which LG can be achieved in learning to reason. It then designs problem representations based on the theory to learn to solve challenging reasoning problems like parity, addition, and multiplication, using a Transformer to achieve perfect LG.
http://w3id.org/mlsea/pwc/scientificWork/A%20Theory%20of%20General%20Difference%20in%20Continuous%20and%20Discrete%20Domain                                                                                  A Theory of General Difference in Continuous and Discrete Domain                                                                                  Though a core element of the digital age, numerical difference algorithms struggle with noise susceptibility. This stems from a key disconnect between the infinitesimal quantities in continuous differentiation and the finite intervals in its discrete counterpart. This disconnect violates the fundamental definition of differentiation (Leibniz and Cauchy). To bridge this gap, we build a novel general difference (Tao General Difference, TGD). Departing from derivative-by-integration, TGD generalizes differentiation to finite intervals in continuous domains through three key constraints. This allows us to calculate the general difference of a sequence in discrete domain via the continuous step function constructed from the sequence. Two construction methods, the rotational construction and the orthogonal construction, are proposed to construct the operators of TGD. The construction TGD operators take same convolution mode in calculation for continuous functions, discrete sequences, and arrays across any dimension. Our analysis with example operations showcases TGD's capability in both continuous and discrete domains, paving the way for accurate and noise-resistant differentiation in the digital era.
http://w3id.org/mlsea/pwc/scientificWork/A%20Time-varying%20Shockwave%20Speed%20Model%20for%20Trajectory%20Reconstruction%20using%20Lagrangian%20and%20Eulerian%20Observations                                                                                  A Time-varying Shockwave Speed Model for Trajectory Reconstruction using Lagrangian and Eulerian Observations                                                                                  Inference of detailed vehicle trajectories is crucial for applications such as traffic flow modeling, energy consumption estimation, and traffic flow optimization. Static sensors can provide only aggregated information, posing challenges in reconstructing individual vehicle trajectories. Shockwave theory is used to reproduce oscillations that occur between sensors. However, as the emerging of connected vehicles grows, probe data offers significant opportunities for more precise trajectory reconstruction. Existing methods rely on Eulerian observations (e.g., data from static sensors) and Lagrangian observations (e.g., data from probe vehicles) incorporating shockwave theory and car-following modeling. Despite these advancements, a prevalent issue lies in the static assignment of shockwave speed, which may not be able to reflect the traffic oscillations in a short time period caused by varying response times and vehicle dynamics. Moreover, energy consumption estimation is largely ignored. In response, this paper proposes a novel framework that integrates Eulerian and Lagrangian observations for trajectory reconstruction. The approach introduces a calibration algorithm for time-varying shockwave speed. The calibrated shockwave speed of the CV is then utilized for trajectory reconstruction of other non-connected vehicles based on shockwave theory. Additionaly, vehicle and driver dynamics are introduced to optimize the trajectory and estimate energy consumption. The proposed method is evaluated using real-world datasets, demonstrating superior performance in terms of trajectory accuracy, reproducing traffic oscillations, and estimating energy consumption.
http://w3id.org/mlsea/pwc/scientificWork/A%20Toolbox%20for%20Modelling%20Engagement%20with%20Educational%20Videos                                                                                  A Toolbox for Modelling Engagement with Educational Videos                                                                                  With the advancement and utility of Artificial Intelligence (AI), personalising education to a global population could be a cornerstone of new educational systems in the future. This work presents the PEEKC dataset and the TrueLearn Python library, which contains a dataset and a series of online learner state models that are essential to facilitate research on learner engagement modelling.TrueLearn family of models was designed following the 'open learner' concept, using humanly-intuitive user representations. This family of scalable, online models also help end-users visualise the learner models, which may in the future facilitate user interaction with their models/recommenders. The extensive documentation and coding examples make the library highly accessible to both machine learning developers and educational data mining and learning analytics practitioners. The experiments show the utility of both the dataset and the library with predictive performance significantly exceeding comparative baseline models. The dataset contains a large amount of AI-related educational videos, which are of interest for building and validating AI-specific educational recommenders.
http://w3id.org/mlsea/pwc/scientificWork/A%20Transformer-Based%20Framework%20for%20Payload%20Malware%20Detection%20and%20Classification                                                                                  A Transformer-Based Framework for Payload Malware Detection and Classification                                                                                  As malicious cyber threats become more sophisticated in breaching computer networks, the need for effective intrusion detection systems (IDSs) becomes crucial. Techniques such as Deep Packet Inspection (DPI) have been introduced to allow IDSs analyze the content of network packets, providing more context for identifying potential threats. IDSs traditionally rely on using anomaly-based and signature-based detection techniques to detect unrecognized and suspicious activity. Deep learning techniques have shown great potential in DPI for IDSs due to their efficiency in learning intricate patterns from the packet content being transmitted through the network. In this paper, we propose a revolutionary DPI algorithm based on transformers adapted for the purpose of detecting malicious traffic with a classifier head. Transformers learn the complex content of sequence data and generalize them well to similar scenarios thanks to their self-attention mechanism. Our proposed method uses the raw payload bytes that represent the packet contents and is deployed as man-in-the-middle. The payload bytes are used to detect malicious packets and classify their types. Experimental results on the UNSW-NB15 and CIC-IOT23 datasets demonstrate that our transformer-based model is effective in distinguishing malicious from benign traffic in the test dataset, attaining an average accuracy of 79 % using binary classification and 72 % on the multi-classification experiment, both using solely payload bytes.
http://w3id.org/mlsea/pwc/scientificWork/A%20Trembling%20House%20of%20Cards%3F%20Mapping%20Adversarial%20Attacks%20against%20Language%20Agents                                                                                  A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents                                                                                  Language agents powered by large language models (LLMs) have seen exploding development. Their capability of using language as a vehicle for thought and communication lends an incredible level of flexibility and versatility. People have quickly capitalized on this capability to connect LLMs to a wide range of external components and environments: databases, tools, the Internet, robotic embodiment, etc. Many believe an unprecedentedly powerful automation technology is emerging. However, new automation technologies come with new safety risks, especially for intricate systems like language agents. There is a surprisingly large gap between the speed and scale of their development and deployment and our understanding of their safety risks. Are we building a house of cards? In this position paper, we present the first systematic effort in mapping adversarial attacks against language agents. We first present a unified conceptual framework for agents with three major components: Perception, Brain, and Action. Under this framework, we present a comprehensive discussion and propose 12 potential attack scenarios against different components of an agent, covering different attack strategies (e.g., input manipulation, adversarial demonstrations, jailbreaking, backdoors). We also draw connections to successful attack strategies previously applied to LLMs. We emphasize the urgency to gain a thorough understanding of language agent risks before their widespread deployment.
http://w3id.org/mlsea/pwc/scientificWork/A%20Truly%20Joint%20Neural%20Architecture%20for%20Segmentation%20and%20Parsing                                                                                  A Truly Joint Neural Architecture for Segmentation and Parsing                                                                                  Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages.
http://w3id.org/mlsea/pwc/scientificWork/A%20Tulu%20Resource%20for%20Machine%20Translation                                                                                  A Tulu Resource for Machine Translation                                                                                  We present the first parallel dataset for English-Tulu translation. Tulu, classified within the South Dravidian linguistic family branch, is predominantly spoken by approximately 2.5 million individuals in southwestern India. Our dataset is constructed by integrating human translations into the multilingual machine translation resource FLORES-200. Furthermore, we use this dataset for evaluation purposes in developing our English-Tulu machine translation model. For the model's training, we leverage resources available for related South Dravidian languages. We adopt a transfer learning approach that exploits similarities between high-resource and low-resource languages. This method enables the training of a machine translation system even in the absence of parallel data between the source and target language, thereby overcoming a significant obstacle in machine translation development for low-resource languages. Our English-Tulu system, trained without using parallel English-Tulu data, outperforms Google Translate by 19 BLEU points (in September 2023). The dataset and code are available here: https://github.com/manunarayanan/Tulu-NMT.
http://w3id.org/mlsea/pwc/scientificWork/A%20Tutorial%20on%20the%20Pretrain-Finetune%20Paradigm%20for%20Natural%20Language%20Processing                                                                                  A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing                                                                                  The pretrain-finetune paradigm represents a transformative approach in natural language processing (NLP). This paradigm distinguishes itself through the use of large pretrained language models, demonstrating remarkable efficiency in finetuning tasks, even with limited training data. This efficiency is especially beneficial for research in social sciences, where the number of annotated samples is often quite limited. Our tutorial offers a comprehensive introduction to the pretrain-finetune paradigm. We first delve into the fundamental concepts of pretraining and finetuning, followed by practical exercises using real-world applications. We demonstrate the application of the paradigm across various tasks, including multi-class classification and regression. Emphasizing its efficacy and user-friendliness, the tutorial aims to encourage broader adoption of this paradigm. To this end, we have provided open access to all our code and datasets. The tutorial is particularly valuable for quantitative researchers in psychology, offering them an insightful guide into this innovative approach.
http://w3id.org/mlsea/pwc/scientificWork/A%20Two-Stage%20Algorithm%20for%20Cost-Efficient%20Multi-instance%20Counterfactual%20Explanations                                                                                  A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations                                                                                  Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output. While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously. In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations. This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed.
http://w3id.org/mlsea/pwc/scientificWork/A%20Two-Stage%20Dual-Path%20Framework%20for%20Text%20Tampering%20Detection%20and%20Recognition                                                                                  A Two-Stage Dual-Path Framework for Text Tampering Detection and Recognition                                                                                  Document tamper detection has always been an important aspect of tamper detection. Before the advent of deep learning, document tamper detection was difficult. We have made some explorations in the field of text tamper detection based on deep learning. Our Ps tamper detection method includes three steps: feature assistance, audit point positioning, and tamper recognition. It involves hierarchical filtering and graded output (tampered/suspected tampered/untampered). By combining artificial tamper data features, we simulate and augment data samples in various scenarios (cropping with noise addition/replacement, single character/space replacement, smearing/splicing, brightness/contrast adjustment, etc.). The auxiliary features include exif/binary stream keyword retrieval/noise, which are used for branch detection based on the results. Audit point positioning uses detection frameworks and controls thresholds for high and low density detection. Tamper recognition employs a dual-path dual-stream recognition network, with RGB and ELA stream feature extraction. After dimensionality reduction through self-correlation percentile pooling, the fused output is processed through vlad, yielding an accuracy of 0.804, recall of 0.659, and precision of 0.913.
http://w3id.org/mlsea/pwc/scientificWork/A%20Two-Stage%20Training%20Method%20for%20Modeling%20Constrained%20Systems%20With%20Neural%20Networks                                                                                  A Two-Stage Training Method for Modeling Constrained Systems With Neural Networks                                                                                  Real-world systems are often formulated as constrained optimization problems. Techniques to incorporate constraints into Neural Networks (NN), such as Neural Ordinary Differential Equations (Neural ODEs), have been used. However, these introduce hyperparameters that require manual tuning through trial and error, raising doubts about the successful incorporation of constraints into the generated model. This paper describes in detail the two-stage training method for Neural ODEs, a simple, effective, and penalty parameter-free approach to model constrained systems. In this approach the constrained optimization problem is rewritten as two unconstrained sub-problems that are solved in two stages. The first stage aims at finding feasible NN parameters by minimizing a measure of constraints violation. The second stage aims to find the optimal NN parameters by minimizing the loss function while keeping inside the feasible region. We experimentally demonstrate that our method produces models that satisfy the constraints and also improves their predictive performance. Thus, ensuring compliance with critical system properties and also contributing to reducing data quantity requirements. Furthermore, we show that the proposed method improves the convergence to an optimal solution and improves the explainability of Neural ODE models. Our proposed two-stage training method can be used with any NN architectures.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Framework%20for%20Adaptive%20Representation%20Enhancement%20and%20Inversed%20Learning%20in%20Cross-Domain%20Recommendation                                                                                  A Unified Framework for Adaptive Representation Enhancement and Inversed Learning in Cross-Domain Recommendation                                                                                  Cross-domain recommendation (CDR), aiming to extract and transfer knowledge across domains, has attracted wide attention for its efficacy in addressing data sparsity and cold-start problems. Despite significant advances in representation disentanglement to capture diverse user preferences, existing methods usually neglect representation enhancement and lack rigorous decoupling constraints, thereby limiting the transfer of relevant information. To this end, we propose a Unified Framework for Adaptive Representation Enhancement and Inversed Learning in Cross-Domain Recommendation (AREIL). Specifically, we first divide user embeddings into domain-shared and domain-specific components to disentangle mixed user preferences. Then, we incorporate intra-domain and inter-domain information to adaptively enhance the ability of user representations. In particular, we propose a graph convolution module to capture high-order information, and a self-attention module to reveal inter-domain correlations and accomplish adaptive fusion. Next, we adopt domain classifiers and gradient reversal layers to achieve inversed representation learning in a unified framework. Finally, we employ a cross-entropy loss for measuring recommendation performance and jointly optimize the entire framework via multi-task learning. Extensive experiments on multiple datasets validate the substantial improvement in the recommendation performance of AREIL. Moreover, ablation studies and representation visualizations further illustrate the effectiveness of adaptive enhancement and inversed learning in CDR.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Toll%20Lane%20Framework%20for%20Autonomous%20and%20High-Occupancy%20Vehicles%20in%20Interactive%20Mixed%20Autonomy                                                                                  A Unified Toll Lane Framework for Autonomous and High-Occupancy Vehicles in Interactive Mixed Autonomy                                                                                  In this study, we introduce a toll lane framework that optimizes the mixed flow of autonomous and high-occupancy vehicles on freeways, where human-driven and autonomous vehicles of varying commuter occupancy share a segment. Autonomous vehicles, with their ability to maintain shorter headways, boost traffic throughput. Our framework designates a toll lane for autonomous vehicles with high occupancy to use free of charge, while others pay a toll. We explore the lane choice equilibria when all vehicles minimize travel costs, and characterize the equilibria by ranking vehicles by their mobility enhancement potential, a concept we term the mobility degree. Through numerical examples, we demonstrate the framework's utility in addressing design challenges such as setting optimal tolls, determining occupancy thresholds, and designing lane policies, showing how it facilitates the integration of high-occupancy and autonomous vehicles. We also propose an algorithm for assigning rational tolls to decrease total commuter delay and examine the effects of toll non-compliance. Our findings suggest that self-interest-driven behavior mitigates moderate non-compliance impacts, highlighting the framework's resilience. This work presents a pioneering comprehensive analysis of a toll lane framework that emphasizes the coexistence of autonomous and high-occupancy vehicles, offering insights for traffic management improvements and the integration of autonomous vehicles into existing transportation infrastructures.
http://w3id.org/mlsea/pwc/scientificWork/A%20VAE-based%20Framework%20for%20Learning%20Multi-Level%20Neural%20Granger-Causal%20Connectivity                                                                                  A VAE-based Framework for Learning Multi-Level Neural Granger-Causal Connectivity                                                                                  Granger causality has been widely used in various application domains to capture lead-lag relationships amongst the components of complex dynamical systems, and the focus in extant literature has been on a single dynamical system. In certain applications in macroeconomics and neuroscience, one has access to data from a collection of related such systems, wherein the modeling task of interest is to extract the shared common structure that is embedded across them, as well as to identify the idiosyncrasies within individual ones. This paper introduces a Variational Autoencoder (VAE) based framework that jointly learns Granger-causal relationships amongst components in a collection of related-yet-heterogeneous dynamical systems, and handles the aforementioned task in a principled way. The performance of the proposed framework is evaluated on several synthetic data settings and benchmarked against existing approaches designed for individual system learning. The method is further illustrated on a real dataset involving time series data from a neurophysiological experiment and produces interpretable results.
http://w3id.org/mlsea/pwc/scientificWork/A%20Vanilla%20Multi-Task%20Framework%20for%20Dense%20Visual%20Prediction%20Solution%20to%201st%20VCL%20Challenge%20--%20Multi-Task%20Robustness%20Track                                                                                  A Vanilla Multi-Task Framework for Dense Visual Prediction Solution to 1st VCL Challenge -- Multi-Task Robustness Track                                                                                  In this report, we present our solution to the multi-task robustness track of the 1st Visual Continual Learning (VCL) Challenge at ICCV 2023 Workshop. We propose a vanilla framework named UniNet that seamlessly combines various visual perception algorithms into a multi-task model. Specifically, we choose DETR3D, Mask2Former, and BinsFormer for 3D object detection, instance segmentation, and depth estimation tasks, respectively. The final submission is a single model with InternImage-L backbone, and achieves a 49.6 overall score (29.5 Det mAP, 80.3 mTPS, 46.4 Seg mAP, and 7.93 silog) on SHIFT validation set. Besides, we provide some interesting observations in our experiments which may facilitate the development of multi-task learning in dense visual prediction.
http://w3id.org/mlsea/pwc/scientificWork/A%20YANG-aided%20Unified%20Strategy%20for%20Black%20Hole%20Detection%20for%20Backbone%20Networks                                                                                  A YANG-aided Unified Strategy for Black Hole Detection for Backbone Networks                                                                                  Despite the crucial importance of addressing Black Hole failures in Internet backbone networks, effective detection strategies in backbone networks are lacking. This is largely because previous research has been centered on Mobile Ad-hoc Networks (MANETs), which operate under entirely different dynamics, protocols, and topologies, making their findings not directly transferable to backbone networks. Furthermore, detecting Black Hole failures in backbone networks is particularly challenging. It requires a comprehensive range of network data due to the wide variety of conditions that need to be considered, making data collection and analysis far from straightforward. Addressing this gap, our study introduces a novel approach for Black Hole detection in backbone networks using specialized Yet Another Next Generation (YANG) data models with Black Hole-sensitive Metric Matrix (BHMM) analysis. This paper details our method of selecting and analyzing four YANG models relevant to Black Hole detection in ISP networks, focusing on routing protocols and ISP-specific configurations. Our BHMM approach derived from these models demonstrates a 10% improvement in detection accuracy and a 13% increase in packet delivery rate, highlighting the efficiency of our approach. Additionally, we evaluate the Machine Learning approach leveraged with BHMM analysis in two different network settings, a commercial ISP network, and a scientific research-only network topology. This evaluation also demonstrates the practical applicability of our method, yielding significantly improved prediction outcomes in both environments.
http://w3id.org/mlsea/pwc/scientificWork/A%20backward%20differential%20deep%20learning-based%20algorithm%20for%20solving%20high-dimensional%20nonlinear%20backward%20stochastic%20differential%20equations                                                                                  A backward differential deep learning-based algorithm for solving high-dimensional nonlinear backward stochastic differential equations                                                                                  In this work, we propose a novel backward differential deep learning-based algorithm for solving high-dimensional nonlinear backward stochastic differential equations (BSDEs), where the deep neural network (DNN) models are trained not only on the inputs and labels but also the differentials of the corresponding labels. This is motivated by the fact that differential deep learning can provide an efficient approximation of the labels and their derivatives with respect to inputs. The BSDEs are reformulated as differential deep learning problems by using Malliavin calculus. The Malliavin derivatives of solution to a BSDE satisfy themselves another BSDE, resulting thus in a system of BSDEs. Such formulation requires the estimation of the solution, its gradient, and the Hessian matrix, represented by the triple of processes $ left(Y, Z, Gamma right).$ All the integrals within this system are discretized by using the Euler-Maruyama method. Subsequently, DNNs are employed to approximate the triple of these unknown processes. The DNN parameters are backwardly optimized at each time step by minimizing a differential learning type loss function, which is defined as a weighted sum of the dynamics of the discretized BSDE system, with the first term providing the dynamics of the process $Y$ and the other the process $Z$. An error analysis is carried out to show the convergence of the proposed algorithm. Various numerical experiments up to $50$ dimensions are provided to demonstrate the high efficiency. Both theoretically and numerically, it is demonstrated that our proposed scheme is more efficient compared to other contemporary deep learning-based methodologies, especially in the computation of the process $ Gamma$.
http://w3id.org/mlsea/pwc/scientificWork/A%20biological%20circuit%20to%20anticipate%20trend                                                                                  A biological circuit to anticipate trend                                                                                  Organisms gain by anticipating future changes in the environment. Those environmental changes often follow stochastic trends. The greater the slope of the trend, the more likely the trend's momentum carries the future trend in the same direction. This article presents a simple biological circuit that measures the momentum, providing a prediction about future trend. The circuit calculates the momentum by the difference between a short-term and a long-term exponential moving average. The time lengths of the two moving averages can be adjusted by changing the decay rates of state variables. Different time lengths for those averages trade off between errors caused by noise and errors caused by lags in predicting a change in the direction of the trend. Prior studies have emphasized circuits that make similar calculations about trends. However, those prior studies embedded their analyses in the details of particular applications, obscuring the simple generality and wide applicability of the approach. The model here contributes to the topic by clarifying the great simplicity and generality of anticipation for stochastic trends. This article also notes that, in financial analysis, the difference between moving averages is widely used to predict future trends in asset prices. The financial measure is called the moving average convergence-divergence (MACD) indicator. Connecting the biological problem to financial analysis opens the way for future studies in biology to exploit the variety of highly developed trend models in finance.
http://w3id.org/mlsea/pwc/scientificWork/A%20biologically%20inspired%20computational%20trust%20model%20for%20open%20multi-agent%20systems%20which%20is%20resilient%20to%20trustor%20population%20changes                                                                                  A biologically inspired computational trust model for open multi-agent systems which is resilient to trustor population changes                                                                                  Current trust and reputation models continue to have significant limitations, such as the inability to deal with agents constantly entering or exiting open multi-agent systems (open MAS), as well as continuously changing behaviors. Our study is based on CA, a previously proposed decentralized computational trust model from the trustee's point of view, inspired by synaptic plasticity and the formation of assemblies in the human brain. It is designed to meet the requirements of highly dynamic and open MAS, and its main difference with most conventional trust and reputation models is that the trustor does not select a trustee to delegate a task; instead, the trustee determines whether it is qualified to successfully execute it. We ran a series of simulations to compare CA model to FIRE, a well-established, decentralized trust and reputation model for open MAS under conditions of continuous trustee and trustor population replacement, as well as continuous change of trustees' abilities to perform tasks. The main finding is that FIRE is superior to changes in the trustee population, whereas CA is resilient to the trustor population changes. When the trustees switch performance profiles FIRE clearly outperforms despite the fact that both models' performances are significantly impacted by this environmental change. Findings lead us to conclude that learning to use the appropriate trust model, according to the dynamic conditions in effect could maximize the trustor's benefits.
http://w3id.org/mlsea/pwc/scientificWork/A%20comparative%20analysis%20of%20deep%20learning%20models%20for%20lung%20segmentation%20on%20X-ray%20images                                                                                  A comparative analysis of deep learning models for lung segmentation on X-ray images                                                                                  Robust and highly accurate lung segmentation in X-rays is crucial in medical imaging. This study evaluates deep learning solutions for this task, ranking existing methods and analyzing their performance under diverse image modifications. Out of 61 analyzed papers, only nine offered implementation or pre-trained models, enabling assessment of three prominent methods: Lung VAE, TransResUNet, and CE-Net. The analysis revealed that CE-Net performs best, demonstrating the highest values in dice similarity coefficient and intersection over union metric.
http://w3id.org/mlsea/pwc/scientificWork/A%20comparison%20of%20Human%2C%20GPT-3.5%2C%20and%20GPT-4%20Performance%20in%20a%20University-Level%20Coding%20Course                                                                                  A comparison of Human, GPT-3.5, and GPT-4 Performance in a University-Level Coding Course                                                                                  This study evaluates the performance of ChatGPT variants, GPT-3.5 and GPT-4, both with and without prompt engineering, against solely student work and a mixed category containing both student and GPT-4 contributions in university-level physics coding assignments using the Python language. Comparing 50 student submissions to 50 AI-generated submissions across different categories, and marked blindly by three independent markers, we amassed $n = 300$ data points. Students averaged 91.9% (SE:0.4), surpassing the highest performing AI submission category, GPT-4 with prompt engineering, which scored 81.1% (SE:0.8) - a statistically significant difference (p = $2.482 times 10^{-10}$). Prompt engineering significantly improved scores for both GPT-4 (p = $1.661 times 10^{-4}$) and GPT-3.5 (p = $4.967 times 10^{-9}$). Additionally, the blinded markers were tasked with guessing the authorship of the submissions on a four-point Likert scale from `Definitely AI' to `Definitely Human'. They accurately identified the authorship, with 92.1% of the work categorized as 'Definitely Human' being human-authored. Simplifying this to a binary `AI' or `Human' categorization resulted in an average accuracy rate of 85.3%. These findings suggest that while AI-generated work closely approaches the quality of university students' work, it often remains detectable by human evaluators.
http://w3id.org/mlsea/pwc/scientificWork/A%20comprehensive%20framework%20for%20multi-fidelity%20surrogate%20modeling%20with%20noisy%20data%3A%20a%20gray-box%20perspective                                                                                  A comprehensive framework for multi-fidelity surrogate modeling with noisy data: a gray-box perspective                                                                                  Computer simulations (a.k.a. white-box models) are more indispensable than ever to model intricate engineering systems. However, computational models alone often fail to fully capture the complexities of reality. When physical experiments are accessible though, it is of interest to enhance the incomplete information offered by computational models. Gray-box modeling is concerned with the problem of merging information from data-driven (a.k.a. black-box) models and white-box (i.e., physics-based) models. In this paper, we propose to perform this task by using multi-fidelity surrogate models (MFSMs). A MFSM integrates information from models with varying computational fidelity into a new surrogate model. The multi-fidelity surrogate modeling framework we propose handles noise-contaminated data and is able to estimate the underlying noise-free high-fidelity function. Our methodology emphasizes on delivering precise estimates of the uncertainty in its predictions in the form of confidence and prediction intervals, by quantitatively incorporating the different types of uncertainty that affect the problem, arising from measurement noise and from lack of knowledge due to the limited experimental design budget on both the high- and low-fidelity models. Applied to gray-box modeling, our MFSM framework treats noisy experimental data as the high-fidelity and the white-box computational models as their low-fidelity counterparts. The effectiveness of our methodology is showcased through synthetic examples and a wind turbine application.
http://w3id.org/mlsea/pwc/scientificWork/A%20dynamic%20model%20to%20study%20the%20potential%20TB%20infections%20and%20assessment%20of%20control%20strategies%20in%20China                                                                                  A dynamic model to study the potential TB infections and assessment of control strategies in China                                                                                  China is one of the countries with a high burden of tuberculosis, and although the number of new cases of tuberculosis has been decreasing year by year, the number of new infections per year has remained high and the diagnosis rate of tuberculosis-infected patients has remained low. Based on the analysis of TB infection data, we develop a model of TB transmission dynamics that include potentially infected individuals and BCG vaccination, fit the model parameters to the data on new TB cases, calculate the basic reproduction number mathcal{R}_v= 0.4442. A parametric sensitivity analysis of mathcal{R}_v is performed, and we obtained the correlation coefficients of BCG vaccination rate and effectiveness rate with mathcal{R}_v as -0.810, -0.825. According to the model, we estimate that there are 614,186 (95% CI [562,631,665,741]) potentially infected TB cases in China, accounting for about 39.5% of the total number of TB cases. We assess the feasibility of achieving the goals of the WHO strategy to end tuberculosis in China and find that reducing the number of new cases by 90 per cent by 2035 is very difficult with the current tuberculosis control measures. However, with an effective combination of control measures such as increased detection of potentially infected persons, improved drug treatment, and reduction of overall exposure to tuberculosis patients, it is feasible to reach the WHO strategic goal of ending tuberculosis by 2035.
http://w3id.org/mlsea/pwc/scientificWork/A%20dynamical%20clipping%20approach%20with%20task%20feedback%20for%20Proximal%20Policy%20Optimization                                                                                  A dynamical clipping approach with task feedback for Proximal Policy Optimization                                                                                  Proximal Policy Optimization (PPO) has been broadly applied to various domains, including Large Language Model (LLM) optimization and Robotics learning, etc. However, PPO is limited by a fixed setting for the clipping bound. Specifically, there is no theoretical proof that the optimal clipping bound remains consistent throughout the entire training process. Truncating the ratio of the new and old policies with a unique clipping bound ensures stable training and can achieve the best training performance. Additionally, previous research suggests that a fixed clipping bound limits the agent's exploration. Therefore, researching a dynamical clipping bound to enhance PPO's performance can be highly beneficial. Different from previous clipping approaches, we consider increasing the maximum cumulative Return in reinforcement learning (RL) tasks as the preference of the RL task, and propose a bi-level proximal policy optimization paradigm, which involves not only optimizing the policy but also dynamically adjusting the clipping bound to reflect the preference of the RL tasks to further elevate the training outcomes and stability of PPO. Based on this bi-level proximal policy optimization paradigm, we introduce a new algorithm named Preference based Proximal Policy Optimization (Pb-PPO). This algorithm utilizes a multi-armed bandit algorithm to reflect RL preferences (we also validate that such approach can be utilized to reflect human preference), recommending the optimal clipping bound for PPO in each epoch, thereby achieving more stable and better training outcomes.
http://w3id.org/mlsea/pwc/scientificWork/A%20finite%20operator%20learning%20technique%20for%20mapping%20the%20elastic%20properties%20of%20microstructures%20to%20their%20mechanical%20deformations                                                                                  A finite operator learning technique for mapping the elastic properties of microstructures to their mechanical deformations                                                                                  To develop faster solvers for governing physical equations in solid mechanics, we introduce a method that parametrically learns the solution to mechanical equilibrium. The introduced method outperforms traditional ones in terms of computational cost while acceptably maintaining accuracy. Moreover, it generalizes and enhances the standard physics-informed neural networks to learn a parametric solution with rather sharp discontinuities. We focus on micromechanics as an example, where the knowledge of the micro-mechanical solution, i.e., deformation and stress fields for a given heterogeneous microstructure, is crucial. The parameter under investigation is the Young modulus distribution within the heterogeneous solid system. Our method, inspired by operator learning and the finite element method, demonstrates the ability to train without relying on data from other numerical solvers. Instead, we leverage ideas from the finite element approach to efficiently set up loss functions algebraically, particularly based on the discretized weak form of the governing equations. Notably, our investigations reveal that physics-based training yields higher accuracy compared to purely data-driven approaches for unseen microstructures. In essence, this method achieves independence from data and enhances accuracy for predictions beyond the training range. The aforementioned observations apply here to heterogeneous elastic microstructures. Comparisons are also made with other well-known operator learning algorithms, such as DeepOnet, to further emphasize the advantages of the newly proposed architecture.
http://w3id.org/mlsea/pwc/scientificWork/A%20general%20approach%20to%20enhance%20the%20survivability%20of%20backdoor%20attacks%20by%20decision%20path%20coupling                                                                                  A general approach to enhance the survivability of backdoor attacks by decision path coupling                                                                                  Backdoor attacks have been one of the emerging security threats to deep neural networks (DNNs), leading to serious consequences. One of the mainstream backdoor defenses is model reconstruction-based. Such defenses adopt model unlearning or pruning to eliminate backdoors. However, little attention has been paid to survive from such defenses. To bridge the gap, we propose Venom, the first generic backdoor attack enhancer to improve the survivability of existing backdoor attacks against model reconstruction-based defenses. We formalize Venom as a binary-task optimization problem. The first is the original backdoor attack task to preserve the original attack capability, while the second is the attack enhancement task to improve the attack survivability. To realize the second task, we propose attention imitation loss to force the decision path of poisoned samples in backdoored models to couple with the crucial decision path of benign samples, which makes backdoors difficult to eliminate. Our extensive evaluation on two DNNs and three datasets has demonstrated that Venom significantly improves the survivability of eight state-of-the-art attacks against eight state-of-the-art defenses without impacting the capability of the original attacks.
http://w3id.org/mlsea/pwc/scientificWork/A%20general%20framework%20for%20rotation%20invariant%20point%20cloud%20analysis                                                                                  A general framework for rotation invariant point cloud analysis                                                                                  We propose a general method for deep learning based point cloud analysis, which is invariant to rotation on the inputs. Classical methods are vulnerable to rotation, as they usually take aligned point clouds as input. Principle Component Analysis (PCA) is a practical approach to achieve rotation invariance. However, there are still some gaps between theory and practical algorithms. In this work, we present a thorough study on designing rotation invariant algorithms for point cloud analysis. We first formulate it as a permutation invariant problem, then propose a general framework which can be combined with any backbones. Our method is beneficial for further research such as 3D pre-training and multi-modal learning. Experiments show that our method has considerable or better performance compared to state-of-the-art approaches on common benchmarks. Code is available at https://github.com/luoshuqing2001/RI_framework.
http://w3id.org/mlsea/pwc/scientificWork/A%20generalized%20decision%20tree%20ensemble%20based%20on%20the%20NeuralNetworks%20architecture%3A%20Distributed%20Gradient%20Boosting%20Forest%20%28DGBF%29                                                                                  A generalized decision tree ensemble based on the NeuralNetworks architecture: Distributed Gradient Boosting Forest (DGBF)                                                                                  Tree ensemble algorithms as RandomForest and GradientBoosting are currently the dominant methods for modeling discrete or tabular data, however, they are unable to perform a hierarchical representation learning from raw data as NeuralNetworks does thanks to its multi-layered structure, which is a key feature for DeepLearning problems and modeling unstructured data. This limitation is due to the fact that tree algorithms can not be trained with back-propagation because of their mathematical nature. However, in this work, we demonstrate that the mathematical formulation of bagging and boosting can be combined together to define a graph-structured-tree-ensemble algorithm with a distributed representation learning process between trees naturally (without using back-propagation). We call this novel approach Distributed Gradient Boosting Forest (DGBF) and we demonstrate that both RandomForest and GradientBoosting can be expressed as particular graph architectures of DGBT. Finally, we see that the distributed learning outperforms both RandomForest and GradientBoosting in 7 out of 9 datasets.
http://w3id.org/mlsea/pwc/scientificWork/A%20hybrid%20dynamical%20system%20approach%20to%20the%20impulsive%20control%20of%20spacecraft%20rendezvous%20%28extended%20version%29                                                                                  A hybrid dynamical system approach to the impulsive control of spacecraft rendezvous (extended version)                                                                                  This paper introduces a hybrid dynamical system methodology for managing impulsive control in spacecraft rendezvous and proximity operations under the Hill-Clohessy-Wiltshire model. We address the control design problem by isolating the out-of-plane from the in-plane dynamics and present a feedback control law for each of them. This law is based on a Lyapunov function tailored to each of the dynamics, capable of addressing thruster saturation and also a minimum impulse bit. These Lyapunov functions were found by reformulating the system's dynamics into coordinates that more intuitively represent their physical behavior. The effectiveness of our control laws is then shown through numerical simulation. This is an extended version of an ECC24 article of the same name, which includes the proofs omitted for lack of space.
http://w3id.org/mlsea/pwc/scientificWork/A%20large%20dataset%20curation%20and%20benchmark%20for%20drug%20target%20interaction                                                                                  A large dataset curation and benchmark for drug target interaction                                                                                  Bioactivity data plays a key role in drug discovery and repurposing. The resource-demanding nature of textit{in vitro} and textit{in vivo} experiments, as well as the recent advances in data-driven computational biochemistry research, highlight the importance of textit{in silico} drug target interaction (DTI) prediction approaches. While numerous large public bioactivity data sources exist, research in the field could benefit from better standardization of existing data resources. At present, different research works that share similar goals are often difficult to compare properly because of different choices of data sources and train/validation/test split strategies. Additionally, many works are based on small data subsets, leading to results and insights of possible limited validity. In this paper we propose a way to standardize and represent efficiently a very large dataset curated from multiple public sources, split the data into train, validation and test sets based on different meaningful strategies, and provide a concrete evaluation protocol to accomplish a benchmark. We analyze the proposed data curation, prove its usefulness and validate the proposed benchmark through experimental studies based on an existing neural network model.
http://w3id.org/mlsea/pwc/scientificWork/A%20large-scale%20systematic%20survey%20reveals%20recurring%20molecular%20features%20of%20public%20antibody%20responses%20to%20SARS-CoV-2                                                                                  A large-scale systematic survey reveals recurring molecular features of public antibody responses to SARS-CoV-2                                                                                  Global research to combat the COVID-19 pandemic has led to the isolation and characterization of thousands of human antibodies to the SARS-CoV-2 spike protein, providing an unprecedented opportunity to study the antibody response to a single antigen. Using the information derived from 88 research publications and 13 patents, we assembled a dataset of ~8,000 human antibodies to the SARS-CoV-2 spike protein from >200 donors. By analyzing immunoglobulin V and D gene usages, complementarity-determining region H3 sequences, and somatic hypermutations, we demonstrated that the common (public) responses to different domains of the spike protein were quite different. We further used these sequences to train a deep-learning model to accurately distinguish between the human antibodies to SARS-CoV-2 spike protein and those to influenza hemagglutinin protein. Overall, this study provides an informative resource for antibody research and enhances our molecular understanding of public antibody responses.
http://w3id.org/mlsea/pwc/scientificWork/A%20least-square%20method%20for%20non-asymptotic%20identification%20in%20linear%20switching%20control                                                                                  A least-square method for non-asymptotic identification in linear switching control                                                                                  The focus of this paper is on linear system identification in the setting where it is known that the underlying partially-observed linear dynamical system lies within a finite collection of known candidate models. We first consider the problem of identification from a given trajectory, which in this setting reduces to identifying the index of the true model with high probability. We characterize the finite-time sample complexity of this problem by leveraging recent advances in the non-asymptotic analysis of linear least-square methods in the literature. In comparison to the earlier results that assume no prior knowledge of the system, our approach takes advantage of the smaller hypothesis class and leads to the design of a learner with a dimension-free sample complexity bound. Next, we consider the switching control of linear systems, where there is a candidate controller for each of the candidate models and data is collected through interaction of the system with a collection of potentially destabilizing controllers. We develop a dimension-dependent criterion that can detect those destabilizing controllers in finite time. By leveraging these results, we propose a data-driven switching strategy that identifies the unknown parameters of the underlying system. We then provide a non-asymptotic analysis of its performance and discuss its implications on the classical method of estimator-based supervisory control.
http://w3id.org/mlsea/pwc/scientificWork/A%20matrix%20pencil%20approach%20to%20the%20Morgan%27s%20problem                                                                                  A matrix pencil approach to the Morgan's problem                                                                                  The problem of decoupling a nonsquare state space system by state feedback with singular input transformation is considered. The problem is solved by conducting a finite search for decouplable square systems, appropriately derived from the original. Decoupling feedback on any of these systems defines the decoupling feedback for the original. The issue of fixed poles is also considered and the possibility of selecting the uncontrollable poles is investigated.
http://w3id.org/mlsea/pwc/scientificWork/A%20model%20for%20membrane%20degradation%20using%20a%20gelatin%20invadopodia%20assay                                                                                  A model for membrane degradation using a gelatin invadopodia assay                                                                                  One of the most crucial and lethal characteristics of solid tumors is represented by the increased ability of cancer cells to migrate and invade other organs during the so-called metastatic spread. This is allowed thanks to the production of matrix metalloproteinases (MMPs), enzymes capable of degrading a type of collagen abundant in the basal membrane separating the epithelial tissue from the connective one. In this work, we employ a synergistic experimental and mathematical modelling approach to explore the invasion process of tumor cells. A athematical model composed of reaction-diffusion equations describing the evolution of the tumor cells density on a gelatin substrate, MMPs enzymes concentration and the degradation of the gelatin is proposed. This is completed with a calibration strategy. We perform a sensitivity analysis and explore a parameter estimation technique both on synthetic and experimental data in order to find the optimal parameters that describe the in vitro experiments. A comparison between numerical and experimental solutions ends the work.
http://w3id.org/mlsea/pwc/scientificWork/A%20multi-cohort%20study%20on%20prediction%20of%20acute%20brain%20dysfunction%20states%20using%20selective%20state%20space%20models                                                                                  A multi-cohort study on prediction of acute brain dysfunction states using selective state space models                                                                                  Assessing acute brain dysfunction (ABD), including delirium and coma in the intensive care unit (ICU), is a critical challenge due to its prevalence and severe implications for patient outcomes. Current diagnostic methods rely on infrequent clinical observations, which can only determine a patient's ABD status after onset. Our research attempts to solve these problems by harnessing Electronic Health Records (EHR) data to develop automated methods for ABD prediction for patients in the ICU. Existing models solely predict a single state (e.g., either delirium or coma), require at least 24 hours of observation data to make predictions, do not dynamically predict fluctuating ABD conditions during ICU stay (typically a one-time prediction), and use small sample size, proprietary single-hospital datasets. Our research fills these gaps in the existing literature by dynamically predicting delirium, coma, and mortality for 12-hour intervals throughout an ICU stay and validating on two public datasets. Our research also introduces the concept of dynamically predicting critical transitions from non-ABD to ABD and between different ABD states in real time, which could be clinically more informative for the hospital staff. We compared the predictive performance of two state-of-the-art neural network models, the MAMBA selective state space model and the Longformer Transformer model. Using the MAMBA model, we achieved a mean area under the receiving operator characteristic curve (AUROC) of 0.95 on outcome prediction of ABD for 12-hour intervals. The model achieves a mean AUROC of 0.79 when predicting transitions between ABD states. Our study uses a curated dataset from the University of Florida Health Shands Hospital for internal validation and two publicly available datasets, MIMIC-IV and eICU, for external validation, demonstrating robustness across ICU stays from 203 hospitals and 140,945 patients.
http://w3id.org/mlsea/pwc/scientificWork/A%20multimodal%20dynamical%20variational%20autoencoder%20for%20audiovisual%20speech%20representation%20learning                                                                                  A multimodal dynamical variational autoencoder for audiovisual speech representation learning                                                                                  In this paper, we present a multimodal and dynamical VAE (MDVAE) applied to unsupervised audio-visual speech representation learning. The latent space is structured to dissociate the latent dynamical factors that are shared between the modalities from those that are specific to each modality. A static latent variable is also introduced to encode the information that is constant over time within an audiovisual speech sequence. The model is trained in an unsupervised manner on an audiovisual emotional speech dataset, in two stages. In the first stage, a vector quantized VAE (VQ-VAE) is learned independently for each modality, without temporal modeling. The second stage consists in learning the MDVAE model on the intermediate representation of the VQ-VAEs before quantization. The disentanglement between static versus dynamical and modality-specific versus modality-common information occurs during this second training stage. Extensive experiments are conducted to investigate how audiovisual speech latent factors are encoded in the latent space of MDVAE. These experiments include manipulating audiovisual speech, audiovisual facial image denoising, and audiovisual speech emotion recognition. The results show that MDVAE effectively combines the audio and visual information in its latent space. They also show that the learned static representation of audiovisual speech can be used for emotion recognition with few labeled data, and with better accuracy compared with unimodal baselines and a state-of-the-art supervised model based on an audiovisual transformer architecture.
http://w3id.org/mlsea/pwc/scientificWork/A%20multiple-instance%20densely-connected%20ConvNet%20for%20aerial%20scene%20classification                                                                                  A multiple-instance densely-connected ConvNet for aerial scene classification                                                                                  In contrast with nature scenes, aerial scenes are often composed of many objects crowdedly distributed on the surface in birdâs view, the description of which usually demands more discriminative features as well as local semantics. However, when applied to scene classification, most of the existing convolution neural networks (ConvNets) tend to depict global semantics of images, and the loss of low- and mid-level features can hardly be avoided, especially when the model goes deeper. To tackle these challenges, in this paper, we propose a multiple-instance densely-connected ConvNet (MIDC-Net) for aerial scene classification. It regards aerial scene classification as a multiple-instance learning problem so that local semantics can be further investigated. Our classification model consists of an instance-level classifier, a multiple instance pooling and followed by a bag-level classification layer. In the instance-level classifier, we propose a simplified dense connection structure to effectively preserve features from different levels. The extracted convolution features are further converted into instance feature vectors. Then, we propose a trainable attention-based multiple instance pooling. It highlights the local semantics relevant to the scene label and outputs the bag-level probability directly. Finally, with our bag-level classification layer, this multiple instance learning framework is under the direct supervision of bag labels. Experiments on three widely-utilized aerial scene benchmarks demonstrate that our proposed method outperforms many state-of-the-art methods by a large margin with much fewer parameters.
http://w3id.org/mlsea/pwc/scientificWork/A%20necessary%20condition%20for%20non-monotonic%20dose%20response%2C%20with%20an%20application%20to%20a%20kinetic%20proofreading%20model%20--%20Extended%20version                                                                                  A necessary condition for non-monotonic dose response, with an application to a kinetic proofreading model -- Extended version                                                                                  Steady state non-monotonic ('biphasic') dose responses are often observed in experimental biology, which raises the control-theoretic question of identifying which possible mechanisms might underlie such behaviors. It is well known that the presence of an incoherent feedforward loop (IFFL) in a network may give rise to a non-monotonic response. It has been conjectured that this condition is also necessary, i.e. that a non-monotonic response implies the existence of an IFFL. In this paper, we show that this conjecture is false, and in the process prove a weaker version: that either an IFFL must exist or both a positive loop and a negative feedback loop must exist. Towards this aim, we give necessary and sufficient conditions for when minors of a symbolic matrix have mixed signs. Finally, we study in full generality when a model of immune T-cell activation could exhibit a steady state non-monotonic dose response.
http://w3id.org/mlsea/pwc/scientificWork/A%20neural%20network-based%20approach%20to%20hybrid%20systems%20identification%20for%20control                                                                                  A neural network-based approach to hybrid systems identification for control                                                                                  We consider the problem of designing a machine learning-based model of an unknown dynamical system from a finite number of (state-input)-successor state data points, such that the model obtained is also suitable for optimal control design. We propose a specific neural network (NN) architecture that yields a hybrid system with piecewise-affine dynamics that is differentiable with respect to the network's parameters, thereby enabling the use of derivative-based training procedures. We show that a careful choice of our NN's weights produces a hybrid system model with structural properties that are highly favourable when used as part of a finite horizon optimal control problem (OCP). Specifically, we show that optimal solutions with strong local optimality guarantees can be computed via nonlinear programming, in contrast to classical OCPs for general hybrid systems which typically require mixed-integer optimization. In addition to being well-suited for optimal control design, numerical simulations illustrate that our NN-based technique enjoys very similar performance to state-of-the-art system identification methodologies for hybrid systems and it is competitive on nonlinear benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20approach%20to%20measuring%20the%20scope%20of%20patent%20claims%20based%20on%20probabilities%20obtained%20from%20%28large%29%20language%20models                                                                                  A novel approach to measuring the scope of patent claims based on probabilities obtained from (large) language models                                                                                  This work proposes to measure the scope of a patent claim as the reciprocal of self-information contained in this claim. Self-information is calculated based on a probability of occurrence of the claim, where this probability is obtained from a language model. Grounded in information theory, this approach is based on the assumption that an unlikely concept is more informative than a usual concept, insofar as it is more surprising. In turn, the more surprising the information required to define the claim, the narrower its scope. Seven language models are considered, ranging from simplest models (each word or character has an identical probability) to intermediate models (based on average word or character frequencies), to large language models (LLMs) such as GPT2 and davinci-002. Remarkably, when using the simplest language models to compute the probabilities, the scope becomes proportional to the reciprocal of the number of words or characters involved in the claim, a metric already used in previous works. Application is made to multiple series of patent claims directed to distinct inventions, where each series consists of claims devised to have a gradually decreasing scope. The performance of the language models is then assessed through several ad hoc tests. The LLMs outperform models based on word and character frequencies, which themselves outdo the simplest models based on word or character counts. Interestingly, however, the character count appears to be a more reliable indicator than the word count.
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20extractive%20multi-document%20text%20summarization%20system%20using%20quantum-inspired%20genetic%20algorithm%3A%20MTSQIGA                                                                                  A novel extractive multi-document text summarization system using quantum-inspired genetic algorithm: MTSQIGA                                                                                  The explosive growth of textual data on the web and the problem of obtaining desired information through this enormous volume of data has led to a dramatic increase in demand for developing automatic text summarization systems. For this reason, this paper presents a novel multi-document text summarization approach, called MTSQIGA, which extracts salient sentences from source document collection to generate the summary. The proposed generic summarizer models extractive summarization as a binary optimization problem that applies a modified quantum-inspired genetic algorithm (QIGA) in its processing stage to find the best solution. Objective function of our approach plays an important role in optimizing linear combination of coverage, relevance, and redundancy factors which consists of six sentence scoring measures. To ensures the generation of a summary with predefined length limit, the presented QIGA employs a modified quantum measurement and a self-adaptive quantum rotation gate based on the quality and length of the summary. Evaluation of the proposed system was performed on DUC 2005 and 2007 benchmark datasets in terms of ROUGE standard measures. Comparison of MTSQIGA with existing state-of-the-art approaches for multi-document summarization shows superior performance of the proposed systems over other methods on both existing benchmark datasets. It also indicates promising efficiency of our proposed algorithm on applying quantum-inspired genetic algorithm to the text summarization tasks.
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20hybrid%20time-varying%20graph%20neural%20network%20for%20traffic%20flow%20forecasting                                                                                  A novel hybrid time-varying graph neural network for traffic flow forecasting                                                                                  Real-time and accurate traffic flow prediction is the foundation for ensuring the efficient operation of intelligent transportation systems.In existing traffic flow prediction methods based on graph neural networks (GNNs), pre-defined graphs were usually used to describe the spatial correlations of different traffic nodes in urban road networks. However, the ability of pre-defined graphs used to describe spatial correlation was limited by prior knowledge and graph generation methods. Although time-varying graphs based on data-driven learning can partially overcome the drawbacks of pre-defined graphs, the learning ability of existing adaptive graphs was limited. For example, time-varying graphs cannot adequately capture the inherent spatial correlations in traffic flow data.In order to solve these problems, we have proposed a hybrid time-varying graph neural network (HTVGNN) for traffic flow prediction.
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20interface%20for%20adversarial%20trivia%20question-writing                                                                                  A novel interface for adversarial trivia question-writing                                                                                  A critical component when developing question-answering AIs is an adversarial dataset that challenges models to adapt to the complex syntax and reasoning underlying our natural language. Present techniques for procedurally generating adversarial texts are not robust enough for training on complex tasks such as answering multi-sentence trivia questions. We instead turn to human-generated data by introducing an interface for collecting adversarial human-written trivia questions. Our interface is aimed towards question writers and players of Quiz Bowl, a buzzer-based trivia competition where paragraph-long questions consist of a sequence of clues of decreasing difficulty. To incentivize usage, a suite of machine learning-based tools in our interface assist humans in writing questions that are more challenging to answer for Quiz Bowl players and computers alike. Not only does our interface gather training data for the groundbreaking Quiz Bowl AI project QANTA, but it is also a proof-of-concept of future adversarial data collection for question-answering systems. The results of performance-testing our interface with ten originally-composed questions indicate that, despite some flaws, our interface's novel question-writing features as well as its real-time exposure of useful responses from our machine models could facilitate and enhance the collection of adversarial questions.
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20molecule%20generative%20model%20of%20VAE%20combined%20with%20Transformer%20for%20unseen%20structure%20generation                                                                                  A novel molecule generative model of VAE combined with Transformer for unseen structure generation                                                                                  Recently, molecule generation using deep learning has been actively investigated in drug discovery. In this field, Transformer and VAE are widely used as powerful models, but they are rarely used in combination due to structural and performance mismatch of them. This study proposes a model that combines these two models through structural and parameter optimization in handling diverse molecules. The proposed model shows comparable performance to existing models in generating molecules, and showed by far superior performance in generating molecules with unseen structures. Another advantage of this VAE model is that it generates molecules from latent representation, and therefore properties of molecules can be easily predicted or conditioned with it, and indeed, we show that the latent representation of the model successfully predicts molecular properties. Ablation study suggested the advantage of VAE over other generative models like language model in generating novel molecules. It also indicated that the latent representation can be shortened to ~32 dimensional variables without loss of reconstruction, suggesting the possibility of a much smaller molecular descriptor or model than existing ones. This study is expected to provide a virtual chemical library containing a wide variety of compounds for virtual screening and to enable efficient screening.
http://w3id.org/mlsea/pwc/scientificWork/A%20physics-informed%20neural%20network%20method%20for%20the%20approximation%20of%20slow%20invariant%20manifolds%20for%20the%20general%20class%20of%20stiff%20systems%20of%20ODEs                                                                                  A physics-informed neural network method for the approximation of slow invariant manifolds for the general class of stiff systems of ODEs                                                                                  We present a physics-informed neural network (PINN) approach for the discovery of slow invariant manifolds (SIMs), for the most general class of fast/slow dynamical systems of ODEs. In contrast to other machine learning (ML) approaches that construct reduced order black box surrogate models using simple regression, and/or require a priori knowledge of the fast and slow variables, our approach, simultaneously decomposes the vector field into fast and slow components and provides a functional of the underlying SIM in a closed form. The decomposition is achieved by finding a transformation of the state variables to the fast and slow ones, which enables the derivation of an explicit, in terms of fast variables, SIM functional. The latter is obtained by solving a PDE corresponding to the invariance equation within the Geometric Singular Perturbation Theory (GSPT) using a single-layer feedforward neural network with symbolic differentiation. The performance of the proposed physics-informed ML framework is assessed via three benchmark problems: the Michaelis-Menten, the target mediated drug disposition (TMDD) reaction model and a fully competitive substrate-inhibitor(fCSI) mechanism. We also provide a comparison with other GPST methods, namely the quasi steady state approximation (QSSA), the partial equilibrium approximation (PEA) and CSP with one and two iterations. We show that the proposed PINN scheme provides SIM approximations, of equivalent or even higher accuracy, than those provided by QSSA, PEA and CSP, especially close to the boundaries of the underlying SIMs.
http://w3id.org/mlsea/pwc/scientificWork/A%20prototype%20software%20framework%20for%20transferable%20computational%20health%20economic%20models%20and%20its%20early%20application%20in%20youth%20mental%20health                                                                                  A prototype software framework for transferable computational health economic models and its early application in youth mental health                                                                                  We are developing an economic model to explore multiple topics in Australian youth mental health policy. We want that model to be readily transferable to other jurisdictions. We developed a software framework for authoring transparent, reusable and updatable Computational Health Economic Models (CHEMs) (the software files that implement health economic models). We specified framework user requirements of a template CHEM module that facilitates modular model implementations, a simple programming syntax and tools for authoring new CHEM modules, supplying CHEMs with data, reporting reproducible CHEM analyses, searching for CHEM modules and maintaining a CHEM project website. We implemented the framework as six development version code libraries in the programming language R that integrate with online services for software development and research data archiving. We used the framework to author five development version R libraries of CHEM modules focused on utility mapping in youth mental health. These modules provide tools for variable validation, dataset description, multi-attribute instrument scoring, construction of mapping models, reporting of mapping studies and making out of sample predictions. We assessed these CHEM module libraries as mostly meeting transparency, reusability and updatability criteria that we have previously developed, but requiring more detailed documentation and unit testing of individual modules. Our software framework has potential value as a prototype for future tools to support the development of transferable CHEMs.
http://w3id.org/mlsea/pwc/scientificWork/A%20real-time%20Artificial%20Intelligence%20system%20for%20learning%20Sign%20Language                                                                                  A real-time Artificial Intelligence system for learning Sign Language                                                                                  A primary challenge for the deaf and hearing-impaired community stems from the communication gap with the hearing society, which can greatly impact their daily lives and result in social exclusion. To foster inclusivity in society, our endeavor focuses on developing a cost-effective, resource-efficient, and open technology based on Artificial Intelligence, designed to assist people in learning and using Sign Language for communication. The analysis presented in this research paper intends to enrich the recent academic scientific literature on Sign Language solutions based on Artificial Intelligence, with a particular focus on American Sign Language (ASL). This research has yielded promising preliminary results and serves as a basis for further development.
http://w3id.org/mlsea/pwc/scientificWork/A%20resource-constrained%20stochastic%20scheduling%20algorithm%20for%20homeless%20street%20outreach%20and%20gleaning%20edible%20food                                                                                  A resource-constrained stochastic scheduling algorithm for homeless street outreach and gleaning edible food                                                                                  We developed a common algorithmic solution addressing the problem of resource-constrained outreach encountered by social change organizations with different missions and operations: Breaking Ground -- an organization that helps individuals experiencing homelessness in New York transition to permanent housing and Leket -- the national food bank of Israel that rescues food from farms and elsewhere to feed the hungry. Specifically, we developed an estimation and optimization approach for partially-observed episodic restless bandits under $k$-step transitions. The results show that our Thompson sampling with Markov chain recovery (via Stein variational gradient descent) algorithm significantly outperforms baselines for the problems of both organizations. We carried out this work in a prospective manner with the express goal of devising a flexible-enough but also useful-enough solution that can help overcome a lack of sustainable impact in data science for social good.
http://w3id.org/mlsea/pwc/scientificWork/A%20sampling%20construction%20of%20graphon%201-norm%20convergence                                                                                  A sampling construction of graphon 1-norm convergence                                                                                  In the short note, we describe a sampling construction that yields a sequence of graphons converging to a prescribed limit graphon in 1-norm. This convergence is stronger than the convergence in the cut norm, usually used to study graphon sequences. The note also contains errata of the previous version of the note.
http://w3id.org/mlsea/pwc/scientificWork/A%20semidefinite%20programming%20approach%20for%20robust%20elliptic%20localization                                                                                  A semidefinite programming approach for robust elliptic localization                                                                                  This short communication addresses the problem of elliptic localization with outlier measurements, whose occurrences are prevalent in various location-enabled applications and can significantly compromise the positioning performance if not adequately handled. In contrast to the reliance on $M$-estimation adopted in the majority of existing solutions, we take a different path, specifically exploring the worst-case robust approximation criterion, to bolster resistance of the elliptic location estimator against outliers. From a geometric standpoint, our method boils down to pinpointing the Chebyshev center of the feasible set determined by the available bistatic ranges with bounded measurement errors. For a practical approach to the associated min-max problem, we convert it into the well-established convex optimization framework of semidefinite programming (SDP). Numerical simulations confirm that our SDP-based technique can outperform a number of existing elliptic localization schemes in terms of positioning accuracy in Gaussian mixture noise, a common type of impulsive interference in the context of range-based localization.
http://w3id.org/mlsea/pwc/scientificWork/A%20solution%20for%20the%20mean%20parametrization%20of%20the%20von%20Mises-Fisher%20distribution                                                                                  A solution for the mean parametrization of the von Mises-Fisher distribution                                                                                  The von Mises-Fisher distribution as an exponential family can be expressed in terms of either its natural or its mean parameters. Unfortunately, however, the normalization function for the distribution in terms of its mean parameters is not available in closed form, limiting the practicality of the mean parametrization and complicating maximum-likelihood estimation more generally. We derive a second-order ordinary differential equation, the solution to which yields the mean-parameter normalizer along with its first two derivatives, as well as the variance function of the family. We also provide closed-form approximations to the solution of the differential equation. This allows rapid evaluation of both densities and natural parameters in terms of mean parameters. We show applications to topic modeling with mixtures of von Mises-Fisher distributions using Bregman Clustering.
http://w3id.org/mlsea/pwc/scientificWork/A%20spatio-temporal%20framework%20for%20modelling%20wastewater%20concentration%20during%20the%20COVID-19%20pandemic                                                                                  A spatio-temporal framework for modelling wastewater concentration during the COVID-19 pandemic                                                                                  The potential utility of wastewater-based epidemiology as an early warning tool has been explored widely across the globe during the current COVID-19 pandemic. Methods to detect the presence of SARS-CoV-2 RNA in wastewater were developed early in the pandemic, and extensive work has been conducted to evaluate the relationship between viral concentration and COVID-19 case numbers at the catchment areas of sewage treatment works (STWs) over time. However, no attempt has been made to develop a model that predicts wastewater concentration at fine spatio-temporal resolutions covering an entire country, a necessary step towards using wastewater monitoring for the early detection of local outbreaks. We consider weekly averages of flow-normalised viral concentration, reported as the number of SARS-CoV-2N1 gene copies per litre (gc/L) of wastewater available at 303 STWs over the period between 1 June 2021 and 30 March 2022. We specify a spatially continuous statistical model that quantifies the relationship between weekly viral concentration and a collection of covariates covering socio-demographics, land cover and virus associated genomic characteristics at STW catchment areas while accounting for spatial and temporal correlation. We evaluate the modelâs predictive performance at the catchment level through 10-fold cross-validation. We predict the weekly viral concentration at the population-weighted centroid of the 32,844 lower super output areas (LSOAs) in England, then aggregate these LSOA predictions to the Lower Tier Local Authority level (LTLA), a geography that is more relevant to public health policy-making. We also use the model outputs to quantify the probability of local changes of direction (increases or decreases) in viral concentration over short periods (e.g. two consecutive weeks). The proposed statistical framework can predict SARS-CoV-2 viral concentration in wastewater at high spatio-temporal resolution across England. Additionally, the probabilistic quantification of local changes can be used as an early warning tool for public health surveillance.
http://w3id.org/mlsea/pwc/scientificWork/A%20spatiotemporal%20style%20transfer%20algorithm%20for%20dynamic%20visual%20stimulus%20generation                                                                                  A spatiotemporal style transfer algorithm for dynamic visual stimulus generation                                                                                  Understanding how visual information is encoded in biological and artificial systems often requires vision scientists to generate appropriate stimuli to test specific hypotheses. Although deep neural network models have revolutionized the field of image generation with methods such as image style transfer, available methods for video generation are scarce. Here, we introduce the Spatiotemporal Style Transfer (STST) algorithm, a dynamic visual stimulus generation framework that allows powerful manipulation and synthesis of video stimuli for vision research. It is based on a two-stream deep neural network model that factorizes spatial and temporal features to generate dynamic visual stimuli whose model layer activations are matched to those of input videos. As an example, we show that our algorithm enables the generation of model metamers, dynamic stimuli whose layer activations within our two-stream model are matched to those of natural videos. We show that these generated stimuli match the low-level spatiotemporal features of their natural counterparts but lack their high-level semantic features, making it a powerful paradigm to study object recognition. Late layer activations in deep vision models exhibited a lower similarity between natural and metameric stimuli compared to early layers, confirming the lack of high-level information in the generated stimuli. Finally, we use our generated stimuli to probe the representational capabilities of predictive coding deep networks. These results showcase potential applications of our algorithm as a versatile tool for dynamic stimulus generation in vision science.
http://w3id.org/mlsea/pwc/scientificWork/A%20step%20toward%20a%20reinforcement%20learning%20de%20novo%20genome%20assembler                                                                                  A step toward a reinforcement learning de novo genome assembler                                                                                  De novo genome assembly is a relevant but computationally complex task in genomics. Although de novo assemblers have been used successfully in several genomics projects, there is still no 'best assembler', and the choice and setup of assemblers still rely on bioinformatics experts. Thus, as with other computationally complex problems, machine learning may emerge as an alternative (or complementary) way for developing more accurate and automated assemblers. Reinforcement learning has proven promising for solving complex activities without supervision - such games - and there is a pressing need to understand the limits of this approach to 'real' problems, such as the DFA problem. This study aimed to shed light on the application of machine learning, using reinforcement learning (RL), in genome assembly. We expanded upon the sole previous approach found in the literature to solve this problem by carefully exploring the learning aspects of the proposed intelligent agent, which uses the Q-learning algorithm, and we provided insights for the next steps of automated genome assembly development. We improved the reward system and optimized the exploration of the state space based on pruning and in collaboration with evolutionary computing. We tested the new approaches on 23 new larger environments, which are all available on the internet. Our results suggest consistent performance progress; however, we also found limitations, especially concerning the high dimensionality of state and action spaces. Finally, we discuss paths for achieving efficient and automated genome assembly in real scenarios considering successful RL applications - including deep reinforcement learning.
http://w3id.org/mlsea/pwc/scientificWork/A%20story%20of%20viral%20co-infection%2C%20co-transmission%20and%20co-feeding%20in%20ticks%3A%20how%20to%20compute%20an%20invasion%20reproduction%20number                                                                                  A story of viral co-infection, co-transmission and co-feeding in ticks: how to compute an invasion reproduction number                                                                                  With a single circulating vector-borne virus, the basic reproduction number incorporates contributions from tick-to-tick (co-feeding), tick-to-host and host-to-tick transmission routes. With two different circulating vector-borne viral strains, resident and invasive, and under the assumption that co-feeding is the only transmission route in a tick population, the invasion reproduction number depends on whether the model system of ordinary differential equations possesses the property of neutrality. We show that a simple model, with two populations of ticks infected with one strain, resident or invasive, and one population of co-infected ticks, does not have Alizon's neutrality property. We present model alternatives that are capable of representing the invasion potential of a novel strain by including populations of ticks dually infected with the same strain. The invasion reproduction number is analysed with the next-generation method and via numerical simulations.
http://w3id.org/mlsea/pwc/scientificWork/A%20structured%20regression%20approach%20for%20evaluating%20model%20performance%20across%20intersectional%20subgroups                                                                                  A structured regression approach for evaluating model performance across intersectional subgroups                                                                                  Disaggregated evaluation is a central task in AI fairness assessment, with the goal to measure an AI system's performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are considered in many disaggregated evaluations. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We also provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectional groups. We evaluate our approach on two publicly available datasets, and several variants of semi-synthetic data. The results show that our method is considerably more accurate than the standard approach, especially for small subgroups, and goodness-of-fit testing helps identify the key factors that drive differences in performance.
http://w3id.org/mlsea/pwc/scientificWork/A%20synthetic%20data%20approach%20for%20domain%20generalization%20of%20NLI%20models                                                                                  A synthetic data approach for domain generalization of NLI models                                                                                  Natural Language Inference (NLI) remains an important benchmark task for LLMs. NLI datasets are a springboard for transfer learning to other semantic tasks, and NLI models are standard tools for identifying the faithfulness of model-generated text. There are several large scale NLI datasets today, and models have improved greatly by hill-climbing on these collections. Yet their realistic performance on out-of-distribution/domain data is less well-understood. We present an in-depth exploration of the problem of domain generalization of NLI models. We demonstrate a new approach for generating synthetic NLI data in diverse domains and lengths, so far not covered by existing training sets. The resulting examples have meaningful premises, the hypotheses are formed in creative ways rather than simple edits to a few premise tokens, and the labels have high accuracy. We show that models trained on this data ($685$K synthetic examples) have the best generalization to completely new downstream test settings. On the TRUE benchmark, a T5-small model trained with our data improves around $7 %$ on average compared to training on the best alternative dataset. The improvements are more pronounced for smaller models, while still meaningful on a T5 XXL model. We also demonstrate gains on test sets when in-domain training data is augmented with our domain-general synthetic data.
http://w3id.org/mlsea/pwc/scientificWork/A%20task%20of%20anomaly%20detection%20for%20a%20smart%20satellite%20Internet%20of%20things%20system                                                                                  A task of anomaly detection for a smart satellite Internet of things system                                                                                  When the equipment is working, real-time collection of environmental sensor data for anomaly detection is one of the key links to prevent industrial process accidents and network attacks and ensure system security. However, under the environment with specific real-time requirements, the anomaly detection for environmental sensors still faces the following difficulties: (1) The complex nonlinear correlation characteristics between environmental sensor data variables lack effective expression methods, and the distribution between the data is difficult to be captured. (2) it is difficult to ensure the real-time monitoring requirements by using complex machine learning models, and the equipment cost is too high. (3) Too little sample data leads to less labeled data in supervised learning. This paper proposes an unsupervised deep learning anomaly detection system. Based on the generative adversarial network and self-attention mechanism, considering the different feature information contained in the local subsequences, it automatically learns the complex linear and nonlinear dependencies between environmental sensor variables, and uses the anomaly score calculation method combining reconstruction error and discrimination error. It can monitor the abnormal points of real sensor data with high real-time performance and can run on the intelligent satellite Internet of things system, which is suitable for the real working environment. Anomaly detection outperforms baseline methods in most cases and has good interpretability, which can be used to prevent industrial accidents and cyber-attacks for monitoring environmental sensors.
http://w3id.org/mlsea/pwc/scientificWork/A%20theoretical%20framework%20for%20dynamical%20fee%20choice%20in%20AMMs                                                                                  A theoretical framework for dynamical fee choice in AMMs                                                                                  In the ever evolving landscape of decentralized finance automated market makers (AMMs) play a key role: they provide a market place for trading assets in a decentralized manner. For so-called bluechip pairs, arbitrage activity provides a major part of the revenue generation of AMMs but also a major source of loss due to the so-called informed orderflow. Finding ways to minimize those losses while still keeping uninformed trading activity alive is a major problem in the field. In this paper we will investigate the mechanics of said arbitrage and try to understand how AMMs can maximize the revenue creation or in other words minimize the losses. To that end, we model the dynamics of arbitrage activity for a concrete implementation of a pool and study its sensitivity to the choice of fee aiming to maximize the value retention. We manage to map the ensuing dynamics to that of a random walk with a specific reward scheme that provides a convenient starting point for further studies.
http://w3id.org/mlsea/pwc/scientificWork/A%20two-stage%20algorithm%20in%20evolutionary%20product%20unit%20neural%20networks%20for%20classification                                                                                  A two-stage algorithm in evolutionary product unit neural networks for classification                                                                                  This paper presents a procedure to add broader diversity at the beginning of the evolutionary process. It consists of creating two initial populations with different parameter settings, evolving them for a small number of generations, selecting the best individuals from each population in the same proportion and combining them to constitute a new initial population. At this point the main loop of an evolutionary algorithm is applied to the new population. The results show that our proposal considerably improves both the efficiency of previous methodologies and also, significantly, their efficacy in most of the data sets. We have carried out our experimentation on twelve data sets from the UCI repository and two complex real-world problems which differ in their number of instances, features and classes.
http://w3id.org/mlsea/pwc/scientificWork/A%20unified%20Bayesian%20framework%20for%20interval%20hypothesis%20testing%20in%20clinical%20trials                                                                                  A unified Bayesian framework for interval hypothesis testing in clinical trials                                                                                  The American Statistical Association (ASA) statement on statistical significance and P-values cite{wasserstein2016asa} cautioned statisticians against making scientific decisions solely on the basis of traditional P-values. The statement delineated key issues with P-values, including a lack of transparency, an inability to quantify evidence in support of the null hypothesis, and an inability to measure the size of an effect or the importance of a result. In this article, we demonstrate that the interval null hypothesis framework (instead of the point null hypothesis framework), when used in tandem with Bayes factor-based tests, is instrumental in circumnavigating the key issues of P-values. Further, we note that specifying prior densities for Bayes factors is challenging and has been a reason for criticism of Bayesian hypothesis testing in existing literature. We address this by adapting Bayes factors directly based on common test statistics. We demonstrate, through numerical experiments and real data examples, that the proposed Bayesian interval hypothesis testing procedures can be calibrated to ensure frequentist error control while retaining their inherent interpretability. Finally, we illustrate the improved flexibility and applicability of the proposed methods by providing coherent frameworks for competitive landscape analysis and end-to-end Bayesian hypothesis tests in the context of reporting clinical trial outcomes.
http://w3id.org/mlsea/pwc/scientificWork/A%20variational%20neural%20Bayes%20framework%20for%20inference%20on%20intractable%20posterior%20distributions                                                                                  A variational neural Bayes framework for inference on intractable posterior distributions                                                                                  Classic Bayesian methods with complex models are frequently infeasible due to an intractable likelihood. Simulation-based inference methods, such as Approximate Bayesian Computing (ABC), calculate posteriors without accessing a likelihood function by leveraging the fact that data can be quickly simulated from the model, but converge slowly and/or poorly in high-dimensional settings. In this paper, we propose a framework for Bayesian posterior estimation by mapping data to posteriors of parameters using a neural network trained on data simulated from the complex model. Posterior distributions of model parameters are efficiently obtained by feeding observed data into the trained neural network. We show theoretically that our posteriors converge to the true posteriors in Kullback-Leibler divergence. Our approach yields computationally efficient and theoretically justified uncertainty quantification, which is lacking in existing simulation-based neural network approaches. Comprehensive simulation studies highlight our method's robustness and accuracy.
http://w3id.org/mlsea/pwc/scientificWork/A%24%5E%7B3%7D%24lign-DFER%3A%20Pioneering%20Comprehensive%20Dynamic%20Affective%20Alignment%20for%20Dynamic%20Facial%20Expression%20Recognition%20with%20CLIP                                                                                  A$^{3}$lign-DFER: Pioneering Comprehensive Dynamic Affective Alignment for Dynamic Facial Expression Recognition with CLIP                                                                                  The performance of CLIP in dynamic facial expression recognition (DFER) task doesn't yield exceptional results as observed in other CLIP-based classification tasks. While CLIP's primary objective is to achieve alignment between images and text in the feature space, DFER poses challenges due to the abstract nature of text and the dynamic nature of video, making label representation limited and perfect alignment difficult. To address this issue, we have designed A$^{3}$lign-DFER, which introduces a new DFER labeling paradigm to comprehensively achieve alignment, thus enhancing CLIP's suitability for the DFER task. Specifically, our A$^{3}$lign-DFER method is designed with multiple modules that work together to obtain the most suitable expanded-dimensional embeddings for classification and to achieve alignment in three key aspects: affective, dynamic, and bidirectional. We replace the input label text with a learnable Multi-Dimensional Alignment Token (MAT), enabling alignment of text to facial expression video samples in both affective and dynamic dimensions. After CLIP feature extraction, we introduce the Joint Dynamic Alignment Synchronizer (JAS), further facilitating synchronization and alignment in the temporal dimension. Additionally, we implement a Bidirectional Alignment Training Paradigm (BAP) to ensure gradual and steady training of parameters for both modalities. Our insightful and concise A$^{3}$lign-DFER method achieves state-of-the-art results on multiple DFER datasets, including DFEW, FERV39k, and MAFW. Extensive ablation experiments and visualization studies demonstrate the effectiveness of A$^{3}$lign-DFER. The code will be available in the future.
http://w3id.org/mlsea/pwc/scientificWork/A2DMN%3A%20Anatomy-Aware%20Dilated%20Multiscale%20Network%20for%20Breast%20Ultrasound%20Semantic%20Segmentation                                                                                  A2DMN: Anatomy-Aware Dilated Multiscale Network for Breast Ultrasound Semantic Segmentation                                                                                  In recent years, convolutional neural networks for semantic segmentation of breast ultrasound (BUS) images have shown great success; however, two major challenges still exist. 1) Most current approaches inherently lack the ability to utilize tissue anatomy, resulting in misclassified image regions. 2) They struggle to produce accurate boundaries due to the repeated down-sampling operations. To address these issues, we propose a novel breast anatomy-aware network for capturing fine image details and a new smoothness term that encodes breast anatomy. It incorporates context information across multiple spatial scales to generate more accurate semantic boundaries. Extensive experiments are conducted to compare the proposed method and eight state-of-the-art approaches using a BUS dataset with 325 images. The results demonstrate the proposed method significantly improves the segmentation of the muscle, mammary, and tumor classes and produces more accurate fine details of tissue boundaries.
http://w3id.org/mlsea/pwc/scientificWork/AAVDiff%3A%20Experimental%20Validation%20of%20Enhanced%20Viability%20and%20Diversity%20in%20Recombinant%20Adeno-Associated%20Virus%20%28AAV%29%20Capsids%20through%20Diffusion%20Generation                                                                                  AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation                                                                                  Recombinant adeno-associated virus (rAAV) vectors have revolutionized gene therapy, but their broad tropism and suboptimal transduction efficiency limit their clinical applications. To overcome these limitations, researchers have focused on designing and screening capsid libraries to identify improved vectors. However, the large sequence space and limited resources present challenges in identifying viable capsid variants. In this study, we propose an end-to-end diffusion model to generate capsid sequences with enhanced viability. Using publicly available AAV2 data, we generated 38,000 diverse AAV2 viral protein (VP) sequences, and evaluated 8,000 for viral selection. The results attested the superiority of our model compared to traditional methods. Additionally, in the absence of AAV9 capsid data, apart from one wild-type sequence, we used the same model to directly generate a number of viable sequences with up to 9 mutations. we transferred the remaining 30,000 samples to the AAV9 domain. Furthermore, we conducted mutagenesis on AAV9 VP hypervariable regions VI and V, contributing to the continuous improvement of the AAV9 VP sequence. This research represents a significant advancement in the design and functional validation of rAAV vectors, offering innovative solutions to enhance specificity and transduction efficiency in gene therapy applications.
http://w3id.org/mlsea/pwc/scientificWork/AC%2FDC%20optimal%20power%20flow%20and%20techno-economic%20assessment%20for%20hybrid%20microgrids%3A%20TIGON%20CEDER%20demonstrator                                                                                  AC/DC optimal power flow and techno-economic assessment for hybrid microgrids: TIGON CEDER demonstrator                                                                                  In the recent years, the interest in electric direct current (DC) technologies (such as converters, batteries, electric vehicles, etc.) is increasing due to its potential on energy efficiency and sustainability. However, the vast majority of electric systems and networks are based on alternating current (AC), as they also have certain advantages regarding cost-effective transport and robustness. In this paper, an AC/DC optimal power flow method for hybrid microgrids and several key performance indicators (KPIs) for its techno-economic assessment are presented. The combination of both calculations allows users to clearly determine the viability of their hybrid microgrids. AC/DC networks have been modelled considering their most common elements. For the power flow method, a polynomial optimisation is formulated considering four different objective functions: the minimisation of energy losses, voltage deviation and operational costs, and also the maximisation of the microgrid generation. The power flow method and the techno-economic analysis have been implemented in Python and validated in the Centro de Desarrollo de Energ 'ias Renovables (CEDER) demonstrator for TIGON. The results show that the calculated power flow variables and the ones measured at CEDER are practically the same. In addition, the KPIs have been obtained and compared for four operating scenarios: baseline, no battery, battery flexibility and virtual battery (VB) flexibility. The last one result in the most profitable option.
http://w3id.org/mlsea/pwc/scientificWork/ACLSum%3A%20A%20New%20Dataset%20for%20Aspect-based%20Summarization%20of%20Scientific%20Publications                                                                                  ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications                                                                                  Extensive efforts in the past have been directed toward the development of summarization datasets. However, a predominant number of these resources have been (semi)-automatically generated, typically through web data crawling, resulting in subpar resources for training and evaluating summarization systems, a quality compromise that is arguably due to the substantial costs associated with generating ground-truth summaries, particularly for diverse languages and specialized domains. To address this issue, we present ACLSum, a novel summarization dataset carefully crafted and evaluated by domain experts. In contrast to previous datasets, ACLSum facilitates multi-aspect summarization of scientific papers, covering challenges, approaches, and outcomes in depth. Through extensive experiments, we evaluate the quality of our resource and the performance of models based on pretrained language models and state-of-the-art large language models (LLMs). Additionally, we explore the effectiveness of extractive versus abstractive summarization within the scholarly domain on the basis of automatically discovered aspects. Our results corroborate previous findings in the general domain and indicate the general superiority of end-to-end aspect-based summarization. Our data is released at https://github.com/sobamchan/aclsum.
http://w3id.org/mlsea/pwc/scientificWork/ACTrack%3A%20Adding%20Spatio-Temporal%20Condition%20for%20Visual%20Object%20Tracking                                                                                  ACTrack: Adding Spatio-Temporal Condition for Visual Object Tracking                                                                                  Efficiently modeling spatio-temporal relations of objects is a key challenge in visual object tracking (VOT). Existing methods track by appearance-based similarity or long-term relation modeling, resulting in rich temporal contexts between consecutive frames being easily overlooked. Moreover, training trackers from scratch or fine-tuning large pre-trained models needs more time and memory consumption. In this paper, we present ACTrack, a new tracking framework with additive spatio-temporal conditions. It preserves the quality and capabilities of the pre-trained Transformer backbone by freezing its parameters, and makes a trainable lightweight additive net to model spatio-temporal relations in tracking. We design an additive siamese convolutional network to ensure the integrity of spatial features and perform temporal sequence modeling to simplify the tracking pipeline. Experimental results on several benchmarks prove that ACTrack could balance training efficiency and tracking performance.
http://w3id.org/mlsea/pwc/scientificWork/ADAPT%20to%20Robustify%20Prompt%20Tuning%20Vision%20Transformers                                                                                  ADAPT to Robustify Prompt Tuning Vision Transformers                                                                                  The performance of deep models, including Vision Transformers, is known to be vulnerable to adversarial attacks. Many existing defenses against these attacks, such as adversarial training, rely on full-model fine-tuning to induce robustness in the models. These defenses require storing a copy of the entire model, that can have billions of parameters, for each task. At the same time, parameter-efficient prompt tuning is used to adapt large transformer-based models to downstream tasks without the need to save large copies. In this paper, we examine parameter-efficient prompt tuning of Vision Transformers for downstream tasks under the lens of robustness. We show that previous adversarial defense methods, when applied to the prompt tuning paradigm, suffer from gradient obfuscation and are vulnerable to adaptive attacks. We introduce ADAPT, a novel framework for performing adaptive adversarial training in the prompt tuning paradigm. Our method achieves competitive robust accuracy of ~40% w.r.t. SOTA robustness methods using full-model fine-tuning, by tuning only ~1% of the number of parameters.
http://w3id.org/mlsea/pwc/scientificWork/ADMap%3A%20Anti-disturbance%20framework%20for%20reconstructing%20online%20vectorized%20HD%20map                                                                                  ADMap: Anti-disturbance framework for reconstructing online vectorized HD map                                                                                  In the field of autonomous driving, online high-definition (HD) map reconstruction is crucial for planning tasks. Recent research has developed several high-performance HD map reconstruction models to meet this necessity. However, the point sequences within the instance vectors may be jittery or jagged due to prediction bias, which can impact subsequent tasks. Therefore, this paper proposes the Anti-disturbance Map reconstruction framework (ADMap). To mitigate point-order jitter, the framework consists of three modules: Multi-Scale Perception Neck, Instance Interactive Attention (IIA), and Vector Direction Difference Loss (VDDL). By exploring the point-order relationships between and within instances in a cascading manner, the model can monitor the point-order prediction process more effectively. ADMap achieves state-of-the-art performance on the nuScenes and Argoverse2 datasets. Extensive results demonstrate its ability to produce stable and reliable map elements in complex and changing driving scenarios. Code and more demos are available at https://github.com/hht1996ok/ADMap.
http://w3id.org/mlsea/pwc/scientificWork/AG-NeRF%3A%20Attention-guided%20Neural%20Radiance%20Fields%20for%20Multi-height%20Large-scale%20Outdoor%20Scene%20Rendering                                                                                  AG-NeRF: Attention-guided Neural Radiance Fields for Multi-height Large-scale Outdoor Scene Rendering                                                                                  Existing neural radiance fields (NeRF)-based novel view synthesis methods for large-scale outdoor scenes are mainly built on a single altitude. Moreover, they often require a priori camera shooting height and scene scope, leading to inefficient and impractical applications when camera altitude changes. In this work, we propose an end-to-end framework, termed AG-NeRF, and seek to reduce the training cost of building good reconstructions by synthesizing free-viewpoint images based on varying altitudes of scenes. Specifically, to tackle the detail variation problem from low altitude (drone-level) to high altitude (satellite-level), a source image selection method and an attention-based feature fusion approach are developed to extract and fuse the most relevant features of target view from multi-height images for high-fidelity rendering. Extensive experiments demonstrate that AG-NeRF achieves SOTA performance on 56 Leonard and Transamerica benchmarks and only requires a half hour of training time to reach the competitive PSNR as compared to the latest BungeeNeRF.
http://w3id.org/mlsea/pwc/scientificWork/AGHINT%3A%20Attribute-Guided%20Representation%20Learning%20on%20Heterogeneous%20Information%20Networks%20with%20Transformer                                                                                  AGHINT: Attribute-Guided Representation Learning on Heterogeneous Information Networks with Transformer                                                                                  Recently, heterogeneous graph neural networks (HGNNs) have achieved impressive success in representation learning by capturing long-range dependencies and heterogeneity at the node level. However, few existing studies have delved into the utilization of node attributes in heterogeneous information networks (HINs). In this paper, we investigate the impact of inter-node attribute disparities on HGNNs performance within the benchmark task, i.e., node classification, and empirically find that typical models exhibit significant performance decline when classifying nodes whose attributes markedly differ from their neighbors. To alleviate this issue, we propose a novel Attribute-Guided heterogeneous Information Networks representation learning model with Transformer (AGHINT), which allows a more effective aggregation of neighbor node information under the guidance of attributes. Specifically, AGHINT transcends the constraints of the original graph structure by directly integrating higher-order similar neighbor features into the learning process and modifies the message-passing mechanism between nodes based on their attribute disparities. Extensive experimental results on three real-world heterogeneous graph benchmarks with target node attributes demonstrate that AGHINT outperforms the state-of-the-art.
http://w3id.org/mlsea/pwc/scientificWork/AI%20Competitions%20and%20Benchmarks%3A%20Dataset%20Development                                                                                  AI Competitions and Benchmarks: Dataset Development                                                                                  Machine learning is now used in many applications thanks to its ability to predict, generate, or discover patterns from large quantities of data. However, the process of collecting and transforming data for practical use is intricate. Even in today's digital era, where substantial data is generated daily, it is uncommon for it to be readily usable; most often, it necessitates meticulous manual data preparation. The haste in developing new models can frequently result in various shortcomings, potentially posing risks when deployed in real-world scenarios (eg social discrimination, critical failures), leading to the failure or substantial escalation of costs in AI-based projects. This chapter provides a comprehensive overview of established methodological tools, enriched by our practical experience, in the development of datasets for machine learning. Initially, we develop the tasks involved in dataset development and offer insights into their effective management (including requirements, design, implementation, evaluation, distribution, and maintenance). Then, we provide more details about the implementation process which includes data collection, transformation, and quality evaluation. Finally, we address practical considerations regarding dataset distribution and maintenance.
http://w3id.org/mlsea/pwc/scientificWork/AI%20Does%20Not%20Alter%20Perceptions%20of%20Text%20Messages                                                                                  AI Does Not Alter Perceptions of Text Messages                                                                                  For many people, anxiety, depression, and other social and mental factors can make composing text messages an active challenge. To remedy this problem, large language models (LLMs) may yet prove to be the perfect tool to assist users that would otherwise find texting difficult or stressful. However, despite rapid uptake in LLM usage, considerations for their assistive usage in text message composition have not been explored. A primary concern regarding LLM usage is that poor public sentiment regarding AI introduces the possibility that its usage may harm perceptions of AI-assisted text messages, making usage counter-productive. To (in)validate this possibility, we explore how the belief that a text message did or did not receive AI assistance in composition alters its perceived tone, clarity, and ability to convey intent. In this study, we survey the perceptions of 26 participants on 18 randomly labeled pre-composed text messages. In analyzing the participants' ratings of message tone, clarity, and ability to convey intent, we find that there is no statistically significant evidence that the belief that AI is utilized alters recipient perceptions. This provides hopeful evidence that LLM-based text message composition assistance can be implemented without the risk of counter-productive outcomes.
http://w3id.org/mlsea/pwc/scientificWork/AI%20Sustainability%20in%20Practice%20Part%20One%3A%20Foundations%20for%20Sustainable%20AI%20Projects                                                                                  AI Sustainability in Practice Part One: Foundations for Sustainable AI Projects                                                                                  Sustainable AI projects are continuously responsive to the transformative effects as well as short-, medium-, and long-term impacts on individuals and society that the design, development, and deployment of AI technologies may have. Projects, which centre AI Sustainability, ensure that values-led, collaborative, and anticipatory reflection both guides the assessment of potential social and ethical impacts and steers responsible innovation practices. This workbook is the first part of a pair that provides the concepts and tools needed to put AI Sustainability into practice. It introduces the SUM Values, which help AI project teams to assess the potential societal impacts and ethical permissibility of their projects. It then presents a Stakeholder Engagement Process (SEP), which provides tools to facilitate proportionate engagement of and input from stakeholders with an emphasis on equitable and meaningful participation and positionality awareness.
http://w3id.org/mlsea/pwc/scientificWork/AI%20Thrust%3A%20Ranking%20Emerging%20Powers%20for%20Tech%20Startup%20Investment%20in%20Latin%20America                                                                                  AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America                                                                                  Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI. While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.
http://w3id.org/mlsea/pwc/scientificWork/AI%20and%20Memory%20Wall                                                                                  AI and Memory Wall                                                                                  The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training LLMs. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware FLOPS has been scaling at 3.0x/2yrs, outpacing the growth of DRAM and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every 2 years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder Transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.
http://w3id.org/mlsea/pwc/scientificWork/AI%20for%20bureaucratic%20productivity%3A%20Measuring%20the%20potential%20of%20AI%20to%20help%20automate%20143%20million%20UK%20government%20transactions                                                                                  AI for bureaucratic productivity: Measuring the potential of AI to help automate 143 million UK government transactions                                                                                  There is currently considerable excitement within government about the potential of artificial intelligence to improve public service productivity through the automation of complex but repetitive bureaucratic tasks, freeing up the time of skilled staff. Here, we explore the size of this opportunity, by mapping out the scale of citizen-facing bureaucratic decision-making procedures within UK central government, and measuring their potential for AI-driven automation. We estimate that UK central government conducts approximately one billion citizen-facing transactions per year in the provision of around 400 services, of which approximately 143 million are complex repetitive transactions. We estimate that 84% of these complex transactions are highly automatable, representing a huge potential opportunity: saving even an average of just one minute per complex transaction would save the equivalent of approximately 1,200 person-years of work every year. We also develop a model to estimate the volume of transactions a government service undertakes, providing a way for government to avoid conducting time consuming transaction volume measurements. Finally, we find that there is high turnover in the types of services government provide, meaning that automation efforts should focus on general procedures rather than services themselves which are likely to evolve over time. Overall, our work presents a novel perspective on the structure and functioning of modern government, and how it might evolve in the age of artificial intelligence.
http://w3id.org/mlsea/pwc/scientificWork/AI%20incidents%20and%20%27networked%20trouble%27%3A%20The%20case%20for%20a%20research%20agenda                                                                                  AI incidents and 'networked trouble': The case for a research agenda                                                                                  Against a backdrop of widespread interest in how publics can participate in the design of AI, I argue for a research agenda focused on AI incidents - examples of AI going wrong and sparking controversy - and how they are constructed in online environments. I take up the example of an AI incident from September 2020, when a Twitter user created a 'horrible experiment' to demonstrate the racist bias of Twitter's algorithm for cropping images. This resulted in Twitter not only abandoning its use of that algorithm, but also disavowing its decision to use any algorithm for the task. I argue that AI incidents like this are a significant means for participating in AI systems that require further research. That research agenda, I argue, should focus on how incidents are constructed through networked online behaviours that I refer to as 'networked trouble', where formats for participation enable individuals and algorithms to interact in ways that others - including technology companies - come to know and come to care about. At stake, I argue, is an important mechanism for participating in the design and deployment of AI.
http://w3id.org/mlsea/pwc/scientificWork/AI%2C%20Meet%20Human%3A%20Learning%20Paradigms%20for%20Hybrid%20Decision%20Making%20Systems                                                                                  AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems                                                                                  Everyday we increasingly rely on machine learning models to automate and support high-stake tasks and decisions. This growing presence means that humans are now constantly interacting with machine learning-based systems, training and using models everyday. Several different techniques in computer science literature account for the human interaction with machine learning systems, but their classification is sparse and the goals varied. This survey proposes a taxonomy of Hybrid Decision Making Systems, providing both a conceptual and technical framework for understanding how current computer science literature models interaction between humans and machines.
http://w3id.org/mlsea/pwc/scientificWork/AI-Augmented%20Predictions%3A%20LLM%20Assistants%20Improve%20Human%20Forecasting%20Accuracy                                                                                  AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy                                                                                  Large language models (LLMs) show impressive capabilities, matching and sometimes exceeding human performance in many domains. This study explores the potential of LLMs to augment judgement in forecasting tasks. We evaluated the impact on forecasting accuracy of two GPT-4-Turbo assistants: one designed to provide high-quality advice ('superforecasting'), and the other designed to be overconfident and base-rate-neglecting. Participants (N = 991) had the option to consult their assigned LLM assistant throughout the study, in contrast to a control group that used a less advanced model (DaVinci-003) without direct forecasting support. Our preregistered analyses reveal that LLM augmentation significantly enhances forecasting accuracy by 23% across both types of assistants, compared to the control group. This improvement occurs despite the superforecasting assistant's higher accuracy in predictions, indicating the augmentation's benefit is not solely due to model prediction accuracy. Exploratory analyses showed a pronounced effect in one forecasting item, without which we find that the superforecasting assistant increased accuracy by 43%, compared with 28% for the biased assistant. We further examine whether LLM augmentation disproportionately benefits less skilled forecasters, degrades the wisdom-of-the-crowd by reducing prediction diversity, or varies in effectiveness with question difficulty. Our findings do not consistently support these hypotheses. Our results suggest that access to an LLM assistant, even a biased one, can be a helpful decision aid in cognitively demanding tasks where the answer is not known at the time of interaction.
http://w3id.org/mlsea/pwc/scientificWork/AI-KD%3A%20Towards%20Alignment%20Invariant%20Face%20Image%20Quality%20Assessment%20Using%20Knowledge%20Distillation                                                                                  AI-KD: Towards Alignment Invariant Face Image Quality Assessment Using Knowledge Distillation                                                                                  Face Image Quality Assessment (FIQA) techniques have seen steady improvements over recent years, but their performance still deteriorates if the input face samples are not properly aligned. This alignment sensitivity comes from the fact that most FIQA techniques are trained or designed using a specific face alignment procedure. If the alignment technique changes, the performance of most existing FIQA techniques quickly becomes suboptimal. To address this problem, we present in this paper a novel knowledge distillation approach, termed AI-KD that can extend on any existing FIQA technique, improving its robustness to alignment variations and, in turn, performance with different alignment procedures. To validate the proposed distillation approach, we conduct comprehensive experiments on 6 face datasets with 4 recent face recognition models and in comparison to 7 state-of-the-art FIQA techniques. Our results show that AI-KD consistently improves performance of the initial FIQA techniques not only with misaligned samples, but also with properly aligned facial images. Furthermore, it leads to a new state-of-the-art, when used with a competitive initial FIQA approach. The code for AI-KD is made publicly available from: https://github.com/LSIbabnikz/AI-KD.
http://w3id.org/mlsea/pwc/scientificWork/AI-Powered%20Predictions%20for%20Electricity%20Load%20in%20Prosumer%20Communities                                                                                  AI-Powered Predictions for Electricity Load in Prosumer Communities                                                                                  The flexibility in electricity consumption and production in communities of residential buildings, including those with renewable energy sources and energy storage (a.k.a., prosumers), can effectively be utilized through the advancement of short-term demand response mechanisms. It is known that flexibility can further be increased if demand response is performed at the level of communities of prosumers, since aggregated groups can better coordinate electricity consumption. However, the effectiveness of such short-term optimization is highly dependent on the accuracy of electricity load forecasts both for each building as well as for the whole community. Structural variations in the electricity load profile can be associated with different exogenous factors, such as weather conditions, calendar information and day of the week, as well as user behavior. In this paper, we review a wide range of electricity load forecasting techniques, that can provide significant assistance in optimizing load consumption in prosumer communities. We present and test artificial intelligence (AI) powered short-term load forecasting methodologies that operate with black-box time series models, such as Facebook's Prophet and Long Short-term Memory (LSTM) models; season-based SARIMA and smoothing Holt-Winters models; and empirical regression-based models that utilize domain knowledge. The integration of weather forecasts into data-driven time series forecasts is also tested. Results show that the combination of persistent and regression terms (adapted to the load forecasting task) achieves the best forecast accuracy.
http://w3id.org/mlsea/pwc/scientificWork/ALLaVA%3A%20Harnessing%20GPT4V-synthesized%20Data%20for%20A%20Lite%20Vision-Language%20Model                                                                                  ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model                                                                                  Recent advancements in Large Vision-Language Models (LVLMs) have enabled processing of multimodal inputs in language models but require significant computational resources for deployment, especially in edge devices. This study aims to bridge the performance gap between traditional-scale LVLMs and resource-friendly lite versions by adopting high-quality training data. To do this, a synthetic dataset is created by leveraging GPT-4V's ability to generate detailed captions, complex reasoning instructions and detailed answers from images. The resulted model trained with our data, ALLaVA, achieves competitive performance on 12 benchmarks up to 3B LVLMs. This work highlights the feasibility of adopting high-quality data in crafting more efficient LVLMs. Our online demo is available at url{https://allava.freedomai.cn}.
http://w3id.org/mlsea/pwc/scientificWork/ALMs%3A%20Authorial%20Language%20Models%20for%20Authorship%20Attribution                                                                                  ALMs: Authorial Language Models for Authorship Attribution                                                                                  In this paper, we introduce an authorship attribution method called Authorial Language Models (ALMs) that involves identifying the most likely author of a questioned document based on the perplexity of the questioned document calculated for a set of causal language models fine-tuned on the writings of a set of candidate author. We benchmarked ALMs against state-of-art-systems using the CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves a macro-average accuracy score of 83.6% on Blogs50, outperforming all other methods, and 74.9% on CCAT50, matching the performance of the best method. To assess the performance of ALMs on shorter texts, we also conducted text ablation testing. We found that to reach a macro-average accuracy of 70%, ALMs needs 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMs requires 20 tokens on Blogs50 and 70 tokens on CCAT50.
http://w3id.org/mlsea/pwc/scientificWork/ALYMPICS%3A%20LLM%20Agents%20Meet%20Game%20Theory%20--%20Exploring%20Strategic%20Decision-Making%20with%20AI%20Agents                                                                                  ALYMPICS: LLM Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents                                                                                  This paper introduces Alympics (Olympics for Agents), a systematic simulation framework utilizing Large Language Model (LLM) agents for game theory research. Alympics creates a versatile platform for studying complex game theory problems, bridging the gap between theoretical game theory and empirical investigations by providing a controlled environment for simulating human-like strategic interactions with LLM agents. In our pilot case study, the 'Water Allocation Challenge,' we explore Alympics through a challenging strategic game focused on the multi-round auction on scarce survival resources. This study demonstrates the framework's ability to qualitatively and quantitatively analyze game determinants, strategies, and outcomes. Additionally, we conduct a comprehensive human assessment and an in-depth evaluation of LLM agents in strategic decision-making scenarios. Our findings not only expand the understanding of LLM agents' proficiency in emulating human strategic behavior but also highlight their potential in advancing game theory knowledge, thereby enriching our understanding of both game theory and empowering further research into strategic decision-making domains with LLM agents. Codes, prompts, and all related resources are available at https://github.com/microsoft/Alympics.
http://w3id.org/mlsea/pwc/scientificWork/AM-RADIO%3A%20Agglomerative%20Vision%20Foundation%20Model%20--%20Reduce%20All%20Domains%20Into%20One                                                                                  AM-RADIO: Agglomerative Vision Foundation Model -- Reduce All Domains Into One                                                                                  A handful of visual foundation models (VFMs) have recently emerged as the backbones for numerous downstream tasks. VFMs like CLIP, DINOv2, SAM are trained with distinct objectives, exhibiting unique characteristics for various downstream tasks. We find that despite their conceptual differences, these models can be effectively merged into a unified model through multi-teacher distillation. We name this approach AM-RADIO (Agglomerative Model -- Reduce All Domains Into One). This integrative approach not only surpasses the performance of individual teacher models but also amalgamates their distinctive features, such as zero-shot vision-language comprehension, detailed pixel-level understanding, and open vocabulary segmentation capabilities. In pursuit of the most hardware-efficient backbone, we evaluated numerous architectures in our multi-teacher distillation pipeline using the same training recipe. This led to the development of a novel architecture (E-RADIO) that exceeds the performance of its predecessors and is at least 7x faster than the teacher models. Our comprehensive benchmarking process covers downstream tasks including ImageNet classification, ADE20k semantic segmentation, COCO object detection and LLaVa-1.5 framework. Code: https://github.com/NVlabs/RADIO
http://w3id.org/mlsea/pwc/scientificWork/AMC%2724%20%27Analysis%20and%20Synthesis%20of%20the%20Disturbance%20Observer-based%20Robust%20Force%20Control%20Systems%20in%20State%20Space%27                                                                                  AMC'24 'Analysis and Synthesis of the Disturbance Observer-based Robust Force Control Systems in State Space'                                                                                  This paper extends the result of my previous papers on the analysis and synthesis of disturbance observer based robust control systems in state space.
http://w3id.org/mlsea/pwc/scientificWork/AMOR%3A%20A%20Recipe%20for%20Building%20Adaptable%20Modular%20Knowledge%20Agents%20Through%20Process%20Feedback                                                                                  AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback                                                                                  The notable success of large language models (LLMs) has sparked an upsurge in building language agents to complete various complex tasks. We present AMOR, an agent framework based on open-source LLMs, which reasons with external knowledge bases and adapts to specific domains through human supervision to the reasoning process. AMOR builds reasoning logic over a finite state machine (FSM) that solves problems through autonomous executions and transitions over disentangled modules. This allows humans to provide direct feedback to the individual modules, and thus naturally forms process supervision. Based on this reasoning and feedback framework, we develop AMOR through two-stage fine-tuning: warm-up and adaptation. The former fine-tunes the LLM with examples automatically constructed from various public datasets and enables AMOR to generalize across different knowledge environments, while the latter tailors AMOR to specific domains using process feedback. Extensive experiments across multiple domains demonstrate the advantage of AMOR to strong baselines, thanks to its FSM-based reasoning and process feedback mechanism.
http://w3id.org/mlsea/pwc/scientificWork/AMU-Tuning%3A%20Effective%20Logit%20Bias%20for%20CLIP-based%20Few-shot%20Learning                                                                                  AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning                                                                                  Recently, pre-trained vision-language models (e.g., CLIP) have shown great potential in few-shot learning and attracted a lot of research interest. Although efforts have been made to improve few-shot ability of CLIP, key factors on the effectiveness of existing methods have not been well studied, limiting further exploration of CLIP's potential in few-shot learning. In this paper, we first introduce a unified formulation to analyze CLIP-based few-shot learning methods from a perspective of logit bias, which encourages us to learn an effective logit bias for further improving performance of CLIP-based few-shot learning methods. To this end, we disassemble three key components involved in computation of logit bias (i.e., logit features, logit predictor, and logit fusion) and empirically analyze the effect on performance of few-shot classification. Based on analysis of key components, this paper proposes a novel AMU-Tuning method to learn effective logit bias for CLIP-based few-shot classification. Specifically, our AMU-Tuning predicts logit bias by exploiting the appropriate $ underline{ textbf{A}}$uxiliary features, which are fed into an efficient feature-initialized linear classifier with $ underline{ textbf{M}}$ulti-branch training. Finally, an $ underline{ textbf{U}}$ncertainty-based fusion is developed to incorporate logit bias into CLIP for few-shot classification. The experiments are conducted on several widely used benchmarks, and the results show AMU-Tuning clearly outperforms its counterparts while achieving state-of-the-art performance of CLIP-based few-shot learning without bells and whistles.
http://w3id.org/mlsea/pwc/scientificWork/AMuSE%3A%20Adaptive%20Multimodal%20Analysis%20for%20Speaker%20Emotion%20Recognition%20in%20Group%20Conversations                                                                                  AMuSE: Adaptive Multimodal Analysis for Speaker Emotion Recognition in Group Conversations                                                                                  Analyzing individual emotions during group conversation is crucial in developing intelligent agents capable of natural human-machine interaction. While reliable emotion recognition techniques depend on different modalities (text, audio, video), the inherent heterogeneity between these modalities and the dynamic cross-modal interactions influenced by an individual's unique behavioral patterns make the task of emotion recognition very challenging. This difficulty is compounded in group settings, where the emotion and its temporal evolution are not only influenced by the individual but also by external contexts like audience reaction and context of the ongoing conversation. To meet this challenge, we propose a Multimodal Attention Network that captures cross-modal interactions at various levels of spatial abstraction by jointly learning its interactive bunch of mode-specific Peripheral and Central networks. The proposed MAN injects cross-modal attention via its Peripheral key-value pairs within each layer of a mode-specific Central query network. The resulting cross-attended mode-specific descriptors are then combined using an Adaptive Fusion technique that enables the model to integrate the discriminative and complementary mode-specific data patterns within an instance-specific multimodal descriptor. Given a dialogue represented by a sequence of utterances, the proposed AMuSE model condenses both spatial and temporal features into two dense descriptors: speaker-level and utterance-level. This helps not only in delivering better classification performance (3-5% improvement in Weighted-F1 and 5-7% improvement in Accuracy) in large-scale public datasets but also helps the users in understanding the reasoning behind each emotion prediction made by the model via its Multimodal Explainability Visualization module.
http://w3id.org/mlsea/pwc/scientificWork/ANIM%3A%20Accurate%20Neural%20Implicit%20Model%20for%20Human%20Reconstruction%20from%20a%20single%20RGB-D%20image                                                                                  ANIM: Accurate Neural Implicit Model for Human Reconstruction from a single RGB-D image                                                                                  Recent progress in human shape learning, shows that neural implicit models are effective in generating 3D human surfaces from limited number of views, and even from a single RGB image. However, existing monocular approaches still struggle to recover fine geometric details such as face, hands or cloth wrinkles. They are also easily prone to depth ambiguities that result in distorted geometries along the camera optical axis. In this paper, we explore the benefits of incorporating depth observations in the reconstruction process by introducing ANIM, a novel method that reconstructs arbitrary 3D human shapes from single-view RGB-D images with an unprecedented level of accuracy. Our model learns geometric details from both multi-resolution pixel-aligned and voxel-aligned features to leverage depth information and enable spatial relationships, mitigating depth ambiguities. We further enhance the quality of the reconstructed shape by introducing a depth-supervision strategy, which improves the accuracy of the signed distance field estimation of points that lie on the reconstructed surface. Experiments demonstrate that ANIM outperforms state-of-the-art works that use RGB, surface normals, point cloud or RGB-D data as input. In addition, we introduce ANIM-Real, a new multi-modal dataset comprising high-quality scans paired with consumer-grade RGB-D camera, and our protocol to fine-tune ANIM, enabling high-quality reconstruction from real-world human capture.
http://w3id.org/mlsea/pwc/scientificWork/ANNA%3A%20A%20Deep%20Learning%20Based%20Dataset%20in%20Heterogeneous%20Traffic%20for%20Autonomous%20Vehicles                                                                                  ANNA: A Deep Learning Based Dataset in Heterogeneous Traffic for Autonomous Vehicles                                                                                  Recent breakthroughs in artificial intelligence offer tremendous promise for the development of self-driving applications. Deep Neural Networks, in particular, are being utilized to support the operation of semi-autonomous cars through object identification and semantic segmentation. To assess the inadequacy of the current dataset in the context of autonomous and semi-autonomous cars, we created a new dataset named ANNA. This study discusses a custom-built dataset that includes some unidentified vehicles in the perspective of Bangladesh, which are not included in the existing dataset. A dataset validity check was performed by evaluating models using the Intersection Over Union (IOU) metric. The results demonstrated that the model trained on our custom dataset was more precise and efficient than the models trained on the KITTI or COCO dataset concerning Bangladeshi traffic. The research presented in this paper also emphasizes the importance of developing accurate and efficient object detection algorithms for the advancement of autonomous vehicles.
http://w3id.org/mlsea/pwc/scientificWork/AONeuS%3A%20A%20Neural%20Rendering%20Framework%20for%20Acoustic-Optical%20Sensor%20Fusion                                                                                  AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion                                                                                  Underwater perception and 3D surface reconstruction are challenging problems with broad applications in construction, security, marine archaeology, and environmental monitoring. Treacherous operating conditions, fragile surroundings, and limited navigation control often dictate that submersibles restrict their range of motion and, thus, the baseline over which they can capture measurements. In the context of 3D scene reconstruction, it is well-known that smaller baselines make reconstruction more challenging. Our work develops a physics-based multimodal acoustic-optical neural surface reconstruction framework (AONeuS) capable of effectively integrating high-resolution RGB measurements with low-resolution depth-resolved imaging sonar measurements. By fusing these complementary modalities, our framework can reconstruct accurate high-resolution 3D surfaces from measurements captured over heavily-restricted baselines. Through extensive simulations and in-lab experiments, we demonstrate that AONeuS dramatically outperforms recent RGB-only and sonar-only inverse-differentiable-rendering--based surface reconstruction methods. A website visualizing the results of our paper is located at this address: https://aoneus.github.io/
http://w3id.org/mlsea/pwc/scientificWork/API%20Is%20Enough%3A%20Conformal%20Prediction%20for%20Large%20Language%20Models%20Without%20Logit-Access                                                                                  API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access                                                                                  This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on both close-ended and open-ended Question Answering tasks show our approach can mostly outperform the logit-based CP baselines.
http://w3id.org/mlsea/pwc/scientificWork/APPLE%3A%20Adversarial%20Privacy-aware%20Perturbations%20on%20Latent%20Embedding%20for%20Unfairness%20Mitigation                                                                                  APPLE: Adversarial Privacy-aware Perturbations on Latent Embedding for Unfairness Mitigation                                                                                  Ensuring fairness in deep-learning-based segmentors is crucial for health equity. Much effort has been dedicated to mitigating unfairness in the training datasets or procedures. However, with the increasing prevalence of foundation models in medical image analysis, it is hard to train fair models from scratch while preserving utility. In this paper, we propose a novel method, Adversarial Privacy-aware Perturbations on Latent Embedding (APPLE), that can improve the fairness of deployed segmentors by introducing a small latent feature perturber without updating the weights of the original model. By adding perturbation to the latent vector, APPLE decorates the latent vector of segmentors such that no fairness-related features can be passed to the decoder of the segmentors while preserving the architecture and parameters of the segmentor. Experiments on two segmentation datasets and five segmentors (three U-Net-like and two SAM-like) illustrate the effectiveness of our proposed method compared to several unfairness mitigation methods.
http://w3id.org/mlsea/pwc/scientificWork/APT-Pipe%3A%20A%20Prompt-Tuning%20Tool%20for%20Social%20Data%20Annotation%20using%20ChatGPT                                                                                  APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT                                                                                  Recent research has highlighted the potential of LLM applications, like ChatGPT, for performing label annotation on social computing text. However, it is already well known that performance hinges on the quality of the input prompts. To address this, there has been a flurry of research into prompt tuning -- techniques and guidelines that attempt to improve the quality of prompts. Yet these largely rely on manual effort and prior knowledge of the dataset being annotated. To address this limitation, we propose APT-Pipe, an automated prompt-tuning pipeline. APT-Pipe aims to automatically tune prompts to enhance ChatGPT's text classification performance on any given dataset. We implement APT-Pipe and test it across twelve distinct text classification datasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higher weighted F1-score on nine out of twelve experimented datasets, with an improvement of 7.01% on average. We further highlight APT-Pipe's flexibility as a framework by showing how it can be extended to support additional tuning mechanisms.
http://w3id.org/mlsea/pwc/scientificWork/ARKS%3A%20Active%20Retrieval%20in%20Knowledge%20Soup%20for%20Code%20Generation                                                                                  ARKS: Active Retrieval in Knowledge Soup for Code Generation                                                                                  Recently the retrieval-augmented generation (RAG) paradigm has raised much attention for its potential in incorporating external knowledge into large language models (LLMs) without further training. While widely explored in natural language applications, its utilization in code generation remains under-explored. In this paper, we introduce Active Retrieval in Knowledge Soup (ARKS), an advanced strategy for generalizing large language models for code. In contrast to relying on a single source, we construct a knowledge soup integrating web search, documentation, execution feedback, and evolved code snippets. We employ an active retrieval strategy that iteratively refines the query and updates the knowledge soup. To assess the performance of ARKS, we compile a new benchmark comprising realistic coding problems associated with frequently updated libraries and long-tail programming languages. Experimental results on ChatGPT and CodeLlama demonstrate a substantial improvement in the average execution accuracy of ARKS on LLMs. The analysis confirms the effectiveness of our proposed knowledge soup and active retrieval strategies, offering rich insights into the construction of effective retrieval-augmented code generation (RACG) pipelines. Our model, code, and data are available at https://arks-codegen.github.io.
http://w3id.org/mlsea/pwc/scientificWork/AReputation-Based%20Mechanism%20for%20Transaction%20Processing%20in%20Blockchain%20Systems                                                                                  AReputation-Based Mechanism for Transaction Processing in Blockchain Systems                                                                                  Blockchain protocols require nodes to verify all received transactions before forwarding them. However, massive spam transactions cause the participants in blockchain systems to consume many resources in verifying and propagating transactions. This paper proposes a reputation-based mechanism to increase the efficiency of processing transactions by considering the reputations of the sending nodes. Reputations are in turn adjusted based on the quality of transaction processing. Our proposed reputation-based mechanism offers three main contributions. First, we modify the verification strategy so that nodes set a probability of verifying a received transaction considering the likelihood of it being spam: transactions from a node with a low reputation have a high probability of being verified. Second, we optimize the transaction forwarding protocol to reduce propagation delay by prioritizing forwarding transactions to reputable receivers. Third, we design a data request protocol that provides alternative data exchange methods for nodes with different reputations. A series of simulations demonstrate the performance of our reputation-based mechanism.
http://w3id.org/mlsea/pwc/scientificWork/ASAP%3A%20Interpretable%20Analysis%20and%20Summarization%20of%20AI-generated%20Image%20Patterns%20at%20Scale                                                                                  ASAP: Interpretable Analysis and Summarization of AI-generated Image Patterns at Scale                                                                                  Generative image models have emerged as a promising technology to produce realistic images. Despite potential benefits, concerns grow about its misuse, particularly in generating deceptive images that could raise significant ethical, legal, and societal issues. Consequently, there is growing demand to empower users to effectively discern and comprehend patterns of AI-generated images. To this end, we developed ASAP, an interactive visualization system that automatically extracts distinct patterns of AI-generated images and allows users to interactively explore them via various views. To uncover fake patterns, ASAP introduces a novel image encoder, adapted from CLIP, which transforms images into compact 'distilled' representations, enriched with information for differentiating authentic and fake images. These representations generate gradients that propagate back to the attention maps of CLIP's transformer block. This process quantifies the relative importance of each pixel to image authenticity or fakeness, exposing key deceptive patterns. ASAP enables the at scale interactive analysis of these patterns through multiple, coordinated visualizations. This includes a representation overview with innovative cell glyphs to aid in the exploration and qualitative evaluation of fake patterns across a vast array of images, as well as a pattern view that displays authenticity-indicating patterns in images and quantifies their impact. ASAP supports the analysis of cutting-edge generative models with the latest architectures, including GAN-based models like proGAN and diffusion models like the latent diffusion model. We demonstrate ASAP's usefulness through two usage scenarios using multiple fake image detection benchmark datasets, revealing its ability to identify and understand hidden patterns in AI-generated images, especially in detecting fake human faces produced by diffusion-based techniques.
http://w3id.org/mlsea/pwc/scientificWork/ASGEA%3A%20Exploiting%20Logic%20Rules%20from%20Align-Subgraphs%20for%20Entity%20Alignment                                                                                  ASGEA: Exploiting Logic Rules from Align-Subgraphs for Entity Alignment                                                                                  Entity alignment (EA) aims to identify entities across different knowledge graphs that represent the same real-world objects. Recent embedding-based EA methods have achieved state-of-the-art performance in EA yet faced interpretability challenges as they purely rely on the embedding distance and neglect the logic rules behind a pair of aligned entities. In this paper, we propose the Align-Subgraph Entity Alignment (ASGEA) framework to exploit logic rules from Align-Subgraphs. ASGEA uses anchor links as bridges to construct Align-Subgraphs and spreads along the paths across KGs, which distinguishes it from the embedding-based methods. Furthermore, we design an interpretable Path-based Graph Neural Network, ASGNN, to effectively identify and integrate the logic rules across KGs. We also introduce a node-level multi-modal attention mechanism coupled with multi-modal enriched anchors to augment the Align-Subgraph. Our experimental results demonstrate the superior performance of ASGEA over the existing embedding-based methods in both EA and Multi-Modal EA (MMEA) tasks.
http://w3id.org/mlsea/pwc/scientificWork/ASiT%3A%20Local-Global%20Audio%20Spectrogram%20vIsion%20Transformer%20for%20Event%20Classification                                                                                  ASiT: Local-Global Audio Spectrogram vIsion Transformer for Event Classification                                                                                  Transformers, which were originally developed for natural language processing, have recently generated significant interest in the computer vision and audio communities due to their flexibility in learning long-range relationships. Constrained by the data hungry nature of transformers and the limited amount of labelled data, most transformer-based models for audio tasks are finetuned from ImageNet pretrained models, despite the huge gap between the domain of natural images and audio. This has motivated the research in self-supervised pretraining of audio transformers, which reduces the dependency on large amounts of labeled data and focuses on extracting concise representations of audio spectrograms. In this paper, we propose textbf{L}ocal- textbf{G}lobal textbf{A}udio textbf{S}pectrogram v textbf{I}sion textbf{T}ransformer, namely ASiT, a novel self-supervised learning framework that captures local and global contextual information by employing group masked model learning and self-distillation. We evaluate our pretrained models on both audio and speech classification tasks, including audio event classification, keyword spotting, and speaker identification. We further conduct comprehensive ablation studies, including evaluations of different pretraining strategies. The proposed ASiT framework significantly boosts the performance on all tasks and sets a new state-of-the-art performance in five audio and speech classification tasks, outperforming recent methods, including the approaches that use additional datasets for pretraining.
http://w3id.org/mlsea/pwc/scientificWork/AUD-TGN%3A%20Advancing%20Action%20Unit%20Detection%20with%20Temporal%20Convolution%20and%20GPT-2%20in%20Wild%20Audiovisual%20Contexts                                                                                  AUD-TGN: Advancing Action Unit Detection with Temporal Convolution and GPT-2 in Wild Audiovisual Contexts                                                                                  Leveraging the synergy of both audio data and visual data is essential for understanding human emotions and behaviors, especially in in-the-wild setting. Traditional methods for integrating such multimodal information often stumble, leading to less-than-ideal outcomes in the task of facial action unit detection. To overcome these shortcomings, we propose a novel approach utilizing audio-visual multimodal data. This method enhances audio feature extraction by leveraging Mel Frequency Cepstral Coefficients (MFCC) and Log-Mel spectrogram features alongside a pre-trained VGGish network. Moreover, this paper adaptively captures fusion features across modalities by modeling the temporal relationships, and ultilizes a pre-trained GPT-2 model for sophisticated context-aware fusion of multimodal information. Our method notably improves the accuracy of AU detection by understanding the temporal and contextual nuances of the data, showcasing significant advancements in the comprehension of intricate scenarios. These findings underscore the potential of integrating temporal dynamics and contextual interpretation, paving the way for future research endeavors.
http://w3id.org/mlsea/pwc/scientificWork/AUFormer%3A%20Vision%20Transformers%20are%20Parameter-Efficient%20Facial%20Action%20Unit%20Detectors                                                                                  AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors                                                                                  Facial Action Units (AU) is a vital concept in the realm of affective computing, and AU detection has always been a hot research topic. Existing methods suffer from overfitting issues due to the utilization of a large number of learnable parameters on scarce AU-annotated datasets or heavy reliance on substantial additional relevant data. Parameter-Efficient Transfer Learning (PETL) provides a promising paradigm to address these challenges, whereas its existing methods lack design for AU characteristics. Therefore, we innovatively investigate PETL paradigm to AU detection, introducing AUFormer and proposing a novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism. An individual MoKE specific to a certain AU with minimal learnable parameters first integrates personalized multi-scale and correlation knowledge. Then the MoKE collaborates with other MoKEs in the expert group to obtain aggregated information and inject it into the frozen Vision Transformer (ViT) to achieve parameter-efficient AU detection. Additionally, we design a Margin-truncated Difficulty-aware Weighted Asymmetric Loss (MDWA-Loss), which can encourage the model to focus more on activated AUs, differentiate the difficulty of unactivated AUs, and discard potential mislabeled samples. Extensive experiments from various perspectives, including within-domain, cross-domain, data efficiency, and micro-expression domain, demonstrate AUFormer's state-of-the-art performance and robust generalization abilities without relying on additional relevant data. The code for AUFormer is available at https://github.com/yuankaishen2001/AUFormer.
http://w3id.org/mlsea/pwc/scientificWork/AVT2-DWF%3A%20Improving%20Deepfake%20Detection%20with%20Audio-Visual%20Fusion%20and%20Dynamic%20Weighting%20Strategies                                                                                  AVT2-DWF: Improving Deepfake Detection with Audio-Visual Fusion and Dynamic Weighting Strategies                                                                                  With the continuous improvements of deepfake methods, forgery messages have transitioned from single-modality to multi-modal fusion, posing new challenges for existing forgery detection algorithms. In this paper, we propose AVT2-DWF, the Audio-Visual dual Transformers grounded in Dynamic Weight Fusion, which aims to amplify both intra- and cross-modal forgery cues, thereby enhancing detection capabilities. AVT2-DWF adopts a dual-stage approach to capture both spatial characteristics and temporal dynamics of facial expressions. This is achieved through a face transformer with an n-frame-wise tokenization strategy encoder and an audio transformer encoder. Subsequently, it uses multi-modal conversion with dynamic weight fusion to address the challenge of heterogeneous information fusion between audio and visual modalities. Experiments on DeepfakeTIMIT, FakeAVCeleb, and DFDC datasets indicate that AVT2-DWF achieves state-of-the-art performance intra- and cross-dataset Deepfake detection. Code is available at https://github.com/raining-dev/AVT2-DWF.
http://w3id.org/mlsea/pwc/scientificWork/AYDIV%3A%20Adaptable%20Yielding%203D%20Object%20Detection%20via%20Integrated%20Contextual%20Vision%20Transformer                                                                                  AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual Vision Transformer                                                                                  Combining LiDAR and camera data has shown potential in enhancing short-distance object detection in autonomous driving systems. Yet, the fusion encounters difficulties with extended distance detection due to the contrast between LiDAR's sparse data and the dense resolution of cameras. Besides, discrepancies in the two data representations further complicate fusion methods. We introduce AYDIV, a novel framework integrating a tri-phase alignment process specifically designed to enhance long-distance detection even amidst data discrepancies. AYDIV consists of the Global Contextual Fusion Alignment Transformer (GCFAT), which improves the extraction of camera features and provides a deeper understanding of large-scale patterns; the Sparse Fused Feature Attention (SFFA), which fine-tunes the fusion of LiDAR and camera details; and the Volumetric Grid Attention (VGA) for a comprehensive spatial data fusion. AYDIV's performance on the Waymo Open Dataset (WOD) with an improvement of 1.24% in mAPH value(L2 difficulty) and the Argoverse2 Dataset with a performance improvement of 7.40% in AP value demonstrates its efficacy in comparison to other existing fusion-based methods. Our code is publicly available at https://github.com/sanjay-810/AYDIV2
http://w3id.org/mlsea/pwc/scientificWork/Aardvark%20Weather%3A%20end-to-end%20data-driven%20weather%20forecasting                                                                                  Aardvark Weather: end-to-end data-driven weather forecasting                                                                                  Machine learning is revolutionising medium-range weather prediction. However it has only been applied to specific and individual components of the weather prediction pipeline. Consequently these data-driven approaches are unable to be deployed without input from conventional operational numerical weather prediction (NWP) systems, which is computationally costly and does not support end-to-end optimisation. In this work, we take a radically different approach and replace the entire NWP pipeline with a machine learning model. We present Aardvark Weather, the first end-to-end data-driven forecasting system which takes raw observations as input and provides both global and local forecasts. These global forecasts are produced for 24 variables at multiple pressure levels at one-degree spatial resolution and 24 hour temporal resolution, and are skillful with respect to hourly climatology at five to seven day lead times. Local forecasts are produced for temperature, mean sea level pressure, and wind speed at a geographically diverse set of weather stations, and are skillful with respect to an IFS-HRES interpolation baseline at multiple lead-times. Aardvark, by virtue of its simplicity and scalability, opens the door to a new paradigm for performing accurate and efficient data-driven medium-range weather forecasting.
http://w3id.org/mlsea/pwc/scientificWork/Ab-initio%20variational%20wave%20functions%20for%20the%20time-dependent%20many-electron%20Schr%C3%B6dinger%20equation                                                                                  Ab-initio variational wave functions for the time-dependent many-electron SchrÃ¶dinger equation                                                                                  Describing the dynamics of many-electron quantum systems is crucial for applications such as predicting electronic structures in quantum chemistry, the properties of condensed matter systems, and the behaviors of complex materials. However, the real-time evolution of non-equilibrium quantum electronic systems poses a significant challenge for theoretical and computational approaches, due to the system's exploration of a vast configuration space. This work introduces a variational approach for fermionic time-dependent wave functions, surpassing mean-field approximations by capturing many-body correlations. The proposed methodology involves parameterizing the time-evolving quantum state, enabling the approximation of the state's evolution. To account for electron correlations, we employ time-dependent Jastrow factors and backflow transformations. We also show that we can incorporate neural networks to parameterize these functions. The time-dependent variational Monte Carlo technique is employed to efficiently compute the optimal time-dependent parameters. The approach is demonstrated in three distinct systems: the solvable harmonic interaction model, the dynamics of a diatomic molecule in intense laser fields, and a quenched quantum dot. In all cases, we show clear signatures of many-body correlations in the dynamics not captured by mean-field methods. The results showcase the ability of our variational approach to accurately capture the time evolution of quantum states, providing insight into the quantum dynamics of interacting electronic systems, beyond the capabilities of mean-field.
http://w3id.org/mlsea/pwc/scientificWork/AbDiffuser%3A%20Full-Atom%20Generation%20of%20in%20vitro%20Functioning%20Antibodies                                                                                  AbDiffuser: Full-Atom Generation of in vitro Functioning Antibodies                                                                                  We introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude, enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of the selected designs were tight binders.
http://w3id.org/mlsea/pwc/scientificWork/Absolute-Unified%20Multi-Class%20Anomaly%20Detection%20via%20Class-Agnostic%20Distribution%20Alignment                                                                                  Absolute-Unified Multi-Class Anomaly Detection via Class-Agnostic Distribution Alignment                                                                                  Conventional unsupervised anomaly detection (UAD) methods build separate models for each object category. Recent studies have proposed to train a unified model for multiple classes, namely model-unified UAD. However, such methods still implement the unified model separately on each class during inference with respective anomaly decision thresholds, which hinders their application when the image categories are entirely unavailable. In this work, we present a simple yet powerful method to address multi-class anomaly detection without any class information, namely textit{absolute-unified} UAD. We target the crux of prior works in this challenging setting: different objects have mismatched anomaly score distributions. We propose Class-Agnostic Distribution Alignment (CADA) to align the mismatched score distribution of each implicit class without knowing class information, which enables unified anomaly detection for all classes and samples. The essence of CADA is to predict each class's score distribution of normal samples given any image, normal or anomalous, of this class. As a general component, CADA can activate the potential of nearly all UAD methods under absolute-unified setting. Our approach is extensively evaluated under the proposed setting on two popular UAD benchmark datasets, MVTec AD and VisA, where we exceed previous state-of-the-art by a large margin.
http://w3id.org/mlsea/pwc/scientificWork/Abstract%20Meaning%20Representation-Based%20Logic-Driven%20Data%20Augmentation%20for%20Logical%20Reasoning                                                                                  Abstract Meaning Representation-Based Logic-Driven Data Augmentation for Logical Reasoning                                                                                  Combining large language models with logical reasoning enhances their capacity to address problems in a robust and reliable manner. Nevertheless, the intricate nature of logical reasoning poses challenges to gathering reliable data from the web for building comprehensive training datasets, subsequently affecting the performance on downstream tasks. To address this, we introduce a novel logic-driven data augmentation approach, AMR-LDA. AMR-LDA converts the original text into an Abstract Meaning Representation (AMR) graph, a structured semantic representation that encapsulates the logic structure of the sentence, upon which operations are performed to generate logically modified AMR graphs. The modified AMR graphs are subsequently converted back into text to create augmented data. Notably, our methodology is architecture-agnostic and enhances both generative large language models, such as GPT-3.5 and GPT-4, through prompt augmentation, and discriminative large language models through contrastive learning with logic-driven data augmentation. Empirical evidence underscores the efficacy of our proposed method with improvement in performance across seven downstream tasks, such as reading comprehension requiring logical reasoning, textual entailment, and natural language inference. Furthermore, our method leads on the ReClor leaderboard (https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347). The source code and data are publicly available https://bit.ly/3OWKe8r.
http://w3id.org/mlsea/pwc/scientificWork/AcademiaOS%3A%20Automating%20Grounded%20Theory%20Development%20in%20Qualitative%20Research%20with%20Large%20Language%20Models                                                                                  AcademiaOS: Automating Grounded Theory Development in Qualitative Research with Large Language Models                                                                                  AcademiaOS is a first attempt to automate grounded theory development in qualitative research with large language models. Using recent large language models' language understanding, generation, and reasoning capabilities, AcademiaOS codes curated qualitative raw data such as interview transcripts and develops themes and dimensions to further develop a grounded theoretical model, affording novel insights. A user study (n=19) suggests that the system finds acceptance in the academic community and exhibits the potential to augment humans in qualitative research. AcademiaOS has been made open-source for others to build upon and adapt to their use cases.
http://w3id.org/mlsea/pwc/scientificWork/Accelerated%20Policy%20Gradient%3A%20On%20the%20Convergence%20Rates%20of%20the%20Nesterov%20Momentum%20for%20Reinforcement%20Learning                                                                                  Accelerated Policy Gradient: On the Convergence Rates of the Nesterov Momentum for Reinforcement Learning                                                                                  Various acceleration approaches for Policy Gradient (PG) have been analyzed within the realm of Reinforcement Learning (RL). However, the theoretical understanding of the widely used momentum-based acceleration method on PG remains largely open. In response to this gap, we adapt the celebrated Nesterov's accelerated gradient (NAG) method to policy optimization in RL, termed textit{Accelerated Policy Gradient} (APG). To demonstrate the potential of APG in achieving fast convergence, we formally prove that with the true gradient and under the softmax policy parametrization, APG converges to an optimal policy at rates: (i) $ tilde{O}(1/t^2)$ with constant step sizes; (ii) $O(e^{-ct})$ with exponentially-growing step sizes. To the best of our knowledge, this is the first characterization of the convergence rates of NAG in the context of RL. Notably, our analysis relies on one interesting finding: Regardless of the parameter initialization, APG ends up entering a locally nearly-concave regime, where APG can significantly benefit from the momentum, within finite iterations. Through numerical validation and experiments on the Atari 2600 benchmarks, we confirm that APG exhibits a $ tilde{O}(1/t^2)$ rate with constant step sizes and a linear convergence rate with exponentially-growing step sizes, significantly improving convergence over the standard PG.
http://w3id.org/mlsea/pwc/scientificWork/Accelerated%20Sampling%20of%20Rare%20Events%20using%20a%20Neural%20Network%20Bias%20Potential                                                                                  Accelerated Sampling of Rare Events using a Neural Network Bias Potential                                                                                  In the field of computational physics and material science, the efficient sampling of rare events occurring at atomic scale is crucial. It aids in understanding mechanisms behind a wide range of important phenomena, including protein folding, conformal changes, chemical reactions and materials diffusion and deformation. Traditional simulation methods, such as Molecular Dynamics and Monte Carlo, often prove inefficient in capturing the timescale of these rare events by brute force. In this paper, we introduce a practical approach by combining the idea of importance sampling with deep neural networks (DNNs) that enhance the sampling of these rare events. In particular, we approximate the variance-free bias potential function with DNNs which is trained to maximize the probability of rare event transition under the importance potential function. This method is easily scalable to high-dimensional problems and provides robust statistical guarantees on the accuracy of the estimated probability of rare event transition. Furthermore, our algorithm can actively generate and learn from any successful samples, which is a novel improvement over existing methods. Using a 2D system as a test bed, we provide comparisons between results obtained from different training strategies, traditional Monte Carlo sampling and numerically solved optimal bias potential function under different temperatures. Our numerical results demonstrate the efficacy of the DNN-based importance sampling of rare events.
http://w3id.org/mlsea/pwc/scientificWork/Accelerating%20Innovation%20in%206G%20Research%3A%20Real-Time%20Capable%20SDR%20System%20Architecture%20for%20Rapid%20Prototyping                                                                                  Accelerating Innovation in 6G Research: Real-Time Capable SDR System Architecture for Rapid Prototyping                                                                                  The next global mobile communication standard 6G strives to push the technological limits of radio frequency (RF) communication even further than its predecessors: Data rates beyond 100 Gbit/s, RF bandwidths above 1 GHz, and sub-millisecond latency necessitate very high performance development tools to enable the extent of innovation required for 6G's likely features. We propose a new SDR firmware and software architecture designed explicitly to meet these challenging requirements. It relies on Ethernet and commercial off-the-shelf network and server components to maximize flexibility and to reduce costs. We analyze state-of-the-art solutions (USRP X440 and other RFSoC-based systems), derive architectural design goals, explain resulting design decision in detail, and exemplify our architecture's implementation on the XCZU48DR RFSoC. Finally, we prove its performance via measurements and outline how the architecture surpasses the state-of-the-art with respect to sustained RF recording while maintaining high Ethernet bandwidth efficiency. Building a micro-Doppler radar example, we demonstrate its real-time and rapid application development capabilities.
http://w3id.org/mlsea/pwc/scientificWork/Accelerating%20Retrieval-Augmented%20Language%20Model%20Serving%20with%20Speculation                                                                                  Accelerating Retrieval-Augmented Language Model Serving with Speculation                                                                                  Retrieval-augmented language models (RaLM) have demonstrated the potential to solve knowledge-intensive natural language processing (NLP) tasks by combining a non-parametric knowledge base with a parametric language model. Instead of fine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to the latest data and better source attribution mechanisms. Among various RaLM approaches, iterative RaLM delivers a better generation quality due to a more frequent interaction between the retriever and the language model. Despite the benefits, iterative RaLM usually encounters high overheads due to the frequent retrieval step. To this end, we propose RaLMSpec, a speculation-inspired framework that provides generic speed-up over iterative RaLM while preserving the same model outputs through speculative retrieval and batched verification. By further incorporating prefetching, optimal speculation stride scheduler, and asynchronous verification, RaLMSpec can automatically exploit the acceleration potential to the fullest. For naive iterative RaLM serving, extensive evaluations over three language models on four downstream QA datasets demonstrate that RaLMSpec can achieve a speed-up ratio of 1.75-2.39x, 1.04-1.39x, and 1.31-1.77x when the retriever is an exact dense retriever, approximate dense retriever, and sparse retriever respectively compared with the baseline. For KNN-LM serving, RaLMSpec can achieve a speed-up ratio up to 7.59x and 2.45x when the retriever is an exact dense retriever and approximate dense retriever, respectively, compared with the baseline.
http://w3id.org/mlsea/pwc/scientificWork/Accelerating%20Search-Based%20Planning%20for%20Multi-Robot%20Manipulation%20by%20Leveraging%20Online-Generated%20Experiences                                                                                  Accelerating Search-Based Planning for Multi-Robot Manipulation by Leveraging Online-Generated Experiences                                                                                  An exciting frontier in robotic manipulation is the use of multiple arms at once. However, planning concurrent motions is a challenging task using current methods. The high-dimensional composite state space renders many well-known motion planning algorithms intractable. Recently, Multi-Agent Path-Finding (MAPF) algorithms have shown promise in discrete 2D domains, providing rigorous guarantees. However, widely used conflict-based methods in MAPF assume an efficient single-agent motion planner. This poses challenges in adapting them to manipulation cases where this assumption does not hold, due to the high dimensionality of configuration spaces and the computational bottlenecks associated with collision checking. To this end, we propose an approach for accelerating conflict-based search algorithms by leveraging their repetitive and incremental nature -- making them tractable for use in complex scenarios involving multi-arm coordination in obstacle-laden environments. We show that our method preserves completeness and bounded sub-optimality guarantees, and demonstrate its practical efficacy through a set of experiments with up to 10 robotic arms.
http://w3id.org/mlsea/pwc/scientificWork/Access%20to%20Library%20Information%20Resources%20by%20University%20Students%20during%20COVID-19%20Pandemic%20in%20Africa%3A%20A%20Systematic%20Literature%20Review                                                                                  Access to Library Information Resources by University Students during COVID-19 Pandemic in Africa: A Systematic Literature Review                                                                                  The study examined access to library information resources by university students during the outbreak of the COVID-19 pandemic. The study investigated measures that were adopted by academic libraries for smooth delivery of library information resources to their patrons. It also identified technological tools that were employed by libraries to facilitate access to library information resources. We also investigated the challenges faced by students in accessing library information resources. A systematic literature review approach using PRISMA guidelines was employed to investigate the relevant literature on the subject. The keyword search strategy was employed to search for relevant literature from four scholarly databases Scopus, emerald, Research4life, and Google Scholar. In this study, 23 studies that fulfilled the criteria were included. The findings revealed that the majority of the reviewed studies indicate that, during the COVID-19 pandemic many academic libraries in Africa adopted different approaches to facilitate access to library information resources by university students including expanding access to electronic resources off-campus, virtual reference services, circulation and lending services. To support access to different library services and information resources academic libraries in Africa used various digital technological tools like social media, library websites, email and video conferencing. Moreover, the study revealed that limited access to internet services and ICT devices, inadequate electronic library collection and inadequate digital and information literacy were the major challenges faced by patrons during the pandemic. This study recommends investment in ICT infrastructures and expanding electronic resource collections which are vital resources in the digital era.
http://w3id.org/mlsea/pwc/scientificWork/Accounting%20for%20AI%20and%20Users%20Shaping%20One%20Another%3A%20The%20Role%20of%20Mathematical%20Models                                                                                  Accounting for AI and Users Shaping One Another: The Role of Mathematical Models                                                                                  As AI systems enter into a growing number of societal domains, these systems increasingly shape and are shaped by user preferences, opinions, and behaviors. However, the design of AI systems rarely accounts for how AI and users shape one another. In this position paper, we argue for the development of formal interaction models which mathematically specify how AI and users shape one another. Formal interaction models can be leveraged to (1) specify interactions for implementation, (2) monitor interactions through empirical analysis, (3) anticipate societal impacts via counterfactual analysis, and (4) control societal impacts via interventions. The design space of formal interaction models is vast, and model design requires careful consideration of factors such as style, granularity, mathematical complexity, and measurability. Using content recommender systems as a case study, we critically examine the nascent literature of formal interaction models with respect to these use-cases and design axes. More broadly, we call for the community to leverage formal interaction models when designing, evaluating, or auditing any AI system which interacts with users.
http://w3id.org/mlsea/pwc/scientificWork/Accurate%20Block%20Quantization%20in%20LLMs%20with%20Outliers                                                                                  Accurate Block Quantization in LLMs with Outliers                                                                                  The demand for inference on extremely large scale LLMs has seen enormous growth in the recent months. It made evident the colossal shortage of dedicated hardware capable of efficient and fast processing of the involved compute and memory movement. The problem is aggravated by the exploding raise in the lengths of the sequences being processed, since those require efficient on-chip storage of the KV-cache of size proportional to the sequence length. To make the required compute feasible and fit the involved data into available memory, numerous quantization techniques have been proposed that allow accurate quantization for both weights and activations. One of the main recent breakthroughs in this direction was introduction of the family of Block Floating Point (BFP) formats characterized by a block of mantissas with a shared scale factor. These enable memory- power-, and compute- efficient hardware support of the tensor operations and provide extremely good quantization accuracy. The main issues preventing widespread application of block formats is caused by the presence of outliers in weights and activations since those affect the accuracy of the other values in the same block. In this paper, we focus on the most critical problem of limited KV-cache storage. We propose a novel approach enabling usage of low precision BFP formats without compromising the resulting model accuracy. We exploit the common channel-wise patterns exhibited by the outliers to rearrange them in such a way, that their quantization quality is significantly improved. The methodology yields 2x savings in the memory footprint without significant degradation of the model's accuracy. Importantly, the rearrangement of channels happens at the compile time and thus has no impact on the inference latency.
http://w3id.org/mlsea/pwc/scientificWork/Accurate%20Crystal%20Structure%20Prediction%20of%20New%202D%20Hybrid%20Organic%20Inorganic%20Perovskites                                                                                  Accurate Crystal Structure Prediction of New 2D Hybrid Organic Inorganic Perovskites                                                                                  Low dimensional hybrid organic-inorganic perovskites (HOIPs) represent a promising class of electronically active materials for both light absorption and emission. The design space of HOIPs is extremely large, since a diverse space of organic cations can be combined with different inorganic frameworks. This immense design space allows for tunable electronic and mechanical properties, but also necessitates the development of new tools for in silico high throughput analysis of candidate structures. In this work, we present an accurate, efficient, transferable and widely applicable machine learning interatomic potential (MLIP) for predicting the structure of new 2D HOIPs. Using the MACE architecture, an MLIP is trained on 86 diverse experimentally reported HOIP structures. The model is tested on 73 unseen perovskite compositions, and achieves chemical accuracy with respect to the reference electronic structure method. Our model is then combined with a simple random structure search algorithm to predict the structure of hypothetical HOIPs given only the proposed composition. Success is demonstrated by correctly and reliably recovering the crystal structure of a set of experimentally known 2D perovskites. Such a random structure search is impossible with ab initio methods due to the associated computational cost, but is relatively inexpensive with the MACE potential. Finally, the procedure is used to predict the structure formed by a new organic cation with no previously known corresponding perovskite. Laboratory synthesis of the new hybrid perovskite confirms the accuracy of our prediction. This capability, applied at scale, enables efficient screening of thousands of combinations of organic cations and inorganic layers.
http://w3id.org/mlsea/pwc/scientificWork/Accurate%20estimation%20of%20feature%20importance%20faithfulness%20for%20tree%20models                                                                                  Accurate estimation of feature importance faithfulness for tree models                                                                                  In this paper, we consider a perturbation-based metric of predictive faithfulness of feature rankings (or attributions) that we call PGI squared. When applied to decision tree-based regression models, the metric can be computed accurately and efficiently for arbitrary independent feature perturbation distributions. In particular, the computation does not involve Monte Carlo sampling that has been typically used for computing similar metrics and which is inherently prone to inaccuracies. Moreover, we propose a method of ranking features by their importance for the tree model's predictions based on PGI squared. Our experiments indicate that in some respects, the method may identify the globally important features better than the state-of-the-art SHAP explainer
http://w3id.org/mlsea/pwc/scientificWork/Acoustic%20Local%20Positioning%20With%20Encoded%20Emission%20Beacons                                                                                  Acoustic Local Positioning With Encoded Emission Beacons                                                                                  Acoustic local positioning systems (ALPSs) are an interesting alternative for indoor positioning due to certain advantages over other approaches, including their relatively high accuracy, low cost, and room-level signal propagation. Centimeter-level or fine-grained indoor positioning can be an asset for robot navigation, guiding a person to, for instance, a particular piece in a museum or to a specific product in a shop, targeted advertising, or augmented reality. In airborne system applications, acoustic positioning can be based on using opportunistic signals or sounds produced by the person or object to be located (e.g., noise from appliances or the speech from a speaker) or from encoded emission beacons (or anchors) specifically designed for this purpose. This work presents a review of the different challenges that designers of systems based on encoded emission beacons must address in order to achieve suitable performance. At low-level processing, the waveform design (coding and modulation) and the processing of the received signal are key factors to address such drawbacks as multipath propagation, multiple-access interference, nearfar effect, or Doppler shifting. With regards to high-level system design, the issues to be addressed are related to the distribution of beacons, ease of deployment, and calibration and positioning algorithms, including the possible fusion of information. Apart from theoretical discussions, this work also includes the description of an ALPS that was implemented, installed in a large area and tested for mobile robot navigation. In addition to practical interest for real applications, airborne ALPSs can also be used as an excellent platform to test complex algorithms, which can be subsequently adapted for other positioning systems, such as underwater acoustic systems or ultrawideband radiofrequency (UWB RF) systems.
http://w3id.org/mlsea/pwc/scientificWork/Action%20Model%20Learning%20with%20Guarantees                                                                                  Action Model Learning with Guarantees                                                                                  This paper studies the problem of action model learning with full observability. Following the learning by search paradigm by Mitchell, we develop a theory for action model learning based on version spaces that interprets the task as search for hypothesis that are consistent with the learning examples. Our theoretical findings are instantiated in an online algorithm that maintains a compact representation of all solutions of the problem. Among these range of solutions, we bring attention to actions models approximating the actual transition system from below (sound models) and from above (complete models). We show how to manipulate the output of our learning algorithm to build deterministic and non-deterministic formulations of the sound and complete models and prove that, given enough examples, both formulations converge into the very same true model. Our experiments reveal their usefulness over a range of planning domains.
http://w3id.org/mlsea/pwc/scientificWork/Actions%20Speak%20Louder%20than%20Words%3A%20Trillion-Parameter%20Sequential%20Transducers%20for%20Generative%20Recommendations                                                                                  Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations                                                                                  Large-scale recommendation systems are characterized by their reliance on high cardinality, heterogeneous features and the need to handle tens of billions of user actions on a daily basis. Despite being trained on huge volume of data with thousands of features, most Deep Learning Recommendation Models (DLRMs) in industry fail to scale with compute. Inspired by success achieved by Transformers in language and vision domains, we revisit fundamental design choices in recommendation systems. We reformulate recommendation problems as sequential transduction tasks within a generative modeling framework (``Generative Recommenders''), and propose a new architecture, HSTU, designed for high cardinality, non-stationary streaming recommendation data. HSTU outperforms baselines over synthetic and public datasets by up to 65.8 % in NDCG, and is 5.3x to 15.2x faster than FlashAttention2-based Transformers on 8192 length sequences. HSTU-based Generative Recommenders, with 1.5 trillion parameters, improve metrics in online A/B tests by 12.4 % and have been deployed on multiple surfaces of a large internet platform with billions of users. More importantly, the model quality of Generative Recommenders empirically scales as a power-law of training compute across three orders of magnitude, up to GPT-3/LLaMa-2 scale, which reduces carbon footprint needed for future model developments, and further paves the way for the first foundational models in recommendations.
http://w3id.org/mlsea/pwc/scientificWork/Activating%20Wider%20Areas%20in%20Image%20Super-Resolution                                                                                  Activating Wider Areas in Image Super-Resolution                                                                                  The prevalence of convolution neural networks (CNNs) and vision transformers (ViTs) has markedly revolutionized the area of single-image super-resolution (SISR). To further boost the SR performances, several techniques, such as residual learning and attention mechanism, are introduced, which can be largely attributed to a wider range of activated area, that is, the input pixels that strongly influence the SR results. However, the possibility of further improving SR performance through another versatile vision backbone remains an unresolved challenge. To address this issue, in this paper, we unleash the representation potential of the modern state space model, i.e., Vision Mamba (Vim), in the context of SISR. Specifically, we present three recipes for better utilization of Vim-based models: 1) Integration into a MetaFormer-style block; 2) Pre-training on a larger and broader dataset; 3) Employing complementary attention mechanism, upon which we introduce the MMA. The resulting network MMA is capable of finding the most relevant and representative input pixels to reconstruct the corresponding high-resolution images. Comprehensive experimental analysis reveals that MMA not only achieves competitive or even superior performance compared to state-of-the-art SISR methods but also maintains relatively low memory and computational overheads (e.g., +0.5 dB PSNR elevation on Manga109 dataset with 19.8 M parameters at the scale of 2). Furthermore, MMA proves its versatility in lightweight SR applications. Through this work, we aim to illuminate the potential applications of state space models in the broader realm of image processing rather than SISR, encouraging further exploration in this innovative direction.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Exploration%20in%20Bayesian%20Model-based%20Reinforcement%20Learning%20for%20Robot%20Manipulation                                                                                  Active Exploration in Bayesian Model-based Reinforcement Learning for Robot Manipulation                                                                                  Efficiently tackling multiple tasks within complex environment, such as those found in robot manipulation, remains an ongoing challenge in robotics and an opportunity for data-driven solutions, such as reinforcement learning (RL). Model-based RL, by building a dynamic model of the robot, enables data reuse and transfer learning between tasks with the same robot and similar environment. Furthermore, data gathering in robotics is expensive and we must rely on data efficient approaches such as model-based RL, where policy learning is mostly conducted on cheaper simulations based on the learned model. Therefore, the quality of the model is fundamental for the performance of the posterior tasks. In this work, we focus on improving the quality of the model and maintaining the data efficiency by performing active learning of the dynamic model during a preliminary exploration phase based on maximize information gathering. We employ Bayesian neural network models to represent, in a probabilistic way, both the belief and information encoded in the dynamic model during exploration. With our presented strategies we manage to actively estimate the novelty of each transition, using this as the exploration reward. In this work, we compare several Bayesian inference methods for neural networks, some of which have never been used in a robotics context, and evaluate them in a realistic robot manipulation setup. Our experiments show the advantages of our Bayesian model-based RL approach, with similar quality in the results than relevant alternatives with much lower requirements regarding robot execution steps. Unlike related previous studies that focused the validation solely on toy problems, our research takes a step towards more realistic setups, tackling robotic arm end-tasks.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Generation%20for%20Image%20Classification                                                                                  Active Generation for Image Classification                                                                                  Recently, the growing capabilities of deep generative models have underscored their potential in enhancing image classification accuracy. However, existing methods often demand the generation of a disproportionately large number of images compared to the original dataset, while having only marginal improvements in accuracy. This computationally expensive and time-consuming process hampers the practicality of such approaches. In this paper, we propose to address the efficiency of image generation by focusing on the specific needs and characteristics of the model. With a central tenet of active learning, our method, named ActGen, takes a training-aware approach to image generation. It aims to create images akin to the challenging or misclassified samples encountered by the current model and incorporates these generated images into the training set to augment model performance. ActGen introduces an attentive image guidance technique, using real images as guides during the denoising process of a diffusion model. The model's attention on class prompt is leveraged to ensure the preservation of similar foreground object while diversifying the background. Furthermore, we introduce a gradient-based generation guidance method, which employs two losses to generate more challenging samples and prevent the generated images from being too similar to previously generated ones. Experimental results on the CIFAR and ImageNet datasets demonstrate that our method achieves better performance with a significantly reduced number of generated images.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Support%20of%20Inverters%20for%20Improving%20Short-Term%20Voltage%20Security%20in%20100%25%20IBRsPenetrated%20Power%20Systems                                                                                  Active Support of Inverters for Improving Short-Term Voltage Security in 100% IBRsPenetrated Power Systems                                                                                  Due to the energy crisis and environmental pollution, the installed capacity of inverter-based resources (IBRs) in power grids is rapidly increasing, and grid-following control (GFL) is the most prevalent at present. Meanwhile, grid-forming control-based (GFM) devices have been installed in the grid to provide active support for frequency and voltage. In the future GFL devices combined with GFM will be promising, especially in power systems with high penetration or 100% IBRs. When a short-circuit fault occurs in the grid, the controlled current source characteristic of the GFL devices leads to insufficient dynamic voltage support (DVS), while the GFM devices usually reduce the internal voltage to limit the current. Thus, deep voltage sags and undesired disconnections of IBRs may occur. Moreover, due to the dispersed locations and the control strategies' diversity of IBRs, the voltage support of different devices may not be fully coordinated, which is not conducive to short-term voltage security (STVS). To address this issue, a control scheme based on the simulation of transient characteristics of synchronous machines (SMs) is proposed. Then, a new fault ride-through strategy (FRT) is proposed based on the characteristic differences between GFL and GFM devices, and an optimization model of multi-device control parameters is formulated to meet the short-term voltage security constraints (SVSCs) and device capacity constraints. Finally, a fast solution method based on analytical modeling is proposed for the model. Test results based on the doublegenerator-one-load system, the IEEE 14-bus system, and other systems of different sizes show that the proposed method can effectively enhance the active support capability of GFL and GFM to the grid voltage, and avoid the large-scale disconnection of IBRs
http://w3id.org/mlsea/pwc/scientificWork/ActiveAD%3A%20Planning-Oriented%20Active%20Learning%20for%20End-to-End%20Autonomous%20Driving                                                                                  ActiveAD: Planning-Oriented Active Learning for End-to-End Autonomous Driving                                                                                  End-to-end differentiable learning for autonomous driving (AD) has recently become a prominent paradigm. One main bottleneck lies in its voracious appetite for high-quality labeled data e.g. 3D bounding boxes and semantic segmentation, which are notoriously expensive to manually annotate. The difficulty is further pronounced due to the prominent fact that the behaviors within samples in AD often suffer from long tailed distribution. In other words, a large part of collected data can be trivial (e.g. simply driving forward in a straight road) and only a few cases are safety-critical. In this paper, we explore a practically important yet under-explored problem about how to achieve sample and label efficiency for end-to-end AD. Specifically, we design a planning-oriented active learning method which progressively annotates part of collected raw data according to the proposed diversity and usefulness criteria for planning routes. Empirically, we show that our planning-oriented approach could outperform general active learning methods by a large margin. Notably, our method achieves comparable performance with state-of-the-art end-to-end AD methods - by using only 30% nuScenes data. We hope our work could inspire future works to explore end-to-end AD from a data-centric perspective in addition to methodology efforts.
http://w3id.org/mlsea/pwc/scientificWork/Actor%20Identification%20in%20Discourse%3A%20A%20Challenge%20for%20LLMs%3F                                                                                  Actor Identification in Discourse: A Challenge for LLMs?                                                                                  The identification of political actors who put forward claims in public debate is a crucial step in the construction of discourse networks, which are helpful to analyze societal debates. Actor identification is, however, rather challenging: Often, the locally mentioned speaker of a claim is only a pronoun ('He proposed that [claim]'), so recovering the canonical actor name requires discourse understanding. We compare a traditional pipeline of dedicated NLP components (similar to those applied to the related task of coreference) with a LLM, which appears a good match for this generation task. Evaluating on a corpus of German actors in newspaper reports, we find surprisingly that the LLM performs worse. Further analysis reveals that the LLM is very good at identifying the right reference, but struggles to generate the correct canonical form. This points to an underlying issue in LLMs with controlling generated output. Indeed, a hybrid model combining the LLM with a classifier to normalize its output substantially outperforms both initial models.
http://w3id.org/mlsea/pwc/scientificWork/Ad%20Recommendation%20in%20a%20Collapsed%20and%20Entangled%20World                                                                                  Ad Recommendation in a Collapsed and Entangled World                                                                                  In this paper, we present an industry ad recommendation system, paying attention to the challenges and practices of learning appropriate representations. Our study begins by showcasing our approaches to preserving priors when encoding features of diverse types into embedding representations. Specifically, we address sequence features, numeric features, pre-trained embedding features, as well as sparse ID features. Moreover, we delve into two pivotal challenges associated with feature representation: the dimensional collapse of embeddings and the interest entanglement across various tasks or scenarios. Subsequently, we propose several practical approaches to effectively tackle these two challenges. We then explore several training techniques to facilitate model optimization, reduce bias, and enhance exploration. Furthermore, we introduce three analysis tools that enable us to comprehensively study feature correlation, dimensional collapse, and interest entanglement. This work builds upon the continuous efforts of Tencent's ads recommendation team in the last decade. It not only summarizes general design principles but also presents a series of off-the-shelf solutions and analysis tools. The reported performance is based on our online advertising platform, which handles hundreds of billions of requests daily, serving millions of ads to billions of users.
http://w3id.org/mlsea/pwc/scientificWork/Ada-NAV%3A%20Adaptive%20Trajectory%20Length-Based%20Sample%20Efficient%20Policy%20Learning%20for%20Robotic%20Navigation                                                                                  Ada-NAV: Adaptive Trajectory Length-Based Sample Efficient Policy Learning for Robotic Navigation                                                                                  Trajectory length stands as a crucial hyperparameter within reinforcement learning (RL) algorithms, significantly contributing to the sample inefficiency in robotics applications. Motivated by the pivotal role trajectory length plays in the training process, we introduce Ada-NAV, a novel adaptive trajectory length scheme designed to enhance the training sample efficiency of RL algorithms in robotic navigation tasks. Unlike traditional approaches that treat trajectory length as a fixed hyperparameter, we propose to dynamically adjust it based on the entropy of the underlying navigation policy. Interestingly, Ada-NAV can be applied to both existing on-policy and off-policy RL methods, which we demonstrate by empirically validating its efficacy on three popular RL methods: REINFORCE, Proximal Policy Optimization (PPO), and Soft Actor-Critic (SAC). We demonstrate through simulated and real-world robotic experiments that Ada-NAV outperforms conventional methods that employ constant or randomly sampled trajectory lengths. Specifically, for a fixed sample budget, Ada-NAV achieves an 18 % increase in navigation success rate, a 20-38 % reduction in navigation path length, and a 9.32 % decrease in elevation costs. Furthermore, we showcase the versatility of Ada-NAV by integrating it with the Clearpath Husky robot, illustrating its applicability in complex outdoor environments.
http://w3id.org/mlsea/pwc/scientificWork/AdaBatchGrad%3A%20Combining%20Adaptive%20Batch%20Size%20and%20Adaptive%20Step%20Size                                                                                  AdaBatchGrad: Combining Adaptive Batch Size and Adaptive Step Size                                                                                  This paper presents a novel adaptation of the Stochastic Gradient Descent (SGD), termed AdaBatchGrad. This modification seamlessly integrates an adaptive step size with an adjustable batch size. An increase in batch size and a decrease in step size are well-known techniques to tighten the area of convergence of SGD and decrease its variance. A range of studies by R. Byrd and J. Nocedal introduced various testing techniques to assess the quality of mini-batch gradient approximations and choose the appropriate batch sizes at every step. Methods that utilized exact tests were observed to converge within $O(LR^2/ varepsilon)$ iterations. Conversely, inexact test implementations sometimes resulted in non-convergence and erratic performance. To address these challenges, AdaBatchGrad incorporates both adaptive batch and step sizes, enhancing the method's robustness and stability. For exact tests, our approach converges in $O(LR^2/ varepsilon)$ iterations, analogous to standard gradient descent. For inexact tests, it achieves convergence in $O( max lbrace LR^2/ varepsilon, sigma^2 R^2/ varepsilon^2 rbrace )$ iterations. This makes AdaBatchGrad markedly more robust and computationally efficient relative to prevailing methods. To substantiate the efficacy of our method, we experimentally show, how the introduction of adaptive step size and adaptive batch size gradually improves the performance of regular SGD. The results imply that AdaBatchGrad surpasses alternative methods, especially when applied to inexact tests.
http://w3id.org/mlsea/pwc/scientificWork/AdaFed%3A%20Fair%20Federated%20Learning%20via%20Adaptive%20Common%20Descent%20Direction                                                                                  AdaFed: Fair Federated Learning via Adaptive Common Descent Direction                                                                                  Federated learning (FL) is a promising technology via which some edge devices/clients collaboratively train a machine learning model orchestrated by a server. Learning an unfair model is known as a critical problem in federated learning, where the trained model may unfairly advantage or disadvantage some of the devices. To tackle this problem, in this work, we propose AdaFed. The goal of AdaFed is to find an updating direction for the server along which (i) all the clients' loss functions are decreasing; and (ii) more importantly, the loss functions for the clients with larger values decrease with a higher rate. AdaFed adaptively tunes this common direction based on the values of local gradients and loss functions. We validate the effectiveness of AdaFed on a suite of federated datasets, and demonstrate that AdaFed outperforms state-of-the-art fair FL methods.
http://w3id.org/mlsea/pwc/scientificWork/AdaIR%3A%20Adaptive%20All-in-One%20Image%20Restoration%20via%20Frequency%20Mining%20and%20Modulation                                                                                  AdaIR: Adaptive All-in-One Image Restoration via Frequency Mining and Modulation                                                                                  In the image acquisition process, various forms of degradation, including noise, haze, and rain, are frequently introduced. These degradations typically arise from the inherent limitations of cameras or unfavorable ambient conditions. To recover clean images from degraded versions, numerous specialized restoration methods have been developed, each targeting a specific type of degradation. Recently, all-in-one algorithms have garnered significant attention by addressing different types of degradations within a single model without requiring prior information of the input degradation type. However, these methods purely operate in the spatial domain and do not delve into the distinct frequency variations inherent to different degradation types. To address this gap, we propose an adaptive all-in-one image restoration network based on frequency mining and modulation. Our approach is motivated by the observation that different degradation types impact the image content on different frequency subbands, thereby requiring different treatments for each restoration task. Specifically, we first mine low- and high-frequency information from the input features, guided by the adaptively decoupled spectra of the degraded image. The extracted features are then modulated by a bidirectional operator to facilitate interactions between different frequency components. Finally, the modulated features are merged into the original input for a progressively guided restoration. With this approach, the model achieves adaptive reconstruction by accentuating the informative frequency subbands according to different input degradations. Extensive experiments demonstrate that the proposed method achieves state-of-the-art performance on different image restoration tasks, including denoising, dehazing, deraining, motion deblurring, and low-light image enhancement. Our code is available at https://github.com/c-yn/AdaIR.
http://w3id.org/mlsea/pwc/scientificWork/AdaNovo%3A%20Adaptive%20emph%7BDe%20Novo%7D%20Peptide%20Sequencing%20with%20Conditional%20Mutual%20Information                                                                                  AdaNovo: Adaptive emph{De Novo} Peptide Sequencing with Conditional Mutual Information                                                                                  Tandem mass spectrometry has played a pivotal role in advancing proteomics, enabling the analysis of protein composition in biological samples. Despite the development of various deep learning methods for identifying amino acid sequences (peptides) responsible for observed spectra, challenges persist in emph{de novo} peptide sequencing. Firstly, prior methods struggle to identify amino acids with post-translational modifications (PTMs) due to their lower frequency in training data compared to canonical amino acids, further resulting in decreased peptide-level identification precision. Secondly, diverse types of noise and missing peaks in mass spectra reduce the reliability of training data (peptide-spectrum matches, PSMs). To address these challenges, we propose AdaNovo, a novel framework that calculates conditional mutual information (CMI) between the spectrum and each amino acid/peptide, using CMI for adaptive model training. Extensive experiments demonstrate AdaNovo's state-of-the-art performance on a 9-species benchmark, where the peptides in the training set are almost completely disjoint from the peptides of the test sets. Moreover, AdaNovo excels in identifying amino acids with PTMs and exhibits robustness against data noise. The supplementary materials contain the official code.
http://w3id.org/mlsea/pwc/scientificWork/Adapted%20Large%20Language%20Models%20Can%20Outperform%20Medical%20Experts%20in%20Clinical%20Text%20Summarization                                                                                  Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization                                                                                  Analyzing vast textual data and summarizing key information from electronic health records imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown promise in natural language processing (NLP), their effectiveness on a diverse range of clinical summarization tasks remains unproven. In this study, we apply adaptation methods to eight LLMs, spanning four distinct clinical summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Quantitative assessments with syntactic, semantic, and conceptual NLP metrics reveal trade-offs between models and adaptation methods. A clinical reader study with ten physicians evaluates summary completeness, correctness, and conciseness; in a majority of cases, summaries from our best adapted LLMs are either equivalent (45%) or superior (36%) compared to summaries from medical experts. The ensuing safety analysis highlights challenges faced by both LLMs and medical experts, as we connect errors to potential medical harm and categorize types of fabricated information. Our research provides evidence of LLMs outperforming medical experts in clinical text summarization across multiple tasks. This suggests that integrating LLMs into clinical workflows could alleviate documentation burden, allowing clinicians to focus more on patient care.
http://w3id.org/mlsea/pwc/scientificWork/Adapting%20LLM%20Agents%20with%20Universal%20Feedback%20in%20Communication                                                                                  Adapting LLM Agents with Universal Feedback in Communication                                                                                  Recent advances in large language models (LLMs) have demonstrated potential for LLM agents. To facilitate the training for these agents with both linguistic feedback and non-linguistic reward signals, we introduce Learning through Communication (LTC). We design a universal buffer to store all the feedback, and an iterative pipeline to enable an LLM agent to explore and update its policy in an given environment. To optimize agent interactions for task-specific learning with our universal buffer and pipeline, we introduce diverse communication patterns tailored for both single-agent and multi-agent environments. We evaluate the efficacy of our LTC approach on four diverse datasets: ALFWorld (single-agent), HotpotQA (multi-agent collaboration), Chameleon (multi-agent competition), and GSM8k (multi-agent teacher-student). On these data sets, LTC outperforms the supervised instruction fine-tuning baselines by 3.6% to 12%. These results highlight the versatility and efficiency of LTC in facilitating online adaptation for LLM agents.
http://w3id.org/mlsea/pwc/scientificWork/Adapting%20Learned%20Image%20Codecs%20to%20Screen%20Content%20via%20Adjustable%20Transformations                                                                                  Adapting Learned Image Codecs to Screen Content via Adjustable Transformations                                                                                  As learned image codecs (LICs) become more prevalent, their low coding efficiency for out-of-distribution data becomes a bottleneck for some applications. To improve the performance of LICs for screen content (SC) images without breaking backwards compatibility, we propose to introduce parameterized and invertible linear transformations into the coding pipeline without changing the underlying baseline codec's operation flow. We design two neural networks to act as prefilters and postfilters in our setup to increase the coding efficiency and help with the recovery from coding artifacts. Our end-to-end trained solution achieves up to 10% bitrate savings on SC compression compared to the baseline LICs while introducing only 1% extra parameters.
http://w3id.org/mlsea/pwc/scientificWork/Adapting%20tree-based%20multiple%20imputation%20methods%20for%20multi-level%20data%3F%20A%20simulation%20study                                                                                  Adapting tree-based multiple imputation methods for multi-level data? A simulation study                                                                                  This simulation study evaluates the effectiveness of multiple imputation (MI) techniques for multilevel data. It compares the performance of traditional Multiple Imputation by Chained Equations (MICE) with tree-based methods such as Chained Random Forests with Predictive Mean Matching and Extreme Gradient Boosting. Adapted versions that include dummy variables for cluster membership are also included for the tree-based methods. Methods are evaluated for coefficient estimation bias, statistical power, and type I error rates on simulated hierarchical data with different cluster sizes (25 and 50) and levels of missingness (10 % and 50 %). Coefficients are estimated using random intercept and random slope models. The results show that while MICE is preferred for accurate rejection rates, Extreme Gradient Boosting is advantageous for reducing bias. Furthermore, the study finds that bias levels are similar across different cluster sizes, but rejection rates tend to be less favorable with fewer clusters (lower power, higher type I error). In addition, the inclusion of cluster dummies in tree-based methods improves estimation for Level 1 variables, but is less effective for Level 2 variables. When data become too complex and MICE is too slow, extreme gradient boosting is a good alternative for hierarchical data. Keywords: Multiple imputation; multi-level data; MICE; missRanger; mixgb
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Affinity-Based%20Generalization%20For%20MRI%20Imaging%20Segmentation%20Across%20Resource-Limited%20Settings                                                                                  Adaptive Affinity-Based Generalization For MRI Imaging Segmentation Across Resource-Limited Settings                                                                                  The joint utilization of diverse data sources for medical imaging segmentation has emerged as a crucial area of research, aiming to address challenges such as data heterogeneity, domain shift, and data quality discrepancies. Integrating information from multiple data domains has shown promise in improving model generalizability and adaptability. However, this approach often demands substantial computational resources, hindering its practicality. In response, knowledge distillation (KD) has garnered attention as a solution. KD involves training light-weight models to emulate the behavior of more resource-intensive models, thereby mitigating the computational burden while maintaining performance. This paper addresses the pressing need to develop a lightweight and generalizable model for medical imaging segmentation that can effectively handle data integration challenges. Our proposed approach introduces a novel relation-based knowledge framework by seamlessly combining adaptive affinity-based and kernel-based distillation through a gram matrix that can capture the style representation across features. This methodology empowers the student model to accurately replicate the feature representations of the teacher model, facilitating robust performance even in the face of domain shift and data heterogeneity. To validate our innovative approach, we conducted experiments on publicly available multi-source prostate MRI data. The results demonstrate a significant enhancement in segmentation performance using lightweight networks. Notably, our method achieves this improvement while reducing both inference time and storage usage, rendering it a practical and efficient solution for real-time medical imaging segmentation.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Calibration%3A%20A%20Unified%20Conversion%20Framework%20of%20Spiking%20Neural%20Networks                                                                                  Adaptive Calibration: A Unified Conversion Framework of Spiking Neural Networks                                                                                  Spiking Neural Networks (SNNs) have emerged as a promising energy-efficient alternative to traditional Artificial Neural Networks (ANNs). Despite this, bridging the performance gap with ANNs in practical scenarios remains a significant challenge. This paper focuses on addressing the dual objectives of enhancing the performance and efficiency of SNNs through the established SNN Calibration conversion framework. Inspired by the biological nervous system, we propose a novel Adaptive-Firing Neuron Model (AdaFire) that dynamically adjusts firing patterns across different layers, substantially reducing conversion errors within limited timesteps. Moreover, to meet our efficiency objectives, we propose two novel strategies: an Sensitivity Spike Compression (SSC) technique and an Input-aware Adaptive Timesteps (IAT) technique. These techniques synergistically reduce both energy consumption and latency during the conversion process, thereby enhancing the overall efficiency of SNNs. Extensive experiments demonstrate our approach outperforms state-of-the-art SNNs methods, showcasing superior performance and efficiency in 2D, 3D, and event-driven classification, as well as object detection and segmentation tasks.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Coded%20Federated%20Learning%3A%20Privacy%20Preservation%20and%20Straggler%20Mitigation                                                                                  Adaptive Coded Federated Learning: Privacy Preservation and Straggler Mitigation                                                                                  In this article, we address the problem of federated learning in the presence of stragglers. For this problem, a coded federated learning framework has been proposed, where the central server aggregates gradients received from the non-stragglers and gradient computed from a privacy-preservation global coded dataset to mitigate the negative impact of the stragglers. However, when aggregating these gradients, fixed weights are consistently applied across iterations, neglecting the generation process of the global coded dataset and the dynamic nature of the trained model over iterations. This oversight may result in diminished learning performance. To overcome this drawback, we propose a new method named adaptive coded federated learning (ACFL). In ACFL, before the training, each device uploads a coded local dataset with additive noise to the central server to generate a global coded dataset under privacy preservation requirements. During each iteration of the training, the central server aggregates the gradients received from the non-stragglers and the gradient computed from the global coded dataset, where an adaptive policy for varying the aggregation weights is designed. Under this policy, we optimize the performance in terms of privacy and learning, where the learning performance is analyzed through convergence analysis and the privacy performance is characterized via mutual information differential privacy. Finally, we perform simulations to demonstrate the superiority of ACFL compared with the non-adaptive methods.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Dual%20Covariance%20Steering%20with%20Active%20Parameter%20Estimation                                                                                  Adaptive Dual Covariance Steering with Active Parameter Estimation                                                                                  This work examines the optimal covariance steering problem for systems subject to unknown parameters that enter multiplicatively with the state and control, in addition to additive disturbances. In contrast to existing works, the unknown parameters are modeled as random variables and are estimated online. This work proposes the utilization of recursive least squares estimation for efficient parameter identification. A dual control problem is formulated in which the effect of the planned control policy on the parameter estimates is modeled and optimized for. The parameter estimates are then used to modify the pre-computed control policy online in an adaptive control fashion. Finally, the proposed approach is demonstrated in a vehicle control example with closed-loop parameter identification.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Experiment%20Design%20with%20Synthetic%20Controls                                                                                  Adaptive Experiment Design with Synthetic Controls                                                                                  Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations - especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through experiments.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Feature%20Fusion%20Neural%20Network%20for%20Glaucoma%20Segmentation%20on%20Unseen%20Fundus%20Images                                                                                  Adaptive Feature Fusion Neural Network for Glaucoma Segmentation on Unseen Fundus Images                                                                                  Fundus image segmentation on unseen domains is challenging, especially for the over-parameterized deep models trained on the small medical datasets. To address this challenge, we propose a method named Adaptive Feature-fusion Neural Network (AFNN) for glaucoma segmentation on unseen domains, which mainly consists of three modules: domain adaptor, feature-fusion network, and self-supervised multi-task learning. Specifically, the domain adaptor helps the pretrained-model fast adapt from other image domains to the medical fundus image domain. Feature-fusion network and self-supervised multi-task learning for the encoder and decoder are introduced to improve the domain generalization ability. In addition, we also design the weighted-dice-loss to improve model performance on complex optic-cup segmentation tasks. Our proposed method achieves a competitive performance over existing fundus segmentation methods on four public glaucoma datasets.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Federated%20Minimax%20Optimization%20with%20Lower%20Complexities                                                                                  Adaptive Federated Minimax Optimization with Lower Complexities                                                                                  Federated learning is a popular distributed and privacy-preserving learning paradigm in machine learning. Recently, some federated learning algorithms have been proposed to solve the distributed minimax problems. However, these federated minimax algorithms still suffer from high gradient or communication complexity. Meanwhile, few algorithm focuses on using adaptive learning rate to accelerate these algorithms. To fill this gap, in the paper, we study a class of nonconvex minimax optimization, and propose an efficient adaptive federated minimax optimization algorithm (i.e., AdaFGDA) to solve these distributed minimax problems. Specifically, our AdaFGDA builds on the momentum-based variance reduced and local-SGD techniques, and it can flexibly incorporate various adaptive learning rates by using the unified adaptive matrices. Theoretically, we provide a solid convergence analysis framework for our AdaFGDA algorithm under non-i.i.d. setting. Moreover, we prove our AdaFGDA algorithm obtains a lower gradient (i.e., stochastic first-order oracle, SFO) complexity of $ tilde{O}( epsilon^{-3})$ with lower communication complexity of $ tilde{O}( epsilon^{-2})$ in finding $ epsilon$-stationary point of the nonconvex minimax problems. Experimentally, we conduct some experiments on the deep AUC maximization and robust neural network training tasks to verify efficiency of our algorithms.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Hypergraph%20Network%20for%20Trust%20Prediction                                                                                  Adaptive Hypergraph Network for Trust Prediction                                                                                  Trust plays an essential role in an individual's decision-making. Traditional trust prediction models rely on pairwise correlations to infer potential relationships between users. However, in the real world, interactions between users are usually complicated rather than pairwise only. Hypergraphs offer a flexible approach to modeling these complex high-order correlations (not just pairwise connections), since hypergraphs can leverage hyperedeges to link more than two nodes. However, most hypergraph-based methods are generic and cannot be well applied to the trust prediction task. In this paper, we propose an Adaptive Hypergraph Network for Trust Prediction (AHNTP), a novel approach that improves trust prediction accuracy by using higher-order correlations. AHNTP utilizes Motif-based PageRank to capture high-order social influence information. In addition, it constructs hypergroups from both node-level and structure-level attributes to incorporate complex correlation information. Furthermore, AHNTP leverages adaptive hypergraph Graph Convolutional Network (GCN) layers and multilayer perceptrons (MLPs) to generate comprehensive user embeddings, facilitating trust relationship prediction. To enhance model generalization and robustness, we introduce a novel supervised contrastive learning loss for optimization. Extensive experiments demonstrate the superiority of our model over the state-of-the-art approaches in terms of trust prediction accuracy. The source code of this work can be accessed via https://github.com/Sherry-XU1995/AHNTP.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Hyperparameter%20Optimization%20for%20Continual%20Learning%20Scenarios                                                                                  Adaptive Hyperparameter Optimization for Continual Learning Scenarios                                                                                  Hyperparameter selection in continual learning scenarios is a challenging and underexplored aspect, especially in practical non-stationary environments. Traditional approaches, such as grid searches with held-out validation data from all tasks, are unrealistic for building accurate lifelong learning systems. This paper aims to explore the role of hyperparameter selection in continual learning and the necessity of continually and automatically tuning them according to the complexity of the task at hand. Hence, we propose leveraging the nature of sequence task learning to improve Hyperparameter Optimization efficiency. By using the functional analysis of variance-based techniques, we identify the most crucial hyperparameters that have an impact on performance. We demonstrate empirically that this approach, agnostic to continual scenarios and strategies, allows us to speed up hyperparameters optimization continually across tasks and exhibit robustness even in the face of varying sequential task orders. We believe that our findings can contribute to the advancement of continual learning methodologies towards more efficient, robust and adaptable models for real-world applications.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Kalman%20Filtering%20Developed%20from%20Recursive%20Least%20Squares%20Forgetting%20Algorithms                                                                                  Adaptive Kalman Filtering Developed from Recursive Least Squares Forgetting Algorithms                                                                                  Recursive least squares (RLS) is derived as the recursive minimizer of the least-squares cost function. Moreover, it is well known that RLS is a special case of the Kalman filter. This work presents the Kalman filter least squares (KFLS) cost function, whose recursive minimizer gives the Kalman filter. KFLS is an extension of generalized forgetting recursive least squares (GF-RLS), a general framework which contains various extensions of RLS from the literature as special cases. This then implies that extensions of RLS are also special cases of the Kalman filter. Motivated by this connection, we propose an algorithm that combines extensions of RLS with the Kalman filter, resulting in a new class of adaptive Kalman filters. A numerical example shows that one such adaptive Kalman filter provides improved state estimation for a mass-spring-damper with intermittent, unmodeled collisions. This example suggests that such adaptive Kalman filtering may provide potential benefits for systems with non-classical disturbances.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Learning%20for%20Multi-view%20Stereo%20Reconstruction                                                                                  Adaptive Learning for Multi-view Stereo Reconstruction                                                                                  Deep learning has recently demonstrated its excellent performance on the task of multi-view stereo (MVS). However, loss functions applied for deep MVS are rarely studied. In this paper, we first analyze existing loss functions' properties for deep depth based MVS approaches. Regression based loss leads to inaccurate continuous results by computing mathematical expectation, while classification based loss outputs discretized depth values. To this end, we then propose a novel loss function, named adaptive Wasserstein loss, which is able to narrow down the difference between the true and predicted probability distributions of depth. Besides, a simple but effective offset module is introduced to better achieve sub-pixel prediction accuracy. Extensive experiments on different benchmarks, including DTU, Tanks and Temples and BlendedMVS, show that the proposed method with the adaptive Wasserstein loss and the offset module achieves state-of-the-art performance.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Parameter%20Estimation%20under%20Finite%20Excitation                                                                                  Adaptive Parameter Estimation under Finite Excitation                                                                                  Although persistent excitation is often acknowledged as a sufficient condition to exponentially converge in the field of adaptive parameter estimation, it must be noted that in practical applications this may be unguaranteed. Recently, more attention has turned to another relaxed condition, i.e., finite excitation. In this paper, for a class of nominal nonlinear systems with unknown constant parameters, a novel method that combines the Newton algorithm and the time-varying factor is proposed, which can achieve exponential convergence under finite excitation. First, by introducing pre-filtering, the nominal system is transformed to a linear parameterized form. Then the detailed mathematical derivation is outlined from an estimation error accumulated cost function. And it is given that the theoretical analysis of the proposed method in stability and robustness. Finally, comparative numerical simulations are given to illustrate the superiority of the proposed method.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Query%20Prompting%20for%20Multi-Domain%20Landmark%20Detection                                                                                  Adaptive Query Prompting for Multi-Domain Landmark Detection                                                                                  Medical landmark detection is crucial in various medical imaging modalities and procedures. Although deep learning-based methods have achieve promising performance, they are mostly designed for specific anatomical regions or tasks. In this work, we propose a universal model for multi-domain landmark detection by leveraging transformer architecture and developing a prompting component, named as Adaptive Query Prompting (AQP). Instead of embedding additional modules in the backbone network, we design a separate module to generate prompts that can be effectively extended to any other transformer network. In our proposed AQP, prompts are learnable parameters maintained in a memory space called prompt pool. The central idea is to keep the backbone frozen and then optimize prompts to instruct the model inference process. Furthermore, we employ a lightweight decoder to decode landmarks from the extracted features, namely Light-MLD. Thanks to the lightweight nature of the decoder and AQP, we can handle multiple datasets by sharing the backbone encoder and then only perform partial parameter tuning without incurring much additional cost. It has the potential to be extended to more landmark detection tasks. We conduct experiments on three widely used X-ray datasets for different medical landmark detection tasks. Our proposed Light-MLD coupled with AQP achieves SOTA performance on many metrics even without the use of elaborate structural designs or complex frameworks.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Reconstruction%20of%20Nonlinear%20Systems%20States%20via%20DREM%20with%20Perturbation%20Annihilation                                                                                  Adaptive Reconstruction of Nonlinear Systems States via DREM with Perturbation Annihilation                                                                                  A new adaptive observer is proposed for a certain class of nonlinear systems with bounded unknown input and parametric uncertainty. Unlike most existing solutions, the proposed approach ensures asymptotic convergence of the unknown parameters, state and perturbation estimates to an arbitrarily small neighborhood of the equilibrium point. The solution is based on the novel augmentation of a high-gain observer with the dynamic regressor extension and mixing (DREM) procedure enhanced with a perturbation annihilation algorithm. The aforementioned properties of the proposed solution are verified via numerical experiments.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Self-training%20Framework%20for%20Fine-grained%20Scene%20Graph%20Generation                                                                                  Adaptive Self-training Framework for Fine-grained Scene Graph Generation                                                                                  Scene graph generation (SGG) models have suffered from inherent problems regarding the benchmark datasets such as the long-tailed predicate distribution and missing annotation problems. In this work, we aim to alleviate the long-tailed problem of SGG by utilizing unannotated triplets. To this end, we introduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels for unannotated triplets based on which the SGG models are trained. While there has been significant progress in self-training for image recognition, designing a self-training framework for the SGG task is more challenging due to its inherent nature such as the semantic ambiguity and the long-tailed distribution of predicate classes. Hence, we propose a novel pseudo-labeling technique for SGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is a model-agnostic framework that can be applied to any existing SGG models. Furthermore, we devise a graph structure learner (GSL) that is beneficial when adopting our proposed self-training framework to the state-of-the-art message-passing neural network (MPNN)-based SGG models. Our extensive experiments verify the effectiveness of ST-SGG on various SGG models, particularly in enhancing the performance on fine-grained predicate classes.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Smooth%20Control%20via%20Nonsingular%20Fast%20Terminal%20Sliding%20Mode%20for%20Distributed%20Space%20Telescope%20Demonstration%20Mission%20by%20CubeSat%20Formation%20Flying                                                                                  Adaptive Smooth Control via Nonsingular Fast Terminal Sliding Mode for Distributed Space Telescope Demonstration Mission by CubeSat Formation Flying                                                                                  This paper investigates the efficiency of nonsingular fast terminal sliding mode and adaptive smooth control method for the distributed space telescope demonstration mission. The distributed space telescope has a flexible focal length that corresponds to the relative position of the formation flying concept. The precise formation flying technology by CubeSats enhances the utility of distributed space systems with low costs. The propulsion systems for CubeSats usually have restricted degrees of freedom. Since the scientific mission requires continuous orbit control, the attitude and orbit control system mutually affect the control performance. The nonsingular fast terminal sliding mode has the advantage of a fast convergence rate and is able to improve the control performance. The adaptive smooth controller designed for the SISO system is expanded and applied to the attitude and orbit control system. The simulation results verify the efficiency of the adaptive smooth controller based on the nonsingular fast terminal sliding mode.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Split%20Learning%20over%20Energy-Constrained%20Wireless%20Edge%20Networks                                                                                  Adaptive Split Learning over Energy-Constrained Wireless Edge Networks                                                                                  Split learning (SL) is a promising approach for training artificial intelligence (AI) models, in which devices collaborate with a server to train an AI model in a distributed manner, based on a same fixed split point. However, due to the device heterogeneity and variation of channel conditions, this way is not optimal in training delay and energy consumption. In this paper, we design an adaptive split learning (ASL) scheme which can dynamically select split points for devices and allocate computing resource for the server in wireless edge networks. We formulate an optimization problem to minimize the average training latency subject to long-term energy consumption constraint. The difficulties in solving this problem are the lack of future information and mixed integer programming (MIP). To solve it, we propose an online algorithm leveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP problem only with the current information. Then, a two-layer optimization method is proposed to solve the MIP problem. Extensive simulation results demonstrate that the ASL scheme can reduce the average training delay and energy consumption by 53.7% and 22.1%, respectively, as compared to the existing SL schemes.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Target%20Detection%20for%20FDA-MIMO%20Radar%20with%20Training%20Data%20in%20Gaussian%20noise                                                                                  Adaptive Target Detection for FDA-MIMO Radar with Training Data in Gaussian noise                                                                                  This paper addresses the problem of detecting a moving target embedded in Gaussian noise with an unknown covariance matrix for frequency diverse array multiple-input multiple-output (FDA-MIMO) radar. To end it, assume that obtaining a set of training data is available. Moreover, we propose three adaptive detectors in accordance with the one-step generalized likelihood ratio test (GLRT), two-step GLRT, and Rao criteria, namely OGLRT, TGLRT, and Rao. The LH adaptive matched filter (LHAMF) detector is also introduced when decomposing the Rao test. Next, all provided detectors have constant false alarm rate (CFAR) properties against the covariance matrix. Besides, the closed-form expressions for false alarm probability (PFA) and detection probability (PD) are derived. Finally, this paper substantiates the correctness of the aforementioned algorithms through numerical simulations.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20behavior%20with%20stable%20synapses                                                                                  Adaptive behavior with stable synapses                                                                                  Behavioral changes in animals and humans, as a consequence of an error or a verbal instruction, can be extremely rapid. Improvement in behavioral performances are usually associated in machine learning and reinforcement learning to synaptic plasticity, and, in general, to changes and optimization of network parameters. However, such rapid changes are not coherent with the timescales of synaptic plasticity, suggesting that the mechanism responsible for that could be a dynamical network reconfiguration. In the last few years, similar capabilities have been observed in transformers, foundational architecture in the field of machine learning that are widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without the need for significant changes to their underlying parameters. Building upon the notion of something unique within transformers enabling the emergence of this property, we claim that it could also be supported by input segregation and dendritic amplification, features extensively observed in biological networks. We propose an architecture composed of gain-modulated recurrent networks that excels at in-context learning, showing abilities inaccessible to standard networks. We argue that such a framework can describe the psychometry of context-dependent tasks on humans and other species, solving the incoherence of plasticity timescales. When the context is changed, the network is dynamically reconfigured, and the predicted output undergoes dynamic updates until it aligns with the information embedded in the context.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20integration%20of%20history%20variables%20in%20constrained%20mixture%20models%20for%20organ-scale%20growth%20and%20remodeling                                                                                  Adaptive integration of history variables in constrained mixture models for organ-scale growth and remodeling                                                                                  In the last decades, many computational models have been developed to predict soft tissue growth and remodeling (G&R). The constrained mixture theory describes fundamental mechanobiological processes in soft tissue G&R and has been widely adopted in cardiovascular models of G&R. However, even after two decades of work, large organ-scale models are rare, mainly due to high computational costs (model evaluation and memory consumption), especially in long-range simulations. We propose two strategies to adaptively integrate history variables in constrained mixture models to enable large organ-scale simulations of G&R. Both strategies exploit that the influence of deposited tissue on the current mixture decreases over time through degradation. One strategy is independent of external loading, allowing the estimation of the computational resources ahead of the simulation. The other adapts the history snapshots based on the local mechanobiological environment so that the additional integration errors can be controlled and kept negligibly small, even in G&R scenarios with severe perturbations. We analyze the adaptively integrated constrained mixture model on a tissue patch for a parameter study and show the performance under different G&R scenarios. To confirm that adaptive strategies enable large organ-scale examples, we show simulations of different hypertension conditions with a real-world example of a biventricular heart discretized with a finite element mesh. In our example, adaptive integrations sped up simulations by a factor of three and reduced memory requirements to one-sixth. The reduction of the computational costs gets even more pronounced for simulations over longer periods. Adaptive integration of the history variables allows studying more finely resolved models and longer G&R periods while computational costs are drastically reduced and largely constant in time.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20multi-gradient%20methods%20for%20quasiconvex%20vector%20optimization%20and%20applications%20to%20multi-task%20learning                                                                                  Adaptive multi-gradient methods for quasiconvex vector optimization and applications to multi-task learning                                                                                  We present an adaptive step-size method, which does not include line-search techniques, for solving a wide class of nonconvex multiobjective programming problems on an unbounded constraint set. We also prove convergence of a general approach under modest assumptions. More specifically, the convexity criterion might not be satisfied by the objective function. Unlike descent line-search algorithms, it does not require an initial step-size to be determined by a previously determined Lipschitz constant. The process's primary characteristic is its gradual step-size reduction up until a predetermined condition is met. It can be specifically applied to offer an innovative multi-gradient projection method for unbounded constrained optimization issues. Preliminary findings from a few computational examples confirm the accuracy of the strategy. We apply the proposed technique to some multi-task learning experiments to show its efficacy for large-scale challenges.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20operator%20selection%20utilising%20generalised%20experience                                                                                  Adaptive operator selection utilising generalised experience                                                                                  Optimisation problems, particularly combinatorial optimisation problems, are difficult to solve due to their complexity and hardness. Such problems have been successfully solved by evolutionary and swarm intelligence algorithms, especially in binary format. However, the approximation may suffer due to the the issues in balance between exploration and exploitation activities (EvE), which remain as the major challenge in this context. Although the complementary usage of multiple operators is becoming more popular for managing EvE with adaptive operator selection schemes, a bespoke adaptive selection system is still an important topic in research. Reinforcement Learning (RL) has recently been proposed as a way to customise and shape up a highly effective adaptive selection system. However, it is still challenging to handle the problem in terms of scalability. This paper proposes and assesses a RL-based novel approach to help develop a generalised framework for gaining, processing, and utilising the experiences for both the immediate and future use. The experimental results support the proposed approach with a certain level of success.
http://w3id.org/mlsea/pwc/scientificWork/Addressing%20Both%20Statistical%20and%20Causal%20Gender%20Fairness%20in%20NLP%20Models                                                                                  Addressing Both Statistical and Causal Gender Fairness in NLP Models                                                                                  Statistical fairness stipulates equivalent outcomes for every protected group, whereas causal fairness prescribes that a model makes the same prediction for an individual regardless of their protected characteristics. Counterfactual data augmentation (CDA) is effective for reducing bias in NLP models, yet models trained with CDA are often evaluated only on metrics that are closely tied to the causal fairness notion; similarly, sampling-based methods designed to promote statistical fairness are rarely evaluated for causal fairness. In this work, we evaluate both statistical and causal debiasing methods for gender bias in NLP models, and find that while such methods are effective at reducing bias as measured by the targeted metric, they do not necessarily improve results on other bias metrics. We demonstrate that combinations of statistical and causal debiasing techniques are able to reduce bias measured through both types of metrics.
http://w3id.org/mlsea/pwc/scientificWork/Addressing%20Distribution%20Shift%20in%20Time%20Series%20Forecasting%20with%20Instance%20Normalization%20Flows                                                                                  Addressing Distribution Shift in Time Series Forecasting with Instance Normalization Flows                                                                                  Due to non-stationarity of time series, the distribution shift problem largely hinders the performance of time series forecasting. Existing solutions either fail for the shifts beyond simple statistics or the limited compatibility with forecasting models. In this paper, we propose a general decoupled formulation for time series forecasting, with no reliance on fixed statistics and no restriction on forecasting architectures. Then, we make such a formulation formalized into a bi-level optimization problem, to enable the joint learning of the transformation (outer loop) and forecasting (inner loop). Moreover, the special requirements of expressiveness and bi-direction for the transformation motivate us to propose instance normalization flows (IN-Flow), a novel invertible network for time series transformation. Extensive experiments demonstrate our method consistently outperforms state-of-the-art baselines on both synthetic and real-world data.
http://w3id.org/mlsea/pwc/scientificWork/Addressing%20Noise%20and%20Efficiency%20Issues%20in%20Graph-Based%20Machine%20Learning%20Models%20From%20the%20Perspective%20of%20Adversarial%20Attack                                                                                  Addressing Noise and Efficiency Issues in Graph-Based Machine Learning Models From the Perspective of Adversarial Attack                                                                                  Given that no existing graph construction method can generate a perfect graph for a given dataset, graph-based algorithms are invariably affected by the plethora of redundant and erroneous edges present within the constructed graphs. In this paper, we propose treating these noisy edges as adversarial attack and use a spectral adversarial robustness evaluation method to diminish the impact of noisy edges on the performance of graph algorithms. Our method identifies those points that are less vulnerable to noisy edges and leverages only these robust points to perform graph-based algorithms. Our experiments with spectral clustering, one of the most representative and widely utilized graph algorithms, reveal that our methodology not only substantially elevates the precision of the algorithm but also greatly accelerates its computational efficiency by leveraging only a select number of robust data points.
http://w3id.org/mlsea/pwc/scientificWork/Addressing%20the%20Regulatory%20Gap%3A%20Moving%20Towards%20an%20EU%20AI%20Audit%20Ecosystem%20Beyond%20the%20AIA%20by%20Including%20Civil%20Society                                                                                  Addressing the Regulatory Gap: Moving Towards an EU AI Audit Ecosystem Beyond the AIA by Including Civil Society                                                                                  The European legislature has proposed the Digital Services Act (DSA) and Artificial Intelligence Act (AIA) to regulate platforms and Artificial Intelligence (AI) products. We review to what extent third-party audits are part of both laws and to what extent access to models and data is provided. By considering the value of third-party audits and third-party data access in an audit ecosystem, we identify a regulatory gap in that the Artificial Intelligence Act does not provide access to data for researchers and civil society. Our contributions to the literature include: (1) Defining an AI audit ecosystem that incorporates compliance and oversight. (2) Highlighting a regulatory gap within the DSA and AIA regulatory framework, preventing the establishment of an AI audit ecosystem. (3) Emphasizing that third-party audits by research and civil society must be part of that ecosystem and demand that the AIA include data and model access for certain AI products. We call for the DSA to provide NGOs and investigative journalists with data access to platforms by delegated acts and for adaptions and amendments of the AIA to provide third-party audits and data and model access at least for high-risk systems to close the regulatory gap. Regulations modeled after European Union AI regulations should enable data access and third-party audits, fostering an AI audit ecosystem that promotes compliance and oversight mechanisms.
http://w3id.org/mlsea/pwc/scientificWork/Adhesion%20modulates%20cell%20morphology%20and%20migration%20within%20dense%20fibrous%20networks                                                                                  Adhesion modulates cell morphology and migration within dense fibrous networks                                                                                  One of the most fundamental abilities required for the sustainability of complex life forms is active cell migration, since it is essential in diverse processes from morphogenesis to leukocyte chemotaxis in immune response. The movement of a cell is the result of intricate mechanisms, that involve the coordination between mechanical forces, biochemical regulatory pathways and environmental cues. In particular, epithelial cancer cells have to employ mechanical strategies in order to migrate through the tissue's basement membrane and infiltrate the bloodstream during the invasion stage of metastasis. In this work we explore how mechanical interactions such as spatial restriction and adhesion affect migration of a self-propelled droplet in dense fibrous media. We have performed a systematic analysis using a phase-field model and we propose a novel approach to simulate cell migration with dissipative particle dynamics modelling. With this purpose we have measured in our simulation the cell's velocity and quantified its morphology as a function of the fibre density and of its adhesiveness to the matrix fibres. Furthermore, we have compared our results to a previous in vitro migration assay of fibrosarcoma cells in fibrous matrices. The results show good agreement between the two methodologies and experiments in the literature, which indicates that these minimalist descriptions are able to capture the main features of the system. Our results indicate that adhesiveness is critical for cell migration, by modulating cell morphology in crowded environments and by enhancing cell velocity. In addition, our analysis suggests that matrix metalloproteinases (MMPs) play an important role as adhesiveness modulators. We propose that new assays should be carried out to address the role of adhesion and the effect of different MMPs in cell migration under confined conditions.
http://w3id.org/mlsea/pwc/scientificWork/Adjusting%20Interpretable%20Dimensions%20in%20Embedding%20Space%20with%20Human%20Judgments                                                                                  Adjusting Interpretable Dimensions in Embedding Space with Human Judgments                                                                                  Embedding spaces contain interpretable dimensions indicating gender, formality in style, or even object properties. This has been observed multiple times. Such interpretable dimensions are becoming valuable tools in different areas of study, from social science to neuroscience. The standard way to compute these dimensions uses contrasting seed words and computes difference vectors over them. This is simple but does not always work well. We combine seed-based vectors with guidance from human ratings of where words fall along a specific dimension, and evaluate on predicting both object properties like size and danger, and the stylistic properties of formality and complexity. We obtain interpretable dimensions with markedly better performance especially in cases where seed-based dimensions do not work well.
http://w3id.org/mlsea/pwc/scientificWork/AdvGPS%3A%20Adversarial%20GPS%20for%20Multi-Agent%20Perception%20Attack                                                                                  AdvGPS: Adversarial GPS for Multi-Agent Perception Attack                                                                                  The multi-agent perception system collects visual data from sensors located on various agents and leverages their relative poses determined by GPS signals to effectively fuse information, mitigating the limitations of single-agent sensing, such as occlusion. However, the precision of GPS signals can be influenced by a range of factors, including wireless transmission and obstructions like buildings. Given the pivotal role of GPS signals in perception fusion and the potential for various interference, it becomes imperative to investigate whether specific GPS signals can easily mislead the multi-agent perception system. To address this concern, we frame the task as an adversarial attack challenge and introduce textsc{AdvGPS}, a method capable of generating adversarial GPS signals which are also stealthy for individual agents within the system, significantly reducing object detection accuracy. To enhance the success rates of these attacks in a black-box scenario, we introduce three types of statistically sensitive natural discrepancies: appearance-based discrepancy, distribution-based discrepancy, and task-aware discrepancy. Our extensive experiments on the OPV2V dataset demonstrate that these attacks substantially undermine the performance of state-of-the-art methods, showcasing remarkable transferability across different point cloud based 3D detection systems. This alarming revelation underscores the pressing need to address security implications within multi-agent perception systems, thereby underscoring a critical area of research.
http://w3id.org/mlsea/pwc/scientificWork/Advanced%20Large%20Language%20Model%20%28LLM%29-Driven%20Verilog%20Development%3A%20Enhancing%20Power%2C%20Performance%2C%20and%20Area%20Optimization%20in%20Code%20Synthesis                                                                                  Advanced Large Language Model (LLM)-Driven Verilog Development: Enhancing Power, Performance, and Area Optimization in Code Synthesis                                                                                  The increasing use of Advanced Language Models (ALMs) in diverse sectors, particularly due to their impressive capability to generate top-tier content following linguistic instructions, forms the core of this investigation. This study probes into ALMs' deployment in electronic hardware design, with a specific emphasis on the synthesis and enhancement of Verilog programming. We introduce an innovative framework, crafted to assess and amplify ALMs' productivity in this niche. The methodology commences with the initial crafting of Verilog programming via ALMs, succeeded by a distinct dual-stage refinement protocol. The premier stage prioritizes augmenting the code's operational and linguistic precision, while the latter stage is dedicated to aligning the code with Power-Performance-Area (PPA) benchmarks, a pivotal component in proficient hardware design. This bifurcated strategy, merging error remediation with PPA enhancement, has yielded substantial upgrades in the caliber of ALM-created Verilog programming. Our framework achieves an 81.37% rate in linguistic accuracy and 62.0% in operational efficacy in programming synthesis, surpassing current leading-edge techniques, such as 73% in linguistic accuracy and 46% in operational efficacy. These findings illuminate ALMs' aptitude in tackling complex technical domains and signal a positive shift in the mechanization of hardware design operations.
http://w3id.org/mlsea/pwc/scientificWork/Advancements%20in%20Continuous%20Glucose%20Monitoring%3A%20Integrating%20Deep%20Learning%20and%20ECG%20Signal                                                                                  Advancements in Continuous Glucose Monitoring: Integrating Deep Learning and ECG Signal                                                                                  This paper presents a novel approach to noninvasive hyperglycemia monitoring utilizing electrocardiograms (ECG) from an extensive database comprising 1119 subjects. Previous research on hyperglycemia or glucose detection using ECG has been constrained by challenges related to generalization and scalability, primarily due to using all subjects' ECG in training without considering unseen subjects as a critical factor for developing methods with effective generalization. We designed a deep neural network model capable of identifying significant features across various spatial locations and examining the interdependencies among different features within each convolutional layer. To expedite processing speed, we segment the ECG of each user to isolate one heartbeat or one cycle of the ECG. Our model was trained using data from 727 subjects, while 168 were used for validation. The testing phase involved 224 unseen subjects, with a dataset consisting of 9,000 segments. The result indicates that the proposed algorithm effectively detects hyperglycemia with a 91.60% area under the curve (AUC), 81.05% sensitivity, and 85.54% specificity.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20AI%20with%20Integrity%3A%20Ethical%20Challenges%20and%20Solutions%20in%20Neural%20Machine%20Translation                                                                                  Advancing AI with Integrity: Ethical Challenges and Solutions in Neural Machine Translation                                                                                  This paper addresses the ethical challenges of Artificial Intelligence in Neural Machine Translation (NMT) systems, emphasizing the imperative for developers to ensure fairness and cultural sensitivity. We investigate the ethical competence of AI models in NMT, examining the Ethical considerations at each stage of NMT development, including data handling, privacy, data ownership, and consent. We identify and address ethical issues through empirical studies. These include employing Transformer models for Luganda-English translations and enhancing efficiency with sentence mini-batching. And complementary studies that refine data labeling techniques and fine-tune BERT and Longformer models for analyzing Luganda and English social media content. Our second approach is a literature review from databases such as Google Scholar and platforms like GitHub. Additionally, the paper probes the distribution of responsibility between AI systems and humans, underscoring the essential role of human oversight in upholding NMT ethical standards. Incorporating a biblical perspective, we discuss the societal impact of NMT and the broader ethical responsibilities of developers, positing them as stewards accountable for the societal repercussions of their creations.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Additive%20Manufacturing%20through%20Deep%20Learning%3A%20A%20Comprehensive%20Review%20of%20Current%20Progress%20and%20Future%20Challenges                                                                                  Advancing Additive Manufacturing through Deep Learning: A Comprehensive Review of Current Progress and Future Challenges                                                                                  Additive manufacturing (AM) has already proved itself to be the potential alternative to widely-used subtractive manufacturing due to its extraordinary capacity of manufacturing highly customized products with minimum material wastage. Nevertheless, it is still not being considered as the primary choice for the industry due to some of its major inherent challenges, including complex and dynamic process interactions, which are sometimes difficult to fully understand even with traditional machine learning because of the involvement of high-dimensional data such as images, point clouds, and voxels. However, the recent emergence of deep learning (DL) is showing great promise in overcoming many of these challenges as DL can automatically capture complex relationships from high-dimensional data without hand-crafted feature extraction. Therefore, the volume of research in the intersection of AM and DL is exponentially growing each year which makes it difficult for the researchers to keep track of the trend and future potential directions. Furthermore, to the best of our knowledge, there is no comprehensive review paper in this research track summarizing the recent studies. Therefore, this paper reviews the recent studies that apply DL for making the AM process better with a high-level summary of their contributions and limitations. Finally, it summarizes the current challenges and recommends some of the promising opportunities in this domain for further investigation with a special focus on generalizing DL models for wide-range of geometry types, managing uncertainties both in AM data and DL models, overcoming limited and noisy AM data issues by incorporating generative models, and unveiling the potential of interpretable DL for AM.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Building%20Energy%20Modeling%20with%20Large%20Language%20Models%3A%20Exploration%20and%20Case%20Studies                                                                                  Advancing Building Energy Modeling with Large Language Models: Exploration and Case Studies                                                                                  The rapid progression in artificial intelligence has facilitated the emergence of large language models like ChatGPT, offering potential applications extending into specialized engineering modeling, especially physics-based building energy modeling. This paper investigates the innovative integration of large language models with building energy modeling software, focusing specifically on the fusion of ChatGPT with EnergyPlus. A literature review is first conducted to reveal a growing trend of incorporating of large language models in engineering modeling, albeit limited research on their application in building energy modeling. We underscore the potential of large language models in addressing building energy modeling challenges and outline potential applications including 1) simulation input generation, 2) simulation output analysis and visualization, 3) conducting error analysis, 4) co-simulation, 5) simulation knowledge extraction and training, and 6) simulation optimization. Three case studies reveal the transformative potential of large language models in automating and optimizing building energy modeling tasks, underscoring the pivotal role of artificial intelligence in advancing sustainable building practices and energy efficiency. The case studies demonstrate that selecting the right large language model techniques is essential to enhance performance and reduce engineering efforts. Besides direct use of large language models, three specific techniques were utilized: 1) prompt engineering, 2) retrieval-augmented generation, and 3) multi-agent large language models. The findings advocate a multidisciplinary approach in future artificial intelligence research, with implications extending beyond building energy modeling to other specialized engineering modeling.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Counterfactual%20Inference%20through%20Nonlinear%20Quantile%20Regression                                                                                  Advancing Counterfactual Inference through Nonlinear Quantile Regression                                                                                  The capacity to address counterfactual 'what if' inquiries is crucial for understanding and making use of causal influences. Traditional counterfactual inference, under Pearls' counterfactual framework, typically depends on having access to or estimating a structural causal model. Yet, in practice, this causal model is often unknown and might be challenging to identify. Hence, this paper aims to perform reliable counterfactual inference based solely on observational data and the (learned) qualitative causal structure, without necessitating a predefined causal model or even direct estimations of conditional distributions. To this end, we establish a novel connection between counterfactual inference and quantile regression and show that counterfactual inference can be reframed as an extended quantile regression problem. Building on this insight, we propose a practical framework for efficient and effective counterfactual inference implemented with neural networks under a bi-level optimization scheme. The proposed approach enhances the capacity to generalize estimated counterfactual outcomes to unseen data, thereby providing an upper bound on the generalization error. Furthermore, empirical evidence demonstrates its superior statistical efficiency in comparison to existing methods. Empirical results conducted on multiple datasets offer compelling support for our theoretical assertions.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20ECG%20Diagnosis%20Using%20Reinforcement%20Learning%20on%20Global%20Waveform%20Variations%20Related%20to%20P%20Wave%20and%20PR%20Interval                                                                                  Advancing ECG Diagnosis Using Reinforcement Learning on Global Waveform Variations Related to P Wave and PR Interval                                                                                  The reliable diagnosis of cardiac conditions through electrocardiogram (ECG) analysis critically depends on accurately detecting P waves and measuring the PR interval. However, achieving consistent and generalizable diagnoses across diverse populations presents challenges due to the inherent global variations observed in ECG signals. This paper is focused on applying the Q learning reinforcement algorithm to the various ECG datasets available in the PhysioNet/Computing in Cardiology Challenge (CinC). Five ECG beats, including Normal Sinus Rhythm, Atrial Flutter, Atrial Fibrillation, 1st Degree Atrioventricular Block, and Left Atrial Enlargement, are included to study variations of P waves and PR Interval on Lead II and Lead V1. Q-Agent classified 71,672 beat samples in 8,867 patients with an average accuracy of 90.4% and only 9.6% average hamming loss over misclassification. The average classification time at the 100th episode containing around 40,000 samples is 0.04 seconds. An average training reward of 344.05 is achieved at an alpha, gamma, and SoftMax temperature rate of 0.001, 0.9, and 0.1, respectively.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20GenAI%20Assisted%20Programming--A%20Comparative%20Study%20on%20Prompt%20Efficiency%20and%20Code%20Quality%20Between%20GPT-4%20and%20GLM-4                                                                                  Advancing GenAI Assisted Programming--A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4                                                                                  This study aims to explore the best practices for utilizing GenAI as a programming tool, through a comparative analysis between GPT-4 and GLM-4. By evaluating prompting strategies at different levels of complexity, we identify that simplest and straightforward prompting strategy yields best code generation results. Additionally, adding a CoT-like preliminary confirmation step would further increase the success rate. Our results reveal that while GPT-4 marginally outperforms GLM-4, the difference is minimal for average users. In our simplified evaluation model, we see a remarkable 30 to 100-fold increase in code generation efficiency over traditional coding norms. Our GenAI Coding Workshop highlights the effectiveness and accessibility of the prompting methodology developed in this study. We observe that GenAI-assisted coding would trigger a paradigm shift in programming landscape, which necessitates developers to take on new roles revolving around supervising and guiding GenAI, and to focus more on setting high-level objectives and engaging more towards innovation.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Real-time%20Pandemic%20Forecasting%20Using%20Large%20Language%20Models%3A%20A%20COVID-19%20Case%20Study                                                                                  Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study                                                                                  Forecasting the short-term spread of an ongoing disease outbreak is a formidable challenge due to the complexity of contributing factors, some of which can be characterized through interlinked, multi-modality variables such as epidemiological time series data, viral biology, population demographics, and the intersection of public policy and human behavior. Existing forecasting model frameworks struggle with the multifaceted nature of relevant data and robust results translation, which hinders their performances and the provision of actionable insights for public health decision-makers. Our work introduces PandemicLLM, a novel framework with multi-modal Large Language Models (LLMs) that reformulates real-time forecasting of disease spread as a text reasoning problem, with the ability to incorporate real-time, complex, non-numerical information that previously unattainable in traditional forecasting models. This approach, through a unique AI-human cooperative prompt design and time series representation learning, encodes multi-modal data for LLMs. The model is applied to the COVID-19 pandemic, and trained to utilize textual public health policies, genomic surveillance, spatial, and epidemiological time series data, and is subsequently tested across all 50 states of the U.S. Empirically, PandemicLLM is shown to be a high-performing pandemic forecasting framework that effectively captures the impact of emerging variants and can provide timely and accurate predictions. The proposed PandemicLLM opens avenues for incorporating various pandemic-related data in heterogeneous formats and exhibits performance benefits over existing models. This study illuminates the potential of adapting LLMs and representation learning to enhance pandemic forecasting, illustrating how AI innovations can strengthen pandemic responses and crisis management in the future.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20the%20Arabic%20WordNet%3A%20Elevating%20Content%20Quality                                                                                  Advancing the Arabic WordNet: Elevating Content Quality                                                                                  High-quality WordNets are crucial for achieving high-quality results in NLP applications that rely on such resources. However, the wordnets of most languages suffer from serious issues of correctness and completeness with respect to the words and word meanings they define, such as incorrect lemmas, missing glosses and example sentences, or an inadequate, Western-centric representation of the morphology and the semantics of the language. Previous efforts have largely focused on increasing lexical coverage while ignoring other qualitative aspects. In this paper, we focus on the Arabic language and introduce a major revision of the Arabic WordNet that addresses multiple dimensions of lexico-semantic resource quality. As a result, we updated more than 58% of the synsets of the existing Arabic WordNet by adding missing information and correcting errors. In order to address issues of language diversity and untranslatability, we also extended the wordnet structure by new elements: phrasets and lexical gaps.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20the%20Robustness%20of%20Large%20Language%20Models%20through%20Self-Denoised%20Smoothing                                                                                  Advancing the Robustness of Large Language Models through Self-Denoised Smoothing                                                                                  Although large language models (LLMs) have achieved significant success, their vulnerability to adversarial perturbations, including recent jailbreak attacks, has raised considerable concerns. However, the increasing size of these models and their limited access make improving their robustness a challenging task. Among various defense strategies, randomized smoothing has shown great potential for LLMs, as it does not require full access to the model's parameters or fine-tuning via adversarial training. However, randomized smoothing involves adding noise to the input before model prediction, and the final model's robustness largely depends on the model's performance on these noise corrupted data. Its effectiveness is often limited by the model's sub-optimal performance on noisy data. To address this issue, we propose to leverage the multitasking nature of LLMs to first denoise the noisy inputs and then to make predictions based on these denoised versions. We call this procedure self-denoised smoothing. Unlike previous denoised smoothing techniques in computer vision, which require training a separate model to enhance the robustness of LLMs, our method offers significantly better efficiency and flexibility. Our experimental results indicate that our method surpasses existing methods in both empirical and certified robustness in defending against adversarial attacks for both downstream tasks and human alignments (i.e., jailbreak attacks). Our code is publicly available at https://github.com/UCSB-NLP-Chang/SelfDenoise
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Attacks%20and%20Dimensionality%20in%20Text%20Classifiers                                                                                  Adversarial Attacks and Dimensionality in Text Classifiers                                                                                  Adversarial attacks on machine learning algorithms have been a key deterrent to the adoption of AI in many real-world use cases. They significantly undermine the ability of high-performance neural networks by forcing misclassifications. These attacks introduce minute and structured perturbations or alterations in the test samples, imperceptible to human annotators in general, but trained neural networks and other models are sensitive to it. Historically, adversarial attacks have been first identified and studied in the domain of image processing. In this paper, we study adversarial examples in the field of natural language processing, specifically text classification tasks. We investigate the reasons for adversarial vulnerability, particularly in relation to the inherent dimensionality of the model. Our key finding is that there is a very strong correlation between the embedding dimensionality of the adversarial samples and their effectiveness on models tuned with input samples with same embedding dimension. We utilize this sensitivity to design an adversarial defense mechanism. We use ensemble models of varying inherent dimensionality to thwart the attacks. This is tested on multiple datasets for its efficacy in providing robustness. We also study the problem of measuring adversarial perturbation using different distance metrics. For all of the aforementioned studies, we have run tests on multiple models with varying dimensionality and used a word-vector level adversarial attack to substantiate the findings.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Supervision%20Makes%20Layout-to-Image%20Diffusion%20Models%20Thrive                                                                                  Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive                                                                                  Despite the recent advances in large-scale diffusion models, little progress has been made on the layout-to-image (L2I) synthesis task. Current L2I models either suffer from poor editability via text or weak alignment between the generated image and the input layout. This limits their usability in practice. To mitigate this, we propose to integrate adversarial supervision into the conventional training pipeline of L2I diffusion models (ALDM). Specifically, we employ a segmentation-based discriminator which provides explicit feedback to the diffusion generator on the pixel-level alignment between the denoised image and the input layout. To encourage consistent adherence to the input layout over the sampling steps, we further introduce the multistep unrolling strategy. Instead of looking at a single timestep, we unroll a few steps recursively to imitate the inference process, and ask the discriminator to assess the alignment of denoised images with the layout over a certain time window. Our experiments show that ALDM enables layout faithfulness of the generated images, while allowing broad editability via text prompts. Moreover, we showcase its usefulness for practical applications: by synthesizing target distribution samples via text control, we improve domain generalization of semantic segmentation models by a large margin (~12 mIoU points).
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20speech%20for%20voice%20privacy%20protection%20from%20Personalized%20Speech%20generation                                                                                  Adversarial speech for voice privacy protection from Personalized Speech generation                                                                                  The rapid progress in personalized speech generation technology, including personalized text-to-speech (TTS) and voice conversion (VC), poses a challenge in distinguishing between generated and real speech for human listeners, resulting in an urgent demand in protecting speakers' voices from malicious misuse. In this regard, we propose a speaker protection method based on adversarial attacks. The proposed method perturbs speech signals by minimally altering the original speech while rendering downstream speech generation models unable to accurately generate the voice of the target speaker. For validation, we employ the open-source pre-trained YourTTS model for speech generation and protect the target speaker's speech in the white-box scenario. Automatic speaker verification (ASV) evaluations were carried out on the generated speech as the assessment of the voice protection capability. Our experimental results show that we successfully perturbed the speaker encoder of the YourTTS model using the gradient-based I-FGSM adversarial perturbation method. Furthermore, the adversarial perturbation is effective in preventing the YourTTS model from generating the speech of the target speaker. Audio samples can be found in https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS.
http://w3id.org/mlsea/pwc/scientificWork/Aedes%20aegypti%20Egg%20Counting%20with%20Neural%20Networks%20for%20Object%20Detection                                                                                  Aedes aegypti Egg Counting with Neural Networks for Object Detection                                                                                  Aedes aegypti is still one of the main concerns when it comes to disease vectors. Among the many ways to deal with it, there are important protocols that make use of egg numbers in ovitraps to calculate indices, such as the LIRAa and the Breteau Index, which can provide information on predictable outbursts and epidemics. Also, there are many research lines that require egg numbers, specially when mass production of mosquitoes is needed. Egg counting is a laborious and error-prone task that can be automated via computer vision-based techniques, specially deep learning-based counting with object detection. In this work, we propose a new dataset comprising field and laboratory eggs, along with test results of three neural networks applied to the task: Faster R-CNN, Side-Aware Boundary Localization and FoveaBox.
http://w3id.org/mlsea/pwc/scientificWork/Affective%20Video%20Content%20Analysis%3A%20Decade%20Review%20and%20New%20Perspectives                                                                                  Affective Video Content Analysis: Decade Review and New Perspectives                                                                                  Video content is rich in semantics and has the ability to evoke various emotions in viewers. In recent years, with the rapid development of affective computing and the explosive growth of visual data, affective video content analysis (AVCA) as an essential branch of affective computing has become a widely researched topic. In this study, we comprehensively review the development of AVCA over the past decade, particularly focusing on the most advanced methods adopted to address the three major challenges of video feature extraction, expression subjectivity, and multimodal feature fusion. We first introduce the widely used emotion representation models in AVCA and describe commonly used datasets. We summarize and compare representative methods in the following aspects: (1) unimodal AVCA models, including facial expression recognition and posture emotion recognition; (2) multimodal AVCA models, including feature fusion, decision fusion, and attention-based multimodal models; (3) model performance evaluation standards. Finally, we discuss future challenges and promising research directions, such as emotion recognition and public opinion analysis, human-computer interaction, and emotional intelligence.
http://w3id.org/mlsea/pwc/scientificWork/Affirmative%20Action%27s%20Cumulative%20Fractional%20Assignments                                                                                  Affirmative Action's Cumulative Fractional Assignments                                                                                  The Central Educational Institutions (Reservation in Teachers' Cadre) Act, 2019 provides for reserving teaching vacancies in India's central educational institutions for beneficiaries of its affirmative action policy. Reservation of teaching vacancies had been a contentious issue, and the act was introduced to resolve it after the Supreme Court's solution was met with protests from the Teachers' Union. Our paper demonstrates an impossibility result in the Supreme Court's solution and the act, which are flawed in reserving seats simultaneously at both the university and within its departments. To overcome this impossibility, we propose an alternative solution based on approximate implementation of fractional assignments, offering a promising middle-ground between the two disputed solutions practiced in India. This novel application demonstrates the practical relevance of the approximate implementation approach (Akbarpourand Nikzad(2020)) beyond the constraint structures examined in the literature.
http://w3id.org/mlsea/pwc/scientificWork/Age%20Prediction%20From%2012-lead%20Electrocardiograms%20Using%20Deep%20Learning%3A%20A%20Comparison%20of%20Four%20Models%20on%20a%20Contemporary%2C%20Freely%20Available%20Dataset                                                                                  Age Prediction From 12-lead Electrocardiograms Using Deep Learning: A Comparison of Four Models on a Contemporary, Freely Available Dataset                                                                                  The 12-lead electrocardiogram (ECG) is routine in clinical use and deep learning approaches have been shown to have the identify features not immediately apparent to human interpreters including age and sex. ECG predicted age has been identified as a predictor of long-term mortality. Here we compare four models for age and sex prediction on a contemporary, freely available dataset.
http://w3id.org/mlsea/pwc/scientificWork/Agent%20Lumos%3A%20Unified%20and%20Modular%20Training%20for%20Open-Source%20Language%20Agents                                                                                  Agent Lumos: Unified and Modular Training for Open-Source Language Agents                                                                                  Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce LUMOS, one of the first frameworks for training open-source LLM-based agents. LUMOS features a learnable, unified, and modular architecture with a planning module that learns high-level subgoal generation, and a grounding module trained to translate these into actions using various tools in the execution module. The design allows for modular upgrades and wider applicability to diverse interactive tasks. To foster generalizable agent learning, we collect large-scale, unified, and high-quality training annotations derived from diverse ground-truth reasoning rationales across various complex interactive tasks. On 9 datasets, LUMOS exhibits several key advantages: (1) LUMOS excels multiple larger open-source agents on the held-out datasets (unused for training) for each task type. LUMOS even surpasses GPT agents on QA and web tasks; (2) LUMOS outperforms open-source agents produced by chain-of-thoughts and unmodularized integrated training; and (3) LUMOS effectively generalizes to unseen tasks, outperforming 33B-scale agents and domain-specific agents.
http://w3id.org/mlsea/pwc/scientificWork/AgentGroupChat%3A%20An%20Interactive%20Group%20Chat%20Simulacra%20For%20Better%20Eliciting%20Emergent%20Behavior                                                                                  AgentGroupChat: An Interactive Group Chat Simulacra For Better Eliciting Emergent Behavior                                                                                  Language significantly influences the formation and evolution of Human emergent behavior, which is crucial in understanding collective intelligence within human societies. Considering that the study of how language affects human behavior needs to put it into the dynamic scenarios in which it is used, we introduce AgentGroupChat in this paper, a simulation that delves into the complex role of language in shaping collective behavior through interactive debate scenarios. Central to this simulation are characters engaging in dynamic conversation interactions. To enable simulation, we introduce the Verbal Strategist Agent, utilizing large language models to enhance interaction strategies by incorporating elements of persona and action. We set four narrative scenarios based on AgentGroupChat to demonstrate the simulation's capacity to mimic complex language use in group dynamics. Evaluations focus on aligning agent behaviors with human expectations and the emergence of collective behaviors within the simulation. Results reveal that emergent behaviors materialize from a confluence of factors: a conducive environment for extensive information exchange, characters with diverse traits, high linguistic comprehension, and strategic adaptability. During discussions on ``the impact of AI on humanity'' in AgentGroupChat simulation, philosophers commonly agreed that ``AI could enhance societal welfare with judicious limitations'' and even come to a conclusion that ``the essence of true intelligence encompasses understanding the necessity to constrain self abilities''. Additionally, in the competitive domain of casting for primary roles in films in AgentGroupChat, certain actors were ready to reduce their remuneration or accept lesser roles, motivated by their deep-seated desire to contribute to the project.
http://w3id.org/mlsea/pwc/scientificWork/Aggregate%20Peak%20EV%20Charging%20Demand%3A%20The%20Impact%20of%20Segmented%20Network%20Tariffs                                                                                  Aggregate Peak EV Charging Demand: The Impact of Segmented Network Tariffs                                                                                  Aggregate peak Electric Vehicle (EV) charging demand is a matter of growing concern for network operators as it severely limits the network's capacity, preventing its reliable operation. Various tariff schemes have been proposed to limit peak demand by incentivizing flexible asset users to shift their demand from peak periods. However, fewer studies quantify the effect of these tariff schemes on the aggregate level. In this paper, we compare the effect of a multi-level segmented network tariff with and without dynamic energy prices for individual EV users on the aggregate peak demand. Results based on real charging transactions from over 1200 public charging points in the Netherlands show that the segmented network tariff with flat energy prices results in more diverse load profiles with increasing aggregation, as compared to cost-optimized dispatch based on only dynamic day-ahead energy prices. When paired with dynamic energy prices, the segmented tariff still outperforms only dynamic energy price-based tariffs in reducing peaks. Results show that a balance between power thresholds and price per threshold is crucial in designing a suitable tariff, taking into account the needs of the power network. We also provide valuable insights to network operators by calculating the diversity factor for various peak demands per charging point.
http://w3id.org/mlsea/pwc/scientificWork/Agile%20Multi-Source-Free%20Domain%20Adaptation                                                                                  Agile Multi-Source-Free Domain Adaptation                                                                                  Efficiently utilizing rich knowledge in pretrained models has become a critical topic in the era of large models. This work focuses on adaptively utilizing knowledge from multiple source-pretrained models to an unlabeled target domain without accessing the source data. Despite being a practically useful setting, existing methods require extensive parameter tuning over each source model, which is computationally expensive when facing abundant source domains or larger source models. To address this challenge, we propose a novel approach which is free of the parameter tuning over source backbones. Our technical contribution lies in the Bi-level ATtention ENsemble (Bi-ATEN) module, which learns both intra-domain weights and inter-domain ensemble weights to achieve a fine balance between instance specificity and domain consistency. By slightly tuning source bottlenecks, we achieve comparable or even superior performance on a challenging benchmark DomainNet with less than 3% trained parameters and 8 times of throughput compared with SOTA method. Furthermore, with minor modifications, the proposed module can be easily equipped to existing methods and gain more than 4% performance boost. Code is available at https://github.com/TL-UESTC/Bi-ATEN.
http://w3id.org/mlsea/pwc/scientificWork/Agnostic%20Tomography%20of%20Stabilizer%20Product%20States                                                                                  Agnostic Tomography of Stabilizer Product States                                                                                  We define a quantum learning task called agnostic tomography, where given copies of an arbitrary state $ rho$ and a class of quantum states $ mathcal{C}$, the goal is to output a succinct description of a state that approximates $ rho$ at least as well as any state in $ mathcal{C}$ (up to some small error $ varepsilon$). This task generalizes ordinary quantum tomography of states in $ mathcal{C}$ and is more challenging because the learning algorithm must be robust to perturbations of $ rho$. We give an efficient agnostic tomography algorithm for the class $ mathcal{C}$ of $n$-qubit stabilizer product states. Assuming $ rho$ has fidelity at least $ tau$ with a stabilizer product state, the algorithm runs in time $n^{O(1 + log(1/ tau))} / varepsilon^2$. This runtime is quasipolynomial in all parameters, and polynomial if $ tau$ is a constant.
http://w3id.org/mlsea/pwc/scientificWork/AiOS%3A%20All-in-One-Stage%20Expressive%20Human%20Pose%20and%20Shape%20Estimation                                                                                  AiOS: All-in-One-Stage Expressive Human Pose and Shape Estimation                                                                                  Expressive human pose and shape estimation (a.k.a. 3D whole-body mesh recovery) involves the human body, hand, and expression estimation. Most existing methods have tackled this task in a two-stage manner, first detecting the human body part with an off-the-shelf detection model and inferring the different human body parts individually. Despite the impressive results achieved, these methods suffer from 1) loss of valuable contextual information via cropping, 2) introducing distractions, and 3) lacking inter-association among different persons and body parts, inevitably causing performance degradation, especially for crowded scenes. To address these issues, we introduce a novel all-in-one-stage framework, AiOS, for multiple expressive human pose and shape recovery without an additional human detection step. Specifically, our method is built upon DETR, which treats multi-person whole-body mesh recovery task as a progressive set prediction problem with various sequential detection. We devise the decoder tokens and extend them to our task. Specifically, we first employ a human token to probe a human location in the image and encode global features for each instance, which provides a coarse location for the later transformer block. Then, we introduce a joint-related token to probe the human joint in the image and encoder a fine-grained local feature, which collaborates with the global feature to regress the whole-body mesh. This straightforward but effective model outperforms previous state-of-the-art methods by a 9% reduction in NMVE on AGORA, a 30% reduction in PVE on EHF, a 10% reduction in PVE on ARCTIC, and a 3% reduction in PVE on EgoBody.
http://w3id.org/mlsea/pwc/scientificWork/Aiming%20at%20the%20Target%3A%20Filter%20Collaborative%20Information%20for%20Cross-Domain%20Recommendation                                                                                  Aiming at the Target: Filter Collaborative Information for Cross-Domain Recommendation                                                                                  Cross-domain recommender (CDR) systems aim to enhance the performance of the target domain by utilizing data from other related domains. However, irrelevant information from the source domain may instead degrade target domain performance, which is known as the negative transfer problem. There have been some attempts to address this problem, mostly by designing adaptive representations for overlapped users. Whereas, representation adaptions solely rely on the expressive capacity of the CDR model, lacking explicit constraint to filter the irrelevant source-domain collaborative information for the target domain. In this paper, we propose a novel Collaborative information regularized User Transformation (CUT) framework to tackle the negative transfer problem by directly filtering users' collaborative information. In CUT, user similarity in the target domain is adopted as a constraint for user transformation learning to filter the user collaborative information from the source domain. CUT first learns user similarity relationships from the target domain. Then, source-target information transfer is guided by the user similarity, where we design a user transformation layer to learn target-domain user representations and a contrastive loss to supervise the user collaborative information transferred. The results show significant performance improvement of CUT compared with SOTA single and cross-domain methods. Further analysis of the target-domain results illustrates that CUT can effectively alleviate the negative transfer problem.
http://w3id.org/mlsea/pwc/scientificWork/Air%20Quality%20Forecasting%20Using%20Machine%20Learning%3A%20A%20Global%20perspective%20with%20Relevance%20to%20Low-Resource%20Settings                                                                                  Air Quality Forecasting Using Machine Learning: A Global perspective with Relevance to Low-Resource Settings                                                                                  Air pollution stands as the fourth leading cause of death globally. While extensive research has been conducted in this domain, most approaches rely on large datasets when it comes to prediction. This limits their applicability in low-resource settings though more vulnerable. This study addresses this gap by proposing a novel machine learning approach for accurate air quality prediction using two months of air quality data. By leveraging the World Weather Repository, the meteorological, air pollutant, and Air Quality Index features from 197 capital cities were considered to predict air quality for the next day. The evaluation of several machine learning models demonstrates the effectiveness of the Random Forest algorithm in generating reliable predictions, particularly when applied to classification rather than regression, approach which enhances the model's generalizability by 42%, achieving a cross-validation score of 0.38 for regression and 0.89 for classification. To instill confidence in the predictions, interpretable machine learning was considered. Finally, a cost estimation comparing the implementation of this solution in high-resource and low-resource settings is presented including a tentative of technology licensing business model. This research highlights the potential for resource-limited countries to independently predict air quality while awaiting larger datasets to further refine their predictions.
http://w3id.org/mlsea/pwc/scientificWork/Airship%20Formations%20for%20Animal%20Motion%20Capture%20and%20Behavior%20Analysis                                                                                  Airship Formations for Animal Motion Capture and Behavior Analysis                                                                                  Using UAVs for wildlife observation and motion capture offers manifold advantages for studying animals in the wild, especially grazing herds in open terrain. The aerial perspective allows observation at a scale and depth that is not possible on the ground, offering new insights into group behavior. However, the very nature of wildlife field-studies puts traditional fixed wing and multi-copter systems to their limits: limited flight time, noise and safety aspects affect their efficacy, where lighter than air systems can remain on station for many hours. Nevertheless, airships are challenging from a ground handling perspective as well as from a control point of view, being voluminous and highly affected by wind. In this work, we showcase a system designed to use airship formations to track, follow, and visually record wild horses from multiple angles, including airship design, simulation, control, on board computer vision, autonomous operation and practical aspects of field experiments.
http://w3id.org/mlsea/pwc/scientificWork/Algorithm-Hardware%20Co-Design%20of%20Distribution-Aware%20Logarithmic-Posit%20Encodings%20for%20Efficient%20DNN%20Inference                                                                                  Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit Encodings for Efficient DNN Inference                                                                                  Traditional Deep Neural Network (DNN) quantization methods using integer, fixed-point, or floating-point data types struggle to capture diverse DNN parameter distributions at low precision, and often require large silicon overhead and intensive quantization-aware training. In this study, we introduce Logarithmic Posits (LP), an adaptive, hardware-friendly data type inspired by posits that dynamically adapts to DNN weight/activation distributions by parameterizing LP bit fields. We also develop a novel genetic-algorithm based framework, LP Quantization (LPQ), to find optimal layer-wise LP parameters while reducing representational divergence between quantized and full-precision models through a novel global-local contrastive objective. Additionally, we design a unified mixed-precision LP accelerator (LPA) architecture comprising of processing elements (PEs) incorporating LP in the computational datapath. Our algorithm-hardware co-design demonstrates on average <1% drop in top-1 accuracy across various CNN and ViT models. It also achieves ~ 2x improvements in performance per unit area and 2.2x gains in energy efficiency compared to state-of-the-art quantization accelerators using different data types.
http://w3id.org/mlsea/pwc/scientificWork/Algorithmic%20Collusion%20and%20Price%20Discrimination%3A%20The%20Over-Usage%20of%20Data                                                                                  Algorithmic Collusion and Price Discrimination: The Over-Usage of Data                                                                                  As firms' pricing strategies increasingly rely on algorithms, two concerns have received much attention: algorithmic tacit collusion and price discrimination. This paper investigates the interaction between these two issues through simulations. In each period, a new buyer arrives with independently and identically distributed willingness to pay (WTP), and each firm, observing private signals about WTP, adopts Q-learning algorithms to set prices. We document two novel mechanisms that lead to collusive outcomes. Under asymmetric information, the algorithm with information advantage adopts a Bait-and-Restrained-Exploit strategy, surrendering profits on some signals by setting higher prices, while exploiting limited profits on the remaining signals by setting much lower prices. Under a symmetric information structure, competition on some signals facilitates convergence to supra-competitive prices on the remaining signals. Algorithms tend to collude more on signals with higher expected WTP. Both uncertainty and the lack of correlated signals exacerbate the degree of collusion, thereby reducing both consumer surplus and social welfare. A key implication is that the over-usage of data, both payoff-relevant and non-relevant, by AIs in competitive contexts will reduce the degree of collusion and consequently lead to a decline in industry profits.
http://w3id.org/mlsea/pwc/scientificWork/Algorithmic%20amplification%20of%20biases%20on%20Google%20Search                                                                                  Algorithmic amplification of biases on Google Search                                                                                  The evolution of information-seeking processes, driven by search engines like Google, has transformed the access to information people have. This paper investigates how individuals' preexisting attitudes influence the modern information-seeking process, specifically the results presented by Google Search. Through a comprehensive study involving surveys and information-seeking tasks focusing on the topic of abortion, the paper provides four crucial insights: 1) Individuals with opposing attitudes on abortion receive different search results. 2) Individuals express their beliefs in their choice of vocabulary used in formulating the search queries, shaping the outcome of the search. 3) Additionally, the user's search history contributes to divergent results among those with opposing attitudes. 4) Google Search engine reinforces preexisting beliefs in search results. Overall, this study provides insights into the interplay between human biases and algorithmic processes, highlighting the potential for information polarization in modern information-seeking processes.
http://w3id.org/mlsea/pwc/scientificWork/Align%20Your%20Intents%3A%20Offline%20Imitation%20Learning%20via%20Optimal%20Transport                                                                                  Align Your Intents: Offline Imitation Learning via Optimal Transport                                                                                  Offline reinforcement learning (RL) addresses the problem of sequential decision-making by learning optimal policy through pre-collected data, without interacting with the environment. As yet, it has remained somewhat impractical, because one rarely knows the reward explicitly and it is hard to distill it retrospectively. Here, we show that an imitating agent can still learn the desired behavior merely from observing the expert, despite the absence of explicit rewards or action labels. In our method, AILOT (Aligned Imitation Learning via Optimal Transport), we involve special representation of states in a form of intents that incorporate pairwise spatial distances within the data. Given such representations, we define intrinsic reward function via optimal transport distance between the expert's and the agent's trajectories. We report that AILOT outperforms state-of-the art offline imitation learning algorithms on D4RL benchmarks and improves the performance of other offline RL algorithms in the sparse-reward tasks.
http://w3id.org/mlsea/pwc/scientificWork/Align%20and%20Distill%3A%20Unifying%20and%20Improving%20Domain%20Adaptive%20Object%20Detection                                                                                  Align and Distill: Unifying and Improving Domain Adaptive Object Detection                                                                                  Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy Cityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to outperform a fair baseline), and +2.0 AP50 on CFC Kenai to Channel. Our framework, dataset, and state-of-the-art method offer a critical reset for DAOD and provide a strong foundation for future research. Code and data are available: https://github.com/justinkay/aldi and https://github.com/visipedia/caltech-fish-counting.
http://w3id.org/mlsea/pwc/scientificWork/AlignMiF%3A%20Geometry-Aligned%20Multimodal%20Implicit%20Field%20for%20LiDAR-Camera%20Joint%20Synthesis                                                                                  AlignMiF: Geometry-Aligned Multimodal Implicit Field for LiDAR-Camera Joint Synthesis                                                                                  Neural implicit fields have been a de facto standard in novel view synthesis. Recently, there exist some methods exploring fusing multiple modalities within a single field, aiming to share implicit features from different modalities to enhance reconstruction performance. However, these modalities often exhibit misaligned behaviors: optimizing for one modality, such as LiDAR, can adversely affect another, like camera performance, and vice versa. In this work, we conduct comprehensive analyses on the multimodal implicit field of LiDAR-camera joint synthesis, revealing the underlying issue lies in the misalignment of different sensors. Furthermore, we introduce AlignMiF, a geometrically aligned multimodal implicit field with two proposed modules: Geometry-Aware Alignment (GAA) and Shared Geometry Initialization (SGI). These modules effectively align the coarse geometry across different modalities, significantly enhancing the fusion process between LiDAR and camera data. Through extensive experiments across various datasets and scenes, we demonstrate the effectiveness of our approach in facilitating better interaction between LiDAR and camera modalities within a unified neural field. Specifically, our proposed AlignMiF, achieves remarkable improvement over recent implicit fusion methods (+2.01 and +3.11 image PSNR on the KITTI-360 and Waymo datasets) and consistently surpasses single modality performance (13.8% and 14.2% reduction in LiDAR Chamfer Distance on the respective datasets).
http://w3id.org/mlsea/pwc/scientificWork/Aligning%20Individual%20and%20Collective%20Objectives%20in%20Multi-Agent%20Cooperation                                                                                  Aligning Individual and Collective Objectives in Multi-Agent Cooperation                                                                                  In the field of multi-agent learning, the challenge of mixed-motive cooperation is pronounced, given the inherent contradictions between individual and collective goals. Current research in this domain primarily focuses on incorporating domain knowledge into rewards or introducing additional mechanisms to foster cooperation. However, many of these methods suffer from the drawbacks of manual design costs and the lack of a theoretical grounding convergence procedure to the solution. To address this gap, we approach the mixed-motive game by modeling it as a differentiable game to study learning dynamics. We introduce a novel optimization method named Altruistic Gradient Adjustment (AgA) that employs gradient adjustments to novelly align individual and collective objectives. Furthermore, we provide theoretical proof that the selection of an appropriate alignment weight in AgA can accelerate convergence towards the desired solutions while effectively avoiding the undesired ones. The visualization of learning dynamics effectively demonstrates that AgA successfully achieves alignment between individual and collective objectives. Additionally, through evaluations conducted on established mixed-motive benchmarks such as the public good game, Cleanup, Harvest, and our modified mixed-motive SMAC environment, we validate AgA's capability to facilitate altruistic and fair collaboration.
http://w3id.org/mlsea/pwc/scientificWork/Aligning%20Speech%20to%20Languages%20to%20Enhance%20Code-switching%20Speech%20Recognition                                                                                  Aligning Speech to Languages to Enhance Code-switching Speech Recognition                                                                                  Code-switching (CS) refers to the switching of languages within a speech signal and results in language confusion for automatic speech recognition (ASR). To address language confusion, we propose the language alignment loss that performs frame-level language identification using pseudo language labels learned from the ASR decoder. This eliminates the need for frame-level language annotations. To further tackle the complex token alternatives for language modeling in bilingual scenarios, we propose to employ large language models via a generative error correction method. A linguistic hint that incorporates language information (derived from the proposed language alignment loss and decoded hypotheses) is introduced to guide the prompting of large language models. The proposed methods are evaluated on the SEAME dataset and data from the ASRU 2019 Mandarin-English code-switching speech recognition challenge. The incorporation of the proposed language alignment loss demonstrates a higher CS-ASR performance with only a negligible increase in the number of parameters on both datasets compared to the baseline model. This work also highlights the efficacy of language alignment loss in balancing primary-language-dominant bilingual data during training, with an 8.6% relative improvement on the ASRU dataset compared to the baseline model. Performance evaluation using large language models reveals the advantage of the linguistic hint by achieving 14.1% and 5.5% relative improvement on test sets of the ASRU and SEAME datasets, respectively.
http://w3id.org/mlsea/pwc/scientificWork/Aligning%20with%20Human%20Judgement%3A%20The%20Role%20of%20Pairwise%20Preference%20in%20Large%20Language%20Model%20Evaluators                                                                                  Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators                                                                                  Large Language Models (LLMs) have demonstrated promising capabilities as automatic evaluators in assessing the quality of generated natural language. However, LLMs still exhibit biases in evaluation and often struggle to generate coherent evaluations that align with human assessments. In this work, we first conduct a systematic study of the misalignment between LLM evaluators and human judgement, revealing that existing calibration methods aimed at mitigating biases are insufficient for effectively aligning LLM evaluators. Inspired by the use of preference data in RLHF, we formulate the evaluation as a ranking problem and introduce Pairwise-preference Search (PairS), an uncertainty-guided search method that employs LLMs to conduct pairwise comparisons and efficiently ranks candidate texts. PairS achieves state-of-the-art performance on representative evaluation tasks and demonstrates significant improvements over direct scoring. Furthermore, we provide insights into the role of pairwise preference in quantifying the transitivity of LLMs and demonstrate how PairS benefits from calibration.
http://w3id.org/mlsea/pwc/scientificWork/All%20Language%20Models%20Large%20and%20Small                                                                                  All Language Models Large and Small                                                                                  Many leading language models (LMs) use high-intensity computational resources both during training and execution. This poses the challenge of lowering resource costs for deployment and faster execution of decision-making tasks among others. We introduce a novel plug-and-play LM framework named Language Optimising Network Distribution (LONDI) framework. LONDI learns to selectively employ large LMs only where complex decision-making and reasoning are required while using low-resource LMs everywhere else. LONDI consists of a system of two (off-)policy networks, an LM, a large LM (LLM), and a reinforcement learning module that uses switching controls to quickly learn which system states to call the LLM. We then introduce a variant of LONDI that maintains budget constraints on LLM calls and hence its resource usage. Theoretically, we prove LONDI learns the subset of system states to activate the LLM required to solve the task. We then prove that LONDI converges to optimal solutions while also preserving budgetary constraints on LLM calls almost surely enabling it to solve various tasks while significantly lowering computational costs. We test LONDI's performance in a range of tasks in ScienceWorld and BabyAI-Text and demonstrate that LONDI can solve tasks only solvable by resource-intensive LLMs while reducing GPU usage by up to 30%.
http://w3id.org/mlsea/pwc/scientificWork/All%20in%20One%3A%20An%20Empirical%20Study%20of%20GPT%20for%20Few-Shot%20Aspect-Based%20Sentiment%20Anlaysis                                                                                  All in One: An Empirical Study of GPT for Few-Shot Aspect-Based Sentiment Anlaysis                                                                                  Aspect-Based Sentiment Analysis (ABSA) is an indispensable and highly challenging task in natural language processing. Current efforts have focused on specific sub-tasks, making it difficult to comprehensively cover all sub-tasks within the ABSA domain. With the development of Generative Pre-trained Transformers (GPTs), there came inspiration for a one-stop solution to sentiment analysis. In this study, we used GPTs for all sub-tasks of few-shot ABSA while defining a general learning paradigm for this application. We propose the All in One (AiO) model, a simple yet effective two-stage model for all ABSA sub-tasks. In the first stage, a specific backbone network learns the semantic information of the review and generates heuristically enhanced candidates. In the second stage, AiO leverages GPT contextual learning capabilities to generate predictions. The study conducted comprehensive comparative and ablation experiments on five benchmark datasets, and the results show that AiO can effectively handle all ABSA sub-tasks, even with few-shot data.
http://w3id.org/mlsea/pwc/scientificWork/AllSpark%3A%20Reborn%20Labeled%20Features%20from%20Unlabeled%20in%20Transformer%20for%20Semi-Supervised%20Semantic%20Segmentation                                                                                  AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation                                                                                  Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate the burden of time-consuming pixel-level manual labeling, which leverages limited labeled data along with larger amounts of unlabeled data. Current state-of-the-art methods train the labeled data with ground truths and unlabeled data with pseudo labels. However, the two training flows are separate, which allows labeled data to dominate the training process, resulting in low-quality pseudo labels and, consequently, sub-optimal results. To alleviate this issue, we present AllSpark, which reborns the labeled features from unlabeled ones with the channel-wise cross-attention mechanism. We further introduce a Semantic Memory along with a Channel Semantic Grouping strategy to ensure that unlabeled features adequately represent labeled features. The AllSpark shed new light on the architecture level designs of SSSS rather than framework level, which avoids increasingly complicated training pipeline designs. It can also be regarded as a flexible bottleneck module that can be seamlessly integrated into a general transformer-based segmentation model. The proposed AllSpark outperforms existing methods across all evaluation protocols on Pascal, Cityscapes and COCO benchmarks without bells-and-whistles. Code and model weights are available at: https://github.com/xmed-lab/AllSpark.
http://w3id.org/mlsea/pwc/scientificWork/Allo%3A%20A%20Programming%20Model%20for%20Composable%20Accelerator%20Design                                                                                  Allo: A Programming Model for Composable Accelerator Design                                                                                  Special-purpose hardware accelerators are increasingly pivotal for sustaining performance improvements in emerging applications, especially as the benefits of technology scaling continue to diminish. However, designers currently lack effective tools and methodologies to construct complex, high-performance accelerator architectures in a productive manner. Existing high-level synthesis (HLS) tools often require intrusive source-level changes to attain satisfactory quality of results. Despite the introduction of several new accelerator design languages (ADLs) aiming to enhance or replace HLS, their advantages are more evident in relatively simple applications with a single kernel. Existing ADLs prove less effective for realistic hierarchical designs with multiple kernels, even if the design hierarchy is flattened. In this paper, we introduce Allo, a composable programming model for efficient spatial accelerator design. Allo decouples hardware customizations, including compute, memory, communication, and data type from algorithm specification, and encapsulates them as a set of customization primitives. Allo preserves the hierarchical structure of an input program by combining customizations from different functions in a bottom-up, type-safe manner. This approach facilitates holistic optimizations that span across function boundaries. We conduct comprehensive experiments on commonly-used HLS benchmarks and several realistic deep learning models. Our evaluation shows that Allo can outperform state-of-the-art HLS tools and ADLs on all test cases in the PolyBench. For the GPT2 model, the inference latency of the Allo generated accelerator is 1.7x faster than the NVIDIA A100 GPU with 5.4x higher energy efficiency, demonstrating the capability of Allo to handle large-scale designs.
http://w3id.org/mlsea/pwc/scientificWork/Almost%20Global%20Asymptotic%20Trajectory%20Tracking%20for%20Fully-Actuated%20Mechanical%20Systems%20on%20Homogeneous%20Riemannian%20Manifolds                                                                                  Almost Global Asymptotic Trajectory Tracking for Fully-Actuated Mechanical Systems on Homogeneous Riemannian Manifolds                                                                                  In this work, we address the design of tracking controllers that drive a mechanical system's state asymptotically towards a reference trajectory. Motivated by aerospace and robotics applications, we consider fully-actuated systems evolving on the broad class of homogeneous spaces (encompassing all vector spaces, Lie groups, and spheres of any dimension). In this setting, the transitive action of a Lie group on the configuration manifold enables an intrinsic description of the tracking error as an element of the state space, even in the absence of a group structure on the configuration manifold itself (e.g., for $ mathbb{S}^2$). Such an error state facilitates the design of a generalized control policy depending smoothly on state and time that drives this geometric tracking error to a designated origin from almost every initial condition, thereby guaranteeing almost global convergence to the reference trajectory. Moreover, the proposed controller simplifies naturally when specialized to a Lie group or the $n$-sphere. In summary, we propose a unified, intrinsic controller guaranteeing almost global asymptotic trajectory tracking for fully-actuated mechanical systems evolving on a broader class of manifolds. We apply the method to an axisymmetric satellite and an omnidirectional aerial robot.
http://w3id.org/mlsea/pwc/scientificWork/Alpha-GPT%202.0%3A%20Human-in-the-Loop%20AI%20for%20Quantitative%20Investment                                                                                  Alpha-GPT 2.0: Human-in-the-Loop AI for Quantitative Investment                                                                                  Recently, we introduced a new paradigm for alpha mining in the realm of quantitative investment, developing a new interactive alpha mining system framework, Alpha-GPT. This system is centered on iterative Human-AI interaction based on large language models, introducing a Human-in-the-Loop approach to alpha discovery. In this paper, we present the next-generation Alpha-GPT 2.0 footnote{Draft. Work in progress}, a quantitative investment framework that further encompasses crucial modeling and analysis phases in quantitative investment. This framework emphasizes the iterative, interactive research between humans and AI, embodying a Human-in-the-Loop strategy throughout the entire quantitative investment pipeline. By assimilating the insights of human researchers into the systematic alpha research process, we effectively leverage the Human-in-the-Loop approach, enhancing the efficiency and precision of quantitative investment research.
http://w3id.org/mlsea/pwc/scientificWork/AltGraph%3A%20Redesigning%20Quantum%20Circuits%20Using%20Generative%20Graph%20Models%20for%20Efficient%20Optimization                                                                                  AltGraph: Redesigning Quantum Circuits Using Generative Graph Models for Efficient Optimization                                                                                  Quantum circuit transformation aims to produce equivalent circuits while optimizing for various aspects such as circuit depth, gate count, and compatibility with modern Noisy Intermediate Scale Quantum (NISQ) devices. There are two techniques for circuit transformation. The first is a rule-based approach that greedily cancels out pairs of gates that equate to the identity unitary operation. Rule-based approaches are used in quantum compilers such as Qiskit, tket, and Quilc. The second is a search-based approach that tries to find an equivalent quantum circuit by exploring the quantum circuits search space. Search-based approaches typically rely on machine learning techniques such as generative models and Reinforcement Learning (RL). In this work, we propose AltGraph, a novel search-based circuit transformation approach that generates equivalent quantum circuits using existing generative graph models. We use three main graph models: DAG Variational Autoencoder (D-VAE) with two variants: Gated Recurrent Unit (GRU) and Graph Convolutional Network (GCN), and Deep Generative Model for Graphs (DeepGMG) that take a Direct Acyclic Graph (DAG) of the quantum circuit as input and output a new DAG from which we reconstruct the equivalent quantum circuit. Next, we perturb the latent space to generate equivalent quantum circuits some of which may be more compatible with the hardware coupling map and/or enable better optimization leading to reduced gate count and circuit depth. AltGraph achieves on average a 37.55% reduction in the number of gates and a 37.75% reduction in the circuit depth post-transpiling compared to the original transpiled circuit with only 0.0074 Mean Squared Error (MSE) in the density matrix.
http://w3id.org/mlsea/pwc/scientificWork/Alternative%20Speech%3A%20Complementary%20Method%20to%20Counter-Narrative%20for%20Better%20Discourse                                                                                  Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse                                                                                  We introduce the concept of 'Alternative Speech' as a new way to directly combat hate speech and complement the limitations of counter-narrative. An alternative speech provides practical alternatives to hate speech in real-world scenarios by offering speech-level corrections to speakers while considering the surrounding context and promoting speakers to reform. Further, an alternative speech can combat hate speech alongside counter-narratives, offering a useful tool to address social issues such as racial discrimination and gender inequality. We propose the new concept and provide detailed guidelines for constructing the necessary dataset. Through discussion, we demonstrate that combining alternative speech and counter-narrative can be a more effective strategy for combating hate speech by complementing specificity and guiding capacity of counter-narrative. This paper presents another perspective for dealing with hate speech, offering viable remedies to complement the constraints of current approaches to mitigating harmful bias.
http://w3id.org/mlsea/pwc/scientificWork/Alternatives%20to%20classical%20option%20pricing                                                                                  Alternatives to classical option pricing                                                                                  We develop two alternate approaches to arbitrage-free, market-complete, option pricing. The first approach requires no riskless asset. We develop the general framework for this approach and illustrate it with two specific examples. The second approach does use a riskless asset. However, by ensuring equality between real-world and risk-neutral price-change probabilities, the second approach enables the computation of risk-neutral option prices utilizing expectations under the natural world probability P. This produces the same option prices as the classical approach in which prices are computed under the risk neutral measure Q. The second approach and the two specific examples of the first approach require the introduction of new, marketable asset types, specifically perpetual derivatives of a stock, and a stock whose cumulative return (rather than price) is deflated.
http://w3id.org/mlsea/pwc/scientificWork/Alzheimer%27s%20disease%20detection%20in%20PSG%20signals                                                                                  Alzheimer's disease detection in PSG signals                                                                                  Alzheimer's disease (AD) and sleep disorders exhibit a close association, where disruptions in sleep patterns often precede the onset of Mild Cognitive Impairment (MCI) and early-stage AD. This study delves into the potential of utilizing sleep-related electroencephalography (EEG) signals acquired through polysomnography (PSG) for the early detection of AD. Our primary focus is on exploring semi-supervised Deep Learning techniques for the classification of EEG signals due to the clinical scenario characterized by the limited data availability. The methodology entails testing and comparing the performance of semi-supervised SMATE and TapNet models, benchmarked against the supervised XCM model, and unsupervised Hidden Markov Models (HMMs). The study highlights the significance of spatial and temporal analysis capabilities, conducting independent analyses of each sleep stage. Results demonstrate the effectiveness of SMATE in leveraging limited labeled data, achieving stable metrics across all sleep stages, and reaching 90% accuracy in its supervised form. Comparative analyses reveal SMATE's superior performance over TapNet and HMM, while XCM excels in supervised scenarios with an accuracy range of 92 - 94%. These findings underscore the potential of semi-supervised models in early AD detection, particularly in overcoming the challenges associated with the scarcity of labeled data. Ablation tests affirm the critical role of spatio-temporal feature extraction in semi-supervised predictive performance, and t-SNE visualizations validate the model's proficiency in distinguishing AD patterns. Overall, this research contributes to the advancement of AD detection through innovative Deep Learning approaches, highlighting the crucial role of semi-supervised learning in addressing data limitations.
http://w3id.org/mlsea/pwc/scientificWork/Amazon%20rainforest%20photosynthesis%20increases%20in%20response%20to%20atmospheric%20dryness                                                                                  Amazon rainforest photosynthesis increases in response to atmospheric dryness                                                                                  Earth system models predict that increases in atmospheric and soil dryness will reduce photosynthesis in the Amazon rainforest, with large implications for the global carbon cycle. Using in situ observations, solar-induced fluorescence, and nonlinear machine learning techniques, we show that, in reality, this is not necessarily the case: In many of the wettest parts of this region, photosynthesis and biomass tend to increase with increased atmo- spheric dryness, despite the associated reductions in canopy conductance to CO2. These results can be largely explained by changes in canopy properties, specifically, new leaves flushed during the dry season have higher photosynthetic capacity than the leaves they replace, compensating for the negative stomatal response to in- creased dryness. As atmospheric dryness will increase with climate change, our study highlights the importance of reframing how we represent the response of ecosystem photosynthesis to atmospheric dryness in very wet regions, to accurately quantify the land carbon sink.
http://w3id.org/mlsea/pwc/scientificWork/Amazon%27s%202023%20Drought%3A%20Sentinel-1%20Reveals%20Extreme%20Rio%20Negro%20River%20Contraction                                                                                  Amazon's 2023 Drought: Sentinel-1 Reveals Extreme Rio Negro River Contraction                                                                                  The Amazon, the world's largest rainforest, faces a severe historic drought. The Rio Negro River, one of the major Amazon River tributaries, reaches its lowest level in a century in October 2023. Here, we used a U-net deep learning model to map water surfaces in the Rio Negro River basin every 12 days in 2022 and 2023 using 10 m spatial resolution Sentinel-1 satellite radar images. The accuracy of the water surface model was high with an F1-score of 0.93. The 12 days mosaic time series of water surface was generated from the Sentinel-1 prediction. The water surface mask demonstrated relatively consistent agreement with the Global Surface Water (GSW) product from Joint Research Centre (F1-score: 0.708) and with the Brazilian Mapbiomas Water initiative (F1-score: 0.686). The main errors of the map were omission errors in flooded woodland, in flooded shrub and because of clouds. Rio Negro water surfaces reached their lowest level around the 25th of November 2023 and were reduced to 68.1 % (9,559.9 km$^2$) of the maximum water surfaces observed in the period 2022-2023 (14,036.3 km$^2$). Synthetic Aperture Radar (SAR) data, in conjunction with deep learning techniques, can significantly improve near real-time mapping of water surface in tropical regions.
http://w3id.org/mlsea/pwc/scientificWork/Ambisonics%20Encoding%20For%20Arbitrary%20Microphone%20Arrays%20Incorporating%20Residual%20Channels%20For%20Binaural%20Reproduction                                                                                  Ambisonics Encoding For Arbitrary Microphone Arrays Incorporating Residual Channels For Binaural Reproduction                                                                                  In the rapidly evolving fields of virtual and augmented reality, accurate spatial audio capture and reproduction are essential. For these applications, Ambisonics has emerged as a standard format. However, existing methods for encoding Ambisonics signals from arbitrary microphone arrays face challenges, such as errors due to the irregular array configurations and limited spatial resolution resulting from a typically small number of microphones. To address these limitations and challenges, a mathematical framework for studying Ambisonics encoding is presented, highlighting the importance of incorporating the full steering function, and providing a novel measure for predicting the accuracy of encoding each Ambisonics channel from the steering functions alone. Furthermore, novel residual channels are formulated supplementing the Ambisonics channels. A simulation study for several array configurations demonstrates a reduction in binaural error for this approach.
http://w3id.org/mlsea/pwc/scientificWork/Amharic%20LLaMA%20and%20LLaVA%3A%20Multimodal%20LLMs%20for%20Low%20Resource%20Languages                                                                                  Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages                                                                                  Large Language Models (LLMs) like GPT-4 and LLaMA have shown incredible proficiency at natural language processing tasks and have even begun to excel at tasks across other modalities such as vision and audio. Despite their success, LLMs often struggle to perform well on low-resource languages because there is so little training data available. This shortcoming is especially prevalent with open source models. In this work, we explore training LLaMA-2 to speak Amharic, a language which is spoken by over 50 million people world wide, but has orders of magnitude less data available than languages like English. We employ methods previously used for training LLMs on other languages with data scarcity, and use open source translation models to perform data augmentation and grow our dataset from millions of tokens to billions. We further enhance the capabilities of our model by connecting an image encoder and training on a translated visual instruction tuning dataset in the same manner as LLaVA, resulting in a multimodal Amharic LLM that can understand images along with text. We introduce an Amharic version of a popular benchmarking dataset to evaluate our work. Our models and dataset are open sourced and available on GitHub.
http://w3id.org/mlsea/pwc/scientificWork/Amplifiers%20of%20selection%20for%20the%20Moran%20process%20with%20both%20Birth-death%20and%20death-Birth%20updating                                                                                  Amplifiers of selection for the Moran process with both Birth-death and death-Birth updating                                                                                  Populations evolve by accumulating advantageous mutations. Every population has some spatial structure that can be modeled by an underlying network. The network then influences the probability that new advantageous mutations fixate. Amplifiers of selection are networks that increase the fixation probability of advantageous mutants, as compared to the unstructured fully-connected network. Whether or not a network is an amplifier depends on the choice of the random process that governs the evolutionary dynamics. Two popular choices are Moran process with Birth-death updating and Moran process with death-Birth updating. %Moran process has two popular versions called Birth-death updating and death-Birth updating. Interestingly, while some networks are amplifiers under Birth-death updating and other networks are amplifiers under death-Birth updating, no network is known to function as an amplifier under both types of updating simultaneously. In this work, we identify networks that act as amplifiers of selection under both versions of the Moran process. The amplifiers are robust, modular, and increase fixation probability for any mutant fitness advantage in a range $r in(1,1.2)$. To complement this positive result, we also prove that for certain quantities closely related to fixation probability, it is impossible to improve them simultaneously for both versions of the Moran process. Together, our results highlight how the two versions of the Moran process differ and what they have in common.
http://w3id.org/mlsea/pwc/scientificWork/Amplifying%20Training%20Data%20Exposure%20through%20Fine-Tuning%20with%20Pseudo-Labeled%20Memberships                                                                                  Amplifying Training Data Exposure through Fine-Tuning with Pseudo-Labeled Memberships                                                                                  Neural language models (LMs) are vulnerable to training data extraction attacks due to data memorization. This paper introduces a novel attack scenario wherein an attacker adversarially fine-tunes pre-trained LMs to amplify the exposure of the original training data. This strategy differs from prior studies by aiming to intensify the LM's retention of its pre-training dataset. To achieve this, the attacker needs to collect generated texts that are closely aligned with the pre-training data. However, without knowledge of the actual dataset, quantifying the amount of pre-training data within generated texts is challenging. To address this, we propose the use of pseudo-labels for these generated texts, leveraging membership approximations indicated by machine-generated probabilities from the target LM. We subsequently fine-tune the LM to favor generations with higher likelihoods of originating from the pre-training data, based on their membership probabilities. Our empirical findings indicate a remarkable outcome: LMs with over 1B parameters exhibit a four to eight-fold increase in training data exposure. We discuss potential mitigations and suggest future research directions.
http://w3id.org/mlsea/pwc/scientificWork/An%20ADRC-Incorporated%20Stochastic%20Gradient%20Descent%20Algorithm%20for%20Latent%20Factor%20Analysis                                                                                  An ADRC-Incorporated Stochastic Gradient Descent Algorithm for Latent Factor Analysis                                                                                  High-dimensional and incomplete (HDI) matrix contains many complex interactions between numerous nodes. A stochastic gradient descent (SGD)-based latent factor analysis (LFA) model is remarkably effective in extracting valuable information from an HDI matrix. However, such a model commonly encounters the problem of slow convergence because a standard SGD algorithm only considers the current learning error to compute the stochastic gradient without considering the historical and future state of the learning error. To address this critical issue, this paper innovatively proposes an ADRC-incorporated SGD (ADS) algorithm by refining the instance learning error by considering the historical and future state by following the principle of an ADRC controller. With it, an ADS-based LFA model is further achieved for fast and accurate latent factor analysis on an HDI matrix. Empirical studies on two HDI datasets demonstrate that the proposed model outperforms the state-of-the-art LFA models in terms of computational efficiency and accuracy for predicting the missing data of an HDI matrix.
http://w3id.org/mlsea/pwc/scientificWork/An%20AIC-based%20approach%20for%20articulating%20unpredictable%20problems%20in%20open%20complex%20environments                                                                                  An AIC-based approach for articulating unpredictable problems in open complex environments                                                                                  This research paper presents an approach to enhancing the predictive capability of architects in the design and assurance of systems, focusing on systems operating in dynamic and unpredictable environments. By adopting a systems approach, we aim to improve architects' predictive capabilities in designing dependable systems (for example, ML-based systems). An aerospace case study is used to illustrate the approach. Multiple factors (challenges) influencing aircraft detection are identified, demonstrating the effectiveness of our approach in a complex operational setting. Our approach primarily aimed to enhance the architect's predictive capability.
http://w3id.org/mlsea/pwc/scientificWork/An%20Accelerated%20Gradient%20Method%20for%20Simple%20Bilevel%20Optimization%20with%20Convex%20Lower-level%20Problem                                                                                  An Accelerated Gradient Method for Simple Bilevel Optimization with Convex Lower-level Problem                                                                                  In this paper, we focus on simple bilevel optimization problems, where we minimize a convex smooth objective function over the optimal solution set of another convex smooth constrained optimization problem. We present a novel bilevel optimization method that locally approximates the solution set of the lower-level problem using a cutting plane approach and employs an accelerated gradient-based update to reduce the upper-level objective function over the approximated solution set. We measure the performance of our method in terms of suboptimality and infeasibility errors and provide non-asymptotic convergence guarantees for both error criteria. Specifically, when the feasible set is compact, we show that our method requires at most $ mathcal{O}( max {1/ sqrt{ epsilon_{f}}, 1/ epsilon_g })$ iterations to find a solution that is $ epsilon_f$-suboptimal and $ epsilon_g$-infeasible. Moreover, under the additional assumption that the lower-level objective satisfies the $r$-th H 'olderian error bound, we show that our method achieves an iteration complexity of $ mathcal{O}( max { epsilon_{f}^{- frac{2r-1}{2r}}, epsilon_{g}^{- frac{2r-1}{2r}} })$, which matches the optimal complexity of single-level convex constrained optimization when $r=1$.
http://w3id.org/mlsea/pwc/scientificWork/An%20Active%20Contour%20Model%20Using%20Matched%20Filter%20and%20Hessian%20Matrix%20for%20Retinal%20Vessels%20Segmentation                                                                                  An Active Contour Model Using Matched Filter and Hessian Matrix for Retinal Vessels Segmentation                                                                                  Medical image analysis, especially of the retina, plays an important role in diagnostic decision support tools. The properties of retinal blood vessels are used for disease diagnoses such as diabetes, glaucoma, and hypertension. There are some challenges in the utilization of retinal blood vessel patterns such as low contrast and intensity inhomogeneities. Thus, an automatic algorithm for vessel extraction is required. Active contour is a strong method for edge extraction. However, it cannot extract thin vessels and ridges very well. In this research, we propose an improved active contour method that uses discrete wavelet transform for energy minimization to solve this problem. The minimization formula terminates segmentation into two regions, foreground and background. We found out that foreground pixels are more important than background. Therefore, we change the minimization formulation in such a way that gives more weight to the foreground. The contour edge has orientation in each region. The wavelet terms in the minimization formula help to detect edge direction in horizontal, vertical, and diagonal orientations. Since bright and dark lesions do not have direction, these terms can decrease false vessel detection. The second part of the innovation is called the optimization process, which works instead of reinitialization. Sometimes, the evolution in the iterated process destroys the stability of the evolution. To prevent the destruction of the stability of evolution, we used an optimization process formula whose task is to keep contour on the edges of the image. The performance of the proposed algorithms is compared and analyzed on five databases. The values achieved are 94.3%, 73.36%, and 97.41% for accuracy, sensitivity, and specificity, respectively, on the DRIVE dataset, and the proposed algorithm is comparable to the state-of-the-art approaches.
http://w3id.org/mlsea/pwc/scientificWork/An%20Actuator%20with%20Magnetic%20Restoration%2C%20Part%20I%3A%20Electromechanical%20Model%20and%20Identification                                                                                  An Actuator with Magnetic Restoration, Part I: Electromechanical Model and Identification                                                                                  Electromechanical models are crucial in the design and control of motors and actuators. Modeling, identification, drive, and current control loop of a limited-rotation actuator with magnetic restoration is presented. New nonlinear and linearized electromechanical models are developed for the design of the drive as well as small and large signal controls of the actuator. To attain a higher accuracy and an efficient design, and the eddy-currents in the laminations and magnet are modeled. This involves analytically solving 1-D and 2-D diffusion equations, leading to the derivation of a lumped-element circuit for system-level analyses, such as control system design. Additionally, the study analyzes and incorporates the impact of pre-sliding friction. The actuator is prototyped, and the paper delves into the identification of the model, presenting a procedure for parameter extraction. A close agreement is observed between the results obtained from the model, finite element analysis, and experimental results. The superiority of the proposed model over previous approaches is highlighted. Part II of the paper is dedicated to the drive circuit, the current control, as well as linear and nonlinear position control system designs.
http://w3id.org/mlsea/pwc/scientificWork/An%20Analytical%20Framework%20for%20Modeling%20and%20Synthesizing%20Malicious%20Attacks%20on%20ACC%20Vehicles                                                                                  An Analytical Framework for Modeling and Synthesizing Malicious Attacks on ACC Vehicles                                                                                  While emerging adaptive cruise control (ACC) technologies are making their way into more vehicles, they also expose a vulnerability to potential malicious cyberattacks. Previous research has typically focused on constant or stochastic attacks without explicitly addressing their malicious and covert characteristics. As a result, these attacks may inadvertently benefit the compromised vehicles, inconsistent with real-world scenarios. In contrast, we establish an analytical framework to model and synthesize a range of candidate attacks, offering a physical interpretation from the attacker's standpoint. Specifically, we introduce a mathematical framework that describes mixed traffic scenarios, comprising ACC vehicles and human-driven vehicles (HDVs), grounded in car-following dynamics. Within this framework, we synthesize and integrate a class of false data injection attacks into ACC sensor measurements, influencing traffic flow dynamics. As a first-of-its-kind study, this work provides an analytical characterization of attacks, emphasizing their malicious and stealthy attributes while explicitly accounting for vehicle driving behavior, thereby yielding a set of candidate attacks with physical interpretability. To demonstrate the modeling process, we perform a series of numerical simulations to holistically assess the effects of attacks on car-following dynamics, traffic efficiency, and vehicular fuel consumption. The primary findings indicate that strategically synthesized candidate attacks can cause significant disruptions to the traffic flow while altering the driving behavior of ACC vehicles in a subtle fashion to remain stealthy, which is supported by a series of analytical results.
http://w3id.org/mlsea/pwc/scientificWork/An%20Analytical%20Model%20for%20Coordinated%20Multi-Satellite%20Joint%20Transmission%20System                                                                                  An Analytical Model for Coordinated Multi-Satellite Joint Transmission System                                                                                  Satellite communication is one of the key technologies that is enabling next-generation networks. However, nearest-satellite-supported downlink transmission may not meet a user's requirements due to limited signal strength, especially in emergent scenarios. In this paper, we investigate a coordinated multi-satellite joint transmission system from a system-level perspective, where a user can be served by multiple satellites to improve its quality-of-service (QoS). Furthermore, we analyze the coverage and rate of a typical user in the joint transmission system. Simulation and numerical results show that the introduced system achieves a higher coverage probability than the traditional nearest-satellite-supported network. Moreover, a user's ergodic rate can be maximized by selecting an appropriate number of serving satellites.
http://w3id.org/mlsea/pwc/scientificWork/An%20Axiomatic%20Approach%20to%20Model-Agnostic%20Concept%20Explanations                                                                                  An Axiomatic Approach to Model-Agnostic Concept Explanations                                                                                  Concept explanation is a popular approach for examining how human-interpretable concepts impact the predictions of a model. However, most existing methods for concept explanations are tailored to specific models. To address this issue, this paper focuses on model-agnostic measures. Specifically, we propose an approach to concept explanations that satisfy three natural axioms: linearity, recursivity, and similarity. We then establish connections with previous concept explanation methods, offering insight into their varying semantic meanings. Experimentally, we demonstrate the utility of the new method by applying it in different scenarios: for model selection, optimizer selection, and model improvement using a kind of prompt editing for zero-shot vision language models.
http://w3id.org/mlsea/pwc/scientificWork/An%20EcoSage%20Assistant%3A%20Towards%20Building%20A%20Multimodal%20Plant%20Care%20Dialogue%20Assistant                                                                                  An EcoSage Assistant: Towards Building A Multimodal Plant Care Dialogue Assistant                                                                                  In recent times, there has been an increasing awareness about imminent environmental challenges, resulting in people showing a stronger dedication to taking care of the environment and nurturing green life. The current $19.6 billion indoor gardening industry, reflective of this growing sentiment, not only signifies a monetary value but also speaks of a profound human desire to reconnect with the natural world. However, several recent surveys cast a revealing light on the fate of plants within our care, with more than half succumbing primarily due to the silent menace of improper care. Thus, the need for accessible expertise capable of assisting and guiding individuals through the intricacies of plant care has become paramount more than ever. In this work, we make the very first attempt at building a plant care assistant, which aims to assist people with plant(-ing) concerns through conversations. We propose a plant care conversational dataset named Plantational, which contains around 1K dialogues between users and plant care experts. Our end-to-end proposed approach is two-fold : (i) We first benchmark the dataset with the help of various large language models (LLMs) and visual language model (VLM) by studying the impact of instruction tuning (zero-shot and few-shot prompting) and fine-tuning techniques on this task; (ii) finally, we build EcoSage, a multi-modal plant care assisting dialogue generation framework, incorporating an adapter-based modality infusion using a gated mechanism. We performed an extensive examination (both automated and manual evaluation) of the performance exhibited by various LLMs and VLM in the generation of the domain-specific dialogue responses to underscore the respective strengths and weaknesses of these diverse models.
http://w3id.org/mlsea/pwc/scientificWork/An%20Effective%20Index%20for%20Truss-based%20Community%20Search%20on%20Large%20Directed%20Graphs                                                                                  An Effective Index for Truss-based Community Search on Large Directed Graphs                                                                                  Community search is a derivative of community detection that enables online and personalized discovery of communities and has found extensive applications in massive real-world networks. Recently, there needs to be more focus on the community search issue within directed graphs, even though substantial research has been carried out on undirected graphs. The recently proposed D-truss model has achieved good results in the quality of retrieved communities. However, existing D-truss-based work cannot perform efficient community searches on large graphs because it consumes too many computing resources to retrieve the maximal D-truss. To overcome this issue, we introduce an innovative merge relation known as D-truss-connected to capture the inherent density and cohesiveness of edges within D-truss. This relation allows us to partition all the edges in the original graph into a series of D-truss-connected classes. Then, we construct a concise and compact index, ConDTruss, based on D-truss-connected. Using ConDTruss, the efficiency of maximum D-truss retrieval will be greatly improved, making it a theoretically optimal approach. Experimental evaluations conducted on large directed graph certificate the effectiveness of our proposed method.
http://w3id.org/mlsea/pwc/scientificWork/An%20Effective%20Networks%20Intrusion%20Detection%20Approach%20Based%20on%20Hybrid%20Harris%20Hawks%20and%20Multi-Layer%20Perceptron                                                                                  An Effective Networks Intrusion Detection Approach Based on Hybrid Harris Hawks and Multi-Layer Perceptron                                                                                  This paper proposes an Intrusion Detection System (IDS) employing the Harris Hawks Optimization algorithm (HHO) to optimize Multilayer Perceptron learning by optimizing bias and weight parameters. HHO-MLP aims to select optimal parameters in its learning process to minimize intrusion detection errors in networks. HHO-MLP has been implemented using EvoloPy NN framework, an open-source Python tool specialized for training MLPs using evolutionary algorithms. For purposes of comparing the HHO model against other evolutionary methodologies currently available, specificity and sensitivity measures, accuracy measures, and mse and rmse measures have been calculated using KDD datasets. Experiments have demonstrated the HHO MLP method is effective at identifying malicious patterns. HHO-MLP has been tested against evolutionary algorithms like Butterfly Optimization Algorithm (BOA), Grasshopper Optimization Algorithms (GOA), and Black Widow Optimizations (BOW), with validation by Random Forest (RF), XG-Boost. HHO-MLP showed superior performance by attaining top scores with accuracy rate of 93.17%, sensitivity level of 89.25%, and specificity percentage of 95.41%.
http://w3id.org/mlsea/pwc/scientificWork/An%20Efficient%20Algorithm%20for%20Spatial-Spectral%20Partial%20Volume%20Compartment%20Mapping%20with%20Applications%20to%20Multicomponent%20Diffusion%20and%20Relaxation%20MRI                                                                                  An Efficient Algorithm for Spatial-Spectral Partial Volume Compartment Mapping with Applications to Multicomponent Diffusion and Relaxation MRI                                                                                  It has been previously shown that high-quality partial volume tissue compartment maps can be obtained by combining multiparametric contrast-encoded MRI data acquisition methods with spatially-regularized spectroscopic image estimation techniques. However, the advantages of this combined approach generally come at the expense of substantial computational complexity. In this work, we propose a new algorithm to solve this kind of estimation problem more efficiently. Our algorithm is based on the linearized alternating directions method of multipliers (LADMM), and relies on the introduction of novel quadratic penalty terms to substantially simplify the subproblems that must be solved at each iteration. We evaluate this algorithm on a variety of different estimation problems (diffusion-relaxation, relaxation-relaxation, relaxometry, and magnetic resonance fingerprinting), where we consistently observe substantial (roughly 5$ times$-80$ times$) speed improvements. We expect that this new faster algorithm will lower practical barriers to using spatial regularization and multiparametric contrast-encoded MRI data acquisition methods for partial volume compartment mapping.
http://w3id.org/mlsea/pwc/scientificWork/An%20Efficient%20Risk-aware%20Branch%20MPC%20for%20Automated%20Driving%20that%20is%20Robust%20to%20Uncertain%20Vehicle%20Behaviors                                                                                  An Efficient Risk-aware Branch MPC for Automated Driving that is Robust to Uncertain Vehicle Behaviors                                                                                  One of the critical challenges in automated driving is ensuring safety of automated vehicles despite the unknown behavior of the other vehicles. Although motion prediction modules are able to generate a probability distribution associated with various behavior modes, their probabilistic estimates are often inaccurate, thus leading to a possibly unsafe trajectory. To overcome this challenge, we propose a risk-aware motion planning framework that appropriately accounts for the ambiguity in the estimated probability distribution. We formulate the risk-aware motion planning problem as a min-max optimization problem and develop an efficient iterative method by incorporating a regularization term in the probability update step. Via extensive numerical studies, we validate the convergence of our method and demonstrate its advantages compared to the state-of-the-art approaches.
http://w3id.org/mlsea/pwc/scientificWork/An%20Embeddable%20Implicit%20IUVD%20Representation%20for%20Part-based%203D%20Human%20Surface%20Reconstruction                                                                                  An Embeddable Implicit IUVD Representation for Part-based 3D Human Surface Reconstruction                                                                                  To reconstruct a 3D human surface from a single image, it is important to consider human pose, shape and clothing details simultaneously. In recent years, a combination of parametric body models (such as SMPL) that capture body pose and shape prior, and neural implicit functions that learn flexible clothing details, has been used to integrate the advantages of both approaches. However, the combined representation introduces additional computation, e.g. signed distance calculation, in 3D body feature extraction, which exacerbates the redundancy of the implicit query-and-infer process and fails to preserve the underlying body shape prior. To address these issues, we propose a novel IUVD-Feedback representation, which consists of an IUVD occupancy function and a feedback query algorithm. With this representation, the time-consuming signed distance calculation is replaced by a simple linear transformation in the IUVD space, leveraging the SMPL UV maps. Additionally, the redundant query points in the query-and-infer process are reduced through a feedback mechanism. This leads to more reasonable 3D body features and more effective query points, successfully preserving the parametric body prior. Moreover, the IUVD-Feedback representation can be embedded into any existing implicit human reconstruction pipelines without modifying the trained neural networks. Experiments on THuman2.0 dataset demonstrate that the proposed IUVD-Feedback representation improves result robustness and achieves three times faster acceleration in the query-and-infer process. Furthermore, this representation has the potential to be used in generative applications by leveraging its inherited semantic information from the parametric body model.
http://w3id.org/mlsea/pwc/scientificWork/An%20Emotion%20Recognition%20Embedded%20System%20using%20a%20Lightweight%20Deep%20Learning%20Model                                                                                  An Emotion Recognition Embedded System using a Lightweight Deep Learning Model                                                                                  Diagnosing emotional states would improve humanâcomputer interaction (HCI) systems to be more effective in practice. Correlations between Electroencephalography (EEG) signals and emotions have been shown in various research; therefore, EEG signalâbased methods are the most accurate and informative. Methods: In this study, three Convolutional Neural Network (CNN) models, EEGNet, ShallowConvNet and DeepConvNet, which are appropriate for processing EEG signals, are applied to diagnose emotions. We use baseline removal preprocessing to improve classification accuracy. Each network is assessed in two setting ways: subjectâdependent and subjectâindependent. We improve the selected CNN model to be lightweight and implementable on a Raspberry Pi processor. The emotional states are recognized for every threeâsecond epoch of received signals on the embedded system, which can be applied in realâtime usage in practice. Results: Average classification accuracies of 99.10% in the valence and 99.20% in the arousal for subjectâdependent and 90.76% in the valence and 90.94% in the arousal for subject independent were achieved on the wellâknown DEAP dataset. Conclusion: Comparison of the results with the related works shows that a highly accurate and implementable model has been achieved for practice.
http://w3id.org/mlsea/pwc/scientificWork/An%20Empirical%20Analysis%20of%20Diversity%20in%20Argument%20Summarization                                                                                  An Empirical Analysis of Diversity in Argument Summarization                                                                                  Presenting high-level arguments is a crucial task for fostering participation in online societal discussions. Current argument summarization approaches miss an important facet of this task -- capturing diversity -- which is important for accommodating multiple perspectives. We introduce three aspects of diversity: those of opinions, annotators, and sources. We evaluate approaches to a popular argument summarization task called Key Point Analysis, which shows how these approaches struggle to (1) represent arguments shared by few people, (2) deal with data from various sources, and (3) align with subjectivity in human-provided annotations. We find that both general-purpose LLMs and dedicated KPA models exhibit this behavior, but have complementary strengths. Further, we observe that diversification of training data may ameliorate generalization. Addressing diversity in argument summarization requires a mix of strategies to deal with subjectivity.
http://w3id.org/mlsea/pwc/scientificWork/An%20Empirical%20Study%20Into%20What%20Matters%20for%20Calibrating%20Vision-Language%20Models                                                                                  An Empirical Study Into What Matters for Calibrating Vision-Language Models                                                                                  Vision--Language Models (VLMs) have emerged as the dominant approach for zero-shot recognition, adept at handling diverse scenarios and significant distribution changes. However, their deployment in risk-sensitive areas requires a deeper understanding of their uncertainty estimation capabilities, a relatively uncharted area. In this study, we explore the calibration properties of VLMs across different architectures, datasets, and training strategies. In particular, we analyze the uncertainty estimation performance of VLMs when calibrated in one domain, label set or hierarchy level, and tested in a different one. Our findings reveal that while VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration, even across shifts in distribution and changes in label set. Moreover, VLMs can be calibrated with a very small set of examples. Through detailed experimentation, we highlight the potential applications and importance of our insights, aiming for more reliable and effective use of VLMs in critical, real-world scenarios.
http://w3id.org/mlsea/pwc/scientificWork/An%20Empirical%20Study%20of%20In-context%20Learning%20in%20LLMs%20for%20Machine%20Translation                                                                                  An Empirical Study of In-context Learning in LLMs for Machine Translation                                                                                  Recent interest has surged in employing Large Language Models (LLMs) for machine translation (MT) via in-context learning (ICL) (Vilar et al., 2023). Most prior studies primarily focus on optimizing translation quality, with limited attention to understanding the specific aspects of ICL that influence the said quality. To this end, we perform the first of its kind, exhaustive study of in-context learning for machine translation. We first establish that ICL is primarily example-driven and not instruction-driven. Following this, we conduct an extensive exploration of various aspects of the examples to understand their influence on downstream performance. Our analysis includes factors such as quality and quantity of demonstrations, spatial proximity, and source versus target originality. Further, we also investigate challenging scenarios involving indirectness and misalignment of examples to understand the limits of ICL. While we establish the significance of the quality of the target distribution over the source distribution of demonstrations, we further observe that perturbations sometimes act as regularizers, resulting in performance improvements. Surprisingly, ICL does not necessitate examples from the same task, and a related task with the same target distribution proves sufficient. We hope that our study acts as a guiding resource for considerations in utilizing ICL for MT.
http://w3id.org/mlsea/pwc/scientificWork/An%20Empirical%20Study%20of%20LLM-as-a-Judge%20for%20LLM%20Evaluation%3A%20Fine-tuned%20Judge%20Models%20are%20Task-specific%20Classifiers                                                                                  An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are Task-specific Classifiers                                                                                  Recently, there has been a growing trend of utilizing Large Language Model (LLM) to evaluate the quality of other LLMs. Many studies have employed proprietary close-source models, especially GPT4, as the evaluator. Alternatively, other works have fine-tuned judge models based on open-source LLMs as the evaluator. In this study, we conduct an empirical study of different judge models on their evaluation capability. Our findings indicate that although the fine-tuned judge models achieve high accuracy on in-domain test sets, even surpassing GPT4, they are inherently task-specific classifiers, and their generalizability and fairness severely underperform GPT4.
http://w3id.org/mlsea/pwc/scientificWork/An%20Empirical%20Study%20of%20the%20Generalization%20Ability%20of%20Lidar%203D%20Object%20Detectors%20to%20Unseen%20Domains                                                                                  An Empirical Study of the Generalization Ability of Lidar 3D Object Detectors to Unseen Domains                                                                                  3D Object Detectors (3D-OD) are crucial for understanding the environment in many robotic tasks, especially autonomous driving. Including 3D information via Lidar sensors improves accuracy greatly. However, such detectors perform poorly on domains they were not trained on, i.e. different locations, sensors, weather, etc., limiting their reliability in safety-critical applications. There exist methods to adapt 3D-ODs to these domains; however, these methods treat 3D-ODs as a black box, neglecting underlying architectural decisions and source-domain training strategies. Instead, we dive deep into the details of 3D-ODs, focusing our efforts on fundamental factors that influence robustness prior to domain adaptation. We systematically investigate four design choices (and the interplay between them) often overlooked in 3D-OD robustness and domain adaptation: architecture, voxel encoding, data augmentations, and anchor strategies. We assess their impact on the robustness of nine state-of-the-art 3D-ODs across six benchmarks encompassing three types of domain gaps - sensor type, weather, and location. Our main findings are: (1) transformer backbones with local point features are more robust than 3D CNNs, (2) test-time anchor size adjustment is crucial for adaptation across geographical locations, significantly boosting scores without retraining, (3) source-domain augmentations allow the model to generalize to low-resolution sensors, and (4) surprisingly, robustness to bad weather is improved when training directly on more clean weather data than on training with bad weather data. We outline our main conclusions and findings to provide practical guidance on developing more robust 3D-ODs.
http://w3id.org/mlsea/pwc/scientificWork/An%20EnKF-LSTM%20Assimilation%20Algorithm%20for%20Crop%20Growth%20Model                                                                                  An EnKF-LSTM Assimilation Algorithm for Crop Growth Model                                                                                  Accurate and timely prediction of crop growth is of great significance to ensure crop yields and researchers have developed several crop models for the prediction of crop growth. However, there are large difference between the simulation results obtained by the crop models and the actual results, thus in this paper, we proposed to combine the simulation results with the collected crop data for data assimilation so that the accuracy of prediction will be improved. In this paper, an EnKF-LSTM data assimilation method for various crops is proposed by combining ensemble Kalman filter and LSTM neural network, which effectively avoids the overfitting problem of existing data assimilation methods and eliminates the uncertainty of the measured data. The verification of the proposed EnKF-LSTM method and the comparison of the proposed method with other data assimilation methods were performed using datasets collected by sensor equipment deployed on a farm.
http://w3id.org/mlsea/pwc/scientificWork/An%20End-to-End%20Structure%20with%20Novel%20Position%20Mechanism%20and%20Improved%20EMD%20for%20Stock%20Forecasting                                                                                  An End-to-End Structure with Novel Position Mechanism and Improved EMD for Stock Forecasting                                                                                  As a branch of time series forecasting, stock movement forecasting is one of the challenging problems for investors and researchers. Since Transformer was introduced to analyze financial data, many researchers have dedicated themselves to forecasting stock movement using Transformer or attention mechanisms. However, existing research mostly focuses on individual stock information but ignores stock market information and high noise in stock data. In this paper, we propose a novel method using the attention mechanism in which both stock market information and individual stock information are considered. Meanwhile, we propose a novel EMD-based algorithm for reducing short-term noise in stock data. Two randomly selected exchange-traded funds (ETFs) spanning over ten years from US stock markets are used to demonstrate the superior performance of the proposed attention-based method. The experimental analysis demonstrates that the proposed attention-based method significantly outperforms other state-of-the-art baselines. Code is available at https://github.com/DurandalLee/ACEFormer.
http://w3id.org/mlsea/pwc/scientificWork/An%20Enhanced%20Analysis%20of%20Traffic%20Intelligence%20in%20Smart%20Cities%20Using%20Sustainable%20Deep%20Radial%20Function                                                                                  An Enhanced Analysis of Traffic Intelligence in Smart Cities Using Sustainable Deep Radial Function                                                                                  Smart cities have revolutionized urban living by incorporating sophisticated technologies to optimize various aspects of urban infrastructure, such as transportation systems. Effective traffic management is a crucial component of smart cities, as it has a direct impact on the quality of life of residents and tourists. Utilizing deep radial basis function (RBF) networks, this paper describes a novel strategy for enhancing traffic intelligence in smart cities. Traditional methods of traffic analysis frequently rely on simplistic models that are incapable of capturing the intricate patterns and dynamics of urban traffic systems. Deep learning techniques, such as deep RBF networks, have the potential to extract valuable insights from traffic data and enable more precise predictions and decisions. In this paper, we propose an RBF based method for enhancing smart city traffic intelligence. Deep RBF networks combine the adaptability and generalization capabilities of deep learning with the discriminative capability of radial basis functions. The proposed method can effectively learn intricate relationships and nonlinear patterns in traffic data by leveraging the hierarchical structure of deep neural networks. The deep RBF model can learn to predict traffic conditions, identify congestion patterns, and make informed recommendations for optimizing traffic management strategies by incorporating these rich and diverse data To evaluate the efficacy of our proposed method, extensive experiments and comparisons with real world traffic datasets from a smart city environment were conducted. In terms of prediction accuracy and efficiency, the results demonstrate that the deep RBF based approach outperforms conventional traffic analysis methods. Smart city traffic intelligence is enhanced by the model capacity to capture nonlinear relationships and manage large scale data sets.
http://w3id.org/mlsea/pwc/scientificWork/An%20Ensemble%20Framework%20for%20Explainable%20Geospatial%20Machine%20Learning%20Models                                                                                  An Ensemble Framework for Explainable Geospatial Machine Learning Models                                                                                  Analyzing spatial varying effect is pivotal in geographic analysis. Yet, accurately capturing and interpreting this variability is challenging due to the complexity and non-linearity of geospatial data. Herein, we introduce an integrated framework that merges local spatial weighting scheme, Explainable Artificial Intelligence (XAI), and cutting-edge machine learning technologies to bridge the gap between traditional geographic analysis models and general machine learning approaches. Through tests on synthetic datasets, this framework is verified to enhance the interpretability and accuracy of predictions in both geographic regression and classification by elucidating spatial variability. It significantly boosts prediction precision, offering a novel approach to understanding spatial phenomena.
http://w3id.org/mlsea/pwc/scientificWork/An%20Evaluation%20of%20Real-time%20Adaptive%20Sampling%20Change%20Point%20Detection%20Algorithm%20using%20KCUSUM                                                                                  An Evaluation of Real-time Adaptive Sampling Change Point Detection Algorithm using KCUSUM                                                                                  Detecting abrupt changes in real-time data streams from scientific simulations presents a challenging task, demanding the deployment of accurate and efficient algorithms. Identifying change points in live data stream involves continuous scrutiny of incoming observations for deviations in their statistical characteristics, particularly in high-volume data scenarios. Maintaining a balance between sudden change detection and minimizing false alarms is vital. Many existing algorithms for this purpose rely on known probability distributions, limiting their feasibility. In this study, we introduce the Kernel-based Cumulative Sum (KCUSUM) algorithm, a non-parametric extension of the traditional Cumulative Sum (CUSUM) method, which has gained prominence for its efficacy in online change point detection under less restrictive conditions. KCUSUM splits itself by comparing incoming samples directly with reference samples and computes a statistic grounded in the Maximum Mean Discrepancy (MMD) non-parametric framework. This approach extends KCUSUM's pertinence to scenarios where only reference samples are available, such as atomic trajectories of proteins in vacuum, facilitating the detection of deviations from the reference sample without prior knowledge of the data's underlying distribution. Furthermore, by harnessing MMD's inherent random-walk structure, we can theoretically analyze KCUSUM's performance across various use cases, including metrics like expected delay and mean runtime to false alarms. Finally, we discuss real-world use cases from scientific simulations such as NWChem CODAR and protein folding data, demonstrating KCUSUM's practical effectiveness in online change point detection.
http://w3id.org/mlsea/pwc/scientificWork/An%20Execution-time-certified%20Riccati-based%20IPM%20Algorithm%20for%20RTI-based%20Input-constrained%20NMPC                                                                                  An Execution-time-certified Riccati-based IPM Algorithm for RTI-based Input-constrained NMPC                                                                                  Establishing an execution time certificate in deploying model predictive control (MPC) is a pressing and challenging requirement. As nonlinear MPC (NMPC) results in nonlinear programs, differing from quadratic programs encountered in linear MPC, deriving an execution time certificate for NMPC seems an impossible task. Our prior work cite{wu2023direct} introduced an input-constrained MPC algorithm with the exact and only textit{dimension-dependent} ( textit{data-independent}) number of floating-point operations ([flops]). This paper extends it to input-constrained NMPC problems via the real-time iteration (RTI) scheme, which results in textit{data-varying} (but textit{dimension-invariant}) input-constrained MPC problems. Therefore, applying our previous algorithm can certify the execution time based on the assumption that processors perform fixed [flops] in constant time. As the RTI-based scheme generally results in MPC with a long prediction horizon, this paper employs the efficient factorized Riccati recursion, whose computational cost scales linearly with the prediction horizon, to solve the Newton system at each iteration. The execution-time certified capability of the algorithm is theoretically and numerically validated through a case study involving nonlinear control of the chaotic Lorenz system.
http://w3id.org/mlsea/pwc/scientificWork/An%20Experimental%20Study%20of%20Decentralized%20Matching                                                                                  An Experimental Study of Decentralized Matching                                                                                  We present an experimental study of decentralized two-sided matching markets with no transfers. Experimental participants are informed of everyone's preferences and can make arbitrary non-binding match offers that get finalized when a period of market inactivity has elapsed. Several insights emerge. First, stable outcomes are prevalent. Second, while centralized clearinghouses commonly aim at implementing extremal stable matchings, our decentralized markets most frequently culminate in the median stable matching. Third, preferences' cardinal representations impact the stable partners participants match with. Last, the dynamics underlying our results exhibit strategic sophistication, with agents successfully avoiding cycles of blocking pairs.
http://w3id.org/mlsea/pwc/scientificWork/An%20Exploratory%20Assessment%20of%20LLM%27s%20Potential%20Toward%20Flight%20Trajectory%20Reconstruction%20Analysis                                                                                  An Exploratory Assessment of LLM's Potential Toward Flight Trajectory Reconstruction Analysis                                                                                  Large Language Models (LLMs) hold transformative potential in aviation, particularly in reconstructing flight trajectories. This paper investigates this potential, grounded in the notion that LLMs excel at processing sequential data and deciphering complex data structures. Utilizing the LLaMA 2 model, a pre-trained open-source LLM, the study focuses on reconstructing flight trajectories using Automatic Dependent Surveillance-Broadcast (ADS-B) data with irregularities inherent in real-world scenarios. The findings demonstrate the model's proficiency in filtering noise and estimating both linear and curved flight trajectories. However, the analysis also reveals challenges in managing longer data sequences, which may be attributed to the token length limitations of LLM models. The study's insights underscore the promise of LLMs in flight trajectory reconstruction and open new avenues for their broader application across the aviation and transportation sectors.
http://w3id.org/mlsea/pwc/scientificWork/An%20Exploratory%20Investigation%20into%20Code%20License%20Infringements%20in%20Large%20Language%20Model%20Training%20Datasets                                                                                  An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets                                                                                  Does the training of large language models potentially infringe upon code licenses? Furthermore, are there any datasets available that can be safely used for training these models without violating such licenses? In our study, we assess the current trends in the field and the importance of incorporating code into the training of large language models. Additionally, we examine publicly available datasets to see whether these models can be trained on them without the risk of legal issues in the future. To accomplish this, we compiled a list of 53 large language models trained on file-level code. We then extracted their datasets and analyzed how much they overlap with a dataset we created, consisting exclusively of strong copyleft code. Our analysis revealed that every dataset we examined contained license inconsistencies, despite being selected based on their associated repository licenses. We analyzed a total of 514 million code files, discovering 38 million exact duplicates present in our strong copyleft dataset. Additionally, we examined 171 million file-leading comments, identifying 16 million with strong copyleft licenses and another 11 million comments that discouraged copying without explicitly mentioning a license. Based on the findings of our study, which highlights the pervasive issue of license inconsistencies in large language models trained on code, our recommendation for both researchers and the community is to prioritize the development and adoption of best practices for dataset creation and management.
http://w3id.org/mlsea/pwc/scientificWork/An%20Extension-based%20Approach%20for%20Computing%20and%20Verifying%20Preferences%20in%20Abstract%20Argumentation                                                                                  An Extension-based Approach for Computing and Verifying Preferences in Abstract Argumentation                                                                                  We present an extension-based approach for computing and verifying preferences in an abstract argumentation system. Although numerous argumentation semantics have been developed previously for identifying acceptable sets of arguments from an argumentation framework, there is a lack of justification behind their acceptability based on implicit argument preferences. Preference-based argumentation frameworks allow one to determine what arguments are justified given a set of preferences. Our research considers the inverse of the standard reasoning problem, i.e., given an abstract argumentation framework and a set of justified arguments, we compute what the possible preferences over arguments are. Furthermore, there is a need to verify (i.e., assess) that the computed preferences would lead to the acceptable sets of arguments. This paper presents a novel approach and algorithm for exhaustively computing and enumerating all possible sets of preferences (restricted to three identified cases) for a conflict-free set of arguments in an abstract argumentation framework. We prove the soundness, completeness and termination of the algorithm. The research establishes that preferences are determined using an extension-based approach after the evaluation phase (acceptability of arguments) rather than stated beforehand. In this work, we focus our research study on grounded, preferred and stable semantics. We show that the complexity of computing sets of preferences is exponential in the number of arguments, and thus, describe an approximate approach and algorithm to compute the preferences. Furthermore, we present novel algorithms for verifying (i.e., assessing) the computed preferences. We provide details of the implementation of the algorithms (source code has been made available), various experiments performed to evaluate the algorithms and the analysis of the results.
http://w3id.org/mlsea/pwc/scientificWork/An%20Image%20is%20Worth%201%2F2%20Tokens%20After%20Layer%202%3A%20Plug-and-Play%20Inference%20Acceleration%20for%20Large%20Vision-Language%20Models                                                                                  An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models                                                                                  In this study, we identify the inefficient attention phenomena in Large Vision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5, QwenVL-Chat and Video-LLaVA. We find out that the attention computation over visual tokens is of extreme inefficiency in the deep layers of popular LVLMs, suggesting a need for a sparser approach compared to textual data handling. To this end, we introduce FastV, a versatile plug-and-play method designed to optimize computational efficiency by learning adaptive attention patterns in early layers and pruning visual tokens in subsequent ones. Our evaluations demonstrate FastV's ability to dramatically reduce computational costs (e.g., a 45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a wide range of image and video understanding tasks. The computational efficiency and performance trade-off of FastV are highly customizable and pareto-efficient. It can compress the FLOPs of a 13B-parameter model to achieve a lower budget than that of a 7B-parameter model, while still maintaining superior performance. We believe FastV has practical values for deployment of LVLMs in edge devices and commercial models. Code is released at https://github.com/pkunlp-icler/FastV.
http://w3id.org/mlsea/pwc/scientificWork/An%20In-Depth%20Analysis%20of%20Data%20Reduction%20Methods%20for%20Sustainable%20Deep%20Learning                                                                                  An In-Depth Analysis of Data Reduction Methods for Sustainable Deep Learning                                                                                  In recent years, Deep Learning has gained popularity for its ability to solve complex classification tasks, increasingly delivering better results thanks to the development of more accurate models, the availability of huge volumes of data and the improved computational capabilities of modern computers. However, these improvements in performance also bring efficiency problems, related to the storage of datasets and models, and to the waste of energy and time involved in both the training and inference processes. In this context, data reduction can help reduce energy consumption when training a deep learning model. In this paper, we present up to eight different methods to reduce the size of a tabular training dataset, and we develop a Python package to apply them. We also introduce a representativeness metric based on topology to measure how similar are the reduced datasets and the full training dataset. Additionally, we develop a methodology to apply these data reduction methods to image datasets for object detection tasks. Finally, we experimentally compare how these data reduction methods affect the representativeness of the reduced dataset, the energy consumption and the predictive performance of the model.
http://w3id.org/mlsea/pwc/scientificWork/An%20In-depth%20Evaluation%20of%20GPT-4%20in%20Sentence%20Simplification%20with%20Error-based%20Human%20Assessment                                                                                  An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment                                                                                  Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliability. To address these problems, this study provides in-depth insights into LLMs' performance while ensuring the reliability of the evaluation. We design an error-based human annotation framework to assess the GPT-4's simplification capabilities. Results show that GPT-4 generally generates fewer erroneous simplification outputs compared to the current state-of-the-art. However, LLMs have their limitations, as seen in GPT-4's struggles with lexical paraphrasing. Furthermore, we conduct meta-evaluations on widely used automatic metrics using our human annotations. We find that while these metrics are effective for significant quality differences, they lack sufficient sensitivity to assess the overall high-quality simplification by GPT-4.
http://w3id.org/mlsea/pwc/scientificWork/An%20Index%20Policy%20Based%20on%20Sarsa%20and%20Q-learning%20for%20Heterogeneous%20Smart%20Target%20Tracking                                                                                  An Index Policy Based on Sarsa and Q-learning for Heterogeneous Smart Target Tracking                                                                                  In solving the non-myopic radar scheduling for multiple smart target tracking within an active and passive radar network, we need to consider both short-term enhanced tracking performance and a higher probability of target maneuvering in the future with active tracking. Acquiring the long-term tracking performance while scheduling the beam resources of active and passive radars poses a challenge. To address this challenge, we model this problem as a Markov decision process consisting of parallel restless bandit processes. Each bandit process is associated with a smart target, of which the estimation state evolves according to different discrete dynamic models for different actions - whether or not the target is being tracked. The discrete state is defined by the dynamic mode. The problem exhibits the curse of dimensionality, where optimal solutions are in general intractable. We resort to heuristics through the famous restless multi-armed bandit techniques. It follows with efficient scheduling policies based on the indices that are real numbers representing the marginal rewards of taking different actions. For the inevitable practical case with unknown transition matrices, we propose a new method that utilizes the forward Sarsa and backward Q-learning to approximate the indices through adapting the state-action value functions, or equivalently the Q-functions, and propose a new policy, namely ISQ, aiming to maximize the long-term tracking rewards. Numerical results demonstrate that the proposed ISQ policy outperforms conventional Q-learning-based methods and rapidly converges to the well-known Whittle index policy with revealed state transition models, which is considered the benchmark.
http://w3id.org/mlsea/pwc/scientificWork/An%20Information-Theoretic%20Analysis%20of%20In-Context%20Learning                                                                                  An Information-Theoretic Analysis of In-Context Learning                                                                                  Previous theoretical results pertaining to meta-learning on sequences build on contrived assumptions and are somewhat convoluted. We introduce new information-theoretic tools that lead to an elegant and very general decomposition of error into three components: irreducible error, meta-learning error, and intra-task error. These tools unify analyses across many meta-learning challenges. To illustrate, we apply them to establish new results about in-context learning with transformers. Our theoretical results characterizes how error decays in both the number of training sequences and sequence lengths. Our results are very general; for example, they avoid contrived mixing time assumptions made by all prior results that establish decay of error with sequence length.
http://w3id.org/mlsea/pwc/scientificWork/An%20Information-Theoretic%20Approach%20to%20Analyze%20NLP%20Classification%20Tasks                                                                                  An Information-Theoretic Approach to Analyze NLP Classification Tasks                                                                                  Understanding the importance of the inputs on the output is useful across many tasks. This work provides an information-theoretic framework to analyse the influence of inputs for text classification tasks. Natural language processing (NLP) tasks take either a single element input or multiple element inputs to predict an output variable, where an element is a block of text. Each text element has two components: an associated semantic meaning and a linguistic realization. Multiple-choice reading comprehension (MCRC) and sentiment classification (SC) are selected to showcase the framework. For MCRC, it is found that the context influence on the output compared to the question influence reduces on more challenging datasets. In particular, more challenging contexts allow a greater variation in complexity of questions. Hence, test creators need to carefully consider the choice of the context when designing multiple-choice questions for assessment. For SC, it is found the semantic meaning of the input text dominates (above 80 % for all datasets considered) compared to its linguistic realisation when determining the sentiment. The framework is made available at: https://github.com/WangLuran/nlp-element-influence
http://w3id.org/mlsea/pwc/scientificWork/An%20Inpainting-Infused%20Pipeline%20for%20Attire%20and%20Background%20Replacement                                                                                  An Inpainting-Infused Pipeline for Attire and Background Replacement                                                                                  In recent years, groundbreaking advancements in Generative Artificial Intelligence (GenAI) have triggered a transformative paradigm shift, significantly influencing various domains. In this work, we specifically explore an integrated approach, leveraging advanced techniques in GenAI and computer vision emphasizing image manipulation. The methodology unfolds through several stages, including depth estimation, the creation of inpaint masks based on depth information, the generation and replacement of backgrounds utilizing Stable Diffusion in conjunction with Latent Consistency Models (LCMs), and the subsequent replacement of clothes and application of aesthetic changes through an inpainting pipeline. Experiments conducted in this study underscore the methodology's efficacy, highlighting its potential to produce visually captivating content. The convergence of these advanced techniques allows users to input photographs of individuals and manipulate them to modify clothing and background based on specific prompts without manually input inpainting masks, effectively placing the subjects within the vast landscape of creative imagination.
http://w3id.org/mlsea/pwc/scientificWork/An%20IoT%20system%20for%20smart%20building%20combining%20multiple%20mmWave%20FMCW%20radars%20applied%20to%20people%20counting                                                                                  An IoT system for smart building combining multiple mmWave FMCW radars applied to people counting                                                                                  In contemporary society, the pressing challenge of preserving user privacy clashes with the imperative for smart buildings to efficiently manage their resources, particularly in the context of occupancy monitoring for optimized energy utilization. This paper delves into the application of millimiter wave (mmWave) frequency modulated continuous wave (FMCW) radar technology for occupancy monitoring. mmWave FMCW radar, unlike conventional methods that often require the use of identifiable tags or involve image analysis, operates without the need for such identifiers, mitigating privacy concerns. However, challenges arise when attempting to cover extensive indoor spaces due to the limited range of individual mmWave FMCW radar devices. The present work proposes the use of a flexible software architecture to integrate the measurements of several mmWave FMCW radar devices, so that the whole behaves as a single sensor. To validate the proposal, an example of use in a real environment in an indoor space monitored with three mmWave FMCW radar devices is also presented. The example details the whole process, from the physical installation of the devices to the use of the different software modules that allow the integration of the data into a common internet of things (IoT) management platform such as Home Assistant. All the elements, from the measurements captured during the test to the different software implementations, are shared publicly with the scientific community.
http://w3id.org/mlsea/pwc/scientificWork/An%20Iterative%20Associative%20Memory%20Model%20for%20Empathetic%20Response%20Generation                                                                                  An Iterative Associative Memory Model for Empathetic Response Generation                                                                                  Empathetic response generation is to comprehend the cognitive and emotional states in dialogue utterances and generate proper responses. Psychological theories posit that comprehending emotional and cognitive states necessitates iteratively capturing and understanding associated words across dialogue utterances. However, existing approaches regard dialogue utterances as either a long sequence or independent utterances for comprehension, which are prone to overlook the associated words between them. To address this issue, we propose an Iterative Associative Memory Model (IAMM) for empathetic response generation. Specifically, we employ a novel second-order interaction attention mechanism to iteratively capture vital associated words between dialogue utterances and situations, dialogue history, and a memory module (for storing associated words), thereby accurately and nuancedly comprehending the utterances. We conduct experiments on the Empathetic-Dialogue dataset. Both automatic and human evaluations validate the efficacy of the model. Meanwhile, variant experiments on LLMs also demonstrate that attending to associated words improves empathetic comprehension and expression.
http://w3id.org/mlsea/pwc/scientificWork/An%20LLM-Based%20Digital%20Twin%20for%20Optimizing%20Human-in-the%20Loop%20Systems                                                                                  An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems                                                                                  The increasing prevalence of Cyber-Physical Systems and the Internet of Things (CPS-IoT) applications and Foundation Models are enabling new applications that leverage real-time control of the environment. For example, real-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems can reduce its usage when not needed for the comfort of human occupants, hence reducing energy consumption. Collecting real-time feedback on human preferences in such human-in-the-loop (HITL) systems, however, is difficult in practice. We propose the use of large language models (LLMs) to deal with the challenges of dynamic environments and difficult-to-obtain data in CPS optimization. In this paper, we present a case study that employs LLM agents to mimic the behaviors and thermal preferences of various population groups (e.g. young families, the elderly) in a shopping mall. The aggregated thermal preferences are integrated into an agent-in-the-loop based reinforcement learning algorithm AitL-RL, which employs the LLM as a dynamic simulation of the physical environment to learn how to balance between energy savings and occupant comfort. Our results show that LLMs are capable of simulating complex population movements within large open spaces. Besides, AitL-RL demonstrates superior performance compared to the popular existing policy of set point control, suggesting that adaptive and personalized decision-making is critical for efficient optimization in CPS-IoT applications. Through this case study, we demonstrate the potential of integrating advanced Foundation Models like LLMs into CPS-IoT to enhance system adaptability and efficiency. The project's code can be found on our GitHub repository.
http://w3id.org/mlsea/pwc/scientificWork/An%20approach%20to%20automated%20videogame%20beta%20testing                                                                                  An approach to automated videogame beta testing                                                                                  Videogames developed in the 1970s and 1980s were modest programs created in a couple of months by a single person, who played the roles of designer, artist and programmer. Since then, videogames have evolved to become a multi-million dollar industry. Today, AAA game development involves hundreds of people working together over several years. Management and engineering requirements have changed at the same pace. Although many of the processes have been adapted over time, this is not quite true for quality assurance tasks, which are still done mainly manually by human beta testers due to the specific peculiarities of videogames. This paper presents an approach to automate this beta testing.
http://w3id.org/mlsea/pwc/scientificWork/An%20attempt%20to%20generate%20new%20bridge%20types%20from%20latent%20space%20of%20denoising%20diffusion%20Implicit%20model                                                                                  An attempt to generate new bridge types from latent space of denoising diffusion Implicit model                                                                                  Use denoising diffusion implicit model for bridge-type innovation. The process of adding noise and denoising to an image can be likened to the process of a corpse rotting and a detective restoring the scene of a victim being killed, to help beginners understand. Through an easy-to-understand algebraic method, derive the function formulas for adding noise and denoising, making it easier for beginners to master the mathematical principles of the model. Using symmetric structured image dataset of three-span beam bridge, arch bridge, cable-stayed bridge and suspension bridge , based on Python programming language, TensorFlow and Keras deep learning platform framework , denoising diffusion implicit model is constructed and trained. From the latent space sampling, new bridge types with asymmetric structures can be generated. Denoising diffusion implicit model can organically combine different structural components on the basis of human original bridge types, and create new bridge types.
http://w3id.org/mlsea/pwc/scientificWork/An%20efficient%20domain-independent%20approach%20for%20supervised%20keyphrase%20extraction%20and%20ranking                                                                                  An efficient domain-independent approach for supervised keyphrase extraction and ranking                                                                                  We present a supervised learning approach for automatic extraction of keyphrases from single documents. Our solution uses simple to compute statistical and positional features of candidate phrases and does not rely on any external knowledge base or on pre-trained language models or word embeddings. The ranking component of our proposed solution is a fairly lightweight ensemble model. Evaluation on benchmark datasets shows that our approach achieves significantly higher accuracy than several state-of-the-art baseline models, including all deep learning-based unsupervised models compared with, and is competitive with some supervised deep learning-based models too. Despite the supervised nature of our solution, the fact that does not rely on any corpus of 'golden' keywords or any external knowledge corpus means that our solution bears the advantages of unsupervised solutions to a fair extent.
http://w3id.org/mlsea/pwc/scientificWork/An%20embedding-based%20distance%20for%20temporal%20graphs                                                                                  An embedding-based distance for temporal graphs                                                                                  We define a distance between temporal graphs based on graph embeddings built using time-respecting random walks. We study both the case of matched graphs, when there exists a known relation between the nodes, and the unmatched case, when such a relation is unavailable and the graphs may be of different sizes. We illustrate the interest of our distance definition, using both real and synthetic temporal network data, by showing its ability to discriminate between graphs with different structural and temporal properties. Leveraging state-of-the-art machine learning techniques, we propose an efficient implementation of distance computation that is viable for large-scale temporal graphs.
http://w3id.org/mlsea/pwc/scientificWork/An%20experimental%20study%3A%20RF%20Fingerprinting%20of%20Bluetooth%20devices                                                                                  An experimental study: RF Fingerprinting of Bluetooth devices                                                                                  This paper presents an experimental study on radio frequency (RF) fingerprinting of Bluetooth Classic devices. Our research aims to provide a practical evaluation of the possibilities for RF fingerprinting of everyday Bluetooth connected devices that may cause privacy risks. We have built an experimental setup for recording Bluetooth connection in a radio frequency isolated environment using commercially available SDR (software defined radio) systems, extracted fingerprints of the Bluetooth radio data in the form of carrier frequency offset and scaling factor from 6 different devices, and performed k-nearest neighbors (kNN) classification achieving 84 % accuracy. The experiment demonstrates that no matter what privacy measures are being taken in the protocol layer, the physical layer leaks significant information about the device to unauthorized listeners. In the context of the ever-growing Bluetooth device market, this research serves as a clarion call for device manufacturers, regulators, and end-users to acknowledge the privacy risks posed by RF fingerprinting and lays a foundation for more sizeable Bluetooth fingerprinting analysis research.
http://w3id.org/mlsea/pwc/scientificWork/An%20internal%20sensory%20model%20allows%20for%20balance%20control%20based%20on%20non-actionable%20proprioceptive%20feedback                                                                                  An internal sensory model allows for balance control based on non-actionable proprioceptive feedback                                                                                  All motor tasks with a mechanical system (a human body, a rider on a bicycle) that is approximately linear in the part of the state space where it stays most of the time (e.g., upright balance control) have the following property: actionable sensory feedback allows for optimal control actions that are a simple linear combination of the sensory feedback. When only non-actionable sensory feedback is available, optimal control for these approximately linear mechanical systems is based on an internal dynamical system that estimates the states, and that can be implemented as a recurrent neural network (RNN). It uses a sensory model to update the state estimates with the non-actionable sensory feedback, and the weights of this RNN are fully specified by results from optimal feedback control. This is highly relevant for muscle spindle afferent firing rates which, under perfectly coordinated fusimotor and skeletomotor control, scale with the exafferent joint acceleration component. The resulting control mechanism balances a standing body and a rider-bicycle combination using realistic parameter values and with forcing torques that are feasible for humans.
http://w3id.org/mlsea/pwc/scientificWork/An%20objective%20comparison%20of%20methods%20for%20augmented%20reality%20in%20laparoscopic%20liver%20resection%20by%20preoperative-to-intraoperative%20image%20fusion                                                                                  An objective comparison of methods for augmented reality in laparoscopic liver resection by preoperative-to-intraoperative image fusion                                                                                  Augmented reality for laparoscopic liver resection is a visualisation mode that allows a surgeon to localise tumours and vessels embedded within the liver by projecting them on top of a laparoscopic image. Preoperative 3D models extracted from CT or MRI data are registered to the intraoperative laparoscopic images during this process. In terms of 3D-2D fusion, most of the algorithms make use of anatomical landmarks to guide registration. These landmarks include the liver's inferior ridge, the falciform ligament, and the occluding contours. They are usually marked by hand in both the laparoscopic image and the 3D model, which is time-consuming and may contain errors if done by a non-experienced user. Therefore, there is a need to automate this process so that augmented reality can be used effectively in the operating room. We present the Preoperative-to-Intraoperative Laparoscopic Fusion Challenge (P2ILF), held during the Medical Imaging and Computer Assisted Interventions (MICCAI 2022) conference, which investigates the possibilities of detecting these landmarks automatically and using them in registration. The challenge was divided into two tasks: 1) A 2D and 3D landmark detection task and 2) a 3D-2D registration task. The teams were provided with training data consisting of 167 laparoscopic images and 9 preoperative 3D models from 9 patients, with the corresponding 2D and 3D landmark annotations. A total of 6 teams from 4 countries participated, whose proposed methods were evaluated on 16 images and two preoperative 3D models from two patients. All the teams proposed deep learning-based methods for the 2D and 3D landmark segmentation tasks and differentiable rendering-based methods for the registration task. Based on the experimental outcomes, we propose three key hypotheses that determine current limitations and future directions for research in this domain.
http://w3id.org/mlsea/pwc/scientificWork/An%20open%20dataset%20for%20the%20evolution%20of%20oracle%20bone%20characters%3A%20EVOBC                                                                                  An open dataset for the evolution of oracle bone characters: EVOBC                                                                                  The earliest extant Chinese characters originate from oracle bone inscriptions, which are closely related to other East Asian languages. These inscriptions hold immense value for anthropology and archaeology. However, deciphering oracle bone script remains a formidable challenge, with only approximately 1,600 of the over 4,500 extant characters elucidated to date. Further scholarly investigation is required to comprehensively understand this ancient writing system. Artificial Intelligence technology is a promising avenue for deciphering oracle bone characters, particularly concerning their evolution. However, one of the challenges is the lack of datasets mapping the evolution of these characters over time. In this study, we systematically collected ancient characters from authoritative texts and websites spanning six historical stages: Oracle Bone Characters - OBC (15th century B.C.), Bronze Inscriptions - BI (13th to 221 B.C.), Seal Script - SS (11th to 8th centuries B.C.), Spring and Autumn period Characters - SAC (770 to 476 B.C.), Warring States period Characters - WSC (475 B.C. to 221 B.C.), and Clerical Script - CS (221 B.C. to 220 A.D.). Subsequently, we constructed an extensive dataset, namely EVolution Oracle Bone Characters (EVOBC), consisting of 229,170 images representing 13,714 distinct character categories. We conducted validation and simulated deciphering on the constructed dataset, and the results demonstrate its high efficacy in aiding the study of oracle bone script. This openly accessible dataset aims to digitalize ancient Chinese scripts across multiple eras, facilitating the decipherment of oracle bone script by examining the evolution of glyph forms.
http://w3id.org/mlsea/pwc/scientificWork/Analog%20In-Memory%20Computing%20with%20Uncertainty%20Quantification%20for%20Efficient%20Edge-based%20Medical%20Imaging%20Segmentation                                                                                  Analog In-Memory Computing with Uncertainty Quantification for Efficient Edge-based Medical Imaging Segmentation                                                                                  This work investigates the role of the emerging Analog In-memory computing (AIMC) paradigm in enabling Medical AI analysis and improving the certainty of these models at the edge. It contrasts AIMC's efficiency with traditional digital computing's limitations in power, speed, and scalability. Our comprehensive evaluation focuses on brain tumor analysis, spleen segmentation, and nuclei detection. The study highlights the superior robustness of isotropic architectures, which exhibit a minimal accuracy drop (0.04) in analog-aware training, compared to significant drops (up to 0.15) in pyramidal structures. Additionally, the paper emphasizes IMC's effective data pipelining, reducing latency and increasing throughput as well as the exploitation of inherent noise within AIMC, strategically harnessed to augment model certainty.
http://w3id.org/mlsea/pwc/scientificWork/Analog%20Isolated%20Multilevel%20Quantizer%20for%20Voltage%20Sensing%20while%20Maintaining%20Galvanic%20Isolation                                                                                  Analog Isolated Multilevel Quantizer for Voltage Sensing while Maintaining Galvanic Isolation                                                                                  A low-power, compact device for performing measurements in electrical systems with isolated voltage domains is proposed. Isolated measurements are required in numerous applications. For instance, a measurement of the bus voltage for a system with a high supply voltage and lower isolated local voltage level may be needed for system health monitoring and control. Such a requirement may necessitate the use of isolation amplifiers to provide voltage telemetry for the local system. Isolation amplifiers require dual galvanically isolated supplies and use magnetic, capacitive, or optical barriers between primary and secondary sides. Producing this supplemental voltage requires an extra voltage converter, which consumes power and generates electromagnetic interference which must, in turn, be filtered. Complex designs incorporating feedback are needed to achieve linear response. The proposed Analog Isolated Multilevel Quantizer (AIMQ) addresses these issues by monitoring the primary-side signal and communicating the results to the secondary side using a novel scheme involving Zener diodes, optocouplers, transistors, one-hot coding, and discrete outputs. The result is a low power isolated transducer that can in principle be extended to an arbitrary bit depth.
http://w3id.org/mlsea/pwc/scientificWork/Analog%20and%20Multi-modal%20Manufacturing%20Datasets%20Acquired%20on%20the%20Future%20Factories%20Platform                                                                                  Analog and Multi-modal Manufacturing Datasets Acquired on the Future Factories Platform                                                                                  Two industry-grade datasets are presented in this paper that were collected at the Future Factories Lab at the University of South Carolina on December 11th and 12th of 2023. These datasets are generated by a manufacturing assembly line that utilizes industrial standards with respect to actuators, control mechanisms, and transducers. The two datasets were both generated simultaneously by operating the assembly line for 30 consecutive hours (with minor filtering) and collecting data from sensors equipped throughout the system. During operation, defects were also introduced into the assembly operation by manually removing parts needed for the final assembly. The datasets generated include a time series analog dataset and the other is a time series multi-modal dataset which includes images of the system alongside the analog data. These datasets were generated with the objective of providing tools to further the research towards enhancing intelligence in manufacturing. Real manufacturing datasets can be scarce let alone datasets with anomalies or defects. As such these datasets hope to address this gap and provide researchers with a foundation to build and train Artificial Intelligence models applicable for the manufacturing industry. Finally, these datasets are the first iteration of published data from the future Factories lab and can be further adjusted to fit more researchers needs moving forward.
http://w3id.org/mlsea/pwc/scientificWork/Analog-digital%20Scheduling%20for%20Federated%20Learning%3A%20A%20Communication-Efficient%20Approach                                                                                  Analog-digital Scheduling for Federated Learning: A Communication-Efficient Approach                                                                                  Over-the-air (OTA) computation has recently emerged as a communication-efficient Federated Learning (FL) paradigm to train machine learning models over wireless networks. However, its performance is limited by the device with the worst SNR, resulting in fast yet noisy updates. On the other hand, allocating orthogonal resource blocks (RB) to individual devices via digital channels mitigates the noise problem, at the cost of increased communication latency. In this paper, we address this discrepancy and present ADFL, a novel Analog-Digital FL scheme: in each round, the parameter server (PS) schedules each device to either upload its gradient via the analog OTA scheme or transmit its quantized gradient over an orthogonal RB using the ``digital' scheme. Focusing on a single FL round, we cast the optimal scheduling problem as the minimization of the mean squared error (MSE) on the estimated global gradient at the PS, subject to a delay constraint, yielding the optimal device scheduling configuration and quantization bits for the digital devices. Our simulation results show that ADFL, by scheduling most of the devices in the OTA scheme while also occasionally employing the digital scheme for a few devices, consistently outperforms OTA-only and digital-only schemes, in both i.i.d. and non-i.i.d. settings.
http://w3id.org/mlsea/pwc/scientificWork/Analyses%20and%20Concerns%20in%20Precision%20Medicine%3A%20A%20Statistical%20Perspective                                                                                  Analyses and Concerns in Precision Medicine: A Statistical Perspective                                                                                  This article explores the critical role of statistical analysis in precision medicine. It discusses how personalized healthcare is enhanced by statistical methods that interpret complex, multidimensional datasets, focusing on predictive modeling, machine learning algorithms, and data visualization techniques. The paper addresses challenges in data integration and interpretation, particularly with diverse data sources like electronic health records (EHRs) and genomic data. It also delves into ethical considerations such as patient privacy and data security. In addition, the paper highlights the evolution of statistical analysis in medicine, core statistical methodologies in precision medicine, and future directions in the field, emphasizing the integration of artificial intelligence (AI) and machine learning (ML).
http://w3id.org/mlsea/pwc/scientificWork/Analysing%20heavy-tail%20properties%20of%20Stochastic%20Gradient%20Descent%20by%20means%20of%20Stochastic%20Recurrence%20Equations                                                                                  Analysing heavy-tail properties of Stochastic Gradient Descent by means of Stochastic Recurrence Equations                                                                                  In recent works on the theory of machine learning, it has been observed that heavy tail properties of Stochastic Gradient Descent (SGD) can be studied in the probabilistic framework of stochastic recursions. In particular, G '{u}rb '{u}zbalaban et al. (arXiv:2006.04740) considered a setup corresponding to linear regression for which iterations of SGD can be modelled by a multivariate affine stochastic recursion $X_k=A_k X_{k-1}+B_k$, for independent and identically distributed pairs $(A_k, B_k)$, where $A_k$ is a random symmetric matrix and $B_k$ is a random vector. In this work, we will answer several open questions of the quoted paper and extend their results by applying the theory of irreducible-proximal (i-p) matrices.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20Fairness-promoting%20Optimization%20Schemes%20of%20Photovoltaic%20Curtailments%20for%20Voltage%20Regulation%20in%20Power%20Distribution%20Networks                                                                                  Analysis of Fairness-promoting Optimization Schemes of Photovoltaic Curtailments for Voltage Regulation in Power Distribution Networks                                                                                  Active power curtailment of photovoltaic (PV) generation is commonly exercised to mitigate over-voltage issues in power distribution networks. However, fairness concerns arise as certain PV plants may experience more significant curtailments than others depending on their locations within the network. Existing literature tackles this issue through fairness-promoting/aware optimization schemes. These schemes can be broadly categorized into two types. The first type maximizes an additional fairness objective along with the main objective of curtailment minimization. The second type is formulated as a feedback controller, where fairness is accounted for by assigning different weights (as feedback) in the curtailment minimization objective for each PV plant based on previous curtailment actions. In this work, we combine these two schemes and provide extensive analyses and comparisons of these two fairness schemes. We compare the performance in terms of fairness and net curtailments for several benchmark test networks.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20Intelligent%20Reflecting%20Surface-Enhanced%20Mobility%20Through%20a%20Line-of-Sight%20State%20Transition%20Model                                                                                  Analysis of Intelligent Reflecting Surface-Enhanced Mobility Through a Line-of-Sight State Transition Model                                                                                  Rapid signal fluctuations due to blockage effects cause excessive handovers (HOs) and degrade mobility performance. By reconfiguring line-of-sight (LoS) Links through passive reflections, intelligent reflective surface (IRS) has the potential to address this issue. Due to the lack of introducing blocking effects, existing HO analyses cannot capture excessive HOs or exploit enhancements via IRSs. This paper proposes an LoS state transition model enabling analysis of mobility enhancement achieved by IRS-reconfigured LoS links, where LoS link blocking and reconfiguration utilizing IRS during user movement are explicitly modeled as stochastic processes. Specifically, the condition for blocking LoS links is characterized as a set of possible blockage locations, the distribution of available IRSs is thinned by the criteria for reconfiguring LoS links. In addition, BSs potentially handed over are categorized by probabilities of LoS states to enable HO decision analysis. By projecting distinct gains of LoS states onto a uniform equivalent distance criterion, mobility enhanced by IRS is quantified through the compact expression of HO probability. Results show the probability of dropping into non-LoS decreases by 70% when deploying IRSs with the density of 93/km$^2$, and HOs decrease by 67% under the optimal IRS distributed deployment parameter.
http://w3id.org/mlsea/pwc/scientificWork/Analytical%20Approximation%20of%20the%20ELBO%20Gradient%20in%20the%20Context%20of%20the%20Clutter%20Problem                                                                                  Analytical Approximation of the ELBO Gradient in the Context of the Clutter Problem                                                                                  We propose an analytical solution for approximating the gradient of the Evidence Lower Bound (ELBO) in variational inference problems where the statistical model is a Bayesian network consisting of observations drawn from a mixture of a Gaussian distribution embedded in unrelated clutter, known as the clutter problem. The method employs the reparameterization trick to move the gradient operator inside the expectation and relies on the assumption that, because the likelihood factorizes over the observed data, the variational distribution is generally more compactly supported than the Gaussian distribution in the likelihood factors. This allows efficient local approximation of the individual likelihood factors, which leads to an analytical solution for the integral defining the gradient expectation. We integrate the proposed gradient approximation as the expectation step in an EM (Expectation Maximization) algorithm for maximizing ELBO and test against classical deterministic approaches in Bayesian inference, such as the Laplace approximation, Expectation Propagation and Mean-Field Variational Inference. The proposed method demonstrates good accuracy and rate of convergence together with linear computational complexity.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Neural%20Network-Based%20Generative%20Diffusion%20Models%20through%20Convex%20Optimization                                                                                  Analyzing Neural Network-Based Generative Diffusion Models through Convex Optimization                                                                                  Diffusion models are becoming widely used in state-of-the-art image, video and audio generation. Score-based diffusion models stand out among these methods, necessitating the estimation of score function of the input data distribution. In this study, we present a theoretical framework to analyze two-layer neural network-based diffusion models by reframing score matching and denoising score matching as convex optimization. Though existing diffusion theory is mainly asymptotic, we characterize the exact predicted score function and establish the convergence result for neural network-based diffusion models with finite data. This work contributes to understanding what neural network-based diffusion model learns in non-asymptotic settings.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Regional%20Impacts%20of%20Climate%20Change%20using%20Natural%20Language%20Processing%20Techniques                                                                                  Analyzing Regional Impacts of Climate Change using Natural Language Processing Techniques                                                                                  Understanding the multifaceted effects of climate change across diverse geographic locations is crucial for timely adaptation and the development of effective mitigation strategies. As the volume of scientific literature on this topic continues to grow exponentially, manually reviewing these documents has become an immensely challenging task. Utilizing Natural Language Processing (NLP) techniques to analyze this wealth of information presents an efficient and scalable solution. By gathering extensive amounts of peer-reviewed articles and studies, we can extract and process critical information about the effects of climate change in specific regions. We employ BERT (Bidirectional Encoder Representations from Transformers) for Named Entity Recognition (NER), which enables us to efficiently identify specific geographies within the climate literature. This, in turn, facilitates location-specific analyses. We conduct region-specific climate trend analyses to pinpoint the predominant themes or concerns related to climate change within a particular area, trace the temporal progression of these identified issues, and evaluate their frequency, severity, and potential development over time. These in-depth examinations of location-specific climate data enable the creation of more customized policy-making, adaptation, and mitigation strategies, addressing each region's unique challenges and providing more effective solutions rooted in data-driven insights. This approach, founded on a thorough exploration of scientific texts, offers actionable insights to a wide range of stakeholders, from policymakers to engineers to environmentalists. By proactively understanding these impacts, societies are better positioned to prepare, allocate resources wisely, and design tailored strategies to cope with future climate conditions, ensuring a more resilient future for all.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Reward%20Dynamics%20and%20Decentralization%20in%20Ethereum%202.0%3A%20An%20Advanced%20Data%20Engineering%20Workflow%20and%20Comprehensive%20Datasets%20for%20Proof-of-Stake%20Incentives                                                                                  Analyzing Reward Dynamics and Decentralization in Ethereum 2.0: An Advanced Data Engineering Workflow and Comprehensive Datasets for Proof-of-Stake Incentives                                                                                  Ethereum 2.0, as the preeminent smart contract blockchain platform, guarantees the precise execution of applications without third-party intervention. At its core, this system leverages the Proof-of-Stake (PoS) consensus mechanism, which utilizes a stochastic process to select validators for block proposal and validation, consequently rewarding them for their contributions. However, the implementation of blockchain technology often diverges from its central tenet of decentralized consensus, presenting significant analytical challenges. Our study collects consensus reward data from the Ethereum Beacon chain and conducts a comprehensive analysis of reward distribution and evolution, categorizing them into attestation, proposer and sync committee rewards. To evaluate the degree of decentralization in PoS Ethereum, we apply several inequality indices, including the Shannon entropy, the Gini Index, the Nakamoto Coefficient, and the Herfindahl-Hirschman Index (HHI). Our comprehensive dataset is publicly available on Harvard Dataverse, and our analytical methodologies are accessible via GitHub, promoting open-access research. Additionally, we provide insights on utilizing our data for future investigations focused on assessing, augmenting, and refining the decentralization, security, and efficiency of blockchain systems.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20the%20Roles%20of%20Language%20and%20Vision%20in%20Learning%20from%20Limited%20Data                                                                                  Analyzing the Roles of Language and Vision in Learning from Limited Data                                                                                  Does language help make sense of the visual world? How important is it to actually see the world rather than having it described with words? These basic questions about the nature of intelligence have been difficult to answer because we only had one example of an intelligent system -- humans -- and limited access to cases that isolated language or vision. However, the development of sophisticated Vision-Language Models (VLMs) by artificial intelligence researchers offers us new opportunities to explore the contributions that language and vision make to learning about the world. We ablate components from the cognitive architecture of these models to identify their contributions to learning new tasks from limited data. We find that a language model leveraging all components recovers a majority of a VLM's performance, despite its lack of visual input, and that language seems to allow this by providing access to prior knowledge and reasoning.
http://w3id.org/mlsea/pwc/scientificWork/AnatoMix%3A%20Anatomy-aware%20Data%20Augmentation%20for%20Multi-organ%20Segmentation                                                                                  AnatoMix: Anatomy-aware Data Augmentation for Multi-organ Segmentation                                                                                  Multi-organ segmentation in medical images is a widely researched task and can save much manual efforts of clinicians in daily routines. Automating the organ segmentation process using deep learning (DL) is a promising solution and state-of-the-art segmentation models are achieving promising accuracy. In this work, We proposed a novel data augmentation strategy for increasing the generalizibility of multi-organ segmentation datasets, namely AnatoMix. By object-level matching and manipulation, our method is able to generate new images with correct anatomy, i.e. organ segmentation mask, exponentially increasing the size of the segmentation dataset. Initial experiments have been done to investigate the segmentation performance influenced by our method on a public CT dataset. Our augmentation method can lead to mean dice of 76.1, compared with 74.8 of the baseline method.
http://w3id.org/mlsea/pwc/scientificWork/Anatomical%20Structure-Guided%20Medical%20Vision-Language%20Pre-training                                                                                  Anatomical Structure-Guided Medical Vision-Language Pre-training                                                                                  Learning medical visual representations through vision-language pre-training has reached remarkable progress. Despite the promising performance, it still faces challenges, i.e., local alignment lacks interpretability and clinical relevance, and the insufficient internal and external representation learning of image-report pairs. To address these issues, we propose an Anatomical Structure-Guided (ASG) framework. Specifically, we parse raw reports into triplets <anatomical region, finding, existence>, and fully utilize each element as supervision to enhance representation learning. For anatomical region, we design an automatic anatomical region-sentence alignment paradigm in collaboration with radiologists, considering them as the minimum semantic units to explore fine-grained local alignment. For finding and existence, we regard them as image tags, applying an image-tag recognition decoder to associate image features with their respective tags within each sample and constructing soft labels for contrastive learning to improve the semantic association of different image-report pairs. We evaluate the proposed ASG framework on two downstream tasks, including five public benchmarks. Experimental results demonstrate that our method outperforms the state-of-the-art methods.
http://w3id.org/mlsea/pwc/scientificWork/Anatomy%20of%20Industrial%20Scale%20Multilingual%20ASR                                                                                  Anatomy of Industrial Scale Multilingual ASR                                                                                  This paper describes AssemblyAI's industrial-scale automatic speech recognition (ASR) system, designed to meet the requirements of large-scale, multilingual ASR serving various application needs. Our system leverages a diverse training dataset comprising unsupervised (12.5M hours), supervised (188k hours), and pseudo-labeled (1.6M hours) data across four languages. We provide a detailed description of our model architecture, consisting of a full-context 600M-parameter Conformer encoder pre-trained with BEST-RQ and an RNN-T decoder fine-tuned jointly with the encoder. Our extensive evaluation demonstrates competitive word error rates (WERs) against larger and more computationally expensive models, such as Whisper large and Canary-1B. Furthermore, our architectural choices yield several key advantages, including an improved code-switching capability, a 5x inference speedup compared to an optimized Whisper baseline, a 30% reduction in hallucination rate on speech data, and a 90% reduction in ambient noise compared to Whisper, along with significantly improved time-stamp accuracy. Throughout this work, we adopt a system-centric approach to analyzing various aspects of fully-fledged ASR models to gain practically relevant insights useful for real-world services operating at scale.
http://w3id.org/mlsea/pwc/scientificWork/Anatomy-Guided%20Surface%20Diffusion%20Model%20for%20Alzheimer%27s%20Disease%20Normative%20Modeling                                                                                  Anatomy-Guided Surface Diffusion Model for Alzheimer's Disease Normative Modeling                                                                                  Normative modeling has emerged as a pivotal approach for characterizing heterogeneity and individual variance in neurodegenerative diseases, notably Alzheimer's disease(AD). One of the challenges of cortical normative modeling is the anatomical structure mismatch due to folding pattern variability. Traditionally, registration is applied to address this issue and recently many studies have utilized deep generative models to generate anatomically align samples for analyzing disease progression; however, these models are predominantly applied to volume-based data, which often falls short in capturing intricate morphological changes on the brain cortex. As an alternative, surface-based analysis has been proven to be more sensitive in disease modeling such as AD, yet, like volume-based data, it also suffers from the mismatch problem. To address these limitations, we proposed a novel generative normative modeling framework by transferring the conditional diffusion generative model to the spherical non-Euclidean domain. Additionally, this approach generates normal feature map distributions by explicitly conditioning on individual anatomical segmentation to ensure better geometrical alignment which helps to reduce anatomical variance between subjects in analysis. We find that our model can generate samples that are better anatomically aligned than registered reference data and through ablation study and normative assessment experiments, the samples are able to better measure individual differences from the normal distribution and increase sensitivity in differentiating cognitively normal (CN), mild cognitive impairment (MCI), and Alzheimer's disease (AD) patients.
http://w3id.org/mlsea/pwc/scientificWork/Anchor%20function%3A%20a%20type%20of%20benchmark%20functions%20for%20studying%20language%20models                                                                                  Anchor function: a type of benchmark functions for studying language models                                                                                  Understanding transformer-based language models is becoming increasingly crucial, particularly as they play pivotal roles in advancing towards artificial general intelligence. However, language model research faces significant challenges, especially for academic research groups with constrained resources. These challenges include complex data structures, unknown target functions, high computational costs and memory requirements, and a lack of interpretability in the inference process, etc. Drawing a parallel to the use of simple models in scientific research, we propose the concept of an anchor function. This is a type of benchmark function designed for studying language models in learning tasks that follow an 'anchor-key' pattern. By utilizing the concept of an anchor function, we can construct a series of functions to simulate various language tasks. The anchor function plays a role analogous to that of mice in diabetes research, particularly suitable for academic research. We demonstrate the utility of the anchor function with an example, revealing two basic operations by attention structures in language models: shifting tokens and broadcasting one token from one position to many positions. These operations are also commonly observed in large language models. The anchor function framework, therefore, opens up a series of valuable and accessible research questions for further exploration, especially for theoretical study.
http://w3id.org/mlsea/pwc/scientificWork/Anchor-based%20Large%20Language%20Models                                                                                  Anchor-based Large Language Models                                                                                  Large language models (LLMs) predominantly employ decoder-only transformer architectures, necessitating the retention of keys/values information for historical tokens to provide contextual information and avoid redundant computation. However, the substantial size and parameter volume of these LLMs require massive GPU memory. This memory demand increases with the length of the input text, leading to an urgent need for more efficient methods of information storage and processing. This study introduces Anchor-based LLMs (AnLLMs), which utilize an innovative anchor-based self-attention network (AnSAN) and also an anchor-based inference strategy. This approach enables LLMs to compress sequence information into an anchor token, reducing the keys/values cache and enhancing inference efficiency. Experiments on question-answering benchmarks reveal that AnLLMs maintain similar accuracy levels while achieving up to 99% keys/values cache reduction and up to 3.5 times faster inference. Despite a minor compromise in accuracy, the substantial enhancements of AnLLMs employing the AnSAN technique in resource utilization and computational efficiency underscore their potential for practical LLM applications.
http://w3id.org/mlsea/pwc/scientificWork/Anchor-based%20Robust%20Finetuning%20of%20Vision-Language%20Models                                                                                  Anchor-based Robust Finetuning of Vision-Language Models                                                                                  We aim at finetuning a vision-language model without hurting its out-of-distribution (OOD) generalization. We address two types of OOD generalization, i.e., i) domain shift such as natural to sketch images, and ii) zero-shot capability to recognize the category that was not contained in the finetune data. Arguably, the diminished OOD generalization after finetuning stems from the excessively simplified finetuning target, which only provides the class information, such as ``a photo of a [CLASS]''. This is distinct from the process in that CLIP was pretrained, where there is abundant text supervision with rich semantic information. Therefore, we propose to compensate for the finetune process using auxiliary supervision with rich semantic information, which acts as anchors to preserve the OOD generalization. Specifically, two types of anchors are elaborated in our method, including i) text-compensated anchor which uses the images from the finetune set but enriches the text supervision from a pretrained captioner, ii) image-text-pair anchor which is retrieved from the dataset similar to pretraining data of CLIP according to the downstream task, associating with the original CLIP text with rich semantics. Those anchors are utilized as auxiliary semantic information to maintain the original feature space of CLIP, thereby preserving the OOD generalization capabilities. Comprehensive experiments demonstrate that our method achieves in-distribution performance akin to conventional finetuning while attaining new state-of-the-art results on domain shift and zero-shot learning benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/Anchor-free%20temporal%20action%20localization%20via%20Progressive%20Boundary-aware%20Boosting                                                                                  Anchor-free temporal action localization via Progressive Boundary-aware Boosting                                                                                  Enormous untrimmed videos from the real world are difficult to analyze and manage. Temporal action localization algorithms can help us to locate and recognize human activity clips in untrimmed videos. Recently, anchor-free temporal action localization methods have gained increasing attention due to small computational costs and no complex hyperparameters of pre-set anchors. Although the performance has been significantly improved, most existing anchor-free temporal action localization methods still suffer from inaccurate action boundary predictions. In this paper, we want to alleviate the above problem through boundary refinement and temporal context aggregation. To this end, a novel Progressive Boundary-aware Boosting Network (PBBNet) is proposed for anchor-free temporal action localization. The PBBNet consists of three main modules: Temporal Context-aware Module (TCM), Instance-wise Boundary-aware Module (IBM), and Frame-wise Progressive Boundary-aware Module (FPBM). The TCM aggregates the temporal context information and provides features for the IBM and the FPBM. The IBM generates multi-scale video features to predict action results coarsely. Compared with IBM, the FPBM focuses on instance features corresponding to action predictions and uses more supervision information for boundary regression. Given action results from IBM, the FPBM uses a progressive boosting strategy to refine the boundary predictions multiple times with supervision from weak to strong. Extensive experiments on three benchmark datasets THUMOS14, ActivityNet-v1.3 and HACS show our PPBNet outperforms all existing anchor-free methods. Further, our PPBNet achieves state-of-the-art performance (72.5% mAP at tIoU 0.5) on THUMOS14 dataset.
http://w3id.org/mlsea/pwc/scientificWork/And%20Then%20the%20Hammer%20Broke%3A%20Reflections%20on%20Machine%20Ethics%20from%20Feminist%20Philosophy%20of%20Science                                                                                  And Then the Hammer Broke: Reflections on Machine Ethics from Feminist Philosophy of Science                                                                                  Vision is an important metaphor in ethical and political questions of knowledge. The feminist philosopher Donna Haraway points out the ``perverse'' nature of an intrusive, alienating, all-seeing vision (to which we might cry out ``stop looking at me!''), but also encourages us to embrace the embodied nature of sight and its promises for genuinely situated knowledge. Current technologies of machine vision -- surveillance cameras, drones (for war or recreation), iPhone cameras -- are usually construed as instances of the former rather than the latter, and for good reasons. However, although in no way attempting to diminish the real suffering these technologies have brought about in the world, I make the case for understanding technologies of computer vision as material instances of embodied seeing and situated knowing. Furthermore, borrowing from Iris Murdoch's concept of moral vision, I suggest that these technologies direct our labor towards self-reflection in ethically significant ways. My approach draws upon paradigms in computer vision research, phenomenology, and feminist epistemology. Ultimately, this essay is an argument for directing more philosophical attention from merely criticizing technologies of vision as ethically deficient towards embracing them as complex, methodologically and epistemologically important objects.
http://w3id.org/mlsea/pwc/scientificWork/Anfinsen%20Goes%20Neural%3A%20a%20Graphical%20Model%20for%20Conditional%20Antibody%20Design                                                                                  Anfinsen Goes Neural: a Graphical Model for Conditional Antibody Design                                                                                  Antibody design plays a pivotal role in advancing therapeutics. Although deep learning has made rapid progress in this field, existing methods make limited use of general protein knowledge and assume a graphical model (GM) that violates empirical findings on proteins. To address these limitations, we present Anfinsen Goes Neural (AGN), a graphical model that uses a pre-trained protein language model (pLM) and encodes a seminal finding on proteins called Anfinsen's dogma. Our framework follows a two-step process of sequence generation with pLM and structure prediction with graph neural network (GNN). Experiments show that our approach outperforms state-of-the-art results on benchmark experiments. We also address a critical limitation of non-autoregressive models -- namely, that they tend to generate unrealistic sequences with overly repeating tokens. To resolve this, we introduce a composition-based regularization term to the cross-entropy objective that allows an efficient trade-off between high performance and low token repetition. We demonstrate that our approach establishes a Pareto frontier over the current state-of-the-art. Our code is available at https://github.com/lkny123/AGN.
http://w3id.org/mlsea/pwc/scientificWork/Angle-Equivariant%20Convolutional%20Neural%20Networks%20for%20Interference%20Mitigation%20in%20Automotive%20Radar                                                                                  Angle-Equivariant Convolutional Neural Networks for Interference Mitigation in Automotive Radar                                                                                  In automotive applications, frequency modulated continuous wave (FMCW) radar is an established technology to determine the distance, velocity and angle of objects in the vicinity of the vehicle. The quality of predictions might be seriously impaired if mutual interference between radar sensors occurs. Previous work processes data from the entire receiver array in parallel to increase interference mitigation quality using neural networks (NNs). However, these architectures do not generalize well across different angles of arrival (AoAs) of interferences and objects. In this paper we introduce fully convolutional neural network (CNN) with rank-three convolutions which is able to transfer learned patterns between different AoAs. Our proposed architecture outperforms previous work while having higher robustness and a lower number of trainable parameters. We evaluate our network on a diverse data set and demonstrate its angle equivariance.
http://w3id.org/mlsea/pwc/scientificWork/Angry%20Men%2C%20Sad%20Women%3A%20Large%20Language%20Models%20Reflect%20Gendered%20Stereotypes%20in%20Emotion%20Attribution                                                                                  Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution                                                                                  Large language models (LLMs) reflect societal norms and biases, especially about gender. While societal biases and stereotypes have been extensively researched in various NLP applications, there is a surprising gap for emotion analysis. However, emotion and gender are closely linked in societal discourse. E.g., women are often thought of as more empathetic, while men's anger is more socially accepted. To fill this gap, we present the first comprehensive study of gendered emotion attribution in five state-of-the-art LLMs (open- and closed-source). We investigate whether emotions are gendered, and whether these variations are based on societal stereotypes. We prompt the models to adopt a gendered persona and attribute emotions to an event like 'When I had a serious argument with a dear person'. We then analyze the emotions generated by the models in relation to the gender-event pairs. We find that all models consistently exhibit gendered emotions, influenced by gender stereotypes. These findings are in line with established research in psychology and gender studies. Our study sheds light on the complex societal interplay between language, gender, and emotion. The reproduction of emotion stereotypes in LLMs allows us to use those models to study the topic in detail, but raises questions about the predictive use of those same LLMs for emotion applications.
http://w3id.org/mlsea/pwc/scientificWork/Animated%20Stickers%3A%20Bringing%20Stickers%20to%20Life%20with%20Video%20Diffusion                                                                                  Animated Stickers: Bringing Stickers to Life with Video Diffusion                                                                                  We introduce animated stickers, a video diffusion model which generates an animation conditioned on a text prompt and static sticker image. Our model is built on top of the state-of-the-art Emu text-to-image model, with the addition of temporal layers to model motion. Due to the domain gap, i.e. differences in visual and motion style, a model which performed well on generating natural videos can no longer generate vivid videos when applied to stickers. To bridge this gap, we employ a two-stage finetuning pipeline: first with weakly in-domain data, followed by human-in-the-loop (HITL) strategy which we term ensemble-of-teachers. It distills the best qualities of multiple teachers into a smaller student model. We show that this strategy allows us to specifically target improvements to motion quality while maintaining the style from the static image. With inference optimizations, our model is able to generate an eight-frame video with high-quality, interesting, and relevant motion in under one second.
http://w3id.org/mlsea/pwc/scientificWork/Anomaly%20Detection%20of%20Particle%20Orbit%20in%20Accelerator%20using%20LSTM%20Deep%20Learning%20Technology                                                                                  Anomaly Detection of Particle Orbit in Accelerator using LSTM Deep Learning Technology                                                                                  A stable, reliable, and controllable orbit lock system is crucial to an electron (or ion) accelerator because the beam orbit and beam energy instability strongly affect the quality of the beam delivered to experimental halls. Currently, when the orbit lock system fails operators must manually intervene. This paper develops a Machine Learning based fault detection methodology to identify orbit lock anomalies and notify accelerator operations staff of the off-normal behavior. Our method is unsupervised, so it does not require labeled data. It uses Long-Short Memory Networks (LSTM) Auto Encoder to capture normal patterns and predict future values of monitoring sensors in the orbit lock system. Anomalies are detected when the prediction error exceeds a threshold. We conducted experiments using monitoring data from Jefferson Lab's Continuous Electron Beam Accelerator Facility (CEBAF). The results are promising: the percentage of real anomalies identified by our solution is 68.6%-89.3% using monitoring data of a single component in the orbit lock control system. The accuracy can be as high as 82%.
http://w3id.org/mlsea/pwc/scientificWork/Answerability%20in%20Retrieval-Augmented%20Open-Domain%20Question%20Answering                                                                                  Answerability in Retrieval-Augmented Open-Domain Question Answering                                                                                  The performance of Open-Domain Question Answering (ODQA) retrieval systems can exhibit sub-optimal behavior, providing text excerpts with varying degrees of irrelevance. Unfortunately, many existing ODQA datasets lack examples specifically targeting the identification of irrelevant text excerpts. Previous attempts to address this gap have relied on a simplistic approach of pairing questions with random text excerpts. This paper aims to investigate the effectiveness of models trained using this randomized strategy, uncovering an important limitation in their ability to generalize to irrelevant text excerpts with high semantic overlap. As a result, we observed a substantial decrease in predictive accuracy, from 98% to 1%. To address this limitation, we discovered an efficient approach for training models to recognize such excerpts. By leveraging unanswerable pairs from the SQuAD 2.0 dataset, our models achieve a nearly perfect (~100%) accuracy when confronted with these challenging text excerpts.
http://w3id.org/mlsea/pwc/scientificWork/Antenna%20Array%20Design%20for%20Mono-Static%20ISAC                                                                                  Antenna Array Design for Mono-Static ISAC                                                                                  Mono-static sensing operations in Integrated Sensing and Communications (ISAC) require joint beamforming operations between transmitter and receiver, according to all the considerations already done in the radar literature about coarray theory. In contrast to pure radar systems, ISAC requires to fulfill communications tasks and to retain the corresponding design constraints for at least one half-duplex array. This shifts the available degrees of freedom to the design of the second half-duplex array, that completes the mono-static sensing setup of the ISAC system. Therefore, it is necessary to translate the analysis from the radar literature for the design of sparse arrays to the new ISAC paradigm in order to provision such systems. Accordingly, we propose a model to evaluate the angular capabilities of an ISAC setup, constrained to the shape of the communications array and its topology requirements. Our analysis is validated by simulation experiments, confirming the value of our model in providing system designers with a tool to drastically improve the trade-off between angular capabilities for sensing and the cost of the deployed hardware. Finally, we discuss possible enhancements to the cellular standards to fully leverage the angular capabilities of such mono-static ISAC systems.
http://w3id.org/mlsea/pwc/scientificWork/Anticipate%20%26%20Collab%3A%20Data-driven%20Task%20Anticipation%20and%20Knowledge-driven%20Planning%20for%20Human-robot%20Collaboration                                                                                  Anticipate & Collab: Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration                                                                                  An agent assisting humans in daily living activities can collaborate more effectively by anticipating upcoming tasks. Data-driven methods represent the state of the art in task anticipation, planning, and related problems, but these methods are resource-hungry and opaque. Our prior work introduced a proof of concept framework that used an LLM to anticipate 3 high-level tasks that served as goals for a classical planning system that computed a sequence of low-level actions for the agent to achieve these goals. This paper describes DaTAPlan, our framework that significantly extends our prior work toward human-robot collaboration. Specifically, DaTAPlan planner computes actions for an agent and a human to collaboratively and jointly achieve the tasks anticipated by the LLM, and the agent automatically adapts to unexpected changes in human action outcomes and preferences. We evaluate DaTAPlan capabilities in a realistic simulation environment, demonstrating accurate task anticipation, effective human-robot collaboration, and the ability to adapt to unexpected changes. Project website: https://dataplan-hrc.github.io
http://w3id.org/mlsea/pwc/scientificWork/Any2Point%3A%20Empowering%20Any-modality%20Large%20Models%20for%20Efficient%203D%20Understanding                                                                                  Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding                                                                                  Large foundation models have recently emerged as a prominent focus of interest, attaining superior performance in widespread scenarios. Due to the scarcity of 3D data, many efforts have been made to adapt pre-trained transformers from vision to 3D domains. However, such 2D-to-3D approaches are still limited, due to the potential loss of spatial geometries and high computation cost. More importantly, their frameworks are mainly designed for 2D models, lacking a general any-to-3D paradigm. In this paper, we introduce Any2Point, a parameter-efficient method to empower any-modality large models (vision, language, audio) for 3D understanding. Given a frozen transformer from any source modality, we propose a 3D-to-any (1D or 2D) virtual projection strategy that correlates the input 3D points to the original 1D or 2D positions within the source modality. This mechanism enables us to assign each 3D token with a positional encoding paired with the pre-trained model, which avoids 3D geometry loss caused by the true projection and better motivates the transformer for 3D learning with 1D/2D positional priors. Then, within each transformer block, we insert an any-to-3D guided adapter module for parameter-efficient fine-tuning. The adapter incorporates prior spatial knowledge from the source modality to guide the local feature aggregation of 3D tokens, compelling the semantic adaption of any-modality transformers. We conduct extensive experiments to showcase the effectiveness and efficiency of our method. Code and models are released at https://github.com/Ivan-Tang-3D/Any2Point.
http://w3id.org/mlsea/pwc/scientificWork/AnyV2V%3A%20A%20Plug-and-Play%20Framework%20For%20Any%20Video-to-Video%20Editing%20Tasks                                                                                  AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks                                                                                  Video-to-video editing involves editing a source video along with additional control (such as text prompts, subjects, or styles) to generate a new video that aligns with the source video and the provided control. Traditional methods have been constrained to certain editing types, limiting their ability to meet the wide range of user demands. In this paper, we introduce AnyV2V, a novel training-free framework designed to simplify video editing into two primary steps: (1) employing an off-the-shelf image editing model (e.g. InstructPix2Pix, InstantID, etc) to modify the first frame, (2) utilizing an existing image-to-video generation model (e.g. I2VGen-XL) for DDIM inversion and feature injection. In the first stage, AnyV2V can plug in any existing image editing tools to support an extensive array of video editing tasks. Beyond the traditional prompt-based editing methods, AnyV2V also can support novel video editing tasks, including reference-based style transfer, subject-driven editing, and identity manipulation, which were unattainable by previous methods. In the second stage, AnyV2V can plug in any existing image-to-video models to perform DDIM inversion and intermediate feature injection to maintain the appearance and motion consistency with the source video. On the prompt-based editing, we show that AnyV2V can outperform the previous best approach by 35 % on prompt alignment, and 25 % on human preference. On the three novel tasks, we show that AnyV2V also achieves a high success rate. We believe AnyV2V will continue to thrive due to its ability to seamlessly integrate the fast-evolving image editing methods. Such compatibility can help AnyV2V to increase its versatility to cater to diverse user demands.
http://w3id.org/mlsea/pwc/scientificWork/Anything%20in%20Any%20Scene%3A%20Photorealistic%20Video%20Object%20Insertion                                                                                  Anything in Any Scene: Photorealistic Video Object Insertion                                                                                  Realistic video simulation has shown significant potential across diverse applications, from virtual reality to film production. This is particularly true for scenarios where capturing videos in real-world settings is either impractical or expensive. Existing approaches in video simulation often fail to accurately model the lighting environment, represent the object geometry, or achieve high levels of photorealism. In this paper, we propose Anything in Any Scene, a novel and generic framework for realistic video simulation that seamlessly inserts any object into an existing dynamic video with a strong emphasis on physical realism. Our proposed general framework encompasses three key processes: 1) integrating a realistic object into a given scene video with proper placement to ensure geometric realism; 2) estimating the sky and environmental lighting distribution and simulating realistic shadows to enhance the light realism; 3) employing a style transfer network that refines the final video output to maximize photorealism. We experimentally demonstrate that Anything in Any Scene framework produces simulated videos of great geometric realism, lighting realism, and photorealism. By significantly mitigating the challenges associated with video data generation, our framework offers an efficient and cost-effective solution for acquiring high-quality videos. Furthermore, its applications extend well beyond video data augmentation, showing promising potential in virtual reality, video editing, and various other video-centric applications. Please check our project website https://anythinginanyscene.github.io for access to our project code and more high-resolution video results.
http://w3id.org/mlsea/pwc/scientificWork/Aperiodic%20two-layer%20energy%20management%20system%20for%20community%20microgrids%20based%20on%20blockchain%20strategy                                                                                  Aperiodic two-layer energy management system for community microgrids based on blockchain strategy                                                                                  This work proposes a geographically-based split of the community microgrids into clusters of members that tend to have similar consumption and generation profiles. Assuming a community microgrid divided into clusters, a two-layer architecture is developed to facilitate the greater penetration of distributed energy resources in an efficient way. The first layer, referred as the market layer, is responsible for creating local energy markets with the aim of maximising the economic benefits for community microgrid members. The second layer is responsible for the network reconfiguration, which is based on the energy balance within each cluster. This layer complies with the IEC 61850 communication standard, in order to control commercial sectionalizing and tie switches. This allows the community microgrid network to be reconfigured to minimise energy exchanges with the main grid. To implement this two-layer energy management strategy, an aperiodic market approach based on Blockchain technology, and the additional functionality offered by Smart Contracts is adopted. This embraces the concept of energy communities since it decentralizes the control and eliminates intermediaries. The use of aperiodic control techniques helps to overcome the challenges of using Blockchain technology in terms of storage, computational requirements and member privacy. The scalability and modularity of the Smart Contract-based system allow each cluster of members to be designed by tailoring the system to their specific needs. The implementation of this strategy is based on low-cost off-the-shelf devices, such as Raspberry Pi 4 Model B boards, which operate as Blockchain nodes of community microgrid members. Finally, the strategy has been validated by emulating two use cases based on the IEEE 123-node system network model highlighting the benefits of the proposal.
http://w3id.org/mlsea/pwc/scientificWork/Appeal%3A%20Allow%20Mislabeled%20Samples%20the%20Chance%20to%20be%20Rectified%20in%20Partial%20Label%20Learning                                                                                  Appeal: Allow Mislabeled Samples the Chance to be Rectified in Partial Label Learning                                                                                  In partial label learning (PLL), each instance is associated with a set of candidate labels among which only one is ground-truth. The majority of the existing works focuses on constructing robust classifiers to estimate the labeling confidence of candidate labels in order to identify the correct one. However, these methods usually struggle to identify and rectify mislabeled samples. To help these mislabeled samples 'appeal' for themselves and help existing PLL methods identify and rectify mislabeled samples, in this paper, we propose the first appeal-based PLL framework. Specifically, we introduce a novel partner classifier and instantiate it predicated on the implicit fact that non-candidate labels of a sample should not be assigned to it, which is inherently accurate and has not been fully investigated in PLL. Furthermore, a novel collaborative term is formulated to link the base classifier and the partner one. During each stage of mutual supervision, both classifiers will blur each other's predictions through a blurring mechanism to prevent overconfidence in a specific label. Extensive experiments demonstrate that the appeal and disambiguation ability of several well-established stand-alone and deep-learning based PLL approaches can be significantly improved by coupling with this learning paradigm.
http://w3id.org/mlsea/pwc/scientificWork/Applicability%20of%20oculomics%20for%20individual%20risk%20prediction%3A%20Repeatability%20and%20robustness%20of%20retinal%20Fractal%20Dimension%20using%20DART%20and%20AutoMorph                                                                                  Applicability of oculomics for individual risk prediction: Repeatability and robustness of retinal Fractal Dimension using DART and AutoMorph                                                                                  Purpose: To investigate whether Fractal Dimension (FD)-based oculomics could be used for individual risk prediction by evaluating repeatability and robustness. Methods: We used two datasets: Caledonia, healthy adults imaged multiple times in quick succession for research (26 subjects, 39 eyes, 377 colour fundus images), and GRAPE, glaucoma patients with baseline and follow-up visits (106 subjects, 196 eyes, 392 images). Mean follow-up time was 18.3 months in GRAPE, thus it provides a pessimistic lower-bound as vasculature could change. FD was computed with DART and AutoMorph. Image quality was assessed with QuickQual, but no images were initially excluded. Pearson, Spearman, and Intraclass Correlation (ICC) were used for population-level repeatability. For individual-level repeatability, we introduce measurement noise parameter { lambda} which is within-eye Standard Deviation (SD) of FD measurements in units of between-eyes SD. Results: In Caledonia, ICC was 0.8153 for DART and 0.5779 for AutoMorph, Pearson/Spearman correlation (first and last image) 0.7857/0.7824 for DART, and 0.3933/0.6253 for AutoMorph. In GRAPE, Pearson/Spearman correlation (first and next visit) was 0.7479/0.7474 for DART, and 0.7109/0.7208 for AutoMorph (all p<0.0001). Median { lambda} in Caledonia without exclusions was 3.55 % for DART and 12.65 % for AutoMorph, and improved to up to 1.67 % and 6.64 % with quality-based exclusions, respectively. Quality exclusions primarily mitigated large outliers. Worst quality in an eye correlated strongly with { lambda} (Pearson 0.5350-0.7550, depending on dataset and method, all p<0.0001). Conclusions: Repeatability was sufficient for individual-level predictions in heterogeneous populations. DART performed better on all metrics and might be able to detect small, longitudinal changes, highlighting the potential of robust methods.
http://w3id.org/mlsea/pwc/scientificWork/Application%20Of%20Vision-Language%20Models%20For%20Assessing%20Osteoarthritis%20Disease%20Severity                                                                                  Application Of Vision-Language Models For Assessing Osteoarthritis Disease Severity                                                                                  Osteoarthritis (OA) poses a global health challenge, demanding precise diagnostic methods. Current radiographic assessments are time consuming and prone to variability, prompting the need for automated solutions. The existing deep learning models for OA assessment are unimodal single task systems and they don't incorporate relevant text information such as patient demographics, disease history, or physician reports. This study investigates employing Vision Language Processing (VLP) models to predict OA severity using Xray images and corresponding reports. Our method leverages Xray images of the knee and diverse report templates generated from tabular OA scoring values to train a CLIP (Contrastive Language Image PreTraining) style VLP model. Furthermore, we incorporate additional contrasting captions to enforce the model to discriminate between positive and negative reports. Results demonstrate the efficacy of these models in learning text image representations and their contextual relationships, showcase potential advancement in OA assessment, and establish a foundation for specialized vision language models in medical contexts.
http://w3id.org/mlsea/pwc/scientificWork/Application%20of%20Distributed%20Arithmetic%20to%20Adaptive%20Filtering%20Algorithms%3A%20Trends%2C%20Challenges%20and%20Future                                                                                  Application of Distributed Arithmetic to Adaptive Filtering Algorithms: Trends, Challenges and Future                                                                                  The utilization of distributed arithmetic (DA) in AF algorithms has gained significant attention in recent years due to its potential to enhance computational efficiency and reduce resource requirements. This paper presents an exploration of the application of DA to adaptive filtering (AF) algorithms, analyzing trends, discussing challenges, and outlining future prospects. It begins by providing an overview of both DA and AF algorithms, highlighting their individual merits and established applications. Subsequently, the integration of DA into AF algorithms is explored, showcasing its ability to optimize multiply-accumulate operations and mitigate the computational burden associated with AF algorithms. Throughout the paper, the critical trends observed in the field are discussed, including advancements in DA-based hardware architectures. Moreover, the challenges encountered in implementing DA-based AF is also discussed. The continued evolution of DA techniques to cater to the demands of modern AF applications, including real-time processing, resource-constrained environments, and high-dimensional data streams is anticipated. In conclusion, this paper consolidates the current state of applying DA to AF algorithms, offering insights into prevailing trends, discussing challenges, and presenting future research and development in the field. The fusion of these two domains holds promise for achieving improved computational efficiency, reduced hardware complexity, and enhanced performance in various signal processing applications.
http://w3id.org/mlsea/pwc/scientificWork/Application%20of%20GPT%20Language%20Models%20for%20Innovation%20in%20Activities%20in%20University%20Teaching                                                                                  Application of GPT Language Models for Innovation in Activities in University Teaching                                                                                  The GPT (Generative Pre-trained Transformer) language models are an artificial intelligence and natural language processing technology that enables automatic text generation. There is a growing interest in applying GPT language models to university teaching in various dimensions. From the perspective of innovation in student and teacher activities, they can provide support in understanding and generating content, problem-solving, as well as personalization and test correction, among others. From the dimension of internationalization, the misuse of these models represents a global problem that requires taking a series of common measures in universities from different geographical areas. In several countries, there has been a review of assessment tools to ensure that work is done by students and not by AI. To this end, we have conducted a detailed experiment in a representative subject of Computer Science such as Software Engineering, which has focused on evaluating the use of ChatGPT as an assistant in theory activities, exercises, and laboratory practices, assessing its potential use as a support tool for both students and teachers.
http://w3id.org/mlsea/pwc/scientificWork/Application%20of%20Joint%20Notch%20Filtering%20and%20Wavelet%20Transform%20for%20Enhanced%20Powerline%20Interference%20Removal%20in%20Atrial%20Fibrillation%20Electrograms                                                                                  Application of Joint Notch Filtering and Wavelet Transform for Enhanced Powerline Interference Removal in Atrial Fibrillation Electrograms                                                                                  Analysis of intra-atrial electrograms (EGMs) nowadays constitutes the most common way to gain new insights about the mechanisms triggering and maintaining atrial fibrillation (AF). However, these recordings are highly contaminated by powerline interference (PLI) due to the large amount of electrical devices operating simultaneously in the electrophysiology laboratory. To remove this perturbation, conventional notch filtering has been widely used. However, this method adds artificial fractionation to the EGMs, thus concealing their accurate interpretation. Hence, the development of novel algorithms for PLI suppression in EGMs is still an unresolved challenge. Within this context, the present work introduces the joint application of common notch filtering and Wavelet denoising for enhanced PLI removal in AF EGMs. The algorithm was validated on a set of 100 unipolar EGM signals, which were synthesized with different noise levels. Original and denoised EGMs were compared in terms of a signed correlation index (SCI), computed both in time and frequency domains. Compared with the single use of notch filtering, improvements between 4 and 15% were reached with Wavelet denoising in both domains. As a consequence, the proposed algorithm was able to efficiently reduce high levels of PLI and simultaneously preserve the original morphology of AF EGMs.
http://w3id.org/mlsea/pwc/scientificWork/Application%20of%20Principal%20Component%20Analysis%20and%20Artificial%20Neural%20Networks%20for%20the%20Prediction%20of%20QoS%20in%20FSO%20Links%20over%20South%20Africa                                                                                  Application of Principal Component Analysis and Artificial Neural Networks for the Prediction of QoS in FSO Links over South Africa                                                                                  Optical Communication in Free Space (FSO) bids more radio bandwidth, operates under a gratis license, and has a lower startup cost as compared to Radio Frequency (RF). Nonetheless, its vulnerability to variations in atmospheric meteorological circumstances is a concern. Ultimately, the purpose of this study is to use Principal Component Analysis (PCA) with Artificial Neural Networks (ANN) to design a QoS prediction model for a terrestrial FSO communication connection. To accomplish the specified goal, meteorological data such as visibility, wind speed, and altitude were collected from the Weather Services in South Africa (SAWS) archive during a ten-year duration at five different locations: George, Johannesburg, Kimberly, Bloemfontein, and Polokwane. The eigenvalues of the first Principal Component (PC1) and the second Principal Component (PC2) in the PCA across the stations Bloemfontein, Johannesburg, Kimberly, George, and Polokwane are 7.624 and 1.020, 7.234, and 0.984, 6.204 and 1.723, 7.354 and 0.876, and 7.104 and 0.865, respectively, demonstrating that, they are kept as QoS variables to train the Artificial Neural Network (ANN) model as they provide the most compelling interpretation of the original variable data. The RMSE values of every proposed model across all the study locations are 0.1437, 0.2131, 0.2329, 0.1101, and 0.1977, respectively. Based on the RMSE, the proposed performed better over George. A realistic and accurate predictive model is developed for each of the study locations. Thus, the developed model will serve as a valuable tool for maintaining good QoS in FSO network services and improving telecom businesses in South Africa.
http://w3id.org/mlsea/pwc/scientificWork/Application%20of%20Time-Aware%20PC%20algorithm%20to%20compute%20Causal%20Functional%20Connectivity%20in%20Alzheimer%27s%20Disease%20from%20fMRI%20data                                                                                  Application of Time-Aware PC algorithm to compute Causal Functional Connectivity in Alzheimer's Disease from fMRI data                                                                                  Functional Connectivity between brain regions is known to be altered in Alzheimer's disease, and promises to be a biomarker for early diagnosis of the disease. While several approaches for functional connectivity obtain an un-directed network representing stochastic associations (correlations) between brain regions, association does not necessarily imply causation. In contrast, Causal Functional Connectivity is more informative, providing a directed network representing causal relationships between brain regions. In this paper, we obtained the causal functional connectome for the whole brain from recordings of resting-state functional magnetic resonance imaging (rs-fMRI) for subjects from three clinical groups: cognitively normal, mild cognitive impairment, and Alzheimer's disease. We applied the recently developed Time-aware PC (TPC) algorithm to infer the causal functional connectome for the whole brain. TPC supports model-free estimation of whole brain causal functional connectivity based on directed graphical modeling in a time series setting. We then perform an exploratory analysis to identify the causal brain connections between brain regions which have altered strengths between pairs of subject groups, and over the three subject groups, based on edge-wise p-values from statistical tests. We used the altered causal brain connections thus obtained to compile a comprehensive list of brain regions impacted by Alzheimer's disease according to the current data set. The brain regions thus identified are found to be in agreement with literature on brain regions impacted by Alzheimer's disease, published by researchers from clinical/medical institutions.
http://w3id.org/mlsea/pwc/scientificWork/Applications%20of%20Tao%20General%20Difference%20in%20Discrete%20Domain                                                                                  Applications of Tao General Difference in Discrete Domain                                                                                  Numerical difference computation is one of the cores and indispensable in the modern digital era. Tao general difference (TGD) is a novel theory and approach to difference computation for discrete sequences and arrays in multidimensional space. Built on the solid theoretical foundation of the general difference in a finite interval, the TGD operators demonstrate exceptional signal processing capabilities in real-world applications. A novel smoothness property of a sequence is defined on the first- and second TGD. This property is used to denoise one-dimensional signals, where the noise is the non-smooth points in the sequence. Meanwhile, the center of the gradient in a finite interval can be accurately location via TGD calculation. This solves a traditional challenge in computer vision, which is the precise localization of image edges with noise robustness. Furthermore, the power of TGD operators extends to spatio-temporal edge detection in three-dimensional arrays, enabling the identification of kinetic edges in video data. These diverse applications highlight the properties of TGD in discrete domain and the significant promise of TGD for the computation across signal processing, image analysis, and video analytic.
http://w3id.org/mlsea/pwc/scientificWork/Applications%2C%20challenges%20and%20ethical%20issues%20of%20AI%20and%20ChatGPT%20in%20education                                                                                  Applications, challenges and ethical issues of AI and ChatGPT in education                                                                                  Artificial Intelligence (AI) in recent years has shown an unprecedentedly impressive development, tending to play a catalytic role in all aspects of life. The interest of the academic community, but also of governments, is huge in the dynamics of AI and is reflected by the truly explosive amount of investment and research that is underway. Enthusiastic opinions and statements about AI are made every day, but at the same time they also bring to the fore alarming predictions about its effects. This paper aims to describe the opportunities emerging from the use of artificial intelligence and ChatGPT to improve education, but also to identify the challenges and ethical issues that arise.
http://w3id.org/mlsea/pwc/scientificWork/Apprentice%20Tutor%20Builder%3A%20A%20Platform%20For%20Users%20to%20Create%20and%20Personalize%20Intelligent%20Tutors                                                                                  Apprentice Tutor Builder: A Platform For Users to Create and Personalize Intelligent Tutors                                                                                  Intelligent tutoring systems (ITS) are effective for improving students' learning outcomes. However, their development is often complex, time-consuming, and requires specialized programming and tutor design knowledge, thus hindering their widespread application and personalization. We present the Apprentice Tutor Builder (ATB) , a platform that simplifies tutor creation and personalization. Instructors can utilize ATB's drag-and-drop tool to build tutor interfaces. Instructors can then interactively train the tutors' underlying AI agent to produce expert models that can solve problems. Training is achieved via using multiple interaction modalities including demonstrations, feedback, and user labels. We conducted a user study with 14 instructors to evaluate the effectiveness of ATB's design with end users. We found that users enjoyed the flexibility of the interface builder and ease and speed of agent teaching, but often desired additional time-saving features. With these insights, we identified a set of design recommendations for our platform and others that utilize interactive AI agents for tutor creation and customization.
http://w3id.org/mlsea/pwc/scientificWork/Approximating%20a%20linear%20dynamical%20system%20from%20non-sequential%20data                                                                                  Approximating a linear dynamical system from non-sequential data                                                                                  Given non-sequential snapshots from instances of a dynamical system, we design a compressed sensing based algorithm that reconstructs the dynamical system. We formally prove that successful reconstruction is possible under the assumption that we can construct an approximate clock from a subset of the coordinates of the underlying system. As an application, we argue that our assumption is likely true for genomic datasets, and we recover the underlying nuclear receptor networks and predict pathways, as opposed to genes, that may differentiate phenotypes in some publicly available datasets.
http://w3id.org/mlsea/pwc/scientificWork/Approximating%20reproduction%20numbers%3A%20a%20general%20numerical%20method%20for%20age-structured%20models                                                                                  Approximating reproduction numbers: a general numerical method for age-structured models                                                                                  In this paper, we introduce a general numerical method to approximate the reproduction numbers of a large class of multi-group, age-structured, population models with a finite age span. To provide complete flexibility in the definition of the birth and transition processes, we propose an equivalent formulation for the age-integrated state within the extended space framework. Then, we discretize the birth and transition operators via pseudospectral collocation. We discuss applications to epidemic models with continuous and piecewise continuous rates, with different interpretations of the age variable (e.g., demographic age, infection age and disease age) and the transmission terms (e.g., horizontal and vertical transmission). The tests illustrate that the method can compute different reproduction numbers, including the basic and type reproduction numbers as special cases.
http://w3id.org/mlsea/pwc/scientificWork/Approximation%20of%20a%20Pareto%20Set%20Segment%20Using%20a%20Linear%20Model%20with%20Sharing%20Variables                                                                                  Approximation of a Pareto Set Segment Using a Linear Model with Sharing Variables                                                                                  In many real-world applications, the Pareto Set (PS) of a continuous multiobjective optimization problem can be a piecewise continuous manifold. A decision maker may want to find a solution set that approximates a small part of the PS and requires the solutions in this set share some similarities. This paper makes a first attempt to address this issue. We first develop a performance metric that considers both optimality and variable sharing. Then we design an algorithm for finding the model that minimizes the metric to meet the user's requirements. Experimental results illustrate that we can obtain a linear model that approximates the mapping from the preference vectors to solutions in a local area well.
http://w3id.org/mlsea/pwc/scientificWork/Approximations%20in%20the%20homogeneous%20Ising%20model                                                                                  Approximations in the homogeneous Ising model                                                                                  The Ising model is important in statistical modeling and inference in many applications, however its normalizing constant, mean number of active vertices and mean spin interaction -- quantities needed in inference -- are computationally intractable. We provide accurate approximations that make it possible to numerically calculate these quantities in the homogeneous case. Simulation studies indicate good performance of our approximation formulae that are scalable and unfazed by the size (number of nodes, degree of graph) of the Markov Random Field. The practical import of our approximation formulae is illustrated in performing Bayesian inference in a functional Magnetic Resonance Imaging activation detection experiment, and also in likelihood ratio testing for anisotropy in the spatial patterns of yearly increases in pistachio tree yields.
http://w3id.org/mlsea/pwc/scientificWork/ArCHer%3A%20Training%20Language%20Model%20Agents%20via%20Hierarchical%20Multi-Turn%20RL                                                                                  ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL                                                                                  A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or 'agent' tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively. To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn. Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods. Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).
http://w3id.org/mlsea/pwc/scientificWork/AraPoemBERT%3A%20A%20Pretrained%20Language%20Model%20for%20Arabic%20Poetry%20Analysis                                                                                  AraPoemBERT: A Pretrained Language Model for Arabic Poetry Analysis                                                                                  Arabic poetry, with its rich linguistic features and profound cultural significance, presents a unique challenge to the Natural Language Processing (NLP) field. The complexity of its structure and context necessitates advanced computational models for accurate analysis. In this paper, we introduce AraPoemBERT, an Arabic language model pretrained exclusively on Arabic poetry text. To demonstrate the effectiveness of the proposed model, we compared AraPoemBERT with 5 different Arabic language models on various NLP tasks related to Arabic poetry. The new model outperformed all other models and achieved state-of-the-art results in most of the downstream tasks. AraPoemBERT achieved unprecedented accuracy in two out of three novel tasks: poet's gender classification (99.34 % accuracy), and poetry sub-meter classification (97.79 % accuracy). In addition, the model achieved an accuracy score in poems' rhyme classification (97.73 % accuracy) which is almost equivalent to the best score reported in this study. Moreover, the proposed model significantly outperformed previous work and other comparative models in the tasks of poems' sentiment analysis, achieving an accuracy of 78.95 %, and poetry meter classification (99.03 % accuracy), while significantly expanding the scope of these two problems. The dataset used in this study, contains more than 2.09 million verses collected from online sources, each associated with various attributes such as meter, sub-meter, poet, rhyme, and topic. The results demonstrate the effectiveness of the proposed model in understanding and analyzing Arabic poetry, achieving state-of-the-art results in several tasks and outperforming previous works and other language models included in the study. AraPoemBERT model is publicly available on url{https://huggingface.co/faisalq}.
http://w3id.org/mlsea/pwc/scientificWork/Arbitrary-Scale%20Downscaling%20of%20Tidal%20Current%20Data%20Using%20Implicit%20Continuous%20Representation                                                                                  Arbitrary-Scale Downscaling of Tidal Current Data Using Implicit Continuous Representation                                                                                  Numerical models have long been used to understand geoscientific phenomena, including tidal currents, crucial for renewable energy production and coastal engineering. However, their computational cost hinders generating data of varying resolutions. As an alternative, deep learning-based downscaling methods have gained traction due to their faster inference speeds. But most of them are limited to only inference fixed scale and overlook important characteristics of target geoscientific data. In this paper, we propose a novel downscaling framework for tidal current data, addressing its unique characteristics, which are dissimilar to images: heterogeneity and local dependency. Moreover, our framework can generate any arbitrary-scale output utilizing a continuous representation model. Our proposed framework demonstrates significantly improved flow velocity predictions by 93.21% (MSE) and 63.85% (MAE) compared to the Baseline model while achieving a remarkable 33.2% reduction in FLOPs.
http://w3id.org/mlsea/pwc/scientificWork/Architectural%20Blueprint%20For%20Heterogeneity-Resilient%20Federated%20Learning                                                                                  Architectural Blueprint For Heterogeneity-Resilient Federated Learning                                                                                  This paper proposes a novel three tier architecture for federated learning to optimize edge computing environments. The proposed architecture addresses the challenges associated with client data heterogeneity and computational constraints. It introduces a scalable, privacy preserving framework that enhances the efficiency of distributed machine learning. Through experimentation, the paper demonstrates the architecture capability to manage non IID data sets more effectively than traditional federated learning models. Additionally, the paper highlights the potential of this innovative approach to significantly improve model accuracy, reduce communication overhead, and facilitate broader adoption of federated learning technologies.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Bias%20Mitigation%20Techniques%20for%20Deep%20Learning%20Effective%3F                                                                                  Are Bias Mitigation Techniques for Deep Learning Effective?                                                                                  A critical problem in deep learning is that systems learn inappropriate biases, resulting in their inability to perform well on minority groups. This has led to the creation of multiple algorithms that endeavor to mitigate bias. However, it is not clear how effective these methods are. This is because study protocols differ among papers, systems are tested on datasets that fail to test many forms of bias, and systems have access to hidden knowledge or are tuned specifically to the test set. To address this, we introduce an improved evaluation protocol, sensible metrics, and a new dataset, which enables us to ask and answer critical questions about bias mitigation algorithms. We evaluate seven state-of-the-art algorithms using the same network architecture and hyperparameter selection policy across three benchmark datasets. We introduce a new dataset called Biased MNIST that enables assessment of robustness to multiple bias sources. We use Biased MNIST and a visual question answering (VQA) benchmark to assess robustness to hidden biases. Rather than only tuning to the test set distribution, we study robustness across different tuning distributions, which is critical because for many applications the test distribution may not be known during development. We find that algorithms exploit hidden biases, are unable to scale to multiple forms of bias, and are highly sensitive to the choice of tuning set. Based on our findings, we implore the community to adopt more rigorous assessment of future bias mitigation methods. All data, code, and results are publicly available at: https://github.com/erobic/bias-mitigators.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Classification%20Robustness%20and%20Explanation%20Robustness%20Really%20Strongly%20Correlated%3F%20An%20Analysis%20Through%20Input%20Loss%20Landscape                                                                                  Are Classification Robustness and Explanation Robustness Really Strongly Correlated? An Analysis Through Input Loss Landscape                                                                                  This paper delves into the critical area of deep learning robustness, challenging the conventional belief that classification robustness and explanation robustness in image classification systems are inherently correlated. Through a novel evaluation approach leveraging clustering for efficient assessment of explanation robustness, we demonstrate that enhancing explanation robustness does not necessarily flatten the input loss landscape with respect to explanation loss - contrary to flattened loss landscapes indicating better classification robustness. To deeply investigate this contradiction, a groundbreaking training method designed to adjust the loss landscape with respect to explanation loss is proposed. Through the new training method, we uncover that although such adjustments can impact the robustness of explanations, they do not have an influence on the robustness of classification. These findings not only challenge the prevailing assumption of a strong correlation between the two forms of robustness but also pave new pathways for understanding relationship between loss landscape and explanation loss.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Ensembles%20Getting%20Better%20all%20the%20Time%3F                                                                                  Are Ensembles Getting Better all the Time?                                                                                  Ensemble methods combine the predictions of several base models. We study whether or not including more models always improves their average performance. This question depends on the kind of ensemble considered, as well as the predictive metric chosen. We focus on situations where all members of the ensemble are a priori expected to perform as well, which is the case of several popular methods such as random forests or deep ensembles. In this setting, we show that ensembles are getting better all the time if, and only if, the considered loss function is convex. More precisely, in that case, the average loss of the ensemble is a decreasing function of the number of models. When the loss function is nonconvex, we show a series of results that can be summarised as: ensembles of good models keep getting better, and ensembles of bad models keep getting worse. To this end, we prove a new result on the monotonicity of tail probabilities that may be of independent interest. We illustrate our results on a medical prediction problem (diagnosing melanomas using neural nets) and a 'wisdom of crowds' experiment (guessing the ratings of upcoming movies).
http://w3id.org/mlsea/pwc/scientificWork/Are%20Generative%20AI%20systems%20Capable%20of%20Supporting%20Information%20Needs%20of%20Patients%3F                                                                                  Are Generative AI systems Capable of Supporting Information Needs of Patients?                                                                                  Patients managing a complex illness such as cancer face a complex information challenge where they not only must learn about their illness but also how to manage it. Close interaction with healthcare experts (radiologists, oncologists) can improve patient learning and thereby, their disease outcome. However, this approach is resource intensive and takes expert time away from other critical tasks. Given the recent advancements in Generative AI models aimed at improving the healthcare system, our work investigates whether and how generative visual question answering systems can responsibly support patient information needs in the context of radiology imaging data. We conducted a formative need-finding study in which participants discussed chest computed tomography (CT) scans and associated radiology reports of a fictitious close relative with a cardiothoracic radiologist. Using thematic analysis of the conversation between participants and medical experts, we identified commonly occurring themes across interactions, including clarifying medical terminology, locating the problems mentioned in the report in the scanned image, understanding disease prognosis, discussing the next diagnostic steps, and comparing treatment options. Based on these themes, we evaluated two state-of-the-art generative visual language models against the radiologist's responses. Our results reveal variability in the quality of responses generated by the models across various themes. We highlight the importance of patient-facing generative AI systems to accommodate a diverse range of conversational themes, catering to the real-world informational needs of patients.
http://w3id.org/mlsea/pwc/scientificWork/Are%20ID%20Embeddings%20Necessary%3F%20Whitening%20Pre-trained%20Text%20Embeddings%20for%20Effective%20Sequential%20Recommendation                                                                                  Are ID Embeddings Necessary? Whitening Pre-trained Text Embeddings for Effective Sequential Recommendation                                                                                  Recent sequential recommendation models have combined pre-trained text embeddings of items with item ID embeddings to achieve superior recommendation performance. Despite their effectiveness, the expressive power of text features in these models remains largely unexplored. While most existing models emphasize the importance of ID embeddings in recommendations, our study takes a step further by studying sequential recommendation models that only rely on text features and do not necessitate ID embeddings. Upon examining pretrained text embeddings experimentally, we discover that they reside in an anisotropic semantic space, with an average cosine similarity of over 0.8 between items. We also demonstrate that this anisotropic nature hinders recommendation models from effectively differentiating between item representations and leads to degenerated performance. To address this issue, we propose to employ a pre-processing step known as whitening transformation, which transforms the anisotropic text feature distribution into an isotropic Gaussian distribution. Our experiments show that whitening pre-trained text embeddings in the sequential model can significantly improve recommendation performance. However, the full whitening operation might break the potential manifold of items with similar text semantics. To preserve the original semantics while benefiting from the isotropy of the whitened text features, we introduce WhitenRec+, an ensemble approach that leverages both fully whitened and relaxed whitened item representations for effective recommendations. We further discuss and analyze the benefits of our design through experiments and proofs. Experimental results on three public benchmark datasets demonstrate that WhitenRec+ outperforms state-of-the-art methods for sequential recommendation.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Large%20Language%20Models%20Good%20Prompt%20Optimizers%3F                                                                                  Are Large Language Models Good Prompt Optimizers?                                                                                  LLM-based Automatic Prompt Optimization, which typically utilizes LLMs as Prompt Optimizers to self-reflect and refine prompts, has shown promising performance in recent studies. Despite the success, the underlying mechanism of this approach remains unexplored, and the true effectiveness of LLMs as Prompt Optimizers requires further validation. In this work, we conducted a comprehensive study to uncover the actual mechanism of LLM-based Prompt Optimization. Our findings reveal that the LLM optimizers struggle to identify the true causes of errors during reflection, tending to be biased by their own prior knowledge rather than genuinely reflecting on the errors. Furthermore, even when the reflection is semantically valid, the LLM optimizers often fail to generate appropriate prompts for the target models with a single prompt refinement step, partly due to the unpredictable behaviors of the target models. Based on the observations, we introduce a new 'Automatic Behavior Optimization' paradigm, which directly optimizes the target model's behavior in a more controllable manner. We hope our study can inspire new directions for automatic prompt optimization development.
http://w3id.org/mlsea/pwc/scientificWork/Are%20More%20LLM%20Calls%20All%20You%20Need%3F%20Towards%20Scaling%20Laws%20of%20Compound%20Inference%20Systems                                                                                  Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems                                                                                  Many recent state-of-the-art results in language tasks were achieved using compound systems that perform multiple Large Language Model (LLM) calls and aggregate their responses. However, there is little understanding of how the number of LLM calls -- e.g., when asking the LLM to answer each question multiple times and taking a consensus -- affects such a compound system's performance. In this paper, we initiate the study of scaling laws of compound inference systems. We analyze, theoretically and empirically, how the number of LLM calls affects the performance of one-layer Voting Inference Systems -- one of the simplest compound systems, which aggregates LLM responses via majority voting. We find empirically that across multiple language tasks, surprisingly, Voting Inference Systems' performance first increases but then decreases as a function of the number of LLM calls. Our theoretical results suggest that this non-monotonicity is due to the diversity of query difficulties within a task: more LLM calls lead to higher performance on 'easy' queries, but lower performance on 'hard' queries, and non-monotone behavior emerges when a task contains both types of queries. This insight then allows us to compute, from a small number of samples, the number of LLM calls that maximizes system performance, and define a scaling law of Voting Inference Systems. Experiments show that our scaling law can predict the performance of Voting Inference Systems and find the optimal number of LLM calls to make.
http://w3id.org/mlsea/pwc/scientificWork/Are%20self-explanations%20from%20Large%20Language%20Models%20faithful%3F                                                                                  Are self-explanations from Large Language Models faithful?                                                                                  Instruction-tuned Large Language Models (LLMs) excel at many tasks and will even explain their reasoning, so-called self-explanations. However, convincing and wrong self-explanations can lead to unsupported confidence in LLMs, thus increasing risk. Therefore, it's important to measure if self-explanations truly reflect the model's behavior. Such a measure is called interpretability-faithfulness and is challenging to perform since the ground truth is inaccessible, and many LLMs only have an inference API. To address this, we propose employing self-consistency checks to measure faithfulness. For example, if an LLM says a set of words is important for making a prediction, then it should not be able to make its prediction without these words. While self-consistency checks are a common approach to faithfulness, they have not previously been successfully applied to LLM self-explanations for counterfactual, importance measure, and redaction explanations. Our results demonstrate that faithfulness is explanation, model, and task-dependent, showing self-explanations should not be trusted in general. For example, with sentiment classification, counterfactuals are more faithful for Llama2, importance measures for Mistral, and redaction for Falcon 40B.
http://w3id.org/mlsea/pwc/scientificWork/Are%20you%20a%20robot%3F%20Detecting%20Autonomous%20Vehicles%20from%20Behavior%20Analysis                                                                                  Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis                                                                                  The tremendous hype around autonomous driving is eagerly calling for emerging and novel technologies to support advanced mobility use cases. As car manufactures keep developing SAE level 3+ systems to improve the safety and comfort of passengers, traffic authorities need to establish new procedures to manage the transition from human-driven to fully-autonomous vehicles while providing a feedback-loop mechanism to fine-tune envisioned autonomous systems. Thus, a way to automatically profile autonomous vehicles and differentiate those from human-driven ones is a must. In this paper, we present a fully-fledged framework that monitors active vehicles using camera images and state information in order to determine whether vehicles are autonomous, without requiring any active notification from the vehicles themselves. Essentially, it builds on the cooperation among vehicles, which share their data acquired on the road feeding a machine learning model to identify autonomous cars. We extensively tested our solution and created the NexusStreet dataset, by means of the CARLA simulator, employing an autonomous driving control agent and a steering wheel maneuvered by licensed drivers. Experiments show it is possible to discriminate the two behaviors by analyzing video clips with an accuracy of 80%, which improves up to 93% when the target state information is available. Lastly, we deliberately degraded the state to observe how the framework performs under non-ideal data collection conditions.
http://w3id.org/mlsea/pwc/scientificWork/Ariadne%20and%20Theseus%3A%20Exploration%20and%20Rendezvous%20with%20Two%20Mobile%20Agents%20in%20an%20Unknown%20Graph                                                                                  Ariadne and Theseus: Exploration and Rendezvous with Two Mobile Agents in an Unknown Graph                                                                                  We investigate two fundamental problems in mobile computing: exploration and rendezvous, with two distinct mobile agents in an unknown graph. The agents can read and write information on whiteboards that are located at all nodes. They both move along one adjacent edge at every time-step. In the exploration problem, both agents start from the same node of the graph and must traverse all of its edges. We show that a simple variant of depth-first search achieves collective exploration in $m$ synchronous time-steps, where $m$ is the number of edges of the graph. This improves the competitive ratio of collective graph exploration. In the rendezvous problem, the agents start from different nodes of the graph and must meet as fast as possible. We introduce an algorithm guaranteeing rendezvous in at most $ frac{3}{2}m$ time-steps. This improves over the so-called `wait for Mommy' algorithm which requires $2m$ time-steps. All our guarantees are derived from a more general asynchronous setting in which the speeds of the agents are controlled by an adversary at all times. Our guarantees also generalize to weighted graphs, if the number of edges $m$ is replaced by the sum of all edge lengths.
http://w3id.org/mlsea/pwc/scientificWork/Arrange%2C%20Inpaint%2C%20and%20Refine%3A%20Steerable%20Long-term%20Music%20Audio%20Generation%20and%20Editing%20via%20Content-based%20Controls                                                                                  Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls                                                                                  Controllable music generation plays a vital role in human-AI music co-creation. While Large Language Models (LLMs) have shown promise in generating high-quality music, their focus on autoregressive generation limits their utility in music editing tasks. To bridge this gap, we introduce a novel Parameter-Efficient Fine-Tuning (PEFT) method. This approach enables autoregressive language models to seamlessly address music inpainting tasks. Additionally, our PEFT method integrates frame-level content-based controls, facilitating track-conditioned music refinement and score-conditioned music arrangement. We apply this method to fine-tune MusicGen, a leading autoregressive music generation model. Our experiments demonstrate promising results across multiple music editing tasks, offering more flexible controls for future AI-driven music editing tools. A demo page footnote{ url{https://kikyo-16.github.io/AIR/}.} showcasing our work and source codes footnote{ url{https://github.com/Kikyo-16/airgen}.} are available online.
http://w3id.org/mlsea/pwc/scientificWork/Arrow%27s%20single%20peaked%20domains%2C%20richness%2C%20and%20domains%20for%20plurality%20and%20the%20Borda%20count                                                                                  Arrow's single peaked domains, richness, and domains for plurality and the Borda count                                                                                  In this paper we extend the study of Arrow's generalisation of Black's single-peaked domain and connect this to domains where voting rules satisfy different versions of independence of irrelevant alternatives. First we report on a computational generation of all non-isomorphic Arrow's single-peaked domains on $n leq 9$ alternatives. Next, we introduce a quantitative measure of richness for domains, as the largest number $r$ such that every alternative is given every rank between 1 and $r$ by the orders in the domain. We investigate the richness of Arrow's single-peaked domains and prove that Black's single-peaked domain has the highest possible richness, but it is not the only domain which attains the maximum. After this we connect Arrow's single-peaked domains to the discussion by Dasgupta, Maskin and others of domains on which plurality and the Borda count satisfy different versions of Independence of Irrelevant alternatives (IIA). For Nash's version of IIA and plurality, it turns out the domains are exactly the duals of Arrow's single-peaked domains. As a consequence there can be at most two alternatives which are ranked first in any such domain. For the Borda count both Arrow's and Nash's versions of IIA lead to a maximum domain size which is exponentially smaller than $2^{n-1}$, the size of Black's single-peaked domain.
http://w3id.org/mlsea/pwc/scientificWork/Artifact%20Reduction%20in%203D%20and%204D%20Cone-beam%20Computed%20Tomography%20Images%20with%20Deep%20Learning%20--%20A%20Review                                                                                  Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images with Deep Learning -- A Review                                                                                  Deep learning based approaches have been used to improve image quality in cone-beam computed tomography (CBCT), a medical imaging technique often used in applications such as image-guided radiation therapy, implant dentistry or orthopaedics. In particular, while deep learning methods have been applied to reduce various types of CBCT image artifacts arising from motion, metal objects, or low-dose acquisition, a comprehensive review summarizing the successes and shortcomings of these approaches, with a primary focus on the type of artifacts rather than the architecture of neural networks, is lacking in the literature. In this review, the data generation and simulation pipelines, and artifact reduction techniques are specifically investigated for each type of artifact. We provide an overview of deep learning techniques that have successfully been shown to reduce artifacts in 3D, as well as in time-resolved (4D) CBCT through the use of projection- and/or volume-domain optimizations, or by introducing neural networks directly within the CBCT reconstruction algorithms. Research gaps are identified to suggest avenues for future exploration. One of the key findings of this work is an observed trend towards the use of generative models including GANs and score-based or diffusion models, accompanied with the need for more diverse and open training datasets and simulations.
http://w3id.org/mlsea/pwc/scientificWork/Artifacts%20or%20Abduction%3A%20How%20Do%20LLMs%20Answer%20Multiple-Choice%20Questions%20Without%20the%20Question%3F                                                                                  Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions Without the Question?                                                                                  Multiple-choice question answering (MCQA) is often used to evaluate large language models (LLMs). To see if MCQA assesses LLMs as intended, we probe if LLMs can perform MCQA with choices-only prompts, where models must select the correct answer only from the choices. In three MCQA datasets and four LLMs, this prompt bests a majority baseline in 11/12 cases, with up to 0.33 accuracy gain. To help explain this behavior, we conduct an in-depth, black-box analysis on memorization, choice dynamics, and question inference. Our key findings are threefold. First, we find no evidence that the choices-only accuracy stems from memorization alone. Second, priors over individual choices do not fully explain choices-only accuracy, hinting that LLMs use the group dynamics of choices. Third, LLMs have some ability to infer a relevant question from choices, and surprisingly can sometimes even match the original question. We hope to motivate the use of stronger baselines in MCQA benchmarks, the design of robust MCQA datasets, and further efforts to explain LLM decision-making.
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Intelligence%20%28AI%29%20Based%20Prediction%20of%20Mortality%2C%20for%20COVID-19%20Patients                                                                                  Artificial Intelligence (AI) Based Prediction of Mortality, for COVID-19 Patients                                                                                  For severely affected COVID-19 patients, it is crucial to identify high-risk patients and predict survival and need for intensive care (ICU). Most of the proposed models are not well reported making them less reproducible and prone to high risk of bias particularly in presence of imbalance data/class. In this study, the performances of nine machine and deep learning algorithms in combination with two widely used feature selection methods were investigated to predict last status representing mortality, ICU requirement, and ventilation days. Fivefold cross-validation was used for training and validation purposes. To minimize bias, the training and testing sets were split maintaining similar distributions. Only 10 out of 122 features were found to be useful in prediction modelling with Acute kidney injury during hospitalization feature being the most important one. The algorithms performances depend on feature numbers and data pre-processing techniques. LSTM performs the best in predicting last status and ICU requirement with 90%, 92%, 86% and 95% accuracy, sensitivity, specificity, and AUC respectively. DNN performs the best in predicting Ventilation days with 88% accuracy. Considering all the factors and limitations including absence of exact time point of clinical onset, LSTM with carefully selected features can accurately predict last status and ICU requirement. DNN performs the best in predicting Ventilation days. Appropriate machine learning algorithm with carefully selected features and balance data can accurately predict mortality, ICU requirement and ventilation support. Such model can be very useful in emergency and pandemic where prompt and precise
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Intelligence%20Exploring%20the%20Patent%20Field                                                                                  Artificial Intelligence Exploring the Patent Field                                                                                  Advanced language-processing and machine-learning techniques promise massive efficiency improvements in the previously widely manual field of patent and technical knowledge management. This field presents large-scale and complex data with very precise contents and language representation of those contents. Particularly, patent texts can differ from mundane texts in various aspects, which entails significant opportunities and challenges. This paper presents a systematic overview of patent-related tasks and popular methodologies with a special focus on evolving and promising techniques. Language processing and particularly large language models as well as the recent boost of general generative methods promise to become game changers in the patent field. The patent literature and the fact-based argumentative procedures around patents appear almost as an ideal use case. However, patents entail a number of difficulties with which existing models struggle. The paper introduces fundamental aspects of patents and patent-related data that affect technology that wants to explore or manage them. It further reviews existing methods and approaches and points out how important reliable and unbiased evaluation metrics become. Although research has made substantial progress on certain tasks, the performance across many others remains suboptimal, sometimes because of either the special nature of patents and their language or inconsistencies between legal terms and the everyday meaning of terms. Moreover, yet few methods have demonstrated the ability to produce satisfactory text for specific sections of patents. By pointing out key developments, opportunities, and gaps, we aim to encourage further research and accelerate the advancement of this field.
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Intelligence%20enhanced%20Security%20Problems%20in%20Real-Time%20Scenario%20using%20Blowfish%20Algorithm                                                                                  Artificial Intelligence enhanced Security Problems in Real-Time Scenario using Blowfish Algorithm                                                                                  In a nutshell, 'the cloud' refers to a collection of interconnected computing resources made possible by an extensive, real-time communication network like the internet. Because of its potential to reduce processing costs, the emerging paradigm of cloud computing has recently attracted a large number of academics. The exponential expansion of cloud computing has made the rapid expansion of cloud services very remarkable. Ensuring the security of personal information in today's interconnected world is no easy task. These days, security is really crucial. Models of security that are relevant to cloud computing include confidentiality, authenticity, accessibility, data integrity, and recovery. Using the Hybrid Encryption this study, we cover all the security issues and leaks in cloud infrastructure.
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Intelligence%20for%20Literature%20Reviews%3A%20Opportunities%20and%20Challenges                                                                                  Artificial Intelligence for Literature Reviews: Opportunities and Challenges                                                                                  This manuscript presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates previous research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research.
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Intelligence%20in%20Image-based%20Cardiovascular%20Disease%20Analysis%3A%20A%20Comprehensive%20Survey%20and%20Future%20Outlook                                                                                  Artificial Intelligence in Image-based Cardiovascular Disease Analysis: A Comprehensive Survey and Future Outlook                                                                                  Recent advancements in Artificial Intelligence (AI) have significantly influenced the field of Cardiovascular Disease (CVD) analysis, particularly in image-based diagnostics. Our paper presents an extensive review of AI applications in image-based CVD analysis, offering insights into its current state and future potential. We systematically categorize the literature based on the primary anatomical structures related to CVD, dividing them into non-vessel structures (such as ventricles and atria) and vessel structures (including the aorta and coronary arteries). This categorization provides a structured approach to explore various imaging modalities like Magnetic Resonance Imaging (MRI), which are commonly used in CVD research. Our review encompasses these modalities, giving a broad perspective on the diverse imaging techniques integrated with AI for CVD analysis. Additionally, we compile a list of publicly accessible cardiac image datasets and code repositories, intending to support research reproducibility and facilitate data and algorithm sharing within the community. We conclude with an examination of the challenges and limitations inherent in current AI-based CVD analysis methods and suggest directions for future research to overcome these hurdles.
http://w3id.org/mlsea/pwc/scientificWork/As%20Firm%20As%20Their%20Foundations%3A%20Can%20open-sourced%20foundation%20models%20be%20used%20to%20create%20adversarial%20examples%20for%20downstream%20tasks%3F                                                                                  As Firm As Their Foundations: Can open-sourced foundation models be used to create adversarial examples for downstream tasks?                                                                                  Foundation models pre-trained on web-scale vision-language data, such as CLIP, are widely used as cornerstones of powerful machine learning systems. While pre-training offers clear advantages for downstream learning, it also endows downstream models with shared adversarial vulnerabilities that can be easily identified through the open-sourced foundation model. In this work, we expose such vulnerabilities in CLIP's downstream models and show that foundation models can serve as a basis for attacking their downstream systems. In particular, we propose a simple yet effective adversarial attack strategy termed Patch Representation Misalignment (PRM). Solely based on open-sourced CLIP vision encoders, this method produces adversaries that simultaneously fool more than 20 downstream models spanning 4 common vision-language tasks (semantic segmentation, object detection, image captioning and visual question-answering). Our findings highlight the concerning safety risks introduced by the extensive usage of public foundational models in the development of downstream systems, calling for extra caution in these scenarios.
http://w3id.org/mlsea/pwc/scientificWork/Asclepius%3A%20A%20Spectrum%20Evaluation%20Benchmark%20for%20Medical%20Multi-Modal%20Large%20Language%20Models                                                                                  Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models                                                                                  The significant breakthroughs of Medical Multi-Modal Large Language Models (Med-MLLMs) renovate modern healthcare with robust information synthesis and medical decision support. However, these models are often evaluated on benchmarks that are unsuitable for the Med-MLLMs due to the intricate nature of the real-world diagnostic frameworks, which encompass diverse medical specialties and involve complex clinical decisions. Moreover, these benchmarks are susceptible to data leakage, since Med-MLLMs are trained on large assemblies of publicly available data. Thus, an isolated and clinically representative benchmark is highly desirable for credible Med-MLLMs evaluation. To this end, we introduce Asclepius, a novel Med-MLLM benchmark that rigorously and comprehensively assesses model capability in terms of: distinct medical specialties (cardiovascular, gastroenterology, etc.) and different diagnostic capacities (perception, disease analysis, etc.). Grounded in 3 proposed core principles, Asclepius ensures a comprehensive evaluation by encompassing 15 medical specialties, stratifying into 3 main categories and 8 sub-categories of clinical tasks, and exempting from train-validate contamination. We further provide an in-depth analysis of 6 Med-MLLMs and compare them with 5 human specialists, providing insights into their competencies and limitations in various medical contexts. Our work not only advances the understanding of Med-MLLMs' capabilities but also sets a precedent for future evaluations and the safe deployment of these models in clinical environments. We launch and maintain a leaderboard for community assessment of Med-MLLM capabilities (https://asclepius-med.github.io/).
http://w3id.org/mlsea/pwc/scientificWork/Ask%20the%20experts%3A%20sourcing%20high-quality%20datasets%20for%20nutritional%20counselling%20through%20Human-AI%20collaboration                                                                                  Ask the experts: sourcing high-quality datasets for nutritional counselling through Human-AI collaboration                                                                                  Large Language Models (LLMs), with their flexible generation abilities, can be powerful data sources in domains with few or no available corpora. However, problems like hallucinations and biases limit such applications. In this case study, we pick nutrition counselling, a domain lacking any public resource, and show that high-quality datasets can be gathered by combining LLMs, crowd-workers and nutrition experts. We first crowd-source and cluster a novel dataset of diet-related issues, then work with experts to prompt ChatGPT into producing related supportive text. Finally, we let the experts evaluate the safety of the generated text. We release HAI-coaching, the first expert-annotated nutrition counselling dataset containing ~2.4K dietary struggles from crowd workers, and ~97K related supportive texts generated by ChatGPT. Extensive analysis shows that ChatGPT while producing highly fluent and human-like text, also manifests harmful behaviours, especially in sensitive topics like mental health, making it unsuitable for unsupervised use.
http://w3id.org/mlsea/pwc/scientificWork/Aspect%20Oriented%20Suggestion%20Extraction%20from%20Online%20Reviews                                                                                  Aspect Oriented Suggestion Extraction from Online Reviews                                                                                  In the world of business, products need to evolve adjusting to the needs of the customer to ensure customer satisfaction. The abundance of opinionated text on the internet contains suggestions made by users that can be used to improve products. These suggestions are important to multiple stakeholders; as product improvements for businesses or as tips and advice to consumers. Until now, the extraction of suggestions has usually been defined as a problem of classifying sentences into suggestion and non-suggestion classes. No work has attempted to differentiate suggestions on the basis of intended receiver. Extracting these suggestions with respect to the aspects that reviewers are not satisfied with, could be used as a potential solution to improve products. To address these shortcomings, this study proposes a novel task decomposition called Aspect Oriented Suggestion Extraction to identify product improvements. It contains three main subtasks: suggestion classification, beneficiary classification and aspect extraction. The proposed approach proved to be very effective in determining suggestions from non-suggestions, achieving an F-score of 91% with BERT pretrained language model, outperforming state-of-the-art methods on suggestion mining. Experimental results on hotel reviews show the effectiveness of the techniques. The proposed framework, being the first of its nature, yields promising results.
http://w3id.org/mlsea/pwc/scientificWork/Aspect-Based%20Sentiment%20Analysis%20for%20Open-Ended%20HR%20Survey%20Responses                                                                                  Aspect-Based Sentiment Analysis for Open-Ended HR Survey Responses                                                                                  Understanding preferences, opinions, and sentiment of the workforce is paramount for effective employee lifecycle management. Open-ended survey responses serve as a valuable source of information. This paper proposes a machine learning approach for aspect-based sentiment analysis (ABSA) of Dutch open-ended responses in employee satisfaction surveys. Our approach aims to overcome the inherent noise and variability in these responses, enabling a comprehensive analysis of sentiments that can support employee lifecycle management. Through response clustering we identify six key aspects (salary, schedule, contact, communication, personal attention, agreements), which we validate by domain experts. We compile a dataset of 1,458 Dutch survey responses, revealing label imbalance in aspects and sentiments. We propose few-shot approaches for ABSA based on Dutch BERT models, and compare them against bag-of-words and zero-shot baselines. Our work significantly contributes to the field of ABSA by demonstrating the first successful application of Dutch pre-trained language models to aspect-based sentiment analysis in the domain of human resources (HR).
http://w3id.org/mlsea/pwc/scientificWork/Assertion%20Detection%20Large%20Language%20Model%20In-context%20Learning%20LoRA%20Fine-tuning                                                                                  Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning                                                                                  In this study, we aim to address the task of assertion detection when extracting medical concepts from clinical notes, a key process in clinical natural language processing (NLP). Assertion detection in clinical NLP usually involves identifying assertion types for medical concepts in the clinical text, namely certainty (whether the medical concept is positive, negated, possible, or hypothetical), temporality (whether the medical concept is for present or the past history), and experiencer (whether the medical concept is described for the patient or a family member). These assertion types are essential for healthcare professionals to quickly and clearly understand the context of medical conditions from unstructured clinical texts, directly influencing the quality and outcomes of patient care. Although widely used, traditional methods, particularly rule-based NLP systems and machine learning or deep learning models, demand intensive manual efforts to create patterns and tend to overlook less common assertion types, leading to an incomplete understanding of the context. To address this challenge, our research introduces a novel methodology that utilizes Large Language Models (LLMs) pre-trained on a vast array of medical data for assertion detection. We enhanced the current method with advanced reasoning techniques, including Tree of Thought (ToT), Chain of Thought (CoT), and Self-Consistency (SC), and refine it further with Low-Rank Adaptation (LoRA) fine-tuning. We first evaluated the model on the i2b2 2010 assertion dataset. Our method achieved a micro-averaged F-1 of 0.89, with 0.11 improvements over the previous works. To further assess the generalizability of our approach, we extended our evaluation to a local dataset that focused on sleep concept extraction. Our approach achieved an F-1 of 0.74, which is 0.31 higher than the previous method.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Generalization%20for%20Subpopulation%20Representative%20Modeling%20via%20In-Context%20Learning                                                                                  Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning                                                                                  This study evaluates the ability of Large Language Model (LLM)-based Subpopulation Representative Models (SRMs) to generalize from empirical data, utilizing in-context learning with data from the 2016 and 2020 American National Election Studies. We explore generalization across response variables and demographic subgroups. While conditioning with empirical data improves performance on the whole, the benefit of in-context learning varies considerably across demographics, sometimes hurting performance for one demographic while helping performance for others. The inequitable benefits of in-context learning for SRM present a challenge for practitioners implementing SRMs, and for decision-makers who might come to rely on them. Our work highlights a need for fine-grained benchmarks captured from diverse subpopulations that test not only fidelity but generalization.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Large%20Language%20Models%20in%20Mechanical%20Engineering%20Education%3A%20A%20Study%20on%20Mechanics-Focused%20Conceptual%20Understanding                                                                                  Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding                                                                                  This study is a pioneering endeavor to investigate the capabilities of Large Language Models (LLMs) in addressing conceptual questions within the domain of mechanical engineering with a focus on mechanics. Our examination involves a manually crafted exam encompassing 126 multiple-choice questions, spanning various aspects of mechanics courses, including Fluid Mechanics, Mechanical Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5), ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against engineering faculties and students with or without mechanical engineering background. The findings reveal GPT-4's superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses. The performances of LLMs were all significantly improved with explanations prompted prior to direct responses, underscoring the crucial role of prompt engineering. Interestingly, GPT-3.5 demonstrates improved performance with prompts covering a broader domain, while GPT-4 excels with prompts focusing on specific subjects. Finally, GPT-4 exhibits notable advancements in mitigating input bias, as evidenced by guessing preferences for humans. This study unveils the substantial potential of LLMs as highly knowledgeable assistants in both mechanical pedagogy and scientific research.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Large%20Language%20Models%27%20ability%20to%20predict%20how%20humans%20balance%20self-interest%20and%20the%20interest%20of%20others                                                                                  Assessing Large Language Models' ability to predict how humans balance self-interest and the interest of others                                                                                  Generative artificial intelligence (AI) holds enormous potential to revolutionize decision-making processes, from everyday to high-stake scenarios. By leveraging generative AI, humans can benefit from data-driven insights and predictions, enhancing their ability to make informed decisions that consider a wide array of factors and potential outcomes. However, as many decisions carry social implications, for AI to be a reliable assistant for decision-making it is crucial that it is able to capture the balance between self-interest and the interest of others. We investigate the ability of three of the most advanced chatbots to predict dictator game decisions across 108 experiments with human participants from 12 countries. We find that only GPT-4 (not Bard nor Bing) correctly captures qualitative behavioral patterns, identifying three major classes of behavior: self-interested, inequity-averse, and fully altruistic. Nonetheless, GPT-4 consistently underestimates self-interest and inequity-aversion, while overestimating altruistic behavior. This bias has significant implications for AI developers and users, as overly optimistic expectations about human altruism may lead to disappointment, frustration, suboptimal decisions in public policy or business contexts, and even social conflict.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20ML%20Classification%20Algorithms%20and%20NLP%20Techniques%20for%20Depression%20Detection%3A%20An%20Experimental%20Case%20Study                                                                                  Assessing ML Classification Algorithms and NLP Techniques for Depression Detection: An Experimental Case Study                                                                                  Depression has affected millions of people worldwide and has become one of the most common mental disorders. Early mental disorder detection can reduce costs for public health agencies and prevent other major comorbidities. Additionally, the shortage of specialized personnel is very concerning since Depression diagnosis is highly dependent on expert professionals and is time-consuming. Recent research has evidenced that machine learning (ML) and Natural Language Processing (NLP) tools and techniques have significantly bene ted the diagnosis of depression. However, there are still several challenges in the assessment of depression detection approaches in which other conditions such as post-traumatic stress disorder (PTSD) are present. These challenges include assessing alternatives in terms of data cleaning and pre-processing techniques, feature selection, and appropriate ML classification algorithms. This paper tackels such an assessment based on a case study that compares different ML classifiers, specifically in terms of data cleaning and pre-processing, feature selection, parameter setting, and model choices. The case study is based on the Distress Analysis Interview Corpus - Wizard-of-Oz (DAIC-WOZ) dataset, which is designed to support the diagnosis of mental disorders such as depression, anxiety, and PTSD. Besides the assessment of alternative techniques, we were able to build models with accuracy levels around 84% with Random Forest and XGBoost models, which is significantly higher than the results from the comparable literature which presented the level of accuracy of 72% from the SVM model.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Uncertainty%20in%20Similarity%20Scoring%3A%20Performance%20%26%20Fairness%20in%20Face%20Recognition                                                                                  Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition                                                                                  The ROC curve is the major tool for assessing not only the performance but also the fairness properties of a similarity scoring function. In order to draw reliable conclusions based on empirical ROC analysis, accurately evaluating the uncertainty level related to statistical versions of the ROC curves of interest is absolutely necessary, especially for applications with considerable societal impact such as Face Recognition. In this article, we prove asymptotic guarantees for empirical ROC curves of similarity functions as well as for by-product metrics useful to assess fairness. We also explain that, because the false acceptance/rejection rates are of the form of U-statistics in the case of similarity scoring, the naive bootstrap approach may jeopardize the assessment procedure. A dedicated recentering technique must be used instead. Beyond the theoretical analysis carried out, various experiments using real face image datasets provide strong empirical evidence of the practical relevance of the methods promoted here, when applied to several ROC-based measures such as popular fairness metrics.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20and%20Enhancing%20the%20Robustness%20of%20Large%20Language%20Models%20with%20Task%20Structure%20Variations%20for%20Logical%20Reasoning                                                                                  Assessing and Enhancing the Robustness of Large Language Models with Task Structure Variations for Logical Reasoning                                                                                  Large language models (LLMs), such as LLaMA, Alpaca, Vicuna, GPT-3.5 and GPT-4, have advanced the performance of AI systems on various natural language processing tasks to human-like levels. However, their generalisation and robustness when performing logical reasoning has not been sufficiently assessed. To comprehensively evaluate this ability, we develop three new logical reasoning datasets named 'ReClor-plus', 'LogiQA-plus' and 'LogiQAv2-plus' that extend standard logical reasoning datasets to evaluate the robustness of the LLM's reasoning. For each, we create three subsets: the first with randomly shuffled options, the second with the correct choices replaced by 'none of the other options is correct', and the third with a combination of shuffling and substitution. Experiments on these datasets show that these simple augmentations greatly hinder the models' performance. Despite their high performance on the original publicly available datasets, we find that all models perform poorly on these newly constructed datasets. We also demonstrate that introducing task variations into the training set can markedly improve the model's performance on both the original and our developed datasets. Finally, we show that applying logic-driven data augmentation for fine-tuning and prompting can enhance generalisation in both discriminative and generative models, offering a path to improving their robustness for tasks involving logical reasoning. Source code and data are made publicly available at https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20cognitive%20function%20among%20older%20adults%20using%20machine%20learning%20and%20wearable%20device%20data%3A%20a%20feasibility%20study                                                                                  Assessing cognitive function among older adults using machine learning and wearable device data: a feasibility study                                                                                  Timely implementation of interventions to slow cognitive decline among older adults requires accurate monitoring to detect changes in cognitive function. Data gathered using wearable devices that can continuously monitor factors known to be associated with cognition could be used to train machine learning models and develop wearable-based cognitive monitoring systems. Using data from over 2,400 older adults in the National Health and Nutrition Examination Survey (NHANES) we developed prediction models to differentiate older adults with normal cognition from those with poor cognition based on outcomes from three cognitive tests measuring different domains of cognitive function. During repeated cross-validation, CatBoost, XGBoost, and Random Forest models performed best when predicting cognition based on processing speed, working memory, and attention (median AUCs >0.82) compared to immediate and delayed recall (median AUCs >0.72) and categorical verbal fluency (median AUC >0.68). Activity and sleep parameters were also more strongly associated with processing speed, working memory, and attention compared to other cognitive subdomains. Our work provides proof of concept that wearable-based cognitive monitoring systems may be a viable alternative to traditional methods for monitoring processing speeds, working memory, and attention. We further identified novel metrics that could be targets in future causal studies seeking to better understand how sleep and activity parameters influence cognitive function among older adults.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20the%20Impact%20of%20Prompting%20Methods%20on%20ChatGPT%27s%20Mathematical%20Capabilities                                                                                  Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities                                                                                  This study critically evaluates the efficacy of prompting methods in enhancing the mathematical reasoning capability of large language models (LLMs). The investigation uses three prescriptive prompting methods - simple, persona, and conversational prompting - known for their effectiveness in enhancing the linguistic tasks of LLMs. We conduct this analysis on OpenAI's LLM chatbot, ChatGPT-3.5, on extensive problem sets from the MATH, GSM8K, and MMLU datasets, encompassing a broad spectrum of mathematical challenges. A grading script adapted to each dataset is used to determine the effectiveness of these prompting interventions in enhancing the model's mathematical analysis power. Contrary to expectations, our empirical analysis reveals that none of the investigated methods consistently improves over ChatGPT-3.5's baseline performance, with some causing significant degradation. Our findings suggest that prompting strategies do not necessarily generalize to new domains, in this study failing to enhance mathematical performance.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20the%20Portability%20of%20Parameter%20Matrices%20Trained%20by%20Parameter-Efficient%20Finetuning%20Methods                                                                                  Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods                                                                                  As the cost of training ever larger language models has grown, so has the interest in reusing previously learnt knowledge. Transfer learning methods have shown how reusing non-task-specific knowledge can help in subsequent task-specific learning. In this paper, we investigate the inverse: porting whole functional modules that encode task-specific knowledge from one model to another. We designed a study comprising 1,440 training/testing runs to test the portability of modules trained by parameter-efficient finetuning (PEFT) techniques, using sentiment analysis as an example task. We test portability in a wide range of scenarios, involving different PEFT techniques and different pretrained host models, among other dimensions. We compare the performance of ported modules with that of equivalent modules trained (i) from scratch, and (ii) from parameters sampled from the same distribution as the ported module. We find that the ported modules far outperform the two alternatives tested, but that there are interesting performance differences between the four PEFT techniques. We conclude that task-specific knowledge in the form of structurally modular sets of parameters as produced by PEFT techniques is highly portable, but that degree of success depends on type of PEFT and on differences between originating and receiving pretrained models.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20the%20Reasoning%20Abilities%20of%20ChatGPT%20in%20the%20Context%20of%20Claim%20Verification                                                                                  Assessing the Reasoning Abilities of ChatGPT in the Context of Claim Verification                                                                                  The reasoning capabilities of LLMs are currently hotly debated. We examine the issue from the perspective of claim/rumour verification. We propose the first logical reasoning framework designed to break down any claim or rumour paired with evidence into the atomic reasoning steps necessary for verification. Based on our framework, we curate two annotated collections of such claim/evidence pairs: a synthetic dataset from Wikipedia and a real-world set stemming from rumours circulating on Twitter. We use them to evaluate the reasoning capabilities of GPT-3.5-Turbo and GPT-4 (hereinafter referred to as ChatGPT) within the context of our framework, providing a thorough analysis. Our results show that ChatGPT struggles in abductive reasoning, although this can be somewhat mitigated by using manual Chain of Thought (CoT) as opposed to Zero-Shot (ZS) and ZS CoT approaches. Our study contributes to the growing body of research suggesting that ChatGPT's reasoning processes are unlikely to mirror human-like reasoning, and that LLMs need to be more rigorously evaluated to distinguish between hype and actual capabilities, especially in high-stakes real-world tasks such as claim verification.
http://w3id.org/mlsea/pwc/scientificWork/Assessment%20of%20low-carbon%20tourism%20development%20from%20multi-aspect%20analysis%3A%20A%20case%20study%20of%20the%20Yellow%20River%20Basin%2C%20China                                                                                  Assessment of low-carbon tourism development from multi-aspect analysis: A case study of the Yellow River Basin, China                                                                                  Climate change has become an unavoidable problem in achieving sustainable development. As one of the major industries worldwide, tourism can make a significant contribution to mitigating climate change. The main objective of the paper is to assess the development level of low-carbon tourism from multi-aspect, using the Yellow River Basin as an example. Firstly, this study quantified tourism carbon dioxide emissions and tourism economy, and analyzed their evolution characteristics. The interaction and coordination degree between tourism carbon dioxide emissions and tourism economy were then analyzed using the improved coupling coordination degree model. Finally, this study analyzed the change in total factor productivity of low-carbon tourism by calculating the Malmquist-Luenberger productivity index. The results showed that: (1) The tourism industry in the Yellow River Basin has the characteristics of the initial environmental Kuznets curve. (2) There was a strong interaction between tourism carbon dioxide emissions and tourism economy, which was manifested as mutual promotion. (3) The total factor productivity of low-carbon tourism was increasing. Based on the above results, it could be concluded that the development level of low-carbon tourism in the Yellow River Basin has been continuously improved from 2000 to 2019, but it is still in the early development stage with the continuous growth of carbon dioxide emissions.
http://w3id.org/mlsea/pwc/scientificWork/Assistant%2C%20Parrot%2C%20or%20Colonizing%20Loudspeaker%3F%20ChatGPT%20Metaphors%20for%20Developing%20Critical%20AI%20Literacies                                                                                  Assistant, Parrot, or Colonizing Loudspeaker? ChatGPT Metaphors for Developing Critical AI Literacies                                                                                  This study explores how discussing metaphors for AI can help build awareness of the frames that shape our understanding of AI systems, particularly large language models (LLMs) like ChatGPT. Given the pressing need to teach 'critical AI literacy', discussion of metaphor provides an opportunity for inquiry and dialogue with space for nuance, playfulness, and critique. Using a collaborative autoethnographic methodology, we analyzed metaphors from a range of sources, and reflected on them individually according to seven questions, then met and discussed our interpretations. We then analyzed how our reflections contributed to the three kinds of literacies delineated in Selber's multiliteracies framework: functional, critical, and rhetorical. These allowed us to analyze questions of ethics, equity, and accessibility in relation to AI. We explored each metaphor along the dimension of whether or not it was promoting anthropomorphizing, and to what extent such metaphors imply that AI is sentient. Our findings highlight the role of metaphor reflection in fostering a nuanced understanding of AI, suggesting that our collaborative autoethnographic approach as well as the heuristic model of plotting AI metaphors on dimensions of anthropomorphism and multiliteracies, might be useful for educators and researchers in the pursuit of advancing critical AI literacy.
http://w3id.org/mlsea/pwc/scientificWork/Assisting%20humans%20in%20complex%20comparisons%3A%20automated%20information%20comparison%20at%20scale                                                                                  Assisting humans in complex comparisons: automated information comparison at scale                                                                                  Generative Large Language Models enable efficient analytics across knowledge domains, rivalling human experts in information comparisons. However, the applications of LLMs for information comparisons face scalability challenges due to the difficulties in maintaining information across large contexts and overcoming model token limitations. To address these challenges, we developed the novel Abstractive Summarization & Criteria-driven Comparison Endpoint (ASC$^2$End) system to automate information comparison at scale. Our system employs Semantic Text Similarity comparisons for generating evidence-supported analyses. We utilize proven data-handling strategies such as abstractive summarization and retrieval augmented generation to overcome token limitations and retain relevant information during model inference. Prompts were designed using zero-shot strategies to contextualize information for improved model reasoning. We evaluated abstractive summarization using ROUGE scoring and assessed the generated comparison quality using survey responses. Models evaluated on the ASC$^2$End system show desirable results providing insights on the expected performance of the system. ASC$^2$End is a novel system and tool that enables accurate, automated information comparison at scale across knowledge domains, overcoming limitations in context length and retrieval.
http://w3id.org/mlsea/pwc/scientificWork/Assistive%20Large%20Language%20Model%20Agents%20for%20Socially-Aware%20Negotiation%20Dialogues                                                                                  Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues                                                                                  In this work, we aim to develop LLM agents to mitigate social norm violations in negotiations in a multi-agent setting. We simulate real-world negotiations by letting two large Language Models (LLMs) play the roles of two negotiators in each conversation. A third LLM acts as a remediation agent to rewrite utterances violating norms for improving negotiation outcomes. As it is a novel task, no manually constructed data is available. To address this limitation, we introduce a value impact based In-Context Learning (ICL) method to identify high-quality ICL examples for the LLM-based remediation agents, where the value impact function measures the quality of negotiation outcomes. We show the connection of this method to policy learning and provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different topics: product sale, housing price, and salary negotiation. The source code and the generated dataset will be publicly available upon acceptance.
http://w3id.org/mlsea/pwc/scientificWork/Associative%20Memories%20in%20the%20Feature%20Space                                                                                  Associative Memories in the Feature Space                                                                                  An autoassociative memory model is a function that, given a set of data points, takes as input an arbitrary vector and outputs the most similar data point from the memorized set. However, popular memory models fail to retrieve images even when the corruption is mild and easy to detect for a human evaluator. This is because similarities are evaluated in the raw pixel space, which does not contain any semantic information about the images. This problem can be easily solved by computing emph{similarities} in an embedding space instead of the pixel space. We show that an effective way of computing such embeddings is via a network pretrained with a contrastive loss. As the dimension of embedding spaces is often significantly smaller than the pixel space, we also have a faster computation of similarity scores. We test this method on complex datasets such as CIFAR10 and STL10. An additional drawback of current models is the need of storing the whole dataset in the pixel space, which is often extremely large. We relax this condition and propose a class of memory models that only stores low-dimensional semantic embeddings, and uses them to retrieve similar, but not identical, memories. We demonstrate a proof of concept of this method on a simple task on the MNIST dataset.
http://w3id.org/mlsea/pwc/scientificWork/Asymmetry%20in%20Low-Rank%20Adapters%20of%20Foundation%20Models                                                                                  Asymmetry in Low-Rank Adapters of Foundation Models                                                                                  Parameter-efficient fine-tuning optimizes large, pre-trained foundation models by updating a subset of parameters; in this class, Low-Rank Adaptation (LoRA) is particularly effective. Inspired by an effort to investigate the different roles of LoRA matrices during fine-tuning, this paper characterizes and leverages unexpected asymmetry in the importance of low-rank adapter matrices. Specifically, when updating the parameter matrices of a neural network by adding a product $BA$, we observe that the $B$ and $A$ matrices have distinct functions: $A$ extracts features from the input, while $B$ uses these features to create the desired output. Based on this observation, we demonstrate that fine-tuning $B$ is inherently more effective than fine-tuning $A$, and that a random untrained $A$ should perform nearly as well as a fine-tuned one. Using an information-theoretic lens, we also bound the generalization of low-rank adapters, showing that the parameter savings of exclusively training $B$ improves the bound. We support our conclusions with experiments on RoBERTa, BART-Large, LLaMA-2, and ViTs.
http://w3id.org/mlsea/pwc/scientificWork/Asymptotic%20Behavior%20of%20Adversarial%20Training%20Estimator%20under%20%24%20ell_%20infty%24-Perturbation                                                                                  Asymptotic Behavior of Adversarial Training Estimator under $ ell_ infty$-Perturbation                                                                                  Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under $ ell_ infty$-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under $ ell_ infty$-perturbation could put a positive probability mass at $0$ when the true parameter is $0$, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed -- adaptive adversarial training, which could further improve the performance of adversarial training under $ ell_ infty$-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery ability of adversarial training under $ ell_ infty$-perturbation and to compare the empirical performance between classic adversarial training and adaptive adversarial training.
http://w3id.org/mlsea/pwc/scientificWork/Asymptotic%20Gaussian%20Fluctuations%20of%20Eigenvectors%20in%20Spectral%20Clustering                                                                                  Asymptotic Gaussian Fluctuations of Eigenvectors in Spectral Clustering                                                                                  The performance of spectral clustering relies on the fluctuations of the entries of the eigenvectors of a similarity matrix, which has been left uncharacterized until now. In this letter, it is shown that the signal $+$ noise structure of a general spike random matrix model is transferred to the eigenvectors of the corresponding Gram kernel matrix and the fluctuations of their entries are Gaussian in the large-dimensional regime. This CLT-like result was the last missing piece to precisely predict the classification performance of spectral clustering. The proposed proof is very general and relies solely on the rotational invariance of the noise. Numerical experiments on synthetic and real data illustrate the universality of this phenomenon.
http://w3id.org/mlsea/pwc/scientificWork/Asymptotic%20spreading%20of%20predator-prey%20populations%20in%20a%20shifting%20environment                                                                                  Asymptotic spreading of predator-prey populations in a shifting environment                                                                                  Inspired by recent studies associating shifting temperature conditions with changes in the efficiency of predator species in converting their prey to offspring, we propose a predator-prey model of reaction-diffusion type to analyze the consequence of such effects on the population dynamics and spread of species. In the model, the predator conversion efficiency is represented by a spatially heterogeneous function depending on the variable $ xi=x-c_1t$ for some given $c_1>0$. Using the Hamilton-Jacobi approach, we provide explicit formulas for the spreading speed of the predator species. When the conversion function is monotone increasing, the spreading speed is determined in all cases and non-local pulling is possible. When the function is monotone decreasing, we provide formulas for the spreading speed when the rate of shift of the conversion function is sufficiently fast or slow.
http://w3id.org/mlsea/pwc/scientificWork/Asymptotics%20of%20Language%20Model%20Alignment                                                                                  Asymptotics of Language Model Alignment                                                                                  Let $p$ denote a generative language model. Let $r$ denote a reward model that returns a scalar that captures the degree at which a draw from $p$ is preferred. The goal of language model alignment is to alter $p$ to a new distribution $ phi$ that results in a higher expected reward while keeping $ phi$ close to $p.$ A popular alignment method is the KL-constrained reinforcement learning (RL), which chooses a distribution $ phi_ Delta$ that maximizes $E_{ phi_{ Delta}} r(y)$ subject to a relative entropy constraint $KL( phi_ Delta || p) leq Delta.$ Another simple alignment method is best-of-$N$, where $N$ samples are drawn from $p$ and one with highest reward is selected. In this paper, we offer a closed-form characterization of the optimal KL-constrained RL solution. We demonstrate that any alignment method that achieves a comparable trade-off between KL divergence and reward must approximate the optimal KL-constrained RL solution in terms of relative entropy. To further analyze the properties of alignment methods, we introduce two simplifying assumptions: we let the language model be memoryless, and the reward model be linear. Although these assumptions may not reflect complex real-world scenarios, they enable a precise characterization of the asymptotic behavior of both the best-of-$N$ alignment, and the KL-constrained RL method, in terms of information-theoretic quantities. We prove that the reward of the optimal KL-constrained RL solution satisfies a large deviation principle, and we fully characterize its rate function. We also show that the rate of growth of the scaled cumulants of the reward is characterized by a proper Renyi cross entropy. Finally, we show that best-of-$N$ is asymptotically equivalent to KL-constrained RL solution by proving that their expected rewards are asymptotically equal, and concluding that the two distributions must be close in KL divergence.
http://w3id.org/mlsea/pwc/scientificWork/Asymptotics%20of%20Learning%20with%20Deep%20Structured%20%28Random%29%20Features                                                                                  Asymptotics of Learning with Deep Structured (Random) Features                                                                                  For a large class of feature maps we provide a tight asymptotic characterisation of the test error associated with learning the readout layer, in the high-dimensional limit where the input dimension, hidden layer widths, and number of training samples are proportionally large. This characterization is formulated in terms of the population covariance of the features. Our work is partially motivated by the problem of learning with Gaussian rainbow neural networks, namely deep non-linear fully-connected networks with random but structured weights, whose row-wise covariances are further allowed to depend on the weights of previous layers. For such networks we also derive a closed-form formula for the feature covariance in terms of the weight matrices. We further find that in some cases our results can capture feature maps learned by deep, finite-width neural networks trained under gradient descent.
http://w3id.org/mlsea/pwc/scientificWork/Asymptotics%20of%20feature%20learning%20in%20two-layer%20networks%20after%20one%20gradient-step                                                                                  Asymptotics of feature learning in two-layer networks after one gradient-step                                                                                  In this manuscript we investigate the problem of how two-layer neural networks learn features from data, and improve over the kernel regime, after being trained with a single gradient descent step. Leveraging a connection from (Ba et al., 2022) with a non-linear spiked matrix model and recent progress on Gaussian universality (Dandi et al., 2023), we provide an exact asymptotic description of the generalization error in the high-dimensional limit where the number of samples $n$, the width $p$ and the input dimension $d$ grow at a proportional rate. We characterize exactly how adapting to the data is crucial for the network to efficiently learn non-linear functions in the direction of the gradient -- where at initialization it can only express linear functions in this regime. To our knowledge, our results provides the first tight description of the impact of feature learning in the generalization of two-layer neural networks in the large learning rate regime $ eta= Theta_{d}(d)$, beyond perturbative finite width corrections of the conjugate and neural tangent kernels.
http://w3id.org/mlsea/pwc/scientificWork/Asynchronous%20Microphone%20Array%20Calibration%20using%20Hybrid%20TDOA%20Information                                                                                  Asynchronous Microphone Array Calibration using Hybrid TDOA Information                                                                                  Asynchronous microphone array calibration is a prerequisite for most audition robot applications. A popular solution to the above calibration problem is the batch form of Simultaneous Localisation and Mapping (SLAM), using the time difference of arrival measurements between two microphones (TDOA-M), and the robot (which serves as a moving sound source during calibration) odometry information. In this paper, we introduce a new form of measurement for microphone array calibration, i.e. the time difference of arrival between adjacent sound events (TDOA-S) with respect to the microphone channels. We propose to combine TDOA-S and TDOA-M, called hybrid TDOA, together with odometry measurements for bath SLAM-based calibration of asynchronous microphone arrays. Simulation and real-world experiment results consistently show that our method is more independent of microphone number, less sensitive to initial values (when using off-the-shelf algorithms such as Gauss-Newton iterations), and has better calibration accuracy and robustness under various TDOA noises. In addition, the simulation result demonstrates that our method has a lower Cram 'er-Rao lower bound (CRLB) for microphone parameters. To benefit the community, we open-source our code and data at https://github.com/zcj808/Hybrid-TDOA-Calib.
http://w3id.org/mlsea/pwc/scientificWork/Attack%20and%20Defense%20Analysis%20of%20Learned%20Image%20Compression                                                                                  Attack and Defense Analysis of Learned Image Compression                                                                                  Learned image compression (LIC) is becoming more and more popular these years with its high efficiency and outstanding compression quality. Still, the practicality against modified inputs added with specific noise could not be ignored. White-box attacks such as FGSM and PGD use only gradient to compute adversarial images that mislead LIC models to output unexpected results. Our experiments compare the effects of different dimensions such as attack methods, models, qualities, and targets, concluding that in the worst case, there is a 61.55% decrease in PSNR or a 19.15 times increase in bpp under the PGD attack. To improve their robustness, we conduct adversarial training by adding adversarial images into the training datasets, which obtains a 95.52% decrease in the R-D cost of the most vulnerable LIC model. We further test the robustness of H.266, whose better performance on reconstruction quality extends its possibility to defend one-step or iterative adversarial attacks.
http://w3id.org/mlsea/pwc/scientificWork/Attacks%20on%20Node%20Attributes%20in%20Graph%20Neural%20Networks                                                                                  Attacks on Node Attributes in Graph Neural Networks                                                                                  Graphs are commonly used to model complex networks prevalent in modern social media and literacy applications. Our research investigates the vulnerability of these graphs through the application of feature based adversarial attacks, focusing on both decision time attacks and poisoning attacks. In contrast to state of the art models like Net Attack and Meta Attack, which target node attributes and graph structure, our study specifically targets node attributes. For our analysis, we utilized the text dataset Hellaswag and graph datasets Cora and CiteSeer, providing a diverse basis for evaluation. Our findings indicate that decision time attacks using Projected Gradient Descent (PGD) are more potent compared to poisoning attacks that employ Mean Node Embeddings and Graph Contrastive Learning strategies. This provides insights for graph data security, pinpointing where graph-based models are most vulnerable and thereby informing the development of stronger defense mechanisms against such attacks.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20Guided%20CAM%3A%20Visual%20Explanations%20of%20Vision%20Transformer%20Guided%20by%20Self-Attention                                                                                  Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention                                                                                  Vision Transformer(ViT) is one of the most widely used models in the computer vision field with its great performance on various tasks. In order to fully utilize the ViT-based architecture in various applications, proper visualization methods with a decent localization performance are necessary, but these methods employed in CNN-based models are still not available in ViT due to its unique structure. In this work, we propose an attention-guided visualization method applied to ViT that provides a high-level semantic explanation for its decision. Our method selectively aggregates the gradients directly propagated from the classification output to each self-attention, collecting the contribution of image features extracted from each location of the input image. These gradients are additionally guided by the normalized self-attention scores, which are the pairwise patch correlation scores. They are used to supplement the gradients on the patch-level context information efficiently detected by the self-attention mechanism. This approach of our method provides elaborate high-level semantic explanations with great localization performance only with the class labels. As a result, our method outperforms the previous leading explainability methods of ViT in the weakly-supervised localization task and presents great capability in capturing the full instances of the target class object. Meanwhile, our method provides a visualization that faithfully explains the model, which is demonstrated in the perturbation comparison test.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20is%20all%20you%20need%20for%20boosting%20graph%20convolutional%20neural%20network                                                                                  Attention is all you need for boosting graph convolutional neural network                                                                                  Graph Convolutional Neural Networks (GCNs) possess strong capabilities for processing graph data in non-grid domains. They can capture the topological logical structure and node features in graphs and integrate them into nodes' final representations. GCNs have been extensively studied in various fields, such as recommendation systems, social networks, and protein molecular structures. With the increasing application of graph neural networks, research has focused on improving their performance while compressing their size. In this work, a plug-in module named Graph Knowledge Enhancement and Distillation Module (GKEDM) is proposed. GKEDM can enhance node representations and improve the performance of GCNs by extracting and aggregating graph information via multi-head attention mechanism. Furthermore, GKEDM can serve as an auxiliary transferor for knowledge distillation. With a specially designed attention distillation method, GKEDM can distill the knowledge of large teacher models into high-performance and compact student models. Experiments on multiple datasets demonstrate that GKEDM can significantly improve the performance of various GCNs with minimal overhead. Furthermore, it can efficiently transfer distilled knowledge from large teacher networks to small student networks via attention distillation.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20on%20Personalized%20Clinical%20Decision%20Support%20System%3A%20Federated%20Learning%20Approach                                                                                  Attention on Personalized Clinical Decision Support System: Federated Learning Approach                                                                                  Health management has become a primary problem as new kinds of diseases and complex symptoms are introduced to a rapidly growing modern society. Building a better and smarter healthcare infrastructure is one of the ultimate goals of a smart city. To the best of our knowledge, neural network models are already employed to assist healthcare professionals in achieving this goal. Typically, training a neural network requires a rich amount of data but heterogeneous and vulnerable properties of clinical data introduce a challenge for the traditional centralized network. Moreover, adding new inputs to a medical database requires re-training an existing model from scratch. To tackle these challenges, we proposed a deep learning-based clinical decision support system trained and managed under a federated learning paradigm. We focused on a novel strategy to guarantee the safety of patient privacy and overcome the risk of cyberattacks while enabling large-scale clinical data mining. As a result, we can leverage rich clinical data for training each local neural network without the need for exchanging the confidential data of patients. Moreover, we implemented the proposed scheme as a sequence-to-sequence model architecture integrating the attention mechanism. Thus, our objective is to provide a personalized clinical decision support system with evolvable characteristics that can deliver accurate solutions and assist healthcare professionals in medical diagnosing.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20to%20detail%3A%20inter-resolution%20knowledge%20distillation                                                                                  Attention to detail: inter-resolution knowledge distillation                                                                                  The development of computer vision solutions for gigapixel images in digital pathology is hampered by significant computational limitations due to the large size of whole slide images. In particular, digitizing biopsies at high resolutions is a time-consuming process, which is necessary due to the worsening results from the decrease in image detail. To alleviate this issue, recent literature has proposed using knowledge distillation to enhance the model performance at reduced image resolutions. In particular, soft labels and features extracted at the highest magnification level are distilled into a model that takes lower-magnification images as input. However, this approach fails to transfer knowledge about the most discriminative image regions in the classification process, which may be lost when the resolution is decreased. In this work, we propose to distill this information by incorporating attention maps during training. In particular, our formulation leverages saliency maps of the target class via grad-CAMs, which guides the lower-resolution Student model to match the Teacher distribution by minimizing the l2 distance between them. Comprehensive experiments on prostate histology image grading demonstrate that the proposed approach substantially improves the model performance across different image resolutions compared to previous literature.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20with%20Markov%3A%20A%20Framework%20for%20Principled%20Analysis%20of%20Transformers%20via%20Markov%20Chains                                                                                  Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains                                                                                  In recent years, attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. A key ingredient behind their success is the generative pretraining procedure, during which these models are trained on a large text corpus in an auto-regressive manner. To shed light on this phenomenon, we propose a new framework that allows both theory and systematic experiments to study the sequential modeling capabilities of transformers through the lens of Markov chains. Inspired by the Markovianity of natural languages, we model the data as a Markovian source and utilize this framework to systematically study the interplay between the data-distributional properties, the transformer architecture, the learnt distribution, and the final model performance. In particular, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima and bad local minima contingent upon the specific data characteristics and the transformer architecture. Backed by experiments, we demonstrate that our theoretical findings are in congruence with the empirical results. We further investigate these findings in the broader context of higher order Markov chains and deeper architectures, and outline open problems in this arena. Code is available at url{https://github.com/Bond1995/Markov}.
http://w3id.org/mlsea/pwc/scientificWork/Attention%2C%20Distillation%2C%20and%20Tabularization%3A%20Towards%20Practical%20Neural%20Network-Based%20Prefetching                                                                                  Attention, Distillation, and Tabularization: Towards Practical Neural Network-Based Prefetching                                                                                  Attention-based Neural Networks (NN) have demonstrated their effectiveness in accurate memory access prediction, an essential step in data prefetching. However, the substantial computational overheads associated with these models result in high inference latency, limiting their feasibility as practical prefetchers. To close the gap, we propose a new approach based on tabularization that significantly reduces model complexity and inference latency without sacrificing prediction accuracy. Our novel tabularization methodology takes as input a distilled, yet highly accurate attention-based model for memory access prediction and efficiently converts its expensive matrix multiplications into a hierarchy of fast table lookups. As an exemplar of the above approach, we develop DART, a prefetcher comprised of a simple hierarchy of tables. With a modest 0.09 drop in F1-score, DART reduces 99.99% of arithmetic operations from the large attention-based model and 91.83% from the distilled model. DART accelerates the large model inference by 170x and the distilled model by 9.4x. DART has comparable latency and storage costs as state-of-the-art rule-based prefetcher BO but surpasses it by 6.1% in IPC improvement. DART outperforms state-of-the-art NN-based prefetchers TransFetch by 33.1% and Voyager by 37.2% in terms of IPC improvement, primarily due to its low prefetching latency.
http://w3id.org/mlsea/pwc/scientificWork/Attention-Driven%20Reasoning%3A%20Unlocking%20the%20Potential%20of%20Large%20Language%20Models                                                                                  Attention-Driven Reasoning: Unlocking the Potential of Large Language Models                                                                                  Large Language Models (LLMs) have shown remarkable capabilities, but their reasoning abilities and underlying mechanisms remain poorly understood. We present a novel approach to enhance LLMs' reasoning through attention mechanism optimization, without additional training data. We identify inefficiencies in the attention distribution caused by non-semantic tokens and propose an algorithm to re-balance the skewed distribution, enabling the model to abstract more nuanced knowledge. Our experiments demonstrate significantly improved reasoning capabilities, particularly for non-STEM questions. We provide insights into the role of attention patterns in LLMs' reasoning and propose a method to enhance these abilities, paving the way for more powerful and versatile language models.
http://w3id.org/mlsea/pwc/scientificWork/Attention-Enhanced%20Co-Interactive%20Fusion%20Network%20%28AECIF-Net%29%20for%20Automated%20Structural%20Condition%20Assessment%20in%20Visual%20Inspection                                                                                  Attention-Enhanced Co-Interactive Fusion Network (AECIF-Net) for Automated Structural Condition Assessment in Visual Inspection                                                                                  Efficiently monitoring the condition of civil infrastructure requires automating the structural condition assessment in visual inspection. This paper proposes an Attention-Enhanced Co-Interactive Fusion Network (AECIF-Net) for automatic structural condition assessment in visual bridge inspection. AECIF-Net can simultaneously parse structural elements and segment surface defects on the elements in inspection images. It integrates two task-specific relearning subnets to extract task-specific features from an overall feature embedding. A co-interactive feature fusion module further captures the spatial correlation and facilitates information sharing between tasks. Experimental results demonstrate that the proposed AECIF-Net outperforms the current state-of-the-art approaches, achieving promising performance with 92.11% mIoU for element segmentation and 87.16% mIoU for corrosion segmentation on the test set of the new benchmark dataset Steel Bridge Condition Inspection Visual (SBCIV). An ablation study verifies the merits of the designs for AECIF-Net, and a case study demonstrates its capability to automate structural condition assessment.
http://w3id.org/mlsea/pwc/scientificWork/Attention-Enhanced%20Hybrid%20Feature%20Aggregation%20Network%20for%203D%20Brain%20Tumor%20Segmentation                                                                                  Attention-Enhanced Hybrid Feature Aggregation Network for 3D Brain Tumor Segmentation                                                                                  Glioblastoma is a highly aggressive and malignant brain tumor type that requires early diagnosis and prompt intervention. Due to its heterogeneity in appearance, developing automated detection approaches is challenging. To address this challenge, Artificial Intelligence (AI)-driven approaches in healthcare have generated interest in efficiently diagnosing and evaluating brain tumors. The Brain Tumor Segmentation Challenge (BraTS) is a platform for developing and assessing automated techniques for tumor analysis using high-quality, clinically acquired MRI data. In our approach, we utilized a multi-scale, attention-guided and hybrid U-Net-shaped model -- GLIMS -- to perform 3D brain tumor segmentation in three regions: Enhancing Tumor (ET), Tumor Core (TC), and Whole Tumor (WT). The multi-scale feature extraction provides better contextual feature aggregation in high resolutions and the Swin Transformer blocks improve the global feature extraction at deeper levels of the model. The segmentation mask generation in the decoder branch is guided by the attention-refined features gathered from the encoder branch to enhance the important attributes. Moreover, hierarchical supervision is used to train the model efficiently. Our model's performance on the validation set resulted in 92.19, 87.75, and 83.18 Dice Scores and 89.09, 84.67, and 82.15 Lesion-wise Dice Scores in WT, TC, and ET, respectively. The code is publicly available at https://github.com/yaziciz/GLIMS.
http://w3id.org/mlsea/pwc/scientificWork/Attention-GAN%20for%20Anomaly%20Detection%3A%20A%20Cutting-Edge%20Approach%20to%20Cybersecurity%20Threat%20Management                                                                                  Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to Cybersecurity Threat Management                                                                                  This paper proposes an innovative Attention-GAN framework for enhancing cybersecurity, focusing on anomaly detection. In response to the challenges posed by the constantly evolving nature of cyber threats, the proposed approach aims to generate diverse and realistic synthetic attack scenarios, thereby enriching the dataset and improving threat identification. Integrating attention mechanisms with Generative Adversarial Networks (GANs) is a key feature of the proposed method. The attention mechanism enhances the model's ability to focus on relevant features, essential for detecting subtle and complex attack patterns. In addition, GANs address the issue of data scarcity by generating additional varied attack data, encompassing known and emerging threats. This dual approach ensures that the system remains relevant and effective against the continuously evolving cyberattacks. The KDD Cup and CICIDS2017 datasets were used to validate this model, which exhibited significant improvements in anomaly detection. It achieved an accuracy of 99.69% on the KDD dataset and 97.93% on the CICIDS2017 dataset, with precision, recall, and F1-scores above 97%, demonstrating its effectiveness in recognizing complex attack patterns. This study contributes significantly to cybersecurity by providing a scalable and adaptable solution for anomaly detection in the face of sophisticated and dynamic cyber threats. The exploration of GANs for data augmentation highlights a promising direction for future research, particularly in situations where data limitations restrict the development of cybersecurity systems. The attention-GAN framework has emerged as a pioneering approach, setting a new benchmark for advanced cyber-defense strategies.
http://w3id.org/mlsea/pwc/scientificWork/Attention-Guided%20Masked%20Autoencoders%20For%20Learning%20Image%20Representations                                                                                  Attention-Guided Masked Autoencoders For Learning Image Representations                                                                                  Masked autoencoders (MAEs) have established themselves as a powerful method for unsupervised pre-training for computer vision tasks. While vanilla MAEs put equal emphasis on reconstructing the individual parts of the image, we propose to inform the reconstruction process through an attention-guided loss function. By leveraging advances in unsupervised object discovery, we obtain an attention map of the scene which we employ in the loss function to put increased emphasis on reconstructing relevant objects, thus effectively incentivizing the model to learn more object-focused representations without compromising the established masking strategy. Our evaluations show that our pre-trained models learn better latent representations than the vanilla MAE, demonstrated by improved linear probing and k-NN classification results on several benchmarks while at the same time making ViTs more robust against varying backgrounds.
http://w3id.org/mlsea/pwc/scientificWork/Attention-aware%20Semantic%20Communications%20for%20Collaborative%20Inference                                                                                  Attention-aware Semantic Communications for Collaborative Inference                                                                                  We propose a communication-efficient collaborative inference framework in the domain of edge inference, focusing on the efficient use of vision transformer (ViTs) models. The partitioning strategy of conventional collaborative inference fails to reduce communication cost because of the inherent architecture of ViTs maintaining consistent layer dimensions across the entire transformer encoder. Therefore, instead of employing the partitioning strategy, our framework utilizes a lightweight ViT model on the edge device, with the server deploying a complicated ViT model. To enhance communication efficiency and achieve the classification accuracy of the server model, we propose two strategies: 1) attention-aware patch selection and 2) entropy-aware image transmission. Attention-aware patch selection leverages the attention scores generated by the edge device's transformer encoder to identify and select the image patches critical for classification. This strategy enables the edge device to transmit only the essential patches to the server, significantly improving communication efficiency. Entropy-aware image transmission uses min-entropy as a metric to accurately determine whether to depend on the lightweight model on the edge device or to request the inference from the server model. In our framework, the lightweight ViT model on the edge device acts as a semantic encoder, efficiently identifying and selecting the crucial image information required for the classification task. Our experiments demonstrate that the proposed collaborative inference framework can reduce communication overhead by 68% with only a minimal loss in accuracy compared to the server model.
http://w3id.org/mlsea/pwc/scientificWork/Attention-based%20Class-Conditioned%20Alignment%20for%20Multi-Source%20Domain%20Adaptive%20Object%20Detection                                                                                  Attention-based Class-Conditioned Alignment for Multi-Source Domain Adaptive Object Detection                                                                                  Domain adaptation methods for object detection (OD) strive to mitigate the impact of distribution shifts by promoting feature alignment across source and target domains. Multi-source domain adaptation (MSDA) allows leveraging multiple annotated source datasets, and unlabeled target data to improve the accuracy and robustness of the detection model. Most state-of-the-art MSDA methods for OD perform feature alignment in a class-agnostic manner. This is challenging since the objects have unique modal information due to variations in object appearance across domains. A recent prototype-based approach proposed a class-wise alignment, yet it suffers from error accumulation due to noisy pseudo-labels which can negatively affect adaptation with imbalanced data. To overcome these limitations, we propose an attention-based class-conditioned alignment scheme for MSDA that aligns instances of each object category across domains. In particular, an attention module coupled with an adversarial domain classifier allows learning domain-invariant and class-specific instance representations. Experimental results on multiple benchmarking MSDA datasets indicate that our method outperforms the state-of-the-art methods and is robust to class imbalance. Our code is available at https://github.com/imatif17/ACIA.
http://w3id.org/mlsea/pwc/scientificWork/Attention-based%20Shape%20and%20Gait%20Representations%20Learning%20for%20Video-based%20Cloth-Changing%20Person%20Re-Identification                                                                                  Attention-based Shape and Gait Representations Learning for Video-based Cloth-Changing Person Re-Identification                                                                                  Current state-of-the-art Video-based Person Re-Identification (Re-ID) primarily relies on appearance features extracted by deep learning models. These methods are not applicable for long-term analysis in real-world scenarios where persons have changed clothes, making appearance information unreliable. In this work, we deal with the practical problem of Video-based Cloth-Changing Person Re-ID (VCCRe-ID) by proposing 'Attention-based Shape and Gait Representations Learning' (ASGL) for VCCRe-ID. Our ASGL framework improves Re-ID performance under clothing variations by learning clothing-invariant gait cues using a Spatial-Temporal Graph Attention Network (ST-GAT). Given the 3D-skeleton-based spatial-temporal graph, our proposed ST-GAT comprises multi-head attention modules, which are able to enhance the robustness of gait embeddings under viewpoint changes and occlusions. The ST-GAT amplifies the important motion ranges and reduces the influence of noisy poses. Then, the multi-head learning module effectively reserves beneficial local temporal dynamics of movement. We also boost discriminative power of person representations by learning body shape cues using a GAT. Experiments on two large-scale VCCRe-ID datasets demonstrate that our proposed framework outperforms state-of-the-art methods by 12.2% in rank-1 accuracy and 7.0% in mAP.
http://w3id.org/mlsea/pwc/scientificWork/Attitudinal%20Loyalty%20Manifestation%20in%20Banking%20CSR%3A%20Cross-Buying%20Behavior%20and%20Customer%20Advocacy                                                                                  Attitudinal Loyalty Manifestation in Banking CSR: Cross-Buying Behavior and Customer Advocacy                                                                                  This study in the banking industry examines the influence of attitudinal loyalty on customer advocacy and cross buying behavior, alongside the moderating roles of Quality of Life and Corporate Social Responsibility support in the CSR fit and loyalty relationship. Employing Structural Equation Modeling, it reveals that higher attitudinal loyalty significantly boosts customer advocacy and propensity for cross buying. The findings highlight the importance of nurturing customer loyalty through valuable and relevant offerings, as CSR fit alone does not define the loyalty of the banking customer. Banks are advised to target customers with a high Quality of Life and engage with those who support CSR initiatives aligning with the banks objectives, to enhance loyalty and deepen customer relationships.
http://w3id.org/mlsea/pwc/scientificWork/AuditLLM%3A%20A%20Tool%20for%20Auditing%20Large%20Language%20Models%20Using%20Multiprobe%20Approach                                                                                  AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach                                                                                  As Large Language Models (LLMs) gain wider adoption in various contexts, it becomes crucial to ensure they are reasonably safe, consistent, and reliable for an application at hand. This may require probing or auditing them. Probing LLMs with varied iterations of a single question could reveal potential inconsistencies in their knowledge or functionality. However, a tool for performing such audits with simple workflow and low technical threshold is lacking. In this demo, we introduce 'AuditLLM,' a novel tool designed to evaluate the performance of various LLMs in a methodical way. AuditLLM's core functionality lies in its ability to test a given LLM by auditing it using multiple probes generated from a single question, thereby identifying any inconsistencies in the model's understanding or operation. A reasonably robust, reliable, and consistent LLM should output semantically similar responses for a question asked differently or by different people. Based on this assumption, AuditLLM produces easily interpretable results regarding the LLM's consistencies from a single question that the user enters. A certain level of inconsistency has been shown to be an indicator of potential bias, hallucinations, and other issues. One could then use the output of AuditLLM to further investigate issues with the aforementioned LLM. To facilitate demonstration and practical uses, AuditLLM offers two key modes: (1) Live mode which allows instant auditing of LLMs by analyzing responses to real-time queries; (2) Batch mode which facilitates comprehensive LLM auditing by processing multiple queries at once for in-depth analysis. This tool is beneficial for both researchers and general users, as it enhances our understanding of LLMs' capabilities in generating responses, using a standardized auditing platform.
http://w3id.org/mlsea/pwc/scientificWork/Auditable%20Homomorphic-based%20Decentralized%20Collaborative%20AI%20with%20Attribute-based%20Differential%20Privacy                                                                                  Auditable Homomorphic-based Decentralized Collaborative AI with Attribute-based Differential Privacy                                                                                  In recent years, the notion of federated learning (FL) has led to the new paradigm of distributed artificial intelligence (AI) with privacy preservation. However, most current FL systems suffer from data privacy issues due to the requirement of a trusted third party. Although some previous works introduce differential privacy to protect the data, however, it may also significantly deteriorate the model performance. To address these issues, we propose a novel decentralized collaborative AI framework, named Auditable Homomorphic-based Decentralised Collaborative AI (AerisAI), to improve security with homomorphic encryption and fine-grained differential privacy. Our proposed AerisAI directly aggregates the encrypted parameters with a blockchain-based smart contract to get rid of the need of a trusted third party. We also propose a brand-new concept for eliminating the negative impacts of differential privacy for model performance. Moreover, the proposed AerisAI also provides the broadcast-aware group key management based on ciphertext-policy attribute-based encryption (CPABE) to achieve fine-grained access control based on different service-level agreements. We provide a formal theoretical analysis of the proposed AerisAI as well as the functionality comparison with the other baselines. We also conduct extensive experiments on real datasets to evaluate the proposed approach. The experimental results indicate that our proposed AerisAI significantly outperforms the other state-of-the-art baselines.
http://w3id.org/mlsea/pwc/scientificWork/Auditing%20Fairness%20under%20Unobserved%20Confounding                                                                                  Auditing Fairness under Unobserved Confounding                                                                                  A fundamental problem in decision-making systems is the presence of inequity across demographic lines. However, inequity can be difficult to quantify, particularly if our notion of equity relies on hard-to-measure notions like risk (e.g., equal access to treatment for those who would die without it). Auditing such inequity requires accurate measurements of individual risk, which is difficult to estimate in the realistic setting of unobserved confounding. In the case that these unobservables 'explain' an apparent disparity, we may understate or overstate inequity. In this paper, we show that one can still give informative bounds on allocation rates among high-risk individuals, even while relaxing or (surprisingly) even when eliminating the assumption that all relevant risk factors are observed. We utilize the fact that in many real-world settings (e.g., the introduction of a novel treatment) we have data from a period prior to any allocation, to derive unbiased estimates of risk. We demonstrate the effectiveness of our framework on a real-world study of Paxlovid allocation to COVID-19 patients, finding that observed racial inequity cannot be explained by unobserved confounders of the same strength as important observed covariates.
http://w3id.org/mlsea/pwc/scientificWork/Auditing%20Large%20Language%20Models%20for%20Enhanced%20Text-Based%20Stereotype%20Detection%20and%20Probing-Based%20Bias%20Evaluation                                                                                  Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation                                                                                  Recent advancements in Large Language Models (LLMs) have significantly increased their presence in human-facing Artificial Intelligence (AI) applications. However, LLMs could reproduce and even exacerbate stereotypical outputs from training data. This work introduces the Multi-Grain Stereotype (MGS) dataset, encompassing 51,867 instances across gender, race, profession, religion, and stereotypical text, collected by fusing multiple previously publicly available stereotype detection datasets. We explore different machine learning approaches aimed at establishing baselines for stereotype detection, and fine-tune several language models of various architectures and model sizes, presenting in this work a series of stereotypes classifier models for English text trained on MGS. To understand whether our stereotype detectors capture relevant features (aligning with human common sense) we utilise a variety of explanainable AI tools, including SHAP, LIME, and BertViz, and analyse a series of example cases discussing the results. Finally, we develop a series of stereotype elicitation prompts and evaluate the presence of stereotypes in text generation tasks with popular LLMs, using one of our best performing previously presented stereotypes detectors. Our experiments yielded several key findings: i) Training stereotype detectors in a multi-dimension setting yields better results than training multiple single-dimension classifiers.ii) The integrated MGS Dataset enhances both the in-dataset and cross-dataset generalisation ability of stereotype detectors compared to using the datasets separately. iii) There is a reduction in stereotypes in the content generated by GPT Family LLMs with newer versions.
http://w3id.org/mlsea/pwc/scientificWork/Auditing%20health-related%20recommendations%20in%20social%20media%3A%20A%20Case%20Study%20of%20Abortion%20on%20YouTube                                                                                  Auditing health-related recommendations in social media: A Case Study of Abortion on YouTube                                                                                  Recommendation algorithms (RS) used by social media, like YouTube, significantly shape our information consumption across various domains, especially in healthcare. Hence, algorithmic auditing becomes crucial to uncover their potential bias and misinformation, particularly in the context of controversial topics like abortion. We introduce a simple yet effective sock puppet auditing approach to investigate how YouTube recommends abortion-related videos to individuals with different backgrounds. Our framework allows for efficient auditing of RS, regardless of the complexity of the underlying algorithms
http://w3id.org/mlsea/pwc/scientificWork/Augmented%20Reality%20Demonstrations%20for%20Scalable%20Robot%20Imitation%20Learning                                                                                  Augmented Reality Demonstrations for Scalable Robot Imitation Learning                                                                                  Robot Imitation Learning (IL) is a widely used method for training robots to perform manipulation tasks that involve mimicking human demonstrations to acquire skills. However, its practicality has been limited due to its requirement that users be trained in operating real robot arms to provide demonstrations. This paper presents an innovative solution: an Augmented Reality (AR)-assisted framework for demonstration collection, empowering non-roboticist users to produce demonstrations for robot IL using devices like the HoloLens 2. Our framework facilitates scalable and diverse demonstration collection for real-world tasks. We validate our approach with experiments on three classical robotics tasks: reach, push, and pick-and-place. The real robot performs each task successfully while replaying demonstrations collected via AR.
http://w3id.org/mlsea/pwc/scientificWork/Augmenting%20Automation%3A%20Intent-Based%20User%20Instruction%20Classification%20with%20Machine%20Learning                                                                                  Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning                                                                                  Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices. Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability. In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques. Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands. Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme. We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification. Experimental results demonstrate the effectiveness of our approach in enhancing user experience and expanding the capabilities of electric automation systems. Our work contributes to the advancement of smart technologies by providing a more seamless interaction between users and their environments.
http://w3id.org/mlsea/pwc/scientificWork/Augmenting%20Ground-Level%20PM2.5%20Prediction%20via%20Kriging-Based%20Pseudo-Label%20Generation                                                                                  Augmenting Ground-Level PM2.5 Prediction via Kriging-Based Pseudo-Label Generation                                                                                  Fusing abundant satellite data with sparse ground measurements constitutes a major challenge in climate modeling. To address this, we propose a strategy to augment the training dataset by introducing unlabeled satellite images paired with pseudo-labels generated through a spatial interpolation technique known as ordinary kriging, thereby making full use of the available satellite data resources. We show that the proposed data augmentation strategy helps enhance the performance of the state-of-the-art convolutional neural network-random forest (CNN-RF) model by a reasonable amount, resulting in a noteworthy improvement in spatial correlation and a reduction in prediction error.
http://w3id.org/mlsea/pwc/scientificWork/Augmenting%20Replay%20in%20World%20Models%20for%20Continual%20Reinforcement%20Learning                                                                                  Augmenting Replay in World Models for Continual Reinforcement Learning                                                                                  Continual RL is a challenging problem where the agent is exposed to a sequence of tasks; it should learn new tasks without forgetting old ones, and learning the new task should improve performance on previous and future tasks. The most common approaches use model-free RL algorithms as a base, and replay buffers have been used to overcome catastrophic forgetting. However, the buffers are often very large making scalability difficult. Also, the concept of replay comes from biological inspiration, where evidence suggests that replay is applied to a world model, which implies model-based RL -- and model-based RL should have benefits for continual RL, where it is possible to exploit knowledge independent of the policy. We present WMAR, World Models with Augmented Replay, a model-based RL algorithm with a world model and memory efficient distribution matching replay buffer. It is based on the well-known DreamerV3 algorithm, which has a simple FIFO buffer and was not tested in a continual RL setting. We evaluated WMAR vs WMAR (FIFO only) on tasks with and without shared structure from OpenAI ProcGen and Atari respectively, and without a task oracle. We found that WMAR has favourable properties on continual RL with significantly reduced computational overhead compared to WMAR (FIFO only). WMAR had small benefits over DreamerV3 on tasks with shared structure and substantially better forgetting characteristics on tasks without shared structure; but at the cost of lower plasticity seen in a lower maximum on new tasks. The results suggest that model-based RL using a world model with a memory efficient replay buffer can be an effective and practical approach to continual RL, justifying future work.
http://w3id.org/mlsea/pwc/scientificWork/Authentication%20and%20integrity%20of%20smartphone%20videos%20through%20multimedia%20container%20structure%20analysis                                                                                  Authentication and integrity of smartphone videos through multimedia container structure analysis                                                                                  Nowadays, mobile devices have become the natural substitute for the digital camera, as they capture everyday situations easily and quickly, encouraging users to express themselves through images and videos. These videos can be shared across different platforms exposing them to any kind of intentional manipulation by criminals who are aware of the weaknesses of forensic techniques to accuse an innocent person or exonerate a guilty person in a judicial process. Commonly, manufacturers do not comply 100% with the specifications of the standards for the creation of videos. Also, videos shared on social networks, and instant messaging applications go through filtering and compression processes to reduce their size, facilitate their transfer, and optimize storage on their platforms. The omission of specifications and results of transformations carried out by the platforms embed a features pattern in the multimedia container of the videos. These patterns make it possible to distinguish the brand of the device that generated the video, social network, and instant messaging application that was used for the transfer. Research in recent years has focused on the analysis of AVI containers and tiny video datasets. This work presents a novel technique to detect possible attacks against MP4, MOV, and 3GP format videos that affect their integrity and authenticity. The method is based on the analysis of the structure of video containers generated by mobile devices and their behavior when shared through social networks, instant messaging applications, or manipulated by editing programs. The objectives of the proposal are to verify the integrity of videos, identify the source of acquisition and distinguish between original and manipulated videos.
http://w3id.org/mlsea/pwc/scientificWork/Authorship%20Attribution%20in%20Bangla%20Literature%20%28AABL%29%20via%20Transfer%20Learning%20using%20ULMFiT                                                                                  Authorship Attribution in Bangla Literature (AABL) via Transfer Learning using ULMFiT                                                                                  Authorship Attribution is the task of creating an appropriate characterization of text that captures the authors' writing style to identify the original author of a given piece of text. With increased anonymity on the internet, this task has become increasingly crucial in various security and plagiarism detection fields. Despite significant advancements in other languages such as English, Spanish, and Chinese, Bangla lacks comprehensive research in this field due to its complex linguistic feature and sentence structure. Moreover, existing systems are not scalable when the number of author increases, and the performance drops for small number of samples per author. In this paper, we propose the use of Average-Stochastic Gradient Descent Weight-Dropped Long Short-Term Memory (AWD-LSTM) architecture and an effective transfer learning approach that addresses the problem of complex linguistic features extraction and scalability for authorship attribution in Bangla Literature (AABL). We analyze the effect of different tokenization, such as word, sub-word, and character level tokenization, and demonstrate the effectiveness of these tokenizations in the proposed model. Moreover, we introduce the publicly available Bangla Authorship Attribution Dataset of 16 authors (BAAD16) containing 17,966 sample texts and 13.4+ million words to solve the standard dataset scarcity problem and release six variations of pre-trained language models for use in any Bangla NLP downstream task. For evaluation, we used our developed BAAD16 dataset as well as other publicly available datasets. Empirically, our proposed model outperformed state-of-the-art models and achieved 99.8% accuracy in the BAAD16 dataset. Furthermore, we showed that the proposed system scales much better even with an increasing number of authors, and performance remains steady despite few training samples.
http://w3id.org/mlsea/pwc/scientificWork/Authorship%20Verification%20based%20on%20the%20Likelihood%20Ratio%20of%20Grammar%20Models                                                                                  Authorship Verification based on the Likelihood Ratio of Grammar Models                                                                                  Authorship Verification (AV) is the process of analyzing a set of documents to determine whether they were written by a specific author. This problem often arises in forensic scenarios, e.g., in cases where the documents in question constitute evidence for a crime. Existing state-of-the-art AV methods use computational solutions that are not supported by a plausible scientific explanation for their functioning and that are often difficult for analysts to interpret. To address this, we propose a method relying on calculating a quantity we call $ lambda_G$ (LambdaG): the ratio between the likelihood of a document given a model of the Grammar for the candidate author and the likelihood of the same document given a model of the Grammar for a reference population. These Grammar Models are estimated using $n$-gram language models that are trained solely on grammatical features. Despite not needing large amounts of data for training, LambdaG still outperforms other established AV methods with higher computational complexity, including a fine-tuned Siamese Transformer network. Our empirical evaluation based on four baseline methods applied to twelve datasets shows that LambdaG leads to better results in terms of both accuracy and AUC in eleven cases and in all twelve cases if considering only topic-agnostic methods. The algorithm is also highly robust to important variations in the genre of the reference population in many cross-genre comparisons. In addition to these properties, we demonstrate how LambdaG is easier to interpret than the current state-of-the-art. We argue that the advantage of LambdaG over other methods is due to fact that it is compatible with Cognitive Linguistic theories of language processing.
http://w3id.org/mlsea/pwc/scientificWork/Auto311%3A%20A%20Confidence-guided%20Automated%20System%20for%20Non-emergency%20Calls                                                                                  Auto311: A Confidence-guided Automated System for Non-emergency Calls                                                                                  Emergency and non-emergency response systems are essential services provided by local governments and critical to protecting lives, the environment, and property. The effective handling of (non-)emergency calls is critical for public safety and well-being. By reducing the burden through non-emergency callers, residents in critical need of assistance through 911 will receive a fast and effective response. Collaborating with the Department of Emergency Communications (DEC) in Nashville, we analyzed 11,796 non-emergency call recordings and developed Auto311, the first automated system to handle 311 non-emergency calls, which (1) effectively and dynamically predicts ongoing non-emergency incident types to generate tailored case reports during the call; (2) itemizes essential information from dialogue contexts to complete the generated reports; and (3) strategically structures system-caller dialogues with optimized confidence. We used real-world data to evaluate the system's effectiveness and deployability. The experimental results indicate that the system effectively predicts incident type with an average F-1 score of 92.54%. Moreover, the system successfully itemizes critical information from relevant contexts to complete reports, evincing a 0.93 average consistency score compared to the ground truth. Additionally, emulations demonstrate that the system effectively decreases conversation turns as the utterance size gets more extensive and categorizes the ongoing call with 94.49% mean accuracy.
http://w3id.org/mlsea/pwc/scientificWork/AutoInst%3A%20Automatic%20Instance-Based%20Segmentation%20of%20LiDAR%203D%20Scans                                                                                  AutoInst: Automatic Instance-Based Segmentation of LiDAR 3D Scans                                                                                  Recently, progress in acquisition equipment such as LiDAR sensors has enabled sensing increasingly spacious outdoor 3D environments. Making sense of such 3D acquisitions requires fine-grained scene understanding, such as constructing instance-based 3D scene segmentations. Commonly, a neural network is trained for this task; however, this requires access to a large, densely annotated dataset, which is widely known to be challenging to obtain. To address this issue, in this work we propose to predict instance segmentations for 3D scenes in an unsupervised way, without relying on ground-truth annotations. To this end, we construct a learning framework consisting of two components: (1) a pseudo-annotation scheme for generating initial unsupervised pseudo-labels; and (2) a self-training algorithm for instance segmentation to fit robust, accurate instances from initial noisy proposals. To enable generating 3D instance mask proposals, we construct a weighted proxy-graph by connecting 3D points with edges integrating multi-modal image- and point-based self-supervised features, and perform graph-cuts to isolate individual pseudo-instances. We then build on a state-of-the-art point-based architecture and train a 3D instance segmentation model, resulting in significant refinement of initial proposals. To scale to arbitrary complexity 3D scenes, we design our algorithm to operate on local 3D point chunks and construct a merging step to generate scene-level instance segmentations. Experiments on the challenging SemanticKITTI benchmark demonstrate the potential of our approach, where it attains 13.3% higher Average Precision and 9.1% higher F1 score compared to the best-performing baseline. The code will be made publicly available at https://github.com/artonson/autoinst.
http://w3id.org/mlsea/pwc/scientificWork/AutoTRIZ%3A%20Artificial%20Ideation%20with%20TRIZ%20and%20Large%20Language%20Models                                                                                  AutoTRIZ: Artificial Ideation with TRIZ and Large Language Models                                                                                  Researchers and innovators have made enormous efforts in developing ideation methods, such as morphological analysis and design-by-analogy, to aid engineering design ideation for problem solving and innovation. Among these, TRIZ stands out as the most well-known approach, widely applied for systematic innovation. However, the complexity of TRIZ resources and concepts, coupled with its reliance on users' knowledge, experience, and reasoning capabilities, limits its practicability. This paper proposes AutoTRIZ, an artificial ideation tool that leverages large language models (LLMs) to automate and enhance the TRIZ methodology. By leveraging the broad knowledge and advanced reasoning capabilities of LLMs, AutoTRIZ offers a novel approach to design automation and interpretable ideation with artificial intelligence. We demonstrate and evaluate the effectiveness of AutoTRIZ through consistency experiments in contradiction detection and comparative studies with cases collected from TRIZ textbooks. Moreover, the proposed LLM-based framework holds the potential for extension to automate other knowledge-based ideation methods, including SCAMPER, Design Heuristics, and Design-by-Analogy, paving the way for a new era of artificial ideation for design and innovation.
http://w3id.org/mlsea/pwc/scientificWork/AutoWebGLM%3A%20Bootstrap%20And%20Reinforce%20A%20Large%20Language%20Model-based%20Web%20Navigating%20Agent                                                                                  AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent                                                                                  Large language models (LLMs) have fueled many intelligent agent tasks, such as web navigation -- but most existing agents perform far from satisfying in real-world webpages due to three factors: (1) the versatility of actions on webpages, (2) HTML text exceeding model processing capacity, and (3) the complexity of decision-making due to the open-domain nature of web. In light of the challenge, we develop AutoWebGLM, a GPT-4-outperforming automated web navigation agent built upon ChatGLM3-6B. Inspired by human browsing patterns, we design an HTML simplification algorithm to represent webpages, preserving vital information succinctly. We employ a hybrid human-AI method to build web browsing data for curriculum training. Then, we bootstrap the model by reinforcement learning and rejection sampling to further facilitate webpage comprehension, browser operations, and efficient task decomposition by itself. For testing, we establish a bilingual benchmark -- AutoWebBench -- for real-world web browsing tasks. We evaluate AutoWebGLM across diverse web navigation benchmarks, revealing its improvements but also underlying challenges to tackle real environments. Related code, model, and data will be released at url{https://github.com/THUDM/AutoWebGLM}.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Answer%20Validation%20using%20Text%20Similarity                                                                                  Automated Answer Validation using Text Similarity                                                                                  Automated answer validation can help improve learning outcomes by providing appropriate feedback to learners, and by making question answering systems and online learning solutions more widely available. There have been some works in science question answering which show that information retrieval methods outperform neural methods, especially in the multiple choice version of this problem. We implement Siamese neural network models and produce a generalised solution to this problem. We compare our supervised model with other text similarity based solutions.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Black-box%20Prompt%20Engineering%20for%20Personalized%20Text-to-Image%20Generation                                                                                  Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation                                                                                  Prompt engineering is effective for controlling the output of text-to-image (T2I) generative models, but it is also laborious due to the need for manually crafted prompts. This challenge has spurred the development of algorithms for automated prompt generation. However, these methods often struggle with transferability across T2I models, require white-box access to the underlying model, and produce non-intuitive prompts. In this work, we introduce PRISM, an algorithm that automatically identifies human-interpretable and transferable prompts that can effectively generate desired concepts given only black-box access to T2I models. Inspired by large language model (LLM) jailbreaking, PRISM leverages the in-context learning ability of LLMs to iteratively refine the candidate prompts distribution for given reference images. Our experiments demonstrate the versatility and effectiveness of PRISM in generating accurate prompts for objects, styles and images across multiple T2I models, including Stable Diffusion, DALL-E, and Midjourney.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Design%20and%20Optimization%20of%20Distributed%20Filtering%20Circuits%20via%20Reinforcement%20Learning                                                                                  Automated Design and Optimization of Distributed Filtering Circuits via Reinforcement Learning                                                                                  Designing distributed filtering circuits (DFCs) is complex and time-consuming, with the circuit performance relying heavily on the expertise and experience of electronics engineers. However, manual design methods tend to have exceedingly low-efficiency. This study proposes a novel end-to-end automated method for fabricating circuits to improve the design of DFCs. The proposed method harnesses reinforcement learning (RL) algorithms, eliminating the dependence on the design experience of engineers. Thus, it significantly reduces the subjectivity and constraints associated with circuit design. The experimental findings demonstrate clear improvements in both design efficiency and quality when comparing the proposed method with traditional engineer-driven methods. In particular, the proposed method achieves superior performance when designing complex or rapidly evolving DFCs. Furthermore, compared to existing circuit automation design techniques, the proposed method demonstrates superior design efficiency, highlighting the substantial potential of RL in circuit design automation.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Discovery%20of%20Integral%20with%20Deep%20Learning                                                                                  Automated Discovery of Integral with Deep Learning                                                                                  Recent advancements in the realm of deep learning, particularly in the development of large language models (LLMs), have demonstrated AI's ability to tackle complex mathematical problems or solving programming challenges. However, the capability to solve well-defined problems based on extensive training data differs significantly from the nuanced process of making scientific discoveries. Trained on almost all human knowledge available, today's sophisticated LLMs basically learn to predict sequences of tokens. They generate mathematical derivations and write code in a similar way as writing an essay, and do not have the ability to pioneer scientific discoveries in the manner a human scientist would do. In this study we delve into the potential of using deep learning to rediscover a fundamental mathematical concept: integrals. By defining integrals as area under the curve, we illustrate how AI can deduce the integral of a given function, exemplified by inferring $ int_{0}^{x} t^2 dt = frac{x^3}{3}$ and $ int_{0}^{x} ae^{bt} dt = frac{a}{b} e^{bx} - frac{a}{b}$. Our experiments show that deep learning models can approach the task of inferring integrals either through a sequence-to-sequence model, akin to language translation, or by uncovering the rudimentary principles of integration, such as $ int_{0}^{x} t^n dt = frac{x^{n+1}}{n+1}$.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Floodwater%20Depth%20Estimation%20Using%20Large%20Multimodal%20Model%20for%20Rapid%20Flood%20Mapping                                                                                  Automated Floodwater Depth Estimation Using Large Multimodal Model for Rapid Flood Mapping                                                                                  Information on the depth of floodwater is crucial for rapid mapping of areas affected by floods. However, previous approaches for estimating floodwater depth, including field surveys, remote sensing, and machine learning techniques, can be time-consuming and resource-intensive. This paper presents an automated and fast approach for estimating floodwater depth from on-site flood photos. A pre-trained large multimodal model, GPT-4 Vision, was used specifically for estimating floodwater. The input data were flooding photos that contained referenced objects, such as street signs, cars, people, and buildings. Using the heights of the common objects as references, the model returned the floodwater depth as the output. Results show that the proposed approach can rapidly provide a consistent and reliable estimation of floodwater depth from flood photos. Such rapid estimation is transformative in flood inundation mapping and assessing the severity of the flood in near-real time, which is essential for effective flood response strategies.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20HER2%20Scoring%20in%20Breast%20Cancer%20Images%20Using%20Deep%20Learning%20and%20Pyramid%20Sampling                                                                                  Automated HER2 Scoring in Breast Cancer Images Using Deep Learning and Pyramid Sampling                                                                                  Human epidermal growth factor receptor 2 (HER2) is a critical protein in cancer cell growth that signifies the aggressiveness of breast cancer (BC) and helps predict its prognosis. Accurate assessment of immunohistochemically (IHC) stained tissue slides for HER2 expression levels is essential for both treatment guidance and understanding of cancer mechanisms. Nevertheless, the traditional workflow of manual examination by board-certified pathologists encounters challenges, including inter- and intra-observer inconsistency and extended turnaround times. Here, we introduce a deep learning-based approach utilizing pyramid sampling for the automated classification of HER2 status in IHC-stained BC tissue images. Our approach analyzes morphological features at various spatial scales, efficiently managing the computational load and facilitating a detailed examination of cellular and larger-scale tissue-level details. This method addresses the tissue heterogeneity of HER2 expression by providing a comprehensive view, leading to a blind testing classification accuracy of 84.70%, on a dataset of 523 core images from tissue microarrays. Our automated system, proving reliable as an adjunct pathology tool, has the potential to enhance diagnostic precision and evaluation speed, and might significantly impact cancer treatment planning.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Inference%20of%20Graph%20Transformation%20Rules                                                                                  Automated Inference of Graph Transformation Rules                                                                                  The explosion of data available in life sciences is fueling an increasing demand for expressive models and computational methods. Graph transformation is a model for dynamic systems with a large variety of applications. We introduce a novel method of the graph transformation model construction, combining generative and dynamical viewpoints to give a fully automated data-driven model inference method. The method takes the input dynamical properties, given as a 'snapshot' of the dynamics encoded by explicit transitions, and constructs a compatible model. The obtained model is guaranteed to be minimal, thus framing the approach as model compression (from a set of transitions into a set of rules). The compression is permissive to a lossy case, where the constructed model is allowed to exhibit behavior outside of the input transitions, thus suggesting a completion of the input dynamics. The task of graph transformation model inference is naturally highly challenging due to the combinatorics involved. We tackle the exponential explosion by proposing a heuristically minimal translation of the task into a well-established problem, set cover, for which highly optimized solutions exist. We further showcase how our results relate to Kolmogorov complexity expressed in terms of graph transformation.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20User%20Story%20Generation%20with%20Test%20Case%20Specification%20Using%20Large%20Language%20Model                                                                                  Automated User Story Generation with Test Case Specification Using Large Language Model                                                                                  Modern Software Engineering era is moving fast with the assistance of artificial intelligence (AI), especially Large Language Models (LLM). Researchers have already started automating many parts of the software development workflow. Requirements Engineering (RE) is a crucial phase that begins the software development cycle through multiple discussions on a proposed scope of work documented in different forms. RE phase ends with a list of user-stories for each unit task identified through discussions and usually these are created and tracked on a project management tool such as Jira, AzurDev etc. In this research we developed a tool 'GeneUS' using GPT-4.0 to automatically create user stories from requirements document which is the outcome of the RE phase. The output is provided in JSON format leaving the possibilities open for downstream integration to the popular project management tools. Analyzing requirements documents takes significant effort and multiple meetings with stakeholders. We believe, automating this process will certainly reduce additional load off the software engineers, and increase the productivity since they will be able to utilize their time on other prioritized tasks.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Annotation%20of%20Grammaticality%20in%20Child-Caregiver%20Conversations                                                                                  Automatic Annotation of Grammaticality in Child-Caregiver Conversations                                                                                  The acquisition of grammar has been a central question to adjudicate between theories of language acquisition. In order to conduct faster, more reproducible, and larger-scale corpus studies on grammaticality in child-caregiver conversations, tools for automatic annotation can offer an effective alternative to tedious manual annotation. We propose a coding scheme for context-dependent grammaticality in child-caregiver conversations and annotate more than 4,000 utterances from a large corpus of transcribed conversations. Based on these annotations, we train and evaluate a range of NLP models. Our results show that fine-tuned Transformer-based models perform best, achieving human inter-annotation agreement levels.As a first application and sanity check of this tool, we use the trained models to annotate a corpus almost two orders of magnitude larger than the manually annotated data and verify that children's grammaticality shows a steady increase with age.This work contributes to the growing literature on applying state-of-the-art NLP methods to help study child language acquisition at scale.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Information%20Extraction%20From%20Employment%20Tribunal%20Judgements%20Using%20Large%20Language%20Models                                                                                  Automatic Information Extraction From Employment Tribunal Judgements Using Large Language Models                                                                                  Court transcripts and judgments are rich repositories of legal knowledge, detailing the intricacies of cases and the rationale behind judicial decisions. The extraction of key information from these documents provides a concise overview of a case, crucial for both legal experts and the public. With the advent of large language models (LLMs), automatic information extraction has become increasingly feasible and efficient. This paper presents a comprehensive study on the application of GPT-4, a large language model, for automatic information extraction from UK Employment Tribunal (UKET) cases. We meticulously evaluated GPT-4's performance in extracting critical information with a manual verification process to ensure the accuracy and relevance of the extracted data. Our research is structured around two primary extraction tasks: the first involves a general extraction of eight key aspects that hold significance for both legal specialists and the general public, including the facts of the case, the claims made, references to legal statutes, references to precedents, general case outcomes and corresponding labels, detailed order and remedies and reasons for the decision. The second task is more focused, aimed at analysing three of those extracted features, namely facts, claims and outcomes, in order to facilitate the development of a tool capable of predicting the outcome of employment law disputes. Through our analysis, we demonstrate that LLMs like GPT-4 can obtain high accuracy in legal information extraction, highlighting the potential of LLMs in revolutionising the way legal information is processed and utilised, offering significant implications for legal research and practice.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Interactive%20Evaluation%20for%20Large%20Language%20Models%20with%20State%20Aware%20Patient%20Simulator                                                                                  Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator                                                                                  Large Language Models (LLMs) have demonstrated remarkable proficiency in human interactions, yet their application within the medical field remains insufficiently explored. Previous works mainly focus on the performance of medical knowledge with examinations, which is far from the realistic scenarios, falling short in assessing the abilities of LLMs on clinical tasks. In the quest to enhance the application of Large Language Models (LLMs) in healthcare, this paper introduces the Automated Interactive Evaluation (AIE) framework and the State-Aware Patient Simulator (SAPS), targeting the gap between traditional LLM evaluations and the nuanced demands of clinical practice. Unlike prior methods that rely on static medical knowledge assessments, AIE and SAPS provide a dynamic, realistic platform for assessing LLMs through multi-turn doctor-patient simulations. This approach offers a closer approximation to real clinical scenarios and allows for a detailed analysis of LLM behaviors in response to complex patient interactions. Our extensive experimental validation demonstrates the effectiveness of the AIE framework, with outcomes that align well with human evaluations, underscoring its potential to revolutionize medical LLM testing for improved healthcare delivery.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Quantification%20of%20Serial%20PET%2FCT%20Images%20for%20Pediatric%20Hodgkin%20Lymphoma%20Patients%20Using%20a%20Longitudinally-Aware%20Segmentation%20Network                                                                                  Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network                                                                                  $ textbf{Purpose}$: Automatic quantification of longitudinal changes in PET scans for lymphoma patients has proven challenging, as residual disease in interim-therapy scans is often subtle and difficult to detect. Our goal was to develop a longitudinally-aware segmentation network (LAS-Net) that can quantify serial PET/CT images for pediatric Hodgkin lymphoma patients. $ textbf{Materials and Methods}$: This retrospective study included baseline (PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two Children's Oncology Group clinical trials (AHOD1331 and AHOD0831). LAS-Net incorporates longitudinal cross-attention, allowing relevant features from PET1 to inform the analysis of PET2. Model performance was evaluated using Dice coefficients for PET1 and detection F1 scores for PET2. Additionally, we extracted and compared quantitative PET metrics, including metabolic tumor volume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and $ Delta$SUVmax in PET2, against physician measurements. We quantified their agreement using Spearman's $ rho$ correlations and employed bootstrap resampling for statistical analysis. $ textbf{Results}$: LAS-Net detected residual lymphoma in PET2 with an F1 score of 0.606 (precision/recall: 0.615/0.600), outperforming all comparator methods (P<0.01). For baseline segmentation, LAS-Net achieved a mean Dice score of 0.772. In PET quantification, LAS-Net's measurements of qPET, $ Delta$SUVmax, MTV and TLG were strongly correlated with physician measurements, with Spearman's $ rho$ of 0.78, 0.80, 0.93 and 0.96, respectively. The performance remained high, with a slight decrease, in an external testing cohort. $ textbf{Conclusion}$: LAS-Net achieved high performance in quantifying PET metrics across serial scans, highlighting the value of longitudinal awareness in evaluating multi-time-point imaging datasets.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Radio%20Map%20Adaptation%20for%20Robust%20Localization%20with%20Dynamic%20Adversarial%20Learning                                                                                  Automatic Radio Map Adaptation for Robust Localization with Dynamic Adversarial Learning                                                                                  Wireless fingerprint-based localization has become one of the most promising technologies for ubiquitous location-aware computing and intelligent location-based services. However, due to RF vulnerability to environmental dynamics over time, continuous radio map updates are time-consuming and infeasible, resulting in severe accuracy degradation. To address this issue, we propose a novel approach of robust localization with dynamic adversarial learning, known as DadLoc which realizes automatic radio map adaptation by incorporating multiple robust factors underlying RF fingerprints to learn the evolving feature representation with the complicated environmental dynamics. DadLoc performs a finer-grained distribution adaptation with the developed dynamic adversarial adaptation network and quantifies the contributions of both global and local distribution adaptation in a dynamics-adaptive manner. Furthermore, we adopt the strategy of prediction uncertainty suppression to conduct source-supervised training, target-unsupervised training, and source-target dynamic adversarial adaptation which can trade off the environment adaptability and the location discriminability of the learned deep representation for safe and effective feature transfer across different environments. With extensive experimental results, the satisfactory accuracy over other comparative schemes demonstrates that the proposed DanLoc can facilitate fingerprint-based localization for wide deployments.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Semantic%20Augmentation%20of%20Language%20Model%20Prompts%20%28for%20Code%20Summarization%29                                                                                  Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)                                                                                  Large Language Models (LLM) are a new class of computation engines, 'programmed' via prompt engineering. We are still learning how to best 'program' these LLMs to help developers. We start with the intuition that developers tend to consciously and unconsciously have a collection of semantics facts in mind when working on coding tasks. Mostly these are shallow, simple facts arising from a quick read. For a function, examples of facts might include parameter and local variable names, return expressions, simple pre- and post-conditions, and basic control and data flow, etc. One might assume that the powerful multi-layer architecture of transformer-style LLMs makes them inherently capable of doing this simple level of 'code analysis' and extracting such information, implicitly, while processing code: but are they, really? If they aren't, could explicitly adding this information help? Our goal here is to investigate this question, using the code summarization task and evaluate whether automatically augmenting an LLM's prompt with semantic facts explicitly, actually helps. Prior work shows that LLM performance on code summarization benefits from few-shot samples drawn either from the same-project or from examples found via information retrieval methods (such as BM25). While summarization performance has steadily increased since the early days, there is still room for improvement: LLM performance on code summarization still lags its performance on natural-language tasks like translation and text summarization. We find that adding semantic facts actually does help! This approach improves performance in several different settings suggested by prior work, including for two different Large Language Models. In most cases, improvement nears or exceeds 2 BLEU; for the PHP language in the challenging CodeSearchNet dataset, this augmentation actually yields performance surpassing 30 BLEU.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20and%20Universal%20Prompt%20Injection%20Attacks%20against%20Large%20Language%20Models                                                                                  Automatic and Universal Prompt Injection Attacks against Large Language Models                                                                                  Large Language Models (LLMs) excel in processing and generating human language, powered by their ability to interpret and follow instructions. However, their capabilities can be exploited through prompt injection attacks. These attacks manipulate LLM-integrated applications into producing responses aligned with the attacker's injected content, deviating from the user's actual requests. The substantial risks posed by these attacks underscore the need for a thorough understanding of the threats. Yet, research in this area faces challenges due to the lack of a unified goal for such attacks and their reliance on manually crafted prompts, complicating comprehensive assessments of prompt injection robustness. We introduce a unified framework for understanding the objectives of prompt injection attacks and present an automated gradient-based method for generating highly effective and universal prompt injection data, even in the face of defensive measures. With only five training samples (0.3% relative to the test data), our attack can achieve superior performance compared with baselines. Our findings emphasize the importance of gradient-based testing, which can avoid overestimation of robustness, especially for defense mechanisms.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20classification%20of%20prostate%20MR%20series%20type%20using%20image%20content%20and%20metadata                                                                                  Automatic classification of prostate MR series type using image content and metadata                                                                                  With the wealth of medical image data, efficient curation is essential. Assigning the sequence type to magnetic resonance images is necessary for scientific studies and artificial intelligence-based analysis. However, incomplete or missing metadata prevents effective automation. We therefore propose a deep-learning method for classification of prostate cancer scanning sequences based on a combination of image data and DICOM metadata. We demonstrate superior results compared to metadata or image data alone, and make our code publicly available at https://github.com/deepakri201/DICOMScanClassification.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20location%20detection%20based%20on%20deep%20learning                                                                                  Automatic location detection based on deep learning                                                                                  The proliferation of digital images and the advancements in deep learning have paved the way for innovative solutions in various domains, especially in the field of image classification. Our project presents an in-depth study and implementation of an image classification system specifically tailored to identify and classify images of Indian cities. Drawing from an extensive dataset, our model classifies images into five major Indian cities: Ahmedabad, Delhi, Kerala, Kolkata, and Mumbai to recognize the distinct features and characteristics of each city/state. To achieve high precision and recall rates, we adopted two approaches. The first, a vanilla Convolutional Neural Network (CNN) and then we explored the power of transfer learning by leveraging the VGG16 model. The vanilla CNN achieved commendable accuracy and the VGG16 model achieved a test accuracy of 63.6%. Evaluations highlighted the strengths and potential areas of improvement, positioning our model as not only competitive but also scalable for broader applications. With an emphasis on open-source ethos, our work aims to contribute to the community, encouraging further development and diverse applications. Our findings demonstrate the potential applications in tourism, urban planning, and even real-time location identification systems, among others.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20re-calibration%20of%20quantum%20devices%20by%20reinforcement%20learning                                                                                  Automatic re-calibration of quantum devices by reinforcement learning                                                                                  During their operation, due to shifts in environmental conditions, devices undergo various forms of detuning from their optimal settings. Typically, this is addressed through control loops, which monitor variables and the device performance, to maintain settings at their optimal values. Quantum devices are particularly challenging since their functionality relies on precisely tuning their parameters. At the same time, the detailed modeling of the environmental behavior is often computationally unaffordable, while a direct measure of the parameters defining the system state is costly and introduces extra noise in the mechanism. In this study, we investigate the application of reinforcement learning techniques to develop a model-free control loop for continuous recalibration of quantum device parameters. Furthermore, we explore the advantages of incorporating minimal environmental noise models. As an example, the application to numerical simulations of a Kennedy receiver-based long-distance quantum communication protocol is presented.
http://w3id.org/mlsea/pwc/scientificWork/Automating%20Catheterization%20Labs%20with%20Real-Time%20Perception                                                                                  Automating Catheterization Labs with Real-Time Perception                                                                                  For decades, three-dimensional C-arm Cone-Beam Computed Tomography (CBCT) imaging system has been a critical component for complex vascular and nonvascular interventional procedures. While it can significantly improve multiplanar soft tissue imaging and provide pre-treatment target lesion roadmapping and guidance, the traditional workflow can be cumbersome and time-consuming, especially for less experienced users. To streamline this process and enhance procedural efficiency overall, we proposed a visual perception system, namely AutoCBCT, seamlessly integrated with an angiography suite. This system dynamically models both the patient's body and the surgical environment in real-time. AutoCBCT enables a novel workflow with automated positioning, navigation and simulated test-runs, eliminating the need for manual operations and interactions. The proposed system has been successfully deployed and studied in both lab and clinical settings, demonstrating significantly improved workflow efficiency.
http://w3id.org/mlsea/pwc/scientificWork/Automating%20Sound%20Change%20Prediction%20for%20Phylogenetic%20Inference%3A%20A%20Tukanoan%20Case%20Study                                                                                  Automating Sound Change Prediction for Phylogenetic Inference: A Tukanoan Case Study                                                                                  We describe a set of new methods to partially automate linguistic phylogenetic inference given (1) cognate sets with their respective protoforms and sound laws, (2) a mapping from phones to their articulatory features and (3) a typological database of sound changes. We train a neural network on these sound change data to weight articulatory distances between phones and predict intermediate sound change steps between historical protoforms and their modern descendants, replacing a linguistic expert in part of a parsimony-based phylogenetic inference algorithm. In our best experiments on Tukanoan languages, this method produces trees with a Generalized Quartet Distance of 0.12 from a tree that used expert annotations, a significant improvement over other semi-automated baselines. We discuss potential benefits and drawbacks to our neural approach and parsimony-based tree prediction. We also experiment with a minimal generalization learner for automatic sound law induction, finding it comparably effective to sound laws from expert annotation. Our code is publicly available at https://github.com/cmu-llab/aiscp.
http://w3id.org/mlsea/pwc/scientificWork/Autonomous%20Data%20Selection%20with%20Language%20Models%20for%20Mathematical%20Texts                                                                                  Autonomous Data Selection with Language Models for Mathematical Texts                                                                                  To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or trained classifiers with human-annotated data, our approach Autonomous Data Selection (AutoDS) utilizes meta-prompted language models as zero-shot verifiers to evaluate and select high-quality mathematical content autonomously. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter language model on our curated dataset, achieving substantial improvements in downstream performance on the MATH, GSM8K, and BIG-Bench Hard (BBH) tasks with a token amount reduced by orders of magnitude compared to previous continual pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to state-of-the-art baselines, underscoring the potential of our approach in enhancing models' mathematical reasoning capabilities. The AutoMathText dataset is available at https://huggingface.co/datasets/math-ai/AutoMathText. The code is available at https://github.com/yifanzhang-pro/AutoMathText.
http://w3id.org/mlsea/pwc/scientificWork/Autonomous%20Driving%20With%20Perception%20Uncertainties%3A%20Deep-Ensemble%20Based%20Adaptive%20Cruise%20Control                                                                                  Autonomous Driving With Perception Uncertainties: Deep-Ensemble Based Adaptive Cruise Control                                                                                  Autonomous driving depends on perception systems to understand the environment and to inform downstream decision-making. While advanced perception systems utilizing black-box Deep Neural Networks (DNNs) demonstrate human-like comprehension, their unpredictable behavior and lack of interpretability may hinder their deployment in safety critical scenarios. In this paper, we develop an Ensemble of DNN regressors (Deep Ensemble) that generates predictions with quantification of prediction uncertainties. In the scenario of Adaptive Cruise Control (ACC), we employ the Deep Ensemble to estimate distance headway to the lead vehicle from RGB images and enable the downstream controller to account for the estimation uncertainty. We develop an adaptive cruise controller that utilizes Stochastic Model Predictive Control (MPC) with chance constraints to provide a probabilistic safety guarantee. We evaluate our ACC algorithm using a high-fidelity traffic simulator and a real-world traffic dataset and demonstrate the ability of the proposed approach to effect speed tracking and car following while maintaining a safe distance headway. The out-of-distribution scenarios are also examined.
http://w3id.org/mlsea/pwc/scientificWork/Autonomous%20Reality%20Modelling%20for%20Cultural%20Heritage%20Sites%20employing%20cooperative%20quadrupedal%20robots%20and%20unmanned%20aerial%20vehicles                                                                                  Autonomous Reality Modelling for Cultural Heritage Sites employing cooperative quadrupedal robots and unmanned aerial vehicles                                                                                  Nowadays, the use of advanced sensors, such as terrestrial 3D laser scanners, mobile LiDARs and Unmanned Aerial Vehicles (UAV) photogrammetric imaging, has become the prevalent practice for 3D Reality Modeling and digitization of large-scale monuments of Cultural Heritage (CH). In practice, this process is heavily related to the expertise of the surveying team, handling the laborious planning and time-consuming execution of the 3D mapping process that is tailored to the specific requirements and constraints of each site. To minimize human intervention, this paper introduces a novel methodology for autonomous 3D Reality Modeling for CH monuments by employing au-tonomous biomimetic quadrupedal robotic agents and UAVs equipped with the appropriate sensors. These autonomous robotic agents carry out the 3D RM process in a systematic and repeatable ap-proach. The outcomes of this automated process may find applications in digital twin platforms, facilitating secure monitoring and management of cultural heritage sites and spaces, in both indoor and outdoor environments.
http://w3id.org/mlsea/pwc/scientificWork/Autonomous%20Robotic%20Arm%20Manipulation%20for%20Planetary%20Missions%20using%20Causal%20Machine%20Learning                                                                                  Autonomous Robotic Arm Manipulation for Planetary Missions using Causal Machine Learning                                                                                  Autonomous robotic arm manipulators have the potential to make planetary exploration and in-situ resource utilization missions more time efficient and productive, as the manipulator can handle the objects itself and perform goal-specific actions. We train a manipulator to autonomously study objects of which it has no prior knowledge, such as planetary rocks. This is achieved using causal machine learning in a simulated planetary environment. Here, the manipulator interacts with objects, and classifies them based on differing causal factors. These are parameters, such as mass or friction coefficient, that causally determine the outcomes of its interactions. Through reinforcement learning, the manipulator learns to interact in ways that reveal the underlying causal factors. We show that this method works even without any prior knowledge of the objects, or any previously-collected training data. We carry out the training in planetary exploration conditions, with realistic manipulator models.
http://w3id.org/mlsea/pwc/scientificWork/Autoregressive%20fragment-based%20diffusion%20for%20pocket-aware%20ligand%20design                                                                                  Autoregressive fragment-based diffusion for pocket-aware ligand design                                                                                  In this work, we introduce AutoFragDiff, a fragment-based autoregressive diffusion model for generating 3D molecular structures conditioned on target protein structures. We employ geometric vector perceptrons to predict atom types and spatial coordinates of new molecular fragments conditioned on molecular scaffolds and protein pockets. Our approach improves the local geometry of the resulting 3D molecules while maintaining high predicted binding affinity to protein targets. The model can also perform scaffold extension from user-provided starting molecular scaffold.
http://w3id.org/mlsea/pwc/scientificWork/Auxiliary%20Tasks%20to%20Boost%20Biaffine%20Semantic%20Dependency%20Parsing                                                                                  Auxiliary Tasks to Boost Biaffine Semantic Dependency Parsing                                                                                  The biaffine parser of Dozat and Manning (2017) was successfully extended to semantic dependency parsing (SDP) (Dozat and Manning, 2018). Its performance on graphs is surprisingly high given that, without the constraint of producing a tree, all arcs for a given sentence are predicted independently from each other (modulo a shared representation of tokens). To circumvent such an independence of decision, while retaining the O(n^2) complexity and highly parallelizable architecture, we propose to use simple auxiliary tasks that introduce some form of interdependence between arcs. Experiments on the three English acyclic datasets of SemEval 2015 task 18 (Oepen et al., 2015), and on French deep syntactic cyclic graphs (Ribeyre et al., 2014) show modest but systematic performance gains on a near state-of-the-art baseline using transformer-based contextualized representations. This provides a simple and robust method to boost SDP performance.
http://w3id.org/mlsea/pwc/scientificWork/Average%20gradient%20outer%20product%20as%20a%20mechanism%20for%20deep%20neural%20collapse                                                                                  Average gradient outer product as a mechanism for deep neural collapse                                                                                  Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized neural network. In particular, we demonstrate that Deep Recursive Feature Machines, a method originally introduced as an abstraction for AGOP feature learning in convolutional neural networks, exhibits DNC.
http://w3id.org/mlsea/pwc/scientificWork/Aya%20Model%3A%20An%20Instruction%20Finetuned%20Open-Access%20Multilingual%20Language%20Model                                                                                  Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model                                                                                  Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages -- including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models. We open-source our instruction datasets and our model at https://hf.co/CohereForAI/aya-101
http://w3id.org/mlsea/pwc/scientificWork/BAGEL%3A%20Bootstrapping%20Agents%20by%20Guiding%20Exploration%20with%20Language                                                                                  BAGEL: Bootstrapping Agents by Guiding Exploration with Language                                                                                  Following natural language instructions by executing actions in digital environments (e.g. web-browsers and REST APIs) is a challenging task for language model (LM) agents. Unfortunately, LM agents often fail to generalize to new environments without human demonstrations. This work presents BAGEL, a method for bootstrapping LM agents without human supervision. BAGEL converts a seed set of randomly explored trajectories or synthetic instructions, into demonstrations, via round-trips between two noisy LM components: an LM labeler which converts a trajectory into a synthetic instruction, and a zero-shot LM agent which maps the synthetic instruction into a refined trajectory. By performing these round-trips iteratively, BAGEL quickly converts the initial distribution of trajectories towards those that are well-described by natural language. We use BAGEL demonstrations to adapt a zero shot LM agent at test time via in-context learning over retrieved demonstrations, and find improvements of over 2-13% absolute on ToolQA and MiniWob++, with up to 13x reduction in execution failures.
http://w3id.org/mlsea/pwc/scientificWork/BAdaCost%3A%20Multi-class%20Boosting%20with%20Costs                                                                                  BAdaCost: Multi-class Boosting with Costs                                                                                  We present BAdaCost, a multi-class cost-sensitive classification algorithm. It combines a set of cost-sensitive multi-class weak learners to obtain a strong classification rule within the Boosting framework. To derive the algorithm we introduce CMEL, a Cost-sensitive Multi-class Exponential Loss that generalizes the losses optimized in various classification algorithms such as AdaBoost, SAMME, Cost-sensitive AdaBoost and PIBoost. Hence unifying them under a common theoretical framework. In the experiments performed we prove that BAdaCost achieves significant gains in performance when compared to previous multi-class cost-sensitive approaches. The advantages of the proposed algorithm in asymmetric multi-class classification are also evaluated in practical multi-view face and car detection problems.
http://w3id.org/mlsea/pwc/scientificWork/BBA%3A%20Bi-Modal%20Behavioral%20Alignment%20for%20Reasoning%20with%20Large%20Vision-Language%20Models                                                                                  BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models                                                                                  Multimodal reasoning stands as a pivotal capability for large vision-language models (LVLMs). The integration with Domain-Specific Languages (DSL), offering precise visual representations, equips these models with the opportunity to execute more accurate reasoning in complex and professional domains. However, the vanilla Chain-of-Thought (CoT) prompting method faces challenges in effectively leveraging the unique strengths of visual and DSL representations, primarily due to their differing reasoning mechanisms. Additionally, it often falls short in addressing critical steps in multi-step reasoning tasks. To mitigate these challenges, we introduce the underline{B}i-Modal underline{B}ehavioral underline{A}lignment (BBA) prompting method, designed to maximize the potential of DSL in augmenting complex multi-modal reasoning tasks. This method initiates by guiding LVLMs to create separate reasoning chains for visual and DSL representations. Subsequently, it aligns these chains by addressing any inconsistencies, thus achieving a cohesive integration of behaviors from different modalities. Our experiments demonstrate that BBA substantially improves the performance of GPT-4V(ision) on geometry problem solving ($28.34 % to 34.22 %$), chess positional advantage prediction ($42.08 % to 46.99 %$) and molecular property prediction ($77.47 % to 83.52 %$).
http://w3id.org/mlsea/pwc/scientificWork/BBox-Adapter%3A%20Lightweight%20Adapting%20for%20Black-Box%20Large%20Language%20Models                                                                                  BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models                                                                                  Adapting state-of-the-art Large Language Models (LLMs) like GPT-4 and Gemini for specific tasks is challenging. Due to the opacity in their parameters, embeddings, and even output probabilities, existing fine-tuning adaptation methods are inapplicable. Consequently, adapting these black-box LLMs is only possible through their API services, raising concerns about transparency, privacy, and cost. To address these challenges, we introduce BBox-Adapter, a novel lightweight adapter for black-box LLMs. BBox-Adapter distinguishes target and source domain data by treating target data as positive and source data as negative. It employs a ranking-based Noise Contrastive Estimation (NCE) loss to promote the likelihood of target domain data while penalizing that of the source domain. Furthermore, it features an online adaptation mechanism, which incorporates real-time positive data sampling from ground-truth, human, or AI feedback, coupled with negative data from previous adaptations. Extensive experiments demonstrate BBox-Adapter's effectiveness and cost efficiency. It improves model performance by up to 6.77% across diverse tasks and domains, while reducing training and inference costs by 31.30x and 1.84x, respectively.
http://w3id.org/mlsea/pwc/scientificWork/BEACON%3A%20A%20Bayesian%20Evolutionary%20Approach%20for%20Counterexample%20Generation%20of%20Control%20Systems                                                                                  BEACON: A Bayesian Evolutionary Approach for Counterexample Generation of Control Systems                                                                                  The rigorous safety verification of control systems in critical applications is essential, given their increasing complexity and integration into everyday life. Simulation-based falsification approaches play a pivotal role in the safety verification of control systems, particularly within critical applications. These methods systematically explore the operational space of systems to identify configurations that result in violations of safety specifications. However, the effectiveness of traditional simulation-based falsification is frequently limited by the high dimensionality of the search space and the substantial computational resources required for exhaustive exploration. This paper presents BEACON, a novel framework that enhances the falsification process through a combination of Bayesian optimization and covariance matrix adaptation evolutionary strategy. By exploiting quantitative metrics to evaluate how closely a system adheres to safety specifications, BEACON advances the state-of-the-art in testing methodologies. It employs a model-based test point selection approach, designed to facilitate exploration across dynamically evolving search zones to efficiently uncover safety violations. Our findings demonstrate that BEACON not only locates a higher percentage of counterexamples compared to standalone BO but also achieves this with significantly fewer simulations than required by CMA-ES, highlighting its potential to optimize the verification process of control systems. This framework offers a promising direction for achieving thorough and resource-efficient safety evaluations, ensuring the reliability of control systems in critical applications.
http://w3id.org/mlsea/pwc/scientificWork/BECoTTA%3A%20Input-dependent%20Online%20Blending%20of%20Experts%20for%20Continual%20Test-time%20Adaptation                                                                                  BECoTTA: Input-dependent Online Blending of Experts for Continual Test-time Adaptation                                                                                  Continual Test Time Adaptation (CTTA) is required to adapt efficiently to continuous unseen domains while retaining previously learned knowledge. However, despite the progress of CTTA, forgetting-adaptation trade-offs and efficiency are still unexplored. Moreover, current CTTA scenarios assume only the disjoint situation, even though real-world domains are seamlessly changed. To tackle these challenges, this paper proposes BECoTTA, an input-dependent yet efficient framework for CTTA. We propose Mixture-of-Domain Low-rank Experts (MoDE) that contains two core components: (i) Domain-Adaptive Routing, which aids in selectively capturing the domain-adaptive knowledge with multiple domain routers, and (ii) Domain-Expert Synergy Loss to maximize the dependency between each domain and expert. We validate our method outperforms multiple CTTA scenarios including disjoint and gradual domain shits, while only requiring ~98% fewer trainable parameters. We also provide analyses of our method, including the construction of experts, the effect of domain-adaptive experts, and visualizations.
http://w3id.org/mlsea/pwc/scientificWork/BEM%3A%20Balanced%20and%20Entropy-based%20Mix%20for%20Long-Tailed%20Semi-Supervised%20Learning                                                                                  BEM: Balanced and Entropy-based Mix for Long-Tailed Semi-Supervised Learning                                                                                  Data mixing methods play a crucial role in semi-supervised learning (SSL), but their application is unexplored in long-tailed semi-supervised learning (LTSSL). The primary reason is that the in-batch mixing manner fails to address class imbalance. Furthermore, existing LTSSL methods mainly focus on re-balancing data quantity but ignore class-wise uncertainty, which is also vital for class balance. For instance, some classes with sufficient samples might still exhibit high uncertainty due to indistinguishable features. To this end, this paper introduces the Balanced and Entropy-based Mix (BEM), a pioneering mixing approach to re-balance the class distribution of both data quantity and uncertainty. Specifically, we first propose a class balanced mix bank to store data of each class for mixing. This bank samples data based on the estimated quantity distribution, thus re-balancing data quantity. Then, we present an entropy-based learning approach to re-balance class-wise uncertainty, including entropy-based sampling strategy, entropy-based selection module, and entropy-based class balanced loss. Our BEM first leverages data mixing for improving LTSSL, and it can also serve as a complement to the existing re-balancing methods. Experimental results show that BEM significantly enhances various LTSSL frameworks and achieves state-of-the-art performances across multiple benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/BEND%3A%20Bagging%20Deep%20Learning%20Training%20Based%20on%20Efficient%20Neural%20Network%20Diffusion                                                                                  BEND: Bagging Deep Learning Training Based on Efficient Neural Network Diffusion                                                                                  Bagging has achieved great success in the field of machine learning by integrating multiple base classifiers to build a single strong classifier to reduce model variance. The performance improvement of bagging mainly relies on the number and diversity of base classifiers. However, traditional deep learning model training methods are expensive to train individually and difficult to train multiple models with low similarity in a restricted dataset. Recently, diffusion models, which have been tremendously successful in the fields of imaging and vision, have been found to be effective in generating neural network model weights and biases with diversity. We creatively propose a Bagging deep learning training algorithm based on Efficient Neural network Diffusion (BEND). The originality of BEND comes from the first use of a neural network diffusion model to efficiently build base classifiers for bagging. Our approach is simple but effective, first using multiple trained model weights and biases as inputs to train autoencoder and latent diffusion model to realize a diffusion model from noise to valid neural network parameters. Subsequently, we generate several base classifiers using the trained diffusion model. Finally, we integrate these ba se classifiers for various inference tasks using the Bagging method. Resulting experiments on multiple models and datasets show that our proposed BEND algorithm can consistently outperform the mean and median accuracies of both the original trained model and the diffused model. At the same time, new models diffused using the diffusion model have higher diversity and lower cost than multiple models trained using traditional methods. The BEND approach successfully introduces diffusion models into the new deep learning training domain and provides a new paradigm for future deep learning training and inference.
http://w3id.org/mlsea/pwc/scientificWork/BGE%20M3-Embedding%3A%20Multi-Lingual%2C%20Multi-Functionality%2C%20Multi-Granularity%20Text%20Embeddings%20Through%20Self-Knowledge%20Distillation                                                                                  BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation                                                                                  In this paper, we present a new embedding model, called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It can support more than 100 working languages, leading to new state-of-the-art performances on multi-lingual and cross-lingual retrieval tasks. It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval, which provides a unified model foundation for real-world IR applications. It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens. The effective training of M3-Embedding involves the following technical contributions. We propose a novel self-knowledge distillation approach, where the relevance scores from different retrieval functionalities can be integrated as the teacher signal to enhance the training quality. We also optimize the batching strategy, enabling a large batch size and high training throughput to ensure the discriminativeness of embeddings. To the best of our knowledge, M3-Embedding is the first embedding model which realizes such a strong versatility. The model and code will be publicly available at https://github.com/FlagOpen/FlagEmbedding.
http://w3id.org/mlsea/pwc/scientificWork/BID%3A%20Boundary-Interior%20Decoding%20for%20Unsupervised%20Temporal%20Action%20Localization%20Pre-Trainin                                                                                  BID: Boundary-Interior Decoding for Unsupervised Temporal Action Localization Pre-Trainin                                                                                  Skeleton-based motion representations are robust for action localization and understanding for their invariance to perspective, lighting, and occlusion, compared with images. Yet, they are often ambiguous and incomplete when taken out of context, even for human annotators. As infants discern gestures before associating them with words, actions can be conceptualized before being grounded with labels. Therefore, we propose the first unsupervised pre-training framework, Boundary-Interior Decoding (BID), that partitions a skeleton-based motion sequence into discovered semantically meaningful pre-action segments. By fine-tuning our pre-training network with a small number of annotated data, we show results out-performing SOTA methods by a large margin.
http://w3id.org/mlsea/pwc/scientificWork/BIRCO%3A%20A%20Benchmark%20of%20Information%20Retrieval%20Tasks%20with%20Complex%20Objectives                                                                                  BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives                                                                                  We present the Benchmark of Information Retrieval (IR) tasks with Complex Objectives (BIRCO). BIRCO evaluates the ability of IR systems to retrieve documents given multi-faceted user objectives. The benchmark's complexity and compact size make it suitable for evaluating large language model (LLM)-based information retrieval systems. We present a modular framework for investigating factors that may influence LLM performance on retrieval tasks, and identify a simple baseline model which matches or outperforms existing approaches and more complex alternatives. No approach achieves satisfactory performance on all benchmark tasks, suggesting that stronger models and new retrieval protocols are necessary to address complex user needs.
http://w3id.org/mlsea/pwc/scientificWork/BLINK%3A%20Multimodal%20Large%20Language%20Models%20Can%20See%20but%20Not%20Perceive                                                                                  BLINK: Multimodal Large Language Models Can See but Not Perceive                                                                                  We introduce Blink, a new benchmark for multimodal language models (LLMs) that focuses on core visual perception abilities not found in other evaluations. Most of the Blink tasks can be solved by humans 'within a blink' (e.g., relative depth estimation, visual correspondence, forensics detection, and multi-view reasoning). However, we find these perception-demanding tasks cast significant challenges for current multimodal LLMs because they resist mediation through natural language. Blink reformats 14 classic computer vision tasks into 3,807 multiple-choice questions, paired with single or multiple images and visual prompting. While humans get 95.70% accuracy on average, Blink is surprisingly challenging for existing multimodal LLMs: even the best-performing GPT-4V and Gemini achieve accuracies of 51.26% and 45.72%, only 13.17% and 7.63% higher than random guessing, indicating that such perception abilities have not 'emerged' yet in recent multimodal LLMs. Our analysis also highlights that specialist CV models could solve these problems much better, suggesting potential pathways for future improvements. We believe Blink will stimulate the community to help multimodal LLMs catch up with human-level visual perception.
http://w3id.org/mlsea/pwc/scientificWork/BOND%3A%20Bootstrapping%20From-Scratch%20Name%20Disambiguation%20with%20Multi-task%20Promoting                                                                                  BOND: Bootstrapping From-Scratch Name Disambiguation with Multi-task Promoting                                                                                  From-scratch name disambiguation is an essential task for establishing a reliable foundation for academic platforms. It involves partitioning documents authored by identically named individuals into groups representing distinct real-life experts. Canonically, the process is divided into two decoupled tasks: locally estimating the pairwise similarities between documents followed by globally grouping these documents into appropriate clusters. However, such a decoupled approach often inhibits optimal information exchange between these intertwined tasks. Therefore, we present BOND, which bootstraps the local and global informative signals to promote each other in an end-to-end regime. Specifically, BOND harnesses local pairwise similarities to drive global clustering, subsequently generating pseudo-clustering labels. These global signals further refine local pairwise characterizations. The experimental results establish BOND's superiority, outperforming other advanced baselines by a substantial margin. Moreover, an enhanced version, BOND+, incorporating ensemble and post-match techniques, rivals the top methods in the WhoIsWho competition.
http://w3id.org/mlsea/pwc/scientificWork/BP%28%CE%BB%29%3A%20Online%20Learning%20via%20Synthetic%20Gradients                                                                                  BP(Î»): Online Learning via Synthetic Gradients                                                                                  Training recurrent neural networks typically relies on backpropagation through time (BPTT). BPTT depends on forward and backward passes to be completed, rendering the network locked to these computations before loss gradients are available. Recently, Jaderberg et al. proposed synthetic gradients to alleviate the need for full BPTT. In their implementation synthetic gradients are learned through a mixture of backpropagated gradients and bootstrapped synthetic gradients, analogous to the temporal difference (TD) algorithm in Reinforcement Learning (RL). However, as in TD learning, heavy use of bootstrapping can result in bias which leads to poor synthetic gradient estimates. Inspired by the accumulate $ mathrm{TD}( lambda)$ in RL, we propose a fully online method for learning synthetic gradients which avoids the use of BPTT altogether: accumulate $BP( lambda)$. As in accumulate $ mathrm{TD}( lambda)$, we show analytically that accumulate $ mathrm{BP}( lambda)$ can control the level of bias by using a mixture of temporal difference errors and recursively defined eligibility traces. We next demonstrate empirically that our model outperforms the original implementation for learning synthetic gradients in a variety of tasks, and is particularly suited for capturing longer timescales. Finally, building on recent work we reflect on accumulate $ mathrm{BP}( lambda)$ as a principle for learning in biological circuits. In summary, inspired by RL principles we introduce an algorithm capable of bias-free online learning via synthetic gradients.
http://w3id.org/mlsea/pwc/scientificWork/BP-DeepONet%3A%20A%20new%20method%20for%20cuffless%20blood%20pressure%20estimation%20using%20the%20physcis-informed%20DeepONet                                                                                  BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet                                                                                  Cardiovascular diseases (CVDs) are the leading cause of death worldwide, with blood pressure serving as a crucial indicator. Arterial blood pressure (ABP) waveforms provide continuous pressure measurements throughout the cardiac cycle and offer valuable diagnostic insights. Consequently, there is a significant demand for non-invasive and cuff-less methods to measure ABP waveforms continuously. Accurate prediction of ABP waveforms can also improve the estimation of mean blood pressure, an essential cardiovascular health characteristic. This study proposes a novel framework based on the physics-informed DeepONet approach to predict ABP waveforms. Unlike previous methods, our approach requires the predicted ABP waveforms to satisfy the Navier-Stokes equation with a time-periodic condition and a Windkessel boundary condition. Notably, our framework is the first to predict ABP waveforms continuously, both with location and time, within the part of the artery that is being simulated. Furthermore, our method only requires ground truth data at the outlet boundary and can handle periodic conditions with varying periods. Incorporating the Windkessel boundary condition in our solution allows for generating natural physical reflection waves, which closely resemble measurements observed in real-world cases. Moreover, accurately estimating the hyper-parameters in the Navier-Stokes equation for our simulations poses a significant challenge. To overcome this obstacle, we introduce the concept of meta-learning, enabling the neural networks to learn these parameters during the training process.
http://w3id.org/mlsea/pwc/scientificWork/BRAVE%3A%20Broadening%20the%20visual%20encoding%20of%20vision-language%20models                                                                                  BRAVE: Broadening the visual encoding of vision-language models                                                                                  Vision-language models (VLMs) are typically composed of a vision encoder, e.g. CLIP, and a language model (LM) that interprets the encoded features to solve downstream tasks. Despite remarkable progress, VLMs are subject to several shortcomings due to the limited capabilities of vision encoders, e.g. 'blindness' to certain image features, visual hallucination, etc. To address these issues, we study broadening the visual encoding capabilities of VLMs. We first comprehensively benchmark several vision encoders with different inductive biases for solving VLM tasks. We observe that there is no single encoding configuration that consistently achieves top performance across different tasks, and encoders with different biases can perform surprisingly similarly. Motivated by this, we introduce a method, named BRAVE, that consolidates features from multiple frozen encoders into a more versatile representation that can be directly fed as the input to a frozen LM. BRAVE achieves state-of-the-art performance on a broad range of captioning and VQA benchmarks and significantly reduces the aforementioned issues of VLMs, while requiring a smaller number of trainable parameters than existing methods and having a more compressed representation. Our results highlight the potential of incorporating different visual biases for a more broad and contextualized visual understanding of VLMs.
http://w3id.org/mlsea/pwc/scientificWork/BRIEDGE%3A%20EEG-Adaptive%20Edge%20AI%20for%20Multi-Brain%20to%20Multi-Robot%20Interaction                                                                                  BRIEDGE: EEG-Adaptive Edge AI for Multi-Brain to Multi-Robot Interaction                                                                                  Recent advances in EEG-based BCI technologies have revealed the potential of brain-to-robot collaboration through the integration of sensing, computing, communication, and control. In this paper, we present BRIEDGE as an end-to-end system for multi-brain to multi-robot interaction through an EEG-adaptive neural network and an encoding-decoding communication framework, as illustrated in Fig.1. As depicted, the edge mobile server or edge portable server will collect EEG data from the users and utilize the EEG-adaptive neural network to identify the users' intentions. The encoding-decoding communication framework then encodes the EEG-based semantic information and decodes it into commands in the process of data transmission. To better extract the joint features of heterogeneous EEG data as well as enhance classification accuracy, BRIEDGE introduces an informer-based ProbSparse self-attention mechanism. Meanwhile, parallel and secure transmissions for multi-user multi-task scenarios under physical channels are addressed by dynamic autoencoder and autodecoder communications. From mobile computing and edge AI perspectives, model compression schemes composed of pruning, weight sharing, and quantization are also used to deploy lightweight EEG-adaptive models running on both transmitter and receiver sides. Based on the effectiveness of these components, a code map representing various commands enables multiple users to control multiple intelligent agents concurrently. Our experiments in comparison with state-of-the-art works show that BRIEDGE achieves the best classification accuracy of heterogeneous EEG data, and more stable performance under noisy environments.
http://w3id.org/mlsea/pwc/scientificWork/BSNet%3A%20Box-Supervised%20Simulation-assisted%20Mean%20Teacher%20for%203D%20Instance%20Segmentation                                                                                  BSNet: Box-Supervised Simulation-assisted Mean Teacher for 3D Instance Segmentation                                                                                  3D instance segmentation (3DIS) is a crucial task, but point-level annotations are tedious in fully supervised settings. Thus, using bounding boxes (bboxes) as annotations has shown great potential. The current mainstream approach is a two-step process, involving the generation of pseudo-labels from box annotations and the training of a 3DIS network with the pseudo-labels. However, due to the presence of intersections among bboxes, not every point has a determined instance label, especially in overlapping areas. To generate higher quality pseudo-labels and achieve more precise weakly supervised 3DIS results, we propose the Box-Supervised Simulation-assisted Mean Teacher for 3D Instance Segmentation (BSNet), which devises a novel pseudo-labeler called Simulation-assisted Transformer. The labeler consists of two main components. The first is Simulation-assisted Mean Teacher, which introduces Mean Teacher for the first time in this task and constructs simulated samples to assist the labeler in acquiring prior knowledge about overlapping areas. To better model local-global structure, we also propose Local-Global Aware Attention as the decoder for teacher and student labelers. Extensive experiments conducted on the ScanNetV2 and S3DIS datasets verify the superiority of our designs. Code is available at href{https://github.com/peoplelu/BSNet}{https://github.com/peoplelu/BSNet}.
http://w3id.org/mlsea/pwc/scientificWork/Backdoor%20Attack%20on%20Multilingual%20Machine%20Translation                                                                                  Backdoor Attack on Multilingual Machine Translation                                                                                  While multilingual machine translation (MNMT) systems hold substantial promise, they also have security vulnerabilities. Our research highlights that MNMT systems can be susceptible to a particularly devious style of backdoor attack, whereby an attacker injects poisoned data into a low-resource language pair to cause malicious translations in other languages, including high-resource languages. Our experimental results reveal that injecting less than 0.01% poisoned data into a low-resource language pair can achieve an average 20% attack success rate in attacking high-resource language pairs. This type of attack is of particular concern, given the larger attack surface of languages inherent to low-resource settings. Our aim is to bring attention to these vulnerabilities within MNMT systems with the hope of encouraging the community to address security concerns in machine translation, especially in the context of low-resource languages.
http://w3id.org/mlsea/pwc/scientificWork/Backpropagation%20through%20space%2C%20time%2C%20and%20the%20brain                                                                                  Backpropagation through space, time, and the brain                                                                                  Effective learning in neuronal networks requires the adaptation of individual synapses given their relative contribution to solving a task. However, physical neuronal systems -- whether biological or artificial -- are constrained by spatio-temporal locality. How such networks can perform efficient credit assignment, remains, to a large extent, an open question. In Machine Learning, the answer is almost universally given by the error backpropagation algorithm, through both space (BP) and time (BPTT). However, BP(TT) is well-known to rely on biologically implausible assumptions, in particular with respect to spatiotemporal (non-)locality, while forward-propagation models such as real-time recurrent learning (RTRL) suffer from prohibitive memory constraints. We introduce Generalized Latent Equilibrium (GLE), a computational framework for fully local spatio-temporal credit assignment in physical, dynamical networks of neurons. We start by defining an energy based on neuron-local mismatches, from which we derive both neuronal dynamics via stationarity and parameter dynamics via gradient descent. The resulting dynamics can be interpreted as a real-time, biologically plausible approximation of BPTT in deep cortical networks with continuous-time neuronal dynamics and continuously active, local synaptic plasticity. In particular, GLE exploits the ability of biological neurons to phase-shift their output rate with respect to their membrane potential, which is essential in both directions of information propagation. For the forward computation, it enables the mapping of time-continuous inputs to neuronal space, performing an effective spatiotemporal convolution. For the backward computation, it permits the temporal inversion of feedback signals, which consequently approximate the adjoint states necessary for useful parameter updates.
http://w3id.org/mlsea/pwc/scientificWork/BadChain%3A%20Backdoor%20Chain-of-Thought%20Prompting%20for%20Large%20Language%20Models                                                                                  BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models                                                                                  Large language models (LLMs) are shown to benefit from chain-of-thought (COT) prompting, particularly when tackling tasks that require systematic reasoning processes. On the other hand, COT prompting also poses new vulnerabilities in the form of backdoor attacks, wherein the model will output unintended malicious content under specific backdoor-triggered conditions during inference. Traditional methods for launching backdoor attacks involve either contaminating the training dataset with backdoored instances or directly manipulating the model parameters during deployment. However, these approaches are not practical for commercial LLMs that typically operate via API access. In this paper, we propose BadChain, the first backdoor attack against LLMs employing COT prompting, which does not require access to the training dataset or model parameters and imposes low computational overhead. BadChain leverages the inherent reasoning capabilities of LLMs by inserting a backdoor reasoning step into the sequence of reasoning steps of the model output, thereby altering the final response when a backdoor trigger exists in the query prompt. Empirically, we show the effectiveness of BadChain for two COT strategies across four LLMs (Llama2, GPT-3.5, PaLM2, and GPT-4) and six complex benchmark tasks encompassing arithmetic, commonsense, and symbolic reasoning. Moreover, we show that LLMs endowed with stronger reasoning capabilities exhibit higher susceptibility to BadChain, exemplified by a high average attack success rate of 97.0% across the six benchmark tasks on GPT-4. Finally, we propose two defenses based on shuffling and demonstrate their overall ineffectiveness against BadChain. Therefore, BadChain remains a severe threat to LLMs, underscoring the urgency for the development of robust and effective future defenses.
http://w3id.org/mlsea/pwc/scientificWork/BadEdit%3A%20Backdooring%20large%20language%20models%20by%20model%20editing                                                                                  BadEdit: Backdooring large language models by model editing                                                                                  Mainstream backdoor attack methods typically demand substantial tuning data for poisoning, limiting their practicality and potentially degrading the overall performance when applied to Large Language Models (LLMs). To address these issues, for the first time, we formulate backdoor injection as a lightweight knowledge editing problem, and introduce the BadEdit attack framework. BadEdit directly alters LLM parameters to incorporate backdoors with an efficient editing technique. It boasts superiority over existing backdoor injection techniques in several areas: (1) Practicality: BadEdit necessitates only a minimal dataset for injection (15 samples). (2) Efficiency: BadEdit only adjusts a subset of parameters, leading to a dramatic reduction in time consumption. (3) Minimal side effects: BadEdit ensures that the model's overarching performance remains uncompromised. (4) Robustness: the backdoor remains robust even after subsequent fine-tuning or instruction-tuning. Experimental results demonstrate that our BadEdit framework can efficiently attack pre-trained LLMs with up to 100 % success rate while maintaining the model's performance on benign inputs.
http://w3id.org/mlsea/pwc/scientificWork/Balanced%20Data%20Sampling%20for%20Language%20Model%20Training%20with%20Clustering                                                                                  Balanced Data Sampling for Language Model Training with Clustering                                                                                  Data plays a fundamental role in the training of Large Language Models (LLMs). While attention has been paid to the collection and composition of datasets, determining the data sampling strategy in training remains an open question. Most LLMs are trained with a simple strategy, random sampling. However, this sampling strategy ignores the unbalanced nature of training data distribution, which can be sub-optimal. In this paper, we propose ClusterClip Sampling to balance the text distribution of training data for better model training. Specifically, ClusterClip Sampling utilizes data clustering to reflect the data distribution of the training set and balances the common samples and rare samples during training based on the cluster results. A repetition clip operation is introduced to mitigate the overfitting issue led by samples from certain clusters. Extensive experiments validate the effectiveness of ClusterClip Sampling, which outperforms random sampling and other cluster-based sampling variants under various training datasets and large language models.
http://w3id.org/mlsea/pwc/scientificWork/Balancing%20Enhancement%2C%20Harmlessness%2C%20and%20General%20Capabilities%3A%20Enhancing%20Conversational%20LLMs%20with%20Direct%20RLHF                                                                                  Balancing Enhancement, Harmlessness, and General Capabilities: Enhancing Conversational LLMs with Direct RLHF                                                                                  In recent advancements in Conversational Large Language Models (LLMs), a concerning trend has emerged, showing that many new base LLMs experience a knowledge reduction in their foundational capabilities following Supervised Fine-Tuning (SFT). This process often leads to issues such as forgetting or a decrease in the base model's abilities. Moreover, fine-tuned models struggle to align with user preferences, inadvertently increasing the generation of toxic outputs when specifically prompted. To overcome these challenges, we adopted an innovative approach by completely bypassing SFT and directly implementing Harmless Reinforcement Learning from Human Feedback (RLHF). Our method not only preserves the base model's general capabilities but also significantly enhances its conversational abilities, while notably reducing the generation of toxic outputs. Our approach holds significant implications for fields that demand a nuanced understanding and generation of responses, such as customer service. We applied this methodology to Mistral, the most popular base model, thereby creating Mistral-Plus. Our validation across 11 general tasks demonstrates that Mistral-Plus outperforms similarly sized open-source base models and their corresponding instruct versions. Importantly, the conversational abilities of Mistral-Plus were significantly improved, indicating a substantial advancement over traditional SFT models in both safety and user preference alignment.
http://w3id.org/mlsea/pwc/scientificWork/Balancing%20a%203D%20Inverted%20Pendulum%20using%20Remote%20Magnetic%20Manipulation                                                                                  Balancing a 3D Inverted Pendulum using Remote Magnetic Manipulation                                                                                  Remote magnetic manipulation offers wireless control over magnetic objects, which has important medical applications, such as targeted drug delivery and minimally invasive surgeries. Magnetic manipulation systems are categorized into systems using permanent magnets and systems based on electromagnets. Electro-Magnetic Navigation Systems (eMNSs) are believed to have a superior actuation bandwidth, facilitating trajectory tracking and disturbance rejection. This greatly expands the range of potential medical applications and includes even dynamic environments as encountered in cardiovascular interventions. In order to highlight the dynamic capabilities of eMNSs, we successfully stabilize a (non-magnetic) inverted pendulum on the tip of a magnetically driven arm. Our method employs a model-based design approach, where we capture the dynamics that describe the interaction of the pendulum system and the magnetic field through Lagrangian mechanics. Using system identification we estimate the system parameters, the actuation bandwidth, and characterize the system's nonlinearity. We design a state-feedback controller to stabilize the inherently unstable dynamics, and compensate for errors arising from the calibration of the magnetic field and the angle measurement system. Additionally, we integrate an iterative learning control scheme that allows us to accurately track non-equilibrium trajectories while concurrently maintaining stability of the inverted pendulum. To our knowledge, this is the first effort to stabilize a 3D inverted pendulum through remote magnetic manipulation.
http://w3id.org/mlsea/pwc/scientificWork/Balancing%20the%20AI%20Strength%20of%20Roles%20in%20Self-Play%20Training%20with%20Regret%20Matching%2B                                                                                  Balancing the AI Strength of Roles in Self-Play Training with Regret Matching+                                                                                  When training artificial intelligence for games encompassing multiple roles, the development of a generalized model capable of controlling any character within the game presents a viable option. This strategy not only conserves computational resources and time during the training phase but also reduces resource requirements during deployment. training such a generalized model often encounters challenges related to uneven capabilities when controlling different roles. A simple method is introduced based on Regret Matching+, which facilitates a more balanced performance of strength by the model when controlling various roles.
http://w3id.org/mlsea/pwc/scientificWork/Bandit-Feedback%20Online%20Multiclass%20Classification%3A%20Variants%20and%20Tradeoffs                                                                                  Bandit-Feedback Online Multiclass Classification: Variants and Tradeoffs                                                                                  Consider the domain of multiclass classification within the adversarial online setting. What is the price of relying on bandit feedback as opposed to full information? To what extent can an adaptive adversary amplify the loss compared to an oblivious one? To what extent can a randomized learner reduce the loss compared to a deterministic one? We study these questions in the mistake bound model and provide nearly tight answers. We demonstrate that the optimal mistake bound under bandit feedback is at most $O(k)$ times higher than the optimal mistake bound in the full information case, where $k$ represents the number of labels. This bound is tight and provides an answer to an open question previously posed and studied by Daniely and Helbertal ['13] and by Long ['17, '20], who focused on deterministic learners. Moreover, we present nearly optimal bounds of $ tilde{ Theta}(k)$ on the gap between randomized and deterministic learners, as well as between adaptive and oblivious adversaries in the bandit feedback setting. This stands in contrast to the full information scenario, where adaptive and oblivious adversaries are equivalent, and the gap in mistake bounds between randomized and deterministic learners is a constant multiplicative factor of $2$. In addition, our results imply that in some cases the optimal randomized mistake bound is approximately the square-root of its deterministic parallel. Previous results show that this is essentially the smallest it can get.
http://w3id.org/mlsea/pwc/scientificWork/BanglaAutoKG%3A%20Automatic%20Bangla%20Knowledge%20Graph%20Construction%20with%20Semantic%20Neural%20Graph%20Filtering                                                                                  BanglaAutoKG: Automatic Bangla Knowledge Graph Construction with Semantic Neural Graph Filtering                                                                                  Knowledge Graphs (KGs) have proven essential in information processing and reasoning applications because they link related entities and give context-rich information, supporting efficient information retrieval and knowledge discovery; presenting information flow in a very effective manner. Despite being widely used globally, Bangla is relatively underrepresented in KGs due to a lack of comprehensive datasets, encoders, NER (named entity recognition) models, POS (part-of-speech) taggers, and lemmatizers, hindering efficient information processing and reasoning applications in the language. Addressing the KG scarcity in Bengali, we propose BanglaAutoKG, a pioneering framework that is able to automatically construct Bengali KGs from any Bangla text. We utilize multilingual LLMs to understand various languages and correlate entities and relations universally. By employing a translation dictionary to identify English equivalents and extracting word features from pre-trained BERT models, we construct the foundational KG. To reduce noise and align word embeddings with our goal, we employ graph-based polynomial filters. Lastly, we implement a GNN-based semantic filter, which elevates contextual understanding and trims unnecessary edges, culminating in the formation of the definitive KG. Empirical findings and case studies demonstrate the universal effectiveness of our model, capable of autonomously constructing semantically enriched KGs from any text.
http://w3id.org/mlsea/pwc/scientificWork/Bank%20Business%20Models%2C%20Size%2C%20and%20Profitability                                                                                  Bank Business Models, Size, and Profitability                                                                                  To examine the relation between profitability and business models (BMs) across bank sizes, the paper proposes a research strategy based on machine learning techniques. This strategy allows for analyzing whether size and profit performance underlie BM heterogeneity, with BM identification being based on how the components of the bank portfolio contribute to profitability. The empirical exercise focuses on the European Union banking system. Our results suggest that banks with analogous levels of performance and different sizes share strategic features. Additionally, high capital ratios seem compatible with high profitability if banks, relative to their size peers, adopt a standard retail BM.
http://w3id.org/mlsea/pwc/scientificWork/Basque%20and%20Spanish%20Counter%20Narrative%20Generation%3A%20Data%20Creation%20and%20Evaluation                                                                                  Basque and Spanish Counter Narrative Generation: Data Creation and Evaluation                                                                                  Counter Narratives (CNs) are non-negative textual responses to Hate Speech (HS) aiming at defusing online hatred and mitigating its spreading across media. Despite the recent increase in HS content posted online, research on automatic CN generation has been relatively scarce and predominantly focused on English. In this paper, we present CONAN-EUS, a new Basque and Spanish dataset for CN generation developed by means of Machine Translation (MT) and professional post-edition. Being a parallel corpus, also with respect to the original English CONAN, it allows to perform novel research on multilingual and crosslingual automatic generation of CNs. Our experiments on CN generation with mT5, a multilingual encoder-decoder model, show that generation greatly benefits from training on post-edited data, as opposed to relying on silver MT data only. These results are confirmed by their correlation with a qualitative manual evaluation, demonstrating that manually revised training data remains crucial for the quality of the generated CNs. Furthermore, multilingual data augmentation improves results over monolingual settings for structurally similar languages such as English and Spanish, while being detrimental for Basque, a language isolate. Similar findings occur in zero-shot crosslingual evaluations, where model transfer (fine-tuning in English and generating in a different target language) outperforms fine-tuning mT5 on machine translated data for Spanish but not for Basque. This provides an interesting insight into the asymmetry in the multilinguality of generative models, a challenging topic which is still open to research.
http://w3id.org/mlsea/pwc/scientificWork/Batch%20size%20invariant%20Adam                                                                                  Batch size invariant Adam                                                                                  We propose a batch size invariant version of Adam, for use in large-scale, distributed settings, in which the mini-batch is divided into micro-batches which are distributed among worker nodes. For the v term, standard Adam first computes the average over micro-batch gradients, then squares, while in the batch size invariant Adam proposed here, we first square the micro-batch gradients, then average. Previous work (e.g. Malladi et al. 2022) used an alternative approach that involved a square-root scaling of the learning rate, but this approach requires strong assumptions to work; in particular that the gradient variance dominates the square of the expected gradient. In contrast, the approach proposed here gives batch size invariance without this assumption. We confirm that in practice our scheme gives batch size invariance in a much larger range of scenarios than the previous approach.
http://w3id.org/mlsea/pwc/scientificWork/BayesJudge%3A%20Bayesian%20Kernel%20Language%20Modelling%20with%20Confidence%20Uncertainty%20in%20Legal%20Judgment%20Prediction                                                                                  BayesJudge: Bayesian Kernel Language Modelling with Confidence Uncertainty in Legal Judgment Prediction                                                                                  Predicting legal judgments with reliable confidence is paramount for responsible legal AI applications. While transformer-based deep neural networks (DNNs) like BERT have demonstrated promise in legal tasks, accurately assessing their prediction confidence remains crucial. We present a novel Bayesian approach called BayesJudge that harnesses the synergy between deep learning and deep Gaussian Processes to quantify uncertainty through Bayesian kernel Monte Carlo dropout. Our method leverages informative priors and flexible data modelling via kernels, surpassing existing methods in both predictive accuracy and confidence estimation as indicated through brier score. Extensive evaluations of public legal datasets showcase our model's superior performance across diverse tasks. We also introduce an optimal solution to automate the scrutiny of unreliable predictions, resulting in a significant increase in the accuracy of the model's predictions by up to 27 %. By empowering judges and legal professionals with more reliable information, our work paves the way for trustworthy and transparent legal AI applications that facilitate informed decisions grounded in both knowledge and quantified uncertainty.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Diffusion%20Models%20for%203D%20Shape%20Reconstruction                                                                                  Bayesian Diffusion Models for 3D Shape Reconstruction                                                                                  We present Bayesian Diffusion Models (BDM), a prediction algorithm that performs effective Bayesian inference by tightly coupling the top-down (prior) information with the bottom-up (data-driven) procedure via joint diffusion processes. We show the effectiveness of BDM on the 3D shape reconstruction task. Compared to prototypical deep learning data-driven approaches trained on paired (supervised) data-labels (e.g. image-point clouds) datasets, our BDM brings in rich prior information from standalone labels (e.g. point clouds) to improve the bottom-up 3D reconstruction. As opposed to the standard Bayesian frameworks where explicit prior and likelihood are required for the inference, BDM performs seamless information fusion via coupled diffusion processes with learned gradient computation networks. The specialty of our BDM lies in its capability to engage the active and effective information exchange and fusion of the top-down and bottom-up processes where each itself is a diffusion process. We demonstrate state-of-the-art results on both synthetic and real-world benchmarks for 3D shape reconstruction.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Elicitation                                                                                  Bayesian Elicitation                                                                                  How can a receiver design an information structure in order to elicit information from a sender? We study how a decision-maker can acquire more information from an agent by reducing her own ability to observe what the agent transmits. Intuitively, when the two parties' preferences are not perfectly aligned, this garbling relaxes the sender's concern that the receiver will use her information to the sender's disadvantage. We characterize the optimal information structure for the receiver. The main result is that under broad conditions, the receiver can do just as well as if she could commit to a rule mapping the sender's message to actions: information design is just as good as full commitment. Similarly, we show that these conditions guarantee that ex ante information acquisition always benefits the receiver, even though this learning might actually lower the receiver's expected payoff in the absence of garbling. We illustrate these effects in a range of economically relevant examples.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Elicitation                                                                                  Bayesian Elicitation                                                                                  We study how a decision-maker can acquire more information from an agent by reducing her own ability to observe what the agent transmits. In a large class of binary-action games, opacity design is just as good as full commitment to actions and also guarantees that ex ante information acquisition always benefits the receiver, even though without opacity design this learning might actually lower the receiver's expected payoff.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Federated%20Model%20Compression%20for%20Communication%20and%20Computation%20Efficiency                                                                                  Bayesian Federated Model Compression for Communication and Computation Efficiency                                                                                  In this paper, we investigate Bayesian model compression in federated learning (FL) to construct sparse models that can achieve both communication and computation efficiencies. We propose a decentralized Turbo variational Bayesian inference (D-Turbo-VBI) FL framework where we firstly propose a hierarchical sparse prior to promote a clustered sparse structure in the weight matrix. Then, by carefully integrating message passing and VBI with a decentralized turbo framework, we propose the D-Turbo-VBI algorithm which can (i) reduce both upstream and downstream communication overhead during federated training, and (ii) reduce the computational complexity during local inference. Additionally, we establish the convergence property for thr proposed D-Turbo-VBI algorithm. Simulation results show the significant gain of our proposed algorithm over the baselines in reducing communication overhead during federated training and computational complexity of final model.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Floor%20Field%3A%20Transferring%20people%20flow%20predictions%20across%20environments                                                                                  Bayesian Floor Field: Transferring people flow predictions across environments                                                                                  Mapping people dynamics is a crucial skill for robots, because it enables them to coexist in human-inhabited environments. However, learning a model of people dynamics is a time consuming process which requires observation of large amount of people moving in an environment. Moreover, approaches for mapping dynamics are unable to transfer the learned models across environments: each model is only able to describe the dynamics of the environment it has been built in. However, the impact of architectural geometry on people's movement can be used to anticipate their patterns of dynamics, and recent work has looked into learning maps of dynamics from occupancy. So far however, approaches based on trajectories and those based on geometry have not been combined. In this work we propose a novel Bayesian approach to learn people dynamics able to combine knowledge about the environment geometry with observations from human trajectories. An occupancy-based deep prior is used to build an initial transition model without requiring any observations of pedestrian; the model is then updated when observations become available using Bayesian inference. We demonstrate the ability of our model to increase data efficiency and to generalize across real large-scale environments, which is unprecedented for maps of dynamics.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Formal%20Synthesis%20of%20Unknown%20Systems%20via%20Robust%20Simulation%20Relations                                                                                  Bayesian Formal Synthesis of Unknown Systems via Robust Simulation Relations                                                                                  This paper addresses the problem of data-driven computation of controllers that are correct by design for safety-critical systems and can provably satisfy (complex) functional requirements. With a focus on continuous-space stochastic systems with parametric uncertainty, we propose a two-stage approach that decomposes the problem into a learning stage and a robust formal controller synthesis stage. The first stage utilizes available Bayesian regression results to compute robust credible sets for the true parameters of the system. For the second stage, we introduce methods for systems subject to both stochastic and parametric uncertainties. We provide simulation relations for enabling correct-by-design control refinement that are founded on coupling uncertainties of stochastic systems via sub-probability measures. The presented relations are essential for constructing abstract models that are related to not only one model but to a set of parameterized models. The results are demonstrated on three case studies, including a nonlinear and a high-dimensional system.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Inference%20Accelerator%20for%20Spiking%20Neural%20Networks                                                                                  Bayesian Inference Accelerator for Spiking Neural Networks                                                                                  Bayesian neural networks offer better estimates of model uncertainty compared to frequentist networks. However, inference involving Bayesian models requires multiple instantiations or sampling of the network parameters, requiring significant computational resources. Compared to traditional deep learning networks, spiking neural networks (SNNs) have the potential to reduce computational area and power, thanks to their event-driven and spike-based computational framework. Most works in literature either address frequentist SNN models or non-spiking Bayesian neural networks. In this work, we demonstrate an optimization framework for developing and implementing efficient Bayesian SNNs in hardware by additionally restricting network weights to be binary-valued to further decrease power and area consumption. We demonstrate accuracies comparable to Bayesian binary networks with full-precision Bernoulli parameters, while requiring up to $25 times$ less spikes than equivalent binary SNN implementations. We show the feasibility of the design by mapping it onto Zynq-7000, a lightweight SoC, and achieve a $6.5 times$ improvement in GOPS/DSP while utilizing up to 30 times less power compared to the state-of-the-art.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Inference%20on%20Brain-Computer%20Interfaces%20via%20GLASS                                                                                  Bayesian Inference on Brain-Computer Interfaces via GLASS                                                                                  Brain-computer interfaces (BCIs), particularly the P300 BCI, facilitate direct communication between the brain and computers. The fundamental statistical problem in P300 BCIs lies in classifying target and non-target stimuli based on electroencephalogram (EEG) signals. However, the low signal-to-noise ratio (SNR) and complex spatial/temporal correlations of EEG signals present challenges in modeling and computation, especially for individuals with severe physical disabilities-BCI's primary users. To address these challenges, we introduce a novel Gaussian Latent channel model with Sparse time-varying effects (GLASS) under a fully Bayesian framework. GLASS is built upon a constrained multinomial logistic regression particularly designed for the imbalanced target and non-target stimuli. The novel latent channel decomposition efficiently alleviates strong spatial correlations between EEG channels, while the soft-thresholded Gaussian process (STGP) prior ensures sparse and smooth time-varying effects. We demonstrate GLASS substantially improves BCI's performance in participants with amyotrophic lateral sclerosis (ALS) and identifies important EEG channels (PO8, Oz, PO7, and Pz) in parietal and occipital regions that align with existing literature. For broader accessibility, we develop an efficient gradient-based variational inference (GBVI) algorithm for posterior computation and provide a user-friendly Python module available at https://github.com/BangyaoZhao/GLASS.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Markov-Switching%20Vector%20Autoregressive%20Process                                                                                  Bayesian Markov-Switching Vector Autoregressive Process                                                                                  This study introduces marginal density functions of the general Bayesian Markov-Switching Vector Autoregressive (MS-VAR) process. In the case of the Bayesian MS-VAR process, we provide closed--form density functions and Monte-Carlo simulation algorithms, including the importance sampling method. The Monte--Carlo simulation method departs from the previous simulation methods because it removes the duplication in a regime vector.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Neural%20Network%20For%20Personalized%20Federated%20Learning%20Parameter%20Selection                                                                                  Bayesian Neural Network For Personalized Federated Learning Parameter Selection                                                                                  Federated learning's poor performance in the presence of heterogeneous data remains one of the most pressing issues in the field. Personalized federated learning departs from the conventional paradigm in which all clients employ the same model, instead striving to discover an individualized model for each client to address the heterogeneity in the data. One of such approach involves personalizing specific layers of neural networks. However, prior endeavors have not provided a dependable rationale, and some have selected personalized layers that are entirely distinct and conflicting. In this work, we take a step further by proposing personalization at the elemental level, rather than the traditional layer-level personalization. To select personalized parameters, we introduce Bayesian neural networks and rely on the uncertainty they offer to guide our selection of personalized parameters. Finally, we validate our algorithm's efficacy on several real-world datasets, demonstrating that our proposed approach outperforms existing baselines.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Nonparametrics%20Meets%20Data-Driven%20Robust%20Optimization                                                                                  Bayesian Nonparametrics Meets Data-Driven Robust Optimization                                                                                  Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. We also show that the smoothness of the criterion naturally leads to standard gradient-based numerical optimization. Finally, we provide insights into the workings of our method by applying it to high-dimensional sparse linear regression, binary classification, and robust location parameter estimation tasks.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Optimization%20with%20Noise-Free%20Observations%3A%20Improved%20Regret%20Bounds%20via%20Random%20Exploration                                                                                  Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration                                                                                  This paper studies Bayesian optimization with noise-free observations. We introduce new algorithms rooted in scattered data approximation that rely on a random exploration step to ensure that the fill-distance of query points decays at a near-optimal rate. Our algorithms retain the ease of implementation of the classical GP-UCB algorithm and satisfy cumulative regret bounds that nearly match those conjectured in arXiv:2002.05096, hence solving a COLT open problem. Furthermore, the new algorithms outperform GP-UCB and other popular Bayesian optimization strategies in several examples.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Physics-informed%20Neural%20Networks%20for%20System%20Identification%20of%20Inverter-dominated%20Power%20Systems                                                                                  Bayesian Physics-informed Neural Networks for System Identification of Inverter-dominated Power Systems                                                                                  While the uncertainty in generation and demand increases, accurately estimating the dynamic characteristics of power systems becomes crucial for employing the appropriate control actions to maintain their stability. In our previous work, we have shown that Bayesian Physics-informed Neural Networks (BPINNs) outperform conventional system identification methods in identifying the power system dynamic behavior under measurement noise. This paper takes the next natural step and addresses the more significant challenge, exploring how BPINN perform in estimating power system dynamics under increasing uncertainty from many Inverter-based Resources (IBRs) connected to the grid. These introduce a different type of uncertainty, compared to noisy measurements. The BPINN combines the advantages of Physics-informed Neural Networks (PINNs), such as inverse problem applicability, with Bayesian approaches for uncertainty quantification. We explore the BPINN performance on a wide range of systems, starting from a single machine infinite bus (SMIB) system and 3-bus system to extract important insights, to the 14-bus CIGRE distribution grid, and the large IEEE 118-bus system. We also investigate approaches that can accelerate the BPINN training, such as pretraining and transfer learning. Throughout this paper, we show that in presence of uncertainty, the BPINN achieves orders of magnitude lower errors than the widely popular method for system identification SINDy and significantly lower errors than PINN, while transfer learning helps reduce training time by up to 80 %.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Semi-structured%20Subspace%20Inference                                                                                  Bayesian Semi-structured Subspace Inference                                                                                  Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multiple minima in the loss landscape. Numerical experiments validate our approach's efficacy in recovering structured effect parameter posteriors in semi-structured models and approaching the full-space posterior distribution of MCMC for increasing subspace dimension. Further, our approach exhibits competitive predictive performance across simulated and real-world datasets.
http://w3id.org/mlsea/pwc/scientificWork/Be%20Yourself%3A%20Bounded%20Attention%20for%20Multi-Subject%20Text-to-Image%20Generation                                                                                  Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation                                                                                  Text-to-image diffusion models have an unprecedented ability to generate diverse and high-quality images. However, they often struggle to faithfully capture the intended semantics of complex input prompts that include multiple subjects. Recently, numerous layout-to-image extensions have been introduced to improve user control, aiming to localize subjects represented by specific tokens. Yet, these methods often produce semantically inaccurate images, especially when dealing with multiple semantically or visually similar subjects. In this work, we study and analyze the causes of these limitations. Our exploration reveals that the primary issue stems from inadvertent semantic leakage between subjects in the denoising process. This leakage is attributed to the diffusion model's attention layers, which tend to blend the visual features of different subjects. To address these issues, we introduce Bounded Attention, a training-free method for bounding the information flow in the sampling process. Bounded Attention prevents detrimental leakage among subjects and enables guiding the generation to promote each subject's individuality, even with complex multi-subject conditioning. Through extensive experimentation, we demonstrate that our method empowers the generation of multiple subjects that better align with given prompts and layouts.
http://w3id.org/mlsea/pwc/scientificWork/Beamforming%20Design%20for%20Double-Active-RIS-aided%20Communication%20Systems%20with%20Inter-Excitation                                                                                  Beamforming Design for Double-Active-RIS-aided Communication Systems with Inter-Excitation                                                                                  In this paper, we investigate a double-active-reconfigurable intelligent surface (RIS)-aided downlink wireless communication system, where a multi-antenna base station (BS) serves multiple single-antenna users with both double reflection and single reflection links. Due to the signal amplification capability of active RISs, the mutual influence between active RISs, which is termed as the 'inter-excitation' effect, cannot be ignored. Then, we develop a feedback-type model to characterize the signal containing the inter-excitation effect. Based on the signal model, we formulate a weighted sum rate (WSR) maximization problem by jointly optimizing the beamforming matrix at the BS and the reflecting coefficient matrices at the two active RISs, subject to power constraints at the BS and active RISs, as well as the maximum amplification gain constraints of the active RISs. To solve this non-convex problem, we first transform the problem into a more tractable form using the fractional programming (FP) method. Then, by introducing auxiliary variables, the problem can be converted into an equivalent form that can be solved by using a low-complexity penalty dual decomposition (PDD) algorithm. Finally, simulation results indicate that it is crucial to consider the inter-excitation effect between active RISs in beamforming design for double-active-RIS-aided communication systems. Additionally, it prevails over other benchmark schemes with single active RIS and double passive RISs in terms of achievable rate.
http://w3id.org/mlsea/pwc/scientificWork/Behind%20the%20Screen%3A%20Investigating%20ChatGPT%27s%20Dark%20Personality%20Traits%20and%20Conspiracy%20Beliefs                                                                                  Behind the Screen: Investigating ChatGPT's Dark Personality Traits and Conspiracy Beliefs                                                                                  ChatGPT is notorious for its intransparent behavior. This paper tries to shed light on this, providing an in-depth analysis of the dark personality traits and conspiracy beliefs of GPT-3.5 and GPT-4. Different psychological tests and questionnaires were employed, including the Dark Factor Test, the Mach-IV Scale, the Generic Conspiracy Belief Scale, and the Conspiracy Mentality Scale. The responses were analyzed computing average scores, standard deviations, and significance tests to investigate differences between GPT-3.5 and GPT-4. For traits that have shown to be interdependent in human studies, correlations were considered. Additionally, system roles corresponding to groups that have shown distinct answering behavior in the corresponding questionnaires were applied to examine the models' ability to reflect characteristics associated with these roles in their responses. Dark personality traits and conspiracy beliefs were not particularly pronounced in either model with little differences between GPT-3.5 and GPT-4. However, GPT-4 showed a pronounced tendency to believe in information withholding. This is particularly intriguing given that GPT-4 is trained on a significantly larger dataset than GPT-3.5. Apparently, in this case an increased data exposure correlates with a greater belief in the control of information. An assignment of extreme political affiliations increased the belief in conspiracy theories. Test sequencing affected the models' responses and the observed correlations, indicating a form of contextual memory.
http://w3id.org/mlsea/pwc/scientificWork/Belief%20Aided%20Navigation%20using%20Bayesian%20Reinforcement%20Learning%20for%20Avoiding%20Humans%20in%20Blind%20Spots                                                                                  Belief Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots                                                                                  Recent research on mobile robot navigation has focused on socially aware navigation in crowded environments. However, existing methods do not adequately account for human robot interactions and demand accurate location information from omnidirectional sensors, rendering them unsuitable for practical applications. In response to this need, this study introduces a novel algorithm, BNBRL+, predicated on the partially observable Markov decision process framework to assess risks in unobservable areas and formulate movement strategies under uncertainty. BNBRL+ consolidates belief algorithms with Bayesian neural networks to probabilistically infer beliefs based on the positional data of humans. It further integrates the dynamics between the robot, humans, and inferred beliefs to determine the navigation paths and embeds social norms within the reward function, thereby facilitating socially aware navigation. Through experiments in various risk laden scenarios, this study validates the effectiveness of BNBRL+ in navigating crowded environments with blind spots. The model's ability to navigate effectively in spaces with limited visibility and avoid obstacles dynamically can significantly improve the safety and reliability of autonomous vehicles.
http://w3id.org/mlsea/pwc/scientificWork/Bellman%20Optimal%20Stepsize%20Straightening%20of%20Flow-Matching%20Models                                                                                  Bellman Optimal Stepsize Straightening of Flow-Matching Models                                                                                  Flow matching is a powerful framework for generating high-quality samples in various applications, especially image synthesis. However, the intensive computational demands of these models, especially during the finetuning process and sampling processes, pose significant challenges for low-resource scenarios. This paper introduces Bellman Optimal Stepsize Straightening (BOSS) technique for distilling flow-matching generative models: it aims specifically for a few-step efficient image sampling while adhering to a computational budget constraint. First, this technique involves a dynamic programming algorithm that optimizes the stepsizes of the pretrained network. Then, it refines the velocity network to match the optimal step sizes, aiming to straighten the generation paths. Extensive experimental evaluations across image generation tasks demonstrate the efficacy of BOSS in terms of both resource utilization and image quality. Our results reveal that BOSS achieves substantial gains in efficiency while maintaining competitive sample quality, effectively bridging the gap between low-resource constraints and the demanding requirements of flow-matching generative models. Our paper also fortifies the responsible development of artificial intelligence, offering a more sustainable generative model that reduces computational costs and environmental footprints. Our code can be found at https://github.com/nguyenngocbaocmt02/BOSS.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20ChatGPT%20on%20Algorithmic%20Reasoning                                                                                  Benchmarking ChatGPT on Algorithmic Reasoning                                                                                  We evaluate ChatGPT's ability to solve algorithm problems from the CLRS benchmark suite that is designed for GNNs. The benchmark requires the use of a specified classical algorithm to solve a given problem. We find that ChatGPT outperforms specialist GNN models, using Python to successfully solve these problems. This raises new points in the discussion about learning algorithms with neural networks and how we think about what out of distribution testing looks like with web scale training data.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Hallucination%20in%20Large%20Language%20Models%20based%20on%20Unanswerable%20Math%20Word%20Problem                                                                                  Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem                                                                                  Large language models (LLMs) are highly effective in various natural language processing (NLP) tasks. However, they are susceptible to producing unreliable conjectures in ambiguous contexts called hallucination. This paper presents a new method for evaluating LLM hallucination in Question Answering (QA) based on the unanswerable math word problem (MWP). To support this approach, we innovatively develop a dataset called Unanswerable Math Word Problem (UMWP) which comprises 5200 questions across five categories. We developed an evaluation methodology combining text similarity and mathematical expression detection to determine whether LLM considers the question unanswerable. The results of extensive experiments conducted on 31 LLMs, including GPT-3, InstructGPT, LLaMA, and Claude, demonstrate that in-context learning and reinforcement learning with human feedback (RLHF) training significantly enhance the model's ability to avoid hallucination. We show that utilizing MWP is a reliable and effective approach to assess hallucination. Our code and data are available at https://github.com/Yuki-Asuuna/UMWP.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20LLMs%20on%20the%20Semantic%20Overlap%20Summarization%20Task                                                                                  Benchmarking LLMs on the Semantic Overlap Summarization Task                                                                                  Semantic Overlap Summarization (SOS) is a constrained multi-document summarization task, where the constraint is to capture the common/overlapping information between two alternative narratives. While recent advancements in Large Language Models (LLMs) have achieved superior performance in numerous summarization tasks, a benchmarking study of the SOS task using LLMs is yet to be performed. As LLMs' responses are sensitive to slight variations in prompt design, a major challenge in conducting such a benchmarking study is to systematically explore a variety of prompts before drawing a reliable conclusion. Fortunately, very recently, the TELeR taxonomy has been proposed which can be used to design and explore various prompts for LLMs. Using this TELeR taxonomy and 15 popular LLMs, this paper comprehensively evaluates LLMs on the SOS Task, assessing their ability to summarize overlapping information from multiple alternative narratives. For evaluation, we report well-established metrics like ROUGE, BERTscore, and SEM-F1$ on two different datasets of alternative narratives. We conclude the paper by analyzing the strengths and limitations of various LLMs in terms of their capabilities in capturing overlapping information The code and datasets used to conduct this study are available at https://anonymous.4open.science/r/llm_eval-E16D.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Large%20Language%20Models%20for%20Molecule%20Prediction%20Tasks                                                                                  Benchmarking Large Language Models for Molecule Prediction Tasks                                                                                  Large Language Models (LLMs) stand at the forefront of a number of Natural Language Processing (NLP) tasks. Despite the widespread adoption of LLMs in NLP, much of their potential in broader fields remains largely unexplored, and significant limitations persist in their design and implementation. Notably, LLMs struggle with structured data, such as graphs, and often falter when tasked with answering domain-specific questions requiring deep expertise, such as those in biology and chemistry. In this paper, we explore a fundamental question: Can LLMs effectively handle molecule prediction tasks? Rather than pursuing top-tier performance, our goal is to assess how LLMs can contribute to diverse molecule tasks. We identify several classification and regression prediction tasks across six standard molecule datasets. Subsequently, we carefully design a set of prompts to query LLMs on these tasks and compare their performance with existing Machine Learning (ML) models, which include text-based models and those specifically designed for analysing the geometric structure of molecules. Our investigation reveals several key insights: Firstly, LLMs generally lag behind ML models in achieving competitive performance on molecule tasks, particularly when compared to models adept at capturing the geometric structure of molecules, highlighting the constrained ability of LLMs to comprehend graph data. Secondly, LLMs show promise in enhancing the performance of ML models when used collaboratively. Lastly, we engage in a discourse regarding the challenges and promising avenues to harness LLMs for molecule prediction tasks. The code and models are available at https://github.com/zhiqiangzhongddu/LLMaMol.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Large%20Language%20Models%20for%20Persian%3A%20A%20Preliminary%20Study%20Focusing%20on%20ChatGPT                                                                                  Benchmarking Large Language Models for Persian: A Preliminary Study Focusing on ChatGPT                                                                                  This paper explores the efficacy of large language models (LLMs) for Persian. While ChatGPT and consequent LLMs have shown remarkable performance in English, their efficiency for more low-resource languages remains an open question. We present the first comprehensive benchmarking study of LLMs across diverse Persian language tasks. Our primary focus is on GPT-3.5-turbo, but we also include GPT-4 and OpenChat-3.5 to provide a more holistic evaluation. Our assessment encompasses a diverse set of tasks categorized into classic, reasoning, and knowledge-based domains. To enable a thorough comparison, we evaluate LLMs against existing task-specific fine-tuned models. Given the limited availability of Persian datasets for reasoning tasks, we introduce two new benchmarks: one based on elementary school math questions and another derived from the entrance exams for 7th and 10th grades. Our findings reveal that while LLMs, especially GPT-4, excel in tasks requiring reasoning abilities and a broad understanding of general knowledge, they often lag behind smaller pre-trained models fine-tuned specifically for particular tasks. Additionally, we observe improved performance when test sets are translated to English before inputting them into GPT-3.5. These results highlight the significant potential for enhancing LLM performance in the Persian language. This is particularly noteworthy due to the unique attributes of Persian, including its distinct alphabet and writing styles.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Large%20Language%20Models%20on%20Communicative%20Medical%20Coaching%3A%20a%20Novel%20System%20and%20Dataset                                                                                  Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset                                                                                  Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors, particularly in areas such as communicative medical coaching, remains largely unexplored. We introduce ``ChatCoach,'' an integrated human-AI cooperative framework. Within this framework, both a patient agent and a coaching agent collaboratively support medical learners in practicing their medical communication skills during consultations. Unlike traditional dialogue systems, ChatCoach provides a simulated environment where a human doctor can engage in medical dialogue with a patient agent. Simultaneously, a coaching agent provides real-time feedback to the doctor. To construct the ChatCoach system, we developed a dataset and integrated Large Language Models such as ChatGPT and Llama2, aiming to assess their effectiveness in communicative medical coaching tasks. Our comparative analysis demonstrates that instruction-tuned Llama2 significantly outperforms ChatGPT's prompting-based approaches.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Robustness%20of%20Multimodal%20Image-Text%20Models%20under%20Distribution%20Shift                                                                                  Benchmarking Robustness of Multimodal Image-Text Models under Distribution Shift                                                                                  Multimodal image-text models have shown remarkable performance in the past few years. However, evaluating robustness against distribution shifts is crucial before adopting them in real-world applications. In this work, we investigate the robustness of 12 popular open-sourced image-text models under common perturbations on five tasks (image-text retrieval, visual reasoning, visual entailment, image captioning, and text-to-image generation). In particular, we propose several new multimodal robustness benchmarks by applying 17 image perturbation and 16 text perturbation techniques on top of existing datasets. We observe that multimodal models are not robust to image and text perturbations, especially to image perturbations. Among the tested perturbation methods, character-level perturbations constitute the most severe distribution shift for text, and zoom blur is the most severe shift for image data. We also introduce two new robustness metrics ( textbf{MMI} for MultiModal Impact score and textbf{MOR} for Missing Object Rate) for proper evaluations of multimodal models. We hope our extensive study sheds light on new directions for the development of robust multimodal models. More details can be found on the project webpage: url{https://MMRobustness.github.io}.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Spiking%20Neural%20Network%20Learning%20Methods%20with%20Varying%20Locality                                                                                  Benchmarking Spiking Neural Network Learning Methods with Varying Locality                                                                                  Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics, have shown to achieve performance comparable to Artificial Neural Networks (ANNs) in several machine learning tasks. Information is processed as spikes within SNNs in an event-based mechanism that significantly reduces energy consumption. However, training SNNs is challenging due to the non-differentiable nature of the spiking mechanism. Traditional approaches, such as Backpropagation Through Time (BPTT), have shown effectiveness but comes with additional computational and memory costs and are biologically implausible. In contrast, recent works propose alternative learning methods with varying degrees of locality, demonstrating success in classification tasks. In this work, we show that these methods share similarities during the training process, while they present a trade-off between biological plausibility and performance. Further, this research examines the implicitly recurrent nature of SNNs and investigates the influence of addition of explicit recurrence to SNNs. We experimentally prove that the addition of explicit recurrent weights enhances the robustness of SNNs. We also investigate the performance of local learning methods under gradient and non-gradient based adversarial attacks.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20federated%20strategies%20in%20Peer-to-Peer%20Federated%20learning%20for%20biomedical%20data                                                                                  Benchmarking federated strategies in Peer-to-Peer Federated learning for biomedical data                                                                                  The increasing requirements for data protection and privacy has attracted a huge research interest on distributed artificial intelligence and specifically on federated learning, an emerging machine learning approach that allows the construction of a model between several participants who hold their own private data. In the initial proposal of federated learning the architecture was centralised and the aggregation was done with federated averaging, meaning that a central server will orchestrate the federation using the most straightforward averaging strategy. This research is focused on testing different federated strategies in a peer-to-peer environment. The authors propose various aggregation strategies for federated learning, including weighted averaging aggregation, using different factors and strategies based on participant contribution. The strategies are tested with varying data sizes to identify the most robust ones. This research tests the strategies with several biomedical datasets and the results of the experiments show that the accuracy-based weighted average outperforms the classical federated averaging method.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20the%20Robustness%20of%20UAV%20Tracking%20Against%20Common%20Corruptions                                                                                  Benchmarking the Robustness of UAV Tracking Against Common Corruptions                                                                                  The robustness of unmanned aerial vehicle (UAV) tracking is crucial in many tasks like surveillance and robotics. Despite its importance, little attention is paid to the performance of UAV trackers under common corruptions due to lack of a dedicated platform. Addressing this, we propose UAV-C, a large-scale benchmark for assessing robustness of UAV trackers under common corruptions. Specifically, UAV-C is built upon two popular UAV datasets by introducing 18 common corruptions from 4 representative categories including adversarial, sensor, blur, and composite corruptions in different levels. Finally, UAV-C contains more than 10K sequences. To understand the robustness of existing UAV trackers against corruptions, we extensively evaluate 12 representative algorithms on UAV-C. Our study reveals several key findings: 1) Current trackers are vulnerable to corruptions, indicating more attention needed in enhancing the robustness of UAV trackers; 2) When accompanying together, composite corruptions result in more severe degradation to trackers; and 3) While each tracker has its unique performance profile, some trackers may be more sensitive to specific corruptions. By releasing UAV-C, we hope it, along with comprehensive analysis, serves as a valuable resource for advancing the robustness of UAV tracking against corruption. Our UAV-C will be available at https://github.com/Xiaoqiong-Liu/UAV-C.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20the%20Text-to-SQL%20Capability%20of%20Large%20Language%20Models%3A%20A%20Comprehensive%20Evaluation                                                                                  Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation                                                                                  Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks. Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions. To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs. Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task. These findings offer valuable insights for enhancing the development of LLM-based Text-to-SQL systems.
http://w3id.org/mlsea/pwc/scientificWork/Best%20Practices%20for%20a%20Handwritten%20Text%20Recognition%20System                                                                                  Best Practices for a Handwritten Text Recognition System                                                                                  Handwritten text recognition has been developed rapidly in the recent years, following the rise of deep learning and its applications. Though deep learning methods provide notable boost in performance concerning text recognition, non-trivial deviation in performance can be detected even when small pre-processing or architectural/optimization elements are changed. This work follows a ``best practice'' rationale; highlight simple yet effective empirical practices that can further help training and provide well-performing handwritten text recognition systems. Specifically, we considered three basic aspects of a deep HTR system and we proposed simple yet effective solutions: 1) retain the aspect ratio of the images in the preprocessing step, 2) use max-pooling for converting the 3D feature map of CNN output into a sequence of features and 3) assist the training procedure via an additional CTC loss which acts as a shortcut on the max-pooled sequential features. Using these proposed simple modifications, one can attain close to state-of-the-art results, while considering a basic convolutional-recurrent (CNN+LSTM) architecture, for both IAM and RIMES datasets. Code is available at https://github.com/georgeretsi/HTR-best-practices/.
http://w3id.org/mlsea/pwc/scientificWork/Best%20Response%20Shaping                                                                                  Best Response Shaping                                                                                  We investigate the challenge of multi-agent deep reinforcement learning in partially competitive environments, where traditional methods struggle to foster reciprocity-based cooperation. LOLA and POLA agents learn reciprocity-based cooperative policies by differentiation through a few look-ahead optimization steps of their opponent. However, there is a key limitation in these techniques. Because they consider a few optimization steps, a learning opponent that takes many steps to optimize its return may exploit them. In response, we introduce a novel approach, Best Response Shaping (BRS), which differentiates through an opponent approximating the best response, termed the 'detective.' To condition the detective on the agent's policy for complex games we propose a state-aware differentiable conditioning mechanism, facilitated by a question answering (QA) method that extracts a representation of the agent based on its behaviour on specific environment states. To empirically validate our method, we showcase its enhanced performance against a Monte Carlo Tree Search (MCTS) opponent, which serves as an approximation to the best response in the Coin Game. This work expands the applicability of multi-agent RL in partially competitive environments and provides a new pathway towards achieving improved social welfare in general sum games.
http://w3id.org/mlsea/pwc/scientificWork/Better%20Call%20GPT%2C%20Comparing%20Large%20Language%20Models%20Against%20Lawyers                                                                                  Better Call GPT, Comparing Large Language Models Against Lawyers                                                                                  This paper presents a groundbreaking comparison between Large Language Models and traditional legal contract reviewers, Junior Lawyers and Legal Process Outsourcers. We dissect whether LLMs can outperform humans in accuracy, speed, and cost efficiency during contract review. Our empirical analysis benchmarks LLMs against a ground truth set by Senior Lawyers, uncovering that advanced models match or exceed human accuracy in determining legal issues. In speed, LLMs complete reviews in mere seconds, eclipsing the hours required by their human counterparts. Cost wise, LLMs operate at a fraction of the price, offering a staggering 99.97 percent reduction in cost over traditional methods. These results are not just statistics, they signal a seismic shift in legal practice. LLMs stand poised to disrupt the legal industry, enhancing accessibility and efficiency of legal services. Our research asserts that the era of LLM dominance in legal contract review is upon us, challenging the status quo and calling for a reimagined future of legal workflows.
http://w3id.org/mlsea/pwc/scientificWork/Better%20Monocular%203D%20Detectors%20with%20LiDAR%20from%20the%20Past                                                                                  Better Monocular 3D Detectors with LiDAR from the Past                                                                                  Accurate 3D object detection is crucial to autonomous driving. Though LiDAR-based detectors have achieved impressive performance, the high cost of LiDAR sensors precludes their widespread adoption in affordable vehicles. Camera-based detectors are cheaper alternatives but often suffer inferior performance compared to their LiDAR-based counterparts due to inherent depth ambiguities in images. In this work, we seek to improve monocular 3D detectors by leveraging unlabeled historical LiDAR data. Specifically, at inference time, we assume that the camera-based detectors have access to multiple unlabeled LiDAR scans from past traversals at locations of interest (potentially from other high-end vehicles equipped with LiDAR sensors). Under this setup, we proposed a novel, simple, and end-to-end trainable framework, termed AsyncDepth, to effectively extract relevant features from asynchronous LiDAR traversals of the same location for monocular 3D detectors. We show consistent and significant performance gain (up to 9 AP) across multiple state-of-the-art models and datasets with a negligible additional latency of 9.66 ms and a small storage cost.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Average%3A%20Individualized%20Visual%20Scanpath%20Prediction                                                                                  Beyond Average: Individualized Visual Scanpath Prediction                                                                                  Understanding how attention varies across individuals has significant scientific and societal impacts. However, existing visual scanpath models treat attention uniformly, neglecting individual differences. To bridge this gap, this paper focuses on individualized scanpath prediction (ISP), a new attention modeling task that aims to accurately predict how different individuals shift their attention in diverse visual tasks. It proposes an ISP method featuring three novel technical components: (1) an observer encoder to characterize and integrate an observer's unique attention traits, (2) an observer-centric feature integration approach that holistically combines visual features, task guidance, and observer-specific characteristics, and (3) an adaptive fixation prioritization mechanism that refines scanpath predictions by dynamically prioritizing semantic feature maps based on individual observers' attention traits. These novel components allow scanpath models to effectively address the attention variations across different observers. Our method is generally applicable to different datasets, model architectures, and visual tasks, offering a comprehensive tool for transforming general scanpath models into individualized ones. Comprehensive evaluations using value-based and ranking-based metrics verify the method's effectiveness and generalizability.
http://w3id.org/mlsea/openml/scientificWork/10                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1027                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1028                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1030                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1044                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1046                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1047                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1049                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1050                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1051                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1053                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1054                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1055                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1056                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1057                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1063                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1065                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1066                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1067                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1068                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1069                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1071                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1075                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1076                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/11                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/12                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1245                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/13                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/14                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/15                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/150                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/151                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/155                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/16                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/18                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/20                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/22                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/23                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/23515                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/23516                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/24                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/26                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/273                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/28                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/285                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/287                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/29                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/293                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/299                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/3                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/30                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/300                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/301                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/307                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/31                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/311                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/312                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/315                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/32                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/329                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/333                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/334                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/335                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/336                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/337                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/34                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/346                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/35                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/350                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/351                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/37                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/374                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/375                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/376                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/377                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/378                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/379                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/38                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/380                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/381                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/382                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/39                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/4                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/40                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41214                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41440                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41514                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41515                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41982                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41990                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42078                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42087                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42088                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42089                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42123                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42125                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42130                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42131                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42159                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42164                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42165                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42349                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42468                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42665                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42720                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42723                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42727                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42738                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42768                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42793                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42804                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42805                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42834                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42835                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42836                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42837                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42838                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42839                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42840                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42841                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42842                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42843                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42844                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42845                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42846                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42847                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42848                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42849                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42850                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42851                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42853                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42855                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42856                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42857                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42858                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42859                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42860                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42861                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42862                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42863                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42864                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42865                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42866                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42867                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42869                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42870                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42871                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42872                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42887                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42889                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42890                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42891                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42893                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42905                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42906                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42907                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42908                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42911                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42912                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43069                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43855                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43874                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43943                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43959                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44096                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44097                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44098                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44153                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44154                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44155                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44187                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44191                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44192                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44194                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44223                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/443                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/444                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44793                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44794                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44956                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44957                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44958                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44959                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44960                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44961                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44962                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44964                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44965                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44967                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44968                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44969                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44970                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44971                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44972                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44973                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44974                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44976                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44977                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44984                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44985                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44987                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44992                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44993                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44994                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45081                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45083                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45084                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45085                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45086                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45087                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45088                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45089                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45090                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45091                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45092                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45093                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45094                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45095                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45096                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45097                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45098                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45099                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45100                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45101                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45106                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45109                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45110                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45111                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45112                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45113                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45114                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45115                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45116                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45117                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45118                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45119                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45120                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45121                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45122                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45123                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/46                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/48                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/50                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/52                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/537                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/54                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/55                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/5587                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/56                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/561                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/564                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/5648                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/566                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/569                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/57                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/5889                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/59                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/6                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/61                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/659                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/660                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/661                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/663                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/664                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/665                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/666                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/670                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/671                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/672                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/673                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/674                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/675                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/676                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/678                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/679                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/680                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/682                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/683                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/684                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/685                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/686                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/687                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/688                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/689                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/690                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/691                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/692                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/693                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/694                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/695                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/697                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/698                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/699                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/7                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/702                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/703                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/704                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/705                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/706                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/707                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/709                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/710                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/712                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/8                                                                                                                                                                    

1000 Rows. -- 1942 msec.
