Result of /data/leuven/370/vsc37064/new_queries_named_graph_type_split/query_3.txt:
OpenLink Virtuoso Interactive SQL (Virtuoso)
Version 07.20.3240 as of Mar 11 2025
Type HELP; for help and EXIT; to exit.
Connected to OpenLink Virtuoso
Driver: 07.20.3240 OpenLink Virtuoso ODBC Driver
work                                                                              title                                                                             abstract
LONG VARCHAR                                                                      LONG VARCHAR                                                                      LONG VARCHAR
_______________________________________________________________________________

http://w3id.org/mlsea/pwc/scientificWork/%24%20mathbf%7B%28N%2CK%29%7D%24-Puzzle%3A%20A%20Cost-Efficient%20Testbed%20for%20Benchmarking%20Reinforcement%20Learning%20Algorithms%20in%20Generative%20Language%20Model                                                                                  $ mathbf{(N,K)}$-Puzzle: A Cost-Efficient Testbed for Benchmarking Reinforcement Learning Algorithms in Generative Language Model                                                                                  Recent advances in reinforcement learning (RL) algorithms aim to enhance the performance of language models at scale. Yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these algorithms. To bridge this gap, we present a generalized version of the 24-Puzzle: the $(N,K)$-Puzzle, which challenges language models to reach a target value $K$ with $N$ integers. We evaluate the effectiveness of established RL algorithms such as Proximal Policy Optimization (PPO), alongside novel approaches like Identity Policy Optimization (IPO) and Direct Policy Optimization (DPO).
http://w3id.org/mlsea/pwc/scientificWork/%24%20textit%7BL%2BM-24%7D%24%3A%20Building%20a%20Dataset%20for%20Language%20%2B%20Molecules%20%40%20ACL%202024                                                                                  $ textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024                                                                                  Language-molecule models have emerged as an exciting direction for molecular discovery and understanding. However, training these models is challenging due to the scarcity of molecule-language pair datasets. At this point, datasets have been released which are 1) small and scraped from existing databases, 2) large but noisy and constructed by performing entity linking on the scientific literature, and 3) built by converting property prediction datasets to natural language using templates. In this document, we detail the $ textit{L+M-24}$ dataset, which has been created for the Language + Molecules Workshop shared task at ACL 2024. In particular, $ textit{L+M-24}$ is designed to focus on three key benefits of natural language in molecule design: compositionality, functionality, and abstraction.
http://w3id.org/mlsea/pwc/scientificWork/%24%20texttt%7BLM%7D%5E%20texttt%7B2%7D%24%3A%20A%20Simple%20Society%20of%20Language%20Models%20Solves%20Complex%20Reasoning                                                                                  $ texttt{LM}^ texttt{2}$: A Simple Society of Language Models Solves Complex Reasoning                                                                                  Despite demonstrating emergent reasoning abilities, Large Language Models (LLMS) often lose track of complex, multi-step reasoning. Existing studies show that providing guidance via decomposing the original question into multiple subproblems elicits more robustness in LLM reasoning -- a decomposer generates the subproblems, and a solver solves each of these subproblems. However, these techniques fail to accommodate coordination between the decomposer and the solver modules (either in a single model or different specialized ones) -- the decomposer does not keep track of the ability of the solver to follow the decomposed reasoning. In this paper, we propose LM2 to address these challenges. LM2 modularizes the decomposition, solution, and verification into three different language models. The decomposer module identifies the key concepts necessary to solve the problem and generates step-by-step subquestions according to the reasoning requirement. The solver model generates the solution to the subproblems that are then checked by the verifier module; depending upon the feedback from the verifier, the reasoning context is constructed using the subproblems and the solutions. These models are trained to coordinate using policy learning. Exhaustive experimentation suggests the superiority of LM2 over existing methods on in- and out-domain reasoning problems, outperforming the best baselines by $8.1 %$ on MATH, $7.71 %$ on JEEBench, and $9.7 %$ on MedQA problems (code available at https://github.com/LCS2-IIITD/Language_Model_Multiplex).
http://w3id.org/mlsea/pwc/scientificWork/%24%20texttt%7Bimmrax%7D%24%3A%20A%20Parallelizable%20and%20Differentiable%20Toolbox%20for%20Interval%20Analysis%20and%20Mixed%20Monotone%20Reachability%20in%20JAX                                                                                  $ texttt{immrax}$: A Parallelizable and Differentiable Toolbox for Interval Analysis and Mixed Monotone Reachability in JAX                                                                                  We present an implementation of interval analysis and mixed monotone interval reachability analysis as function transforms in Python, fully composable with the computational framework JAX. The resulting toolbox inherits several key features from JAX, including computational efficiency through Just-In-Time Compilation, GPU acceleration for quick parallelized computations, and Automatic Differentiability. We demonstrate the toolbox's performance on several case studies, including a reachability problem on a vehicle model controlled by a neural network, and a robust closed-loop optimal control problem for a swinging pendulum.
http://w3id.org/mlsea/pwc/scientificWork/%24%28%CE%B5%2C%20u%29%24-Adaptive%20Regret%20Minimization%20in%20Heavy-Tailed%20Bandits                                                                                  $(ε, u)$-Adaptive Regret Minimization in Heavy-Tailed Bandits                                                                                  Heavy-tailed distributions naturally arise in several settings, from finance to telecommunications. While regret minimization under subgaussian or bounded rewards has been widely studied, learning with heavy-tailed distributions only gained popularity over the last decade. In this paper, we consider the setting in which the reward distributions have finite absolute raw moments of maximum order $1+ epsilon$, uniformly bounded by a constant $u<+ infty$, for some $ epsilon in (0,1]$. In this setting, we study the regret minimization problem when $ epsilon$ and $u$ are unknown to the learner and it has to adapt. First, we show that adaptation comes at a cost and derive two negative results proving that the same regret guarantees of the non-adaptive case cannot be achieved with no further assumptions. Then, we devise and analyze a fully data-driven trimmed mean estimator and propose a novel adaptive regret minimization algorithm, AdaR-UCB, that leverages such an estimator. Finally, we show that AdaR-UCB is the first algorithm that, under a known distributional assumption, enjoys regret guarantees nearly matching those of the non-adaptive heavy-tailed case.
http://w3id.org/mlsea/pwc/scientificWork/%24%CE%B1%24-Divergence%20Loss%20Function%20for%20Neural%20Density%20Ratio%20Estimation                                                                                  $α$-Divergence Loss Function for Neural Density Ratio Estimation                                                                                  Recently, neural networks have produced state-of-the-art results for density-ratio estimation (DRE), a fundamental technique in machine learning. However, existing methods bear optimization issues that arise from the loss functions of DRE: a large sample requirement of Kullback--Leibler (KL)-divergence, vanishing of train loss gradients, and biased gradients of the loss functions. Thus, an $ alpha$-divergence loss function ($ alpha$-Div) that offers concise implementation and stable optimization is proposed in this paper. Furthermore, technical justifications for the proposed loss function are presented. The stability of the proposed loss function is empirically demonstrated and the estimation accuracy of DRE tasks is investigated. Additionally, this study presents a sample requirement for DRE using the proposed loss function in terms of the upper bound of $L_1$ error, which connects a curse of dimensionality as a common problem in high-dimensional DRE tasks.
http://w3id.org/mlsea/pwc/scientificWork/%24C%5E%2A%24-Algebraic%20Machine%20Learning%3A%20Moving%20in%20a%20New%20Direction                                                                                  $C^*$-Algebraic Machine Learning: Moving in a New Direction                                                                                  Machine learning has a long collaborative tradition with several fields of mathematics, such as statistics, probability and linear algebra. We propose a new direction for machine learning research: $C^*$-algebraic ML $-$ a cross-fertilization between $C^*$-algebra and machine learning. The mathematical concept of $C^*$-algebra is a natural generalization of the space of complex numbers. It enables us to unify existing learning strategies, and construct a new framework for more diverse and information-rich data models. We explain why and how to use $C^*$-algebras in machine learning, and provide technical considerations that go into the design of $C^*$-algebraic learning models in the contexts of kernel methods and neural networks. Furthermore, we discuss open questions and challenges in $C^*$-algebraic ML and give our thoughts for future development and applications.
http://w3id.org/mlsea/pwc/scientificWork/%24L_0%24%20Regularization%20of%20Field-Aware%20Factorization%20Machine%20through%20Ising%20Model                                                                                  $L_0$ Regularization of Field-Aware Factorization Machine through Ising Model                                                                                  We examined the use of the Ising model as an $L_0$ regularization method for field-aware factorization machines (FFM). This approach improves generalization performance and has the advantage of simultaneously determining the best feature combinations for each of several groups. We can deepen the interpretation and understanding of the model from the similarities and differences in the features selected in each group.
http://w3id.org/mlsea/pwc/scientificWork/%27Task%20Success%27%20is%20not%20Enough%3A%20Investigating%20the%20Use%20of%20Video-Language%20Models%20as%20Behavior%20Critics%20for%20Catching%20Undesirable%20Agent%20Behaviors                                                                                  'Task Success' is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors                                                                                  Large-scale generative models are shown to be useful for sampling meaningful candidate solutions, yet they often overlook task constraints and user preferences. Their full power is better harnessed when the models are coupled with external verifiers and the final solutions are derived iteratively or progressively according to the verification feedback. In the context of embodied AI, verification often solely involves assessing whether goal conditions specified in the instructions have been met. Nonetheless, for these agents to be seamlessly integrated into daily life, it is crucial to account for a broader range of constraints and preferences beyond bare task success (e.g., a robot should grasp bread with care to avoid significant deformations). However, given the unbounded scope of robot tasks, it is infeasible to construct scripted verifiers akin to those used for explicit-knowledge tasks like the game of Go and theorem proving. This begs the question: when no sound verifier is available, can we use large vision and language models (VLMs), which are approximately omniscient, as scalable Behavior Critics to catch undesirable robot behaviors in videos? To answer this, we first construct a benchmark that contains diverse cases of goal-reaching yet undesirable robot policies. Then, we comprehensively evaluate VLM critics to gain a deeper understanding of their strengths and failure modes. Based on the evaluation, we provide guidelines on how to effectively utilize VLM critiques and showcase a practical way to integrate the feedback into an iterative process of policy refinement. The dataset and codebase are released at: https://guansuns.github.io/pages/vlm-critic.
http://w3id.org/mlsea/pwc/scientificWork/%27The%20Roller%20Conduction%20Effect%27%20from%20the%20A-share%20Data%20Evidence                                                                                  'The Roller Conduction Effect' from the A-share Data Evidence                                                                                  In the post-epidemic era, consumption recovery has obvious time and space transmission laws, and there are different valuation criteria for consumption segments. Using the A-share data of the consumption recovery stage from January to April 2022, this paper quantitatively compares the rotation effect between different consumption sectors when the valuation returns to the reasonable range. According to the new classification of 'sensory-based consumption', it interprets the internal logic of digital consumption as A consumption upgrade tool and a higher valuation target, and expounds the 'the roller conduction effect'. The law of consumption recovery and valuation return period is explained from the perspective of time and space conduction. The study found that in the early stage of consumption recovery, the recovery of consumer confidence was slow. In this period, A-shares were mainly dominated by the stock capital game, and there was an obvious plate rotation law in the game. Being familiar with this law has strong significance, which not only helps policy makers to adjust the direction of policy guidance, but also helps financial investors to make better investment strategies. The disadvantage of this paper is that it has not yet studied the roller conduction effect of the global financial market, and more rigorous mathematical models are still needed to support the definition of stock funds, which is also the main direction of the author's future research.
http://w3id.org/mlsea/pwc/scientificWork/%27This%20is%20not%20a%20data%20problem%27%3A%20Algorithms%20and%20Power%20in%20Public%20Higher%20Education%20in%20Canada                                                                                  'This is not a data problem': Algorithms and Power in Public Higher Education in Canada                                                                                  Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability.
http://w3id.org/mlsea/pwc/scientificWork/%27Understanding%20AI%27%3A%20Semantic%20Grounding%20in%20Large%20Language%20Models                                                                                  'Understanding AI': Semantic Grounding in Large Language Models                                                                                  Do LLMs understand the meaning of the texts they generate? Do they possess a semantic grounding? And how could we understand whether and what they understand? I start the paper with the observation that we have recently witnessed a generative turn in AI, since generative models, including LLMs, are key for self-supervised learning. To assess the question of semantic grounding, I distinguish and discuss five methodological ways. The most promising way is to apply core assumptions of theories of meaning in philosophy of mind and language to LLMs. Grounding proves to be a gradual affair with a three-dimensional distinction between functional, social and causal grounding. LLMs show basic evidence in all three dimensions. A strong argument is that LLMs develop world models. Hence, LLMs are neither stochastic parrots nor semantic zombies, but already understand the language they generate, at least in an elementary sense.
http://w3id.org/mlsea/pwc/scientificWork/%27What%27s%20my%20model%20inside%20of%3F%27%3A%20Exploring%20the%20role%20of%20environments%20for%20grounded%20natural%20language%20understanding                                                                                  'What's my model inside of?': Exploring the role of environments for grounded natural language understanding                                                                                  In contrast to classical cognitive science which studied brains in isolation, ecological approaches focused on the role of the body and environment in shaping cognition. Similarly, in this thesis we adopt an ecological approach to grounded natural language understanding (NLU) research. Grounded language understanding studies language understanding systems situated in the context of events, actions and precepts in naturalistic/simulated virtual environments. Where classic research tends to focus on designing new models and optimization methods while treating environments as given, we explore the potential of environment design for improving data collection and model development. We developed novel training and annotation approaches for procedural text understanding based on text-based game environments. We also drew upon embodied cognitive linguistics literature to propose a roadmap for grounded NLP research, and to inform the development of a new benchmark for measuring the progress of large language models on challenging commonsense reasoning tasks. We leveraged the richer supervision provided by text-based game environments to develop Breakpoint Transformers, a novel approach to modeling intermediate semantic information in long narrative or procedural texts. Finally, we integrated theories on the role of environments in collective human intelligence to propose a design for AI-augmented 'social thinking environments' for knowledge workers like scientists.
http://w3id.org/mlsea/pwc/scientificWork/%28Empirical%29%20Bayes%20Approaches%20to%20Parallel%20Trends                                                                                  (Empirical) Bayes Approaches to Parallel Trends                                                                                  We consider Bayes and Empirical Bayes (EB) approaches for dealing with violations of parallel trends. In the Bayes approach, the researcher specifies a prior over both the pre-treatment violations of parallel trends $ delta_{pre}$ and the post-treatment violations $ delta_{post}$. The researcher then updates their posterior about the post-treatment bias $ delta_{post}$ given an estimate of the pre-trends $ delta_{pre}$. This allows them to form posterior means and credible sets for the treatment effect of interest, $ tau_{post}$. In the EB approach, the prior on the violations of parallel trends is learned from the pre-treatment observations. We illustrate these approaches in two empirical applications.
http://w3id.org/mlsea/pwc/scientificWork/%28Not%29%20Understanding%20Latin%20Poetic%20Style%20with%20Deep%20Learning                                                                                  (Not) Understanding Latin Poetic Style with Deep Learning                                                                                  This article summarizes some mostly unsuccessful attempts to understand authorial style by examining the attention of various neural networks (LSTMs and CNNs) trained on a corpus of classical Latin verse that has been encoded to include sonic and metrical features. Carefully configured neural networks are shown to be extremely strong authorship classifiers, so it is hoped that they might therefore teach `traditional' readers something about how the authors differ in style. Sadly their reasoning is, so far, inscrutable. While the overall goal has not yet been reached, this work reports some useful findings in terms of effective ways to encode and embed verse, the relative strengths and weaknesses of the neural network families, and useful (and not so useful) techniques for designing and inspecting NN models in this domain. This article suggests that, for poetry, CNNs are better choices than LSTMs -- they train more quickly, have equivalent accuracy, and (potentially) offer better interpretability. Based on a great deal of experimentation, it also suggests that simple, trainable embeddings are more effective than domain-specific schemes, and stresses the importance of techniques to reduce overfitting, like dropout and batch normalization.
http://w3id.org/mlsea/pwc/scientificWork/%5BLions%3A%201%5D%20and%20%5BTigers%3A%202%5D%20and%20%5BBears%3A%203%5D%2C%20Oh%20My%21%20Literary%20Coreference%20Annotation%20with%20LLMs                                                                                  [Lions: 1] and [Tigers: 2] and [Bears: 3], Oh My! Literary Coreference Annotation with LLMs                                                                                  Coreference annotation and resolution is a vital component of computational literary studies. However, it has previously been difficult to build high quality systems for fiction. Coreference requires complicated structured outputs, and literary text involves subtle inferences and highly varied language. New language-model-based seq2seq systems present the opportunity to solve both these problems by learning to directly generate a copy of an input sentence with markdown-like annotations. We create, evaluate, and release several trained models for coreference, as well as a workflow for training new models.
http://w3id.org/mlsea/pwc/scientificWork/%60Eyes%20of%20a%20Hawk%20and%20Ears%20of%20a%20Fox%27%3A%20Part%20Prototype%20Network%20for%20Generalized%20Zero-Shot%20Learning                                                                                  `Eyes of a Hawk and Ears of a Fox': Part Prototype Network for Generalized Zero-Shot Learning                                                                                  Current approaches in Generalized Zero-Shot Learning (GZSL) are built upon base models which consider only a single class attribute vector representation over the entire image. This is an oversimplification of the process of novel category recognition, where different regions of the image may have properties from different seen classes and thus have different predominant attributes. With this in mind, we take a fundamentally different approach: a pre-trained Vision-Language detector (VINVL) sensitive to attribute information is employed to efficiently obtain region features. A learned function maps the region features to region-specific attribute attention used to construct class part prototypes. We conduct experiments on a popular GZSL benchmark consisting of the CUB, SUN, and AWA2 datasets where our proposed Part Prototype Network (PPN) achieves promising results when compared with other popular base models. Corresponding ablation studies and analysis show that our approach is highly practical and has a distinct advantage over global attribute attention when localized proposals are available.
http://w3id.org/mlsea/pwc/scientificWork/%60Keep%20it%20Together%27%3A%20Enforcing%20Cohesion%20in%20Extractive%20Summaries%20by%20Simulating%20Human%20Memory                                                                                  `Keep it Together': Enforcing Cohesion in Extractive Summaries by Simulating Human Memory                                                                                  Extractive summaries are usually presented as lists of sentences with no expected cohesion between them. In this paper, we aim to enforce cohesion whilst controlling for informativeness and redundancy in summaries, in cases where the input exhibits high redundancy. The pipeline controls for redundancy in long inputs as it is consumed, and balances informativeness and cohesion during sentence selection. Our sentence selector simulates human memory to keep track of topics --modeled as lexical chains--, enforcing cohesive ties between noun phrases. Across a variety of domains, our experiments revealed that it is possible to extract highly cohesive summaries that nevertheless read as informative to humans as summaries extracted by only accounting for informativeness or redundancy. The extracted summaries exhibit smooth topic transitions between sentences as signaled by lexical chains, with chains spanning adjacent or near-adjacent sentences.
http://w3id.org/mlsea/pwc/scientificWork/%C2%A9Plug-in%20Authorization%20for%20Human%20Content%20Copyright%20Protection%20in%20Text-to-Image%20Model                                                                                  ©Plug-in Authorization for Human Content Copyright Protection in Text-to-Image Model                                                                                  This paper addresses the contentious issue of copyright infringement in images generated by text-to-image models, sparking debates among AI developers, content creators, and legal entities. State-of-the-art models create high-quality content without crediting original creators, causing concern in the artistic community. To mitigate this, we propose the copyright Plug-in Authorization framework, introducing three operations: addition, extraction, and combination. Addition involves training a copyright plug-in for specific copyright, facilitating proper credit attribution. Extraction allows creators to reclaim copyright from infringing models, and combination enables users to merge different copyright plug-ins. These operations act as permits, incentivizing fair use and providing flexibility in authorization. We present innovative approaches,'Reverse LoRA' for extraction and 'EasyMerge' for seamless combination. Experiments in artist-style replication and cartoon IP recreation demonstrate copyright plug-ins' effectiveness, offering a valuable solution for human copyright protection in the age of generative AIs.
http://w3id.org/mlsea/pwc/scientificWork/%C3%89liv%C3%A1gar%3A%20Efficient%20Quantum%20Circuit%20Search%20for%20Classification                                                                                  Élivágar: Efficient Quantum Circuit Search for Classification                                                                                  Designing performant and noise-robust circuits for Quantum Machine Learning (QML) is challenging -- the design space scales exponentially with circuit size, and there are few well-supported guiding principles for QML circuit design. Although recent Quantum Circuit Search (QCS) methods attempt to search for performant QML circuits that are also robust to hardware noise, they directly adopt designs from classical Neural Architecture Search (NAS) that are misaligned with the unique constraints of quantum hardware, resulting in high search overheads and severe performance bottlenecks. We present 'Eliv 'agar, a novel resource-efficient, noise-guided QCS framework. 'Eliv 'agar innovates in all three major aspects of QCS -- search space, search algorithm and candidate evaluation strategy -- to address the design flaws in current classically-inspired QCS methods. 'Eliv 'agar achieves hardware-efficiency and avoids an expensive circuit-mapping co-search via noise- and device topology-aware candidate generation. By introducing two cheap-to-compute predictors, Clifford noise resilience and Representational capacity, 'Eliv 'agar decouples the evaluation of noise robustness and performance, enabling early rejection of low-fidelity circuits and reducing circuit evaluation costs. Due to its resource-efficiency, 'Eliv 'agar can further search for data embeddings, significantly improving performance. Based on a comprehensive evaluation of 'Eliv 'agar on 12 real quantum devices and 9 QML applications, 'Eliv 'agar achieves 5.3% higher accuracy and a 271$ times$ speedup compared to state-of-the-art QCS methods.
http://w3id.org/mlsea/pwc/scientificWork/100%20Gbps%20Indoor%20Access%20and%204.8%20Gbps%20Outdoor%20Point-to-Point%20LiFi%20Transmission%20Systems%20using%20Laser-based%20Light%20Sources                                                                                  100 Gbps Indoor Access and 4.8 Gbps Outdoor Point-to-Point LiFi Transmission Systems using Laser-based Light Sources                                                                                  In this paper, we demonstrate the communication capabilities of light-fidelity (LiFi) systems based on highbrightness and high-bandwidth integrated laser-based sources in a surface mount device (SMD) packaging platform. The laserbased source is able to deliver 450 lumens of white light illumination and the resultant light brightness is over 1000 cd mm2. It is demonstrated that a wavelength division multiplexing (WDM) LiFi system with ten parallel channels is able to deliver over 100 Gbps data rate with the assistance of Volterra filter-based nonlinear equalisers. In addition, an aggregated transmission data rate of 4.8 Gbps has been achieved over a link distance of 500 m with the same type of SMD light source. This work demonstrates the scalability of LiFi systems that employ laserbased light sources, particularly in their capacity to enable highspeed short range, as well as long-range data transmission.
http://w3id.org/mlsea/pwc/scientificWork/2-Cats%3A%202D%20Copula%20Approximating%20Transforms                                                                                  2-Cats: 2D Copula Approximating Transforms                                                                                  Copulas are powerful statistical tools for capturing dependencies across multiple data dimensions. Applying Copulas involves estimating independent marginals, a straightforward task, followed by the much more challenging task of determining a single copulating function, $C$, that links these marginals. For bivariate data, a copula takes the form of a two-increasing function $C: (u,v) in mathbb{I}^2 rightarrow mathbb{I}$, where $ mathbb{I} = [0, 1]$. In this paper, we propose 2-Cats, a Neural Network (NN) model that learns two-dimensional Copulas while preserving their key properties, without relying on specific Copula families (e.g., Archimedean). Furthermore, we introduce a training strategy inspired by the literature on Physics-Informed Neural Networks and Sobolev Training. Our proposed method exhibits superior performance compared to the state-of-the-art across various datasets while maintaining the fundamental mathematical properties of a Copula.
http://w3id.org/mlsea/pwc/scientificWork/2D%20Gaussian%20Splatting%20for%20Geometrically%20Accurate%20Radiance%20Fields                                                                                  2D Gaussian Splatting for Geometrically Accurate Radiance Fields                                                                                  3D Gaussian Splatting (3DGS) has recently revolutionized radiance field reconstruction, achieving high quality novel view synthesis and fast rendering speed without baking. However, 3DGS fails to accurately represent surfaces due to the multi-view inconsistent nature of 3D Gaussians. We present 2D Gaussian Splatting (2DGS), a novel approach to model and reconstruct geometrically accurate radiance fields from multi-view images. Our key idea is to collapse the 3D volume into a set of 2D oriented planar Gaussian disks. Unlike 3D Gaussians, 2D Gaussians provide view-consistent geometry while modeling surfaces intrinsically. To accurately recover thin surfaces and achieve stable optimization, we introduce a perspective-accurate 2D splatting process utilizing ray-splat intersection and rasterization. Additionally, we incorporate depth distortion and normal consistency terms to further enhance the quality of the reconstructions. We demonstrate that our differentiable renderer allows for noise-free and detailed geometry reconstruction while maintaining competitive appearance quality, fast training speed, and real-time rendering. Our code will be made publicly available.
http://w3id.org/mlsea/pwc/scientificWork/3-D%20Position%20Optimization%20of%20Solar-Powered%20Hovering%20UAV%20Relay%20in%20Optical%20Wireless%20Backhaul                                                                                  3-D Position Optimization of Solar-Powered Hovering UAV Relay in Optical Wireless Backhaul                                                                                  A major hurdle in widespread deployment of UAVs (unmanned aerial vehicle) in existing communications infrastructure is the limited UAV onboard energy. Therefore, this study considers solar energy harvesting UAVs for wireless communications. In this context, we consider three dimensional position optimization of a solar-powered UAV relay that connects a distant sensor field to an optical ground station (OGS) for data processing. The integrated sensor-UAV-OGS network utilizes radio frequency band for sensor-to-UAV links and the optical band for the UAV-to-OGS feeder link. Since atmospheric conditions affect both the harvested solar energy as well as the optical wireless signal, this study tackles UAV position optimization problems under various channel conditions such as clouds, atmospheric turbulence and dirt. From this study, we discover that the optimum position of the UAV -- that maximizes the end-to-end channel capacity -- is heavily dependent on the atmospheric channel conditions.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Human%20Scan%20With%20A%20Moving%20Event%20Camera                                                                                  3D Human Scan With A Moving Event Camera                                                                                  Capturing a 3D human body is one of the important tasks in computer vision with a wide range of applications such as virtual reality and sports analysis. However, conventional frame cameras are limited by their temporal resolution and dynamic range, which imposes constraints in real-world application setups. Event cameras have the advantages of high temporal resolution and high dynamic range (HDR), but the development of event-based methods is necessary to handle data with different characteristics. This paper proposes a novel event-based method for 3D pose estimation and human mesh recovery. Prior work on event-based human mesh recovery require frames (images) as well as event data. The proposed method solely relies on events; it carves 3D voxels by moving the event camera around a stationary body, reconstructs the human pose and mesh by attenuated rays, and fit statistical body models, preserving high-frequency details. The experimental results show that the proposed method outperforms conventional frame-based methods in the estimation accuracy of both pose and body mesh. We also demonstrate results in challenging situations where a conventional camera has motion blur. This is the first to demonstrate event-only human mesh recovery, and we hope that it is the first step toward achieving robust and accurate 3D human body scanning from vision sensors. https://florpeng.github.io/event-based-human-scan/
http://w3id.org/mlsea/pwc/scientificWork/3D%20Object%20Detection%20and%20High-Resolution%20Traffic%20Parameters%20Extraction%20Using%20Low-Resolution%20LiDAR%20Data                                                                                  3D Object Detection and High-Resolution Traffic Parameters Extraction Using Low-Resolution LiDAR Data                                                                                  Traffic volume data collection is a crucial aspect of transportation engineering and urban planning, as it provides vital insights into traffic patterns, congestion, and infrastructure efficiency. Traditional manual methods of traffic data collection are both time-consuming and costly. However, the emergence of modern technologies, particularly Light Detection and Ranging (LiDAR), has revolutionized the process by enabling efficient and accurate data collection. Despite the benefits of using LiDAR for traffic data collection, previous studies have identified two major limitations that have impeded its widespread adoption. These are the need for multiple LiDAR systems to obtain complete point cloud information of objects of interest, as well as the labor-intensive process of annotating 3D bounding boxes for object detection tasks. In response to these challenges, the current study proposes an innovative framework that alleviates the need for multiple LiDAR systems and simplifies the laborious 3D annotation process. To achieve this goal, the study employed a single LiDAR system, that aims at reducing the data acquisition cost and addressed its accompanying limitation of missing point cloud information by developing a Point Cloud Completion (PCC) framework to fill in missing point cloud information using point density. Furthermore, we also used zero-shot learning techniques to detect vehicles and pedestrians, as well as proposed a unique framework for extracting low to high features from the object of interest, such as height, acceleration, and speed. Using the 2D bounding box detection and extracted height information, this study is able to generate 3D bounding boxes automatically without human intervention.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Reconstruction%20of%20Interacting%20Multi-Person%20in%20Clothing%20from%20a%20Single%20Image                                                                                  3D Reconstruction of Interacting Multi-Person in Clothing from a Single Image                                                                                  This paper introduces a novel pipeline to reconstruct the geometry of interacting multi-person in clothing on a globally coherent scene space from a single image. The main challenge arises from the occlusion: a part of a human body is not visible from a single view due to the occlusion by others or the self, which introduces missing geometry and physical implausibility (e.g., penetration). We overcome this challenge by utilizing two human priors for complete 3D geometry and surface contacts. For the geometry prior, an encoder learns to regress the image of a person with missing body parts to the latent vectors; a decoder decodes these vectors to produce 3D features of the associated geometry; and an implicit network combines these features with a surface normal map to reconstruct a complete and detailed 3D humans. For the contact prior, we develop an image-space contact detector that outputs a probability distribution of surface contacts between people in 3D. We use these priors to globally refine the body poses, enabling the penetration-free and accurate reconstruction of interacting multi-person in clothing on the scene space. The results demonstrate that our method is complete, globally coherent, and physically plausible compared to existing methods.
http://w3id.org/mlsea/pwc/scientificWork/3D%20Vertebrae%20Measurements%3A%20Assessing%20Vertebral%20Dimensions%20in%20Human%20Spine%20Mesh%20Models%20Using%20Local%20Anatomical%20Vertebral%20Axes                                                                                  3D Vertebrae Measurements: Assessing Vertebral Dimensions in Human Spine Mesh Models Using Local Anatomical Vertebral Axes                                                                                  Vertebral morphological measurements are important across various disciplines, including spinal biomechanics and clinical applications, pre- and post-operatively. These measurements also play a crucial role in anthropological longitudinal studies, where spinal metrics are repeatedly documented over extended periods. Traditionally, such measurements have been manually conducted, a process that is time-consuming. In this study, we introduce a novel, fully automated method for measuring vertebral morphology using 3D meshes of lumbar and thoracic spine models.Our experimental results demonstrate the method's capability to accurately measure low-resolution patient-specific vertebral meshes with mean absolute error (MAE) of 1.09 mm and those derived from artificially created lumbar spines, where the average MAE value was 0.7 mm. Our qualitative analysis indicates that measurements obtained using our method on 3D spine models can be accurately reprojected back onto the original medical images if these images are available.
http://w3id.org/mlsea/pwc/scientificWork/3DGS-Calib%3A%203D%20Gaussian%20Splatting%20for%20Multimodal%20SpatioTemporal%20Calibration                                                                                  3DGS-Calib: 3D Gaussian Splatting for Multimodal SpatioTemporal Calibration                                                                                  Reliable multimodal sensor fusion algorithms re- quire accurate spatiotemporal calibration. Recently, targetless calibration techniques based on implicit neural representations have proven to provide precise and robust results. Nevertheless, such methods are inherently slow to train given the high compu- tational overhead caused by the large number of sampled points required for volume rendering. With the recent introduction of 3D Gaussian Splatting as a faster alternative to implicit representation methods, we propose to leverage this new ren- dering approach to achieve faster multi-sensor calibration. We introduce 3DGS-Calib, a new calibration method that relies on the speed and rendering accuracy of 3D Gaussian Splatting to achieve multimodal spatiotemporal calibration that is accurate, robust, and with a substantial speed-up compared to methods relying on implicit neural representations. We demonstrate the superiority of our proposal with experimental results on sequences from KITTI-360, a widely used driving dataset.
http://w3id.org/mlsea/pwc/scientificWork/3DMambaComplete%3A%20Exploring%20Structured%20State%20Space%20Model%20for%20Point%20Cloud%20Completion                                                                                  3DMambaComplete: Exploring Structured State Space Model for Point Cloud Completion                                                                                  Point cloud completion aims to generate a complete and high-fidelity point cloud from an initially incomplete and low-quality input. A prevalent strategy involves leveraging Transformer-based models to encode global features and facilitate the reconstruction process. However, the adoption of pooling operations to obtain global feature representations often results in the loss of local details within the point cloud. Moreover, the attention mechanism inherent in Transformers introduces additional computational complexity, rendering it challenging to handle long sequences effectively. To address these issues, we propose 3DMambaComplete, a point cloud completion network built on the novel Mamba framework. It comprises three modules: HyperPoint Generation encodes point cloud features using Mamba's selection mechanism and predicts a set of Hyperpoints. A specific offset is estimated, and the down-sampled points become HyperPoints. The HyperPoint Spread module disperses these HyperPoints across different spatial locations to avoid concentration. Finally, a deformation method transforms the 2D mesh representation of HyperPoints into a fine-grained 3D structure for point cloud reconstruction. Extensive experiments conducted on various established benchmarks demonstrate that 3DMambaComplete surpasses state-of-the-art point cloud completion methods, as confirmed by qualitative and quantitative analyses.
http://w3id.org/mlsea/pwc/scientificWork/3DPFIX%3A%20Improving%20Remote%20Novices%27%203D%20Printing%20Troubleshooting%20through%20Human-AI%20Collaboration                                                                                  3DPFIX: Improving Remote Novices' 3D Printing Troubleshooting through Human-AI Collaboration                                                                                  The widespread consumer-grade 3D printers and learning resources online enable novices to self-train in remote settings. While troubleshooting plays an essential part of 3D printing, the process remains challenging for many remote novices even with the help of well-developed online sources, such as online troubleshooting archives and online community help. We conducted a formative study with 76 active 3D printing users to learn how remote novices leverage online resources in troubleshooting and their challenges. We found that remote novices cannot fully utilize online resources. For example, the online archives statically provide general information, making it hard to search and relate their unique cases with existing descriptions. Online communities can potentially ease their struggles by providing more targeted suggestions, but a helper who can provide custom help is rather scarce, making it hard to obtain timely assistance. We propose 3DPFIX, an interactive 3D troubleshooting system powered by the pipeline to facilitate Human-AI Collaboration, designed to improve novices' 3D printing experiences and thus help them easily accumulate their domain knowledge. We built 3DPFIX that supports automated diagnosis and solution-seeking. 3DPFIX was built upon shared dialogues about failure cases from Q&A discourses accumulated in online communities. We leverage social annotations (i.e., comments) to build an annotated failure image dataset for AI classifiers and extract a solution pool. Our summative study revealed that using 3DPFIX helped participants spend significantly less effort in diagnosing failures and finding a more accurate solution than relying on their common practice. We also found that 3DPFIX users learn about 3D printing domain-specific knowledge. We discuss the implications of leveraging community-driven data in developing future Human-AI Collaboration designs.
http://w3id.org/mlsea/pwc/scientificWork/3M-Diffusion%3A%20Latent%20Multi-Modal%20Diffusion%20for%20Text-Guided%20Generation%20of%20Molecular%20Graphs                                                                                  3M-Diffusion: Latent Multi-Modal Diffusion for Text-Guided Generation of Molecular Graphs                                                                                  Generating molecules with desired properties is a critical task with broad applications in drug discovery and materials design. Inspired by recent advances in large language models, there is a growing interest in using natural language descriptions of molecules to generate molecules with the desired properties. Most existing methods focus on generating molecules that precisely match the text description. However, practical applications call for methods that generate diverse, and ideally novel, molecules with the desired properties. We propose 3M-Diffusion, a novel multi-modal molecular graph generation method, to address this challenge. 3M-Diffusion first encodes molecular graphs into a graph latent space aligned with text descriptions. It then reconstructs the molecular structure and atomic attributes based on the given text descriptions using the molecule decoder. It then learns a probabilistic mapping from the text space to the latent molecular graph space using a diffusion model. The results of our extensive experiments on several datasets demonstrate that 3M-Diffusion can generate high-quality, novel and diverse molecular graphs that semantically match the textual description provided.
http://w3id.org/mlsea/pwc/scientificWork/4D-ONIX%3A%20A%20deep%20learning%20approach%20for%20reconstructing%203D%20movies%20from%20sparse%20X-ray%20projections                                                                                  4D-ONIX: A deep learning approach for reconstructing 3D movies from sparse X-ray projections                                                                                  The X-ray flux provided by X-ray free-electron lasers and storage rings offers new spatiotemporal possibilities to study in-situ and operando dynamics, even using single pulses of such facilities. X-ray Multi-Projection Imaging (XMPI) is a novel technique that enables volumetric information using single pulses of such facilities and avoids centrifugal forces induced by state-of-the-art time-resolved 3D methods such as time-resolved tomography. As a result, XMPI can acquire 3D movies (4D) at least three orders of magnitude faster than current methods. However, it is exceptionally challenging to reconstruct 4D from highly sparse projections as acquired by XMPI with current algorithms. Here, we present 4D-ONIX, a Deep Learning (DL)-based approach that learns to reconstruct 3D movies (4D) from an extremely limited number of projections. It combines the computational physical model of X-ray interaction with matter and state-of-the-art DL methods. We demonstrate the potential of 4D-ONIX to generate high-quality 4D by generalizing over multiple experiments with only two projections per timestamp for binary droplet collisions. We envision that 4D-ONIX will become an enabling tool for 4D analysis, offering new spatiotemporal resolutions to study processes not possible before.
http://w3id.org/mlsea/pwc/scientificWork/94%25%20on%20CIFAR-10%20in%203.29%20Seconds%20on%20a%20Single%20GPU                                                                                  94% on CIFAR-10 in 3.29 Seconds on a Single GPU                                                                                  CIFAR-10 is among the most widely used datasets in machine learning, facilitating thousands of research projects per year. To accelerate research and reduce the cost of experiments, we introduce training methods for CIFAR-10 which reach 94% accuracy in 3.29 seconds, 95% in 10.4 seconds, and 96% in 46.3 seconds, when run on a single NVIDIA A100 GPU. As one factor contributing to these training speeds, we propose a derandomized variant of horizontal flipping augmentation, which we show improves over the standard method in every case where flipping is beneficial over no flipping at all. Our code is released at https://github.com/KellerJordan/cifar10-airbench.
http://w3id.org/mlsea/pwc/scientificWork/A%202D%20Sinogram-Based%20Approach%20to%20Defect%20Localization%20in%20Computed%20Tomography                                                                                  A 2D Sinogram-Based Approach to Defect Localization in Computed Tomography                                                                                  The rise of deep learning has introduced a transformative era in the field of image processing, particularly in the context of computed tomography. Deep learning has made a significant contribution to the field of industrial Computed Tomography. However, many defect detection algorithms are applied directly to the reconstructed domain, often disregarding the raw sensor data. This paper shifts the focus to the use of sinograms. Within this framework, we present a comprehensive three-step deep learning algorithm, designed to identify and analyze defects within objects without resorting to image reconstruction. These three steps are defect segmentation, mask isolation, and defect analysis. We use a U-Net-based architecture for defect segmentation. Our method achieves the Intersection over Union of 92.02% on our simulated data, with an average position error of 1.3 pixels for defect detection on a 512-pixel-wide detector.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bag%20of%20Tricks%20for%20Few-Shot%20Class-Incremental%20Learning                                                                                  A Bag of Tricks for Few-Shot Class-Incremental Learning                                                                                  We present a bag of tricks framework for few-shot class-incremental learning (FSCIL), which is a challenging form of continual learning that involves continuous adaptation to new tasks with limited samples. FSCIL requires both stability and adaptability, i.e., preserving proficiency in previously learned tasks while learning new ones. Our proposed bag of tricks brings together eight key and highly influential techniques that improve stability, adaptability, and overall performance under a unified framework for FSCIL. We organize these tricks into three categories: stability tricks, adaptability tricks, and training tricks. Stability tricks aim to mitigate the forgetting of previously learned classes by enhancing the separation between the embeddings of learned classes and minimizing interference when learning new ones. On the other hand, adaptability tricks focus on the effective learning of new classes. Finally, training tricks improve the overall performance without compromising stability or adaptability. We perform extensive experiments on three benchmark datasets, CIFAR-100, CUB-200, and miniIMageNet, to evaluate the impact of our proposed framework. Our detailed analysis shows that our approach substantially improves both stability and adaptability, establishing a new state-of-the-art by outperforming prior works in the area. We believe our method provides a go-to solution and establishes a robust baseline for future research in this area.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bayesian%20Approach%20to%20Online%20Learning%20for%20Contextual%20Restless%20Bandits%20with%20Applications%20to%20Public%20Health                                                                                  A Bayesian Approach to Online Learning for Contextual Restless Bandits with Applications to Public Health                                                                                  Restless multi-armed bandits (RMABs) are used to model sequential resource allocation in public health intervention programs. In these settings, the underlying transition dynamics are often unknown a priori, requiring online reinforcement learning (RL). However, existing methods in online RL for RMABs cannot incorporate properties often present in real-world public health applications, such as contextual information and non-stationarity. We present Bayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABs that novelly combines techniques in Bayesian modeling with Thompson sampling to flexibly model a wide range of complex RMAB settings, such as contextual and non-stationary RMABs. A key contribution of our approach is its ability to leverage shared information within and between arms to learn unknown RMAB transition dynamics quickly in budget-constrained settings with relatively short time horizons. Empirically, we show that BCoR achieves substantially higher finite-sample performance than existing approaches over a range of experimental settings, including one constructed from a real-world public health campaign in India.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bayesian%20Learning%20Algorithm%20for%20Unknown%20Zero-sum%20Stochastic%20Games%20with%20an%20Arbitrary%20Opponent                                                                                  A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent                                                                                  In this paper, we propose Posterior Sampling Reinforcement Learning for Zero-sum Stochastic Games (PSRL-ZSG), the first online learning algorithm that achieves Bayesian regret bound of $O(HS sqrt{AT})$ in the infinite-horizon zero-sum stochastic games with average-reward criterion. Here $H$ is an upper bound on the span of the bias function, $S$ is the number of states, $A$ is the number of joint actions and $T$ is the horizon. We consider the online setting where the opponent can not be controlled and can take any arbitrary time-adaptive history-dependent strategy. Our regret bound improves on the best existing regret bound of $O( sqrt[3]{DS^2AT^2})$ by Wei et al. (2017) under the same assumption and matches the theoretical lower bound in $T$.
http://w3id.org/mlsea/pwc/scientificWork/A%20Benchmark%20Dataset%20for%20Tornado%20Detection%20and%20Prediction%20using%20Full-Resolution%20Polarimetric%20Weather%20Radar%20Data                                                                                  A Benchmark Dataset for Tornado Detection and Prediction using Full-Resolution Polarimetric Weather Radar Data                                                                                  Weather radar is the primary tool used by forecasters to detect and warn for tornadoes in near-real time. In order to assist forecasters in warning the public, several algorithms have been developed to automatically detect tornadic signatures in weather radar observations. Recently, Machine Learning (ML) algorithms, which learn directly from large amounts of labeled data, have been shown to be highly effective for this purpose. Since tornadoes are extremely rare events within the corpus of all available radar observations, the selection and design of training datasets for ML applications is critical for the performance, robustness, and ultimate acceptance of ML algorithms. This study introduces a new benchmark dataset, TorNet to support development of ML algorithms in tornado detection and prediction. TorNet contains full-resolution, polarimetric, Level-II WSR-88D data sampled from 10 years of reported storm events. A number of ML baselines for tornado detection are developed and compared, including a novel deep learning (DL) architecture capable of processing raw radar imagery without the need for manual feature extraction required for existing ML algorithms. Despite not benefiting from manual feature engineering or other preprocessing, the DL model shows increased detection performance compared to non-DL and operational baselines. The TorNet dataset, as well as source code and model weights of the DL baseline trained in this work, are made freely available.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bi-consolidating%20Model%20for%20Joint%20Relational%20Triple%20Extraction                                                                                  A Bi-consolidating Model for Joint Relational Triple Extraction                                                                                  Current methods to extract relational triples directly make a prediction based on a possible entity pair in a raw sentence without depending on entity recognition. The task suffers from a serious semantic overlapping problem, in which several relation triples may share one or two entities in a sentence. It is weak to learn discriminative semantic features relevant to a relation triple. In this paper, based on a two-dimensional sentence representation, a bi-consolidating model is proposed to address this problem by simultaneously reinforcing the local and global semantic features relevant to a relation triple. This model consists of a local consolidation component and a global consolidation component. The first component uses a pixel difference convolution to enhance semantic information of a possible triple representation from adjacent regions and mitigate noise in neighbouring neighbours. The second component strengthens the triple representation based a channel attention and a spatial attention, which has the advantage to learn remote semantic dependencies in a sentence. They are helpful to improve the performance of both entity identification and relation type classification in relation triple extraction. After evaluated on several publish datasets, it achieves competitive performance. Analytical experiments demonstrate the effectiveness of our model for relational triple extraction and give motivation for other natural language processing tasks.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bionic%20Data-driven%20Approach%20for%20Long-distance%20Underwater%20Navigation%20with%20Anomaly%20Resistance                                                                                  A Bionic Data-driven Approach for Long-distance Underwater Navigation with Anomaly Resistance                                                                                  Various animals exhibit accurate navigation using environment cues. The Earth's magnetic field has been proved a reliable information source in long-distance fauna migration. Inspired by animal navigation, this work proposes a bionic and data-driven approach for long-distance underwater navigation. The proposed approach uses measured geomagnetic data for the navigation, and requires no GPS systems or geographical maps. Particularly, we construct and train a Temporal Attention-based Long Short-Term Memory (TA-LSTM) network to predict the heading angle during the navigation. To mitigate the impact of geomagnetic anomalies, we develop the mechanism to detect and quantify the anomalies based on Maximum Likelihood Estimation. We integrate the developed mechanism with the TA-LSTM, and calibrate the predicted heading angles to gain resistance against geomagnetic anomalies. Using the retrieved data from the WMM model, we conduct numerical simulations with diversified navigation conditions to test our approach. The simulation results demonstrate a resilience navigation against geomagnetic anomalies by our approach, along with precision and stability of the underwater navigation in single and multiple destination missions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Bound%20on%20the%20Maximal%20Marginal%20Degrees%20of%20Freedom                                                                                  A Bound on the Maximal Marginal Degrees of Freedom                                                                                  Common kernel ridge regression is expensive in memory allocation and computation time. This paper addresses low rank approximations and surrogates for kernel ridge regression, which bridge these difficulties. The fundamental contribution of the paper is a lower bound on the rank of the low dimensional approximation, which is required such that the prediction power remains reliable. The bound relates the effective dimension with the largest statistical leverage score. We characterize the effective dimension and its growth behavior with respect to the regularization parameter by involving the regularity of the kernel. This growth is demonstrated to be asymptotically logarithmic for suitably chosen kernels, justifying low-rank approximations as the Nystr 'om method.
http://w3id.org/mlsea/pwc/scientificWork/A%20Ca%24%5E%7B2%2B%7D%24%20puff%20model%20based%20on%20integrodifferential%20equations                                                                                  A Ca$^{2+}$ puff model based on integrodifferential equations                                                                                  The calcium (Ca$^{2+}$) signalling system is important for many cellular processes within the human body. Signals are transmitted within the cell by releasing Ca$^{2+}$ from the endoplasmic reticulum (ER) into the cytosol via clusters of Ca$^{2+}$ channels. Mathematical models of Ca$^{2+}$ release via inositol 1,4,5-trisphosphate receptors (IP$_{3}$R) help with understanding underlying Ca$^{2+}$ dynamics but data-driven modelling of stochastic Ca$^{2+}$ release events, known as Ca$^{2+}$ puffs, is a difficult challenge. Parameterising Markov models for representing the IP$_{3}$R with steady-state single channel data obtained at fixed combinations of the ligands Ca$^{2+}$ and inositol-trisphosphate (IP$_{3}$) has previously been demonstrated to be insufficient. However, by extending an IP$_{3}$R model based on steady-state data with an integral term that incorporates the delayed response of the channel to varying Ca$^{2+}$ concentrations we succeed in generating realistic Ca$^{2+}$ puffs. By interpreting the integral term as a weighted average of Ca$^{2+}$ concentrations that extend over a time interval of length $ tau$ into the past we conclude that the IP$_{3}$R requires a certain amount of memory of past ligand concentrations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Causal%20Analysis%20of%20CO2%20Reduction%20Strategies%20in%20Electricity%20Markets%20Through%20Machine%20Learning-Driven%20Metalearners                                                                                  A Causal Analysis of CO2 Reduction Strategies in Electricity Markets Through Machine Learning-Driven Metalearners                                                                                  This study employs the Causal Machine Learning (CausalML) statistical method to analyze the influence of electricity pricing policies on carbon dioxide (CO2) levels in the household sector. Investigating the causality between potential outcomes and treatment effects, where changes in pricing policies are the treatment, our analysis challenges the conventional wisdom surrounding incentive-based electricity pricing. The study's findings suggest that adopting such policies may inadvertently increase CO2 intensity. Additionally, we integrate a machine learning-based meta-algorithm, reflecting a contemporary statistical approach, to enhance the depth of our causal analysis. The study conducts a comparative analysis of learners X, T, S, and R to ascertain the optimal methods based on the defined question's specified goals and contextual nuances. This research contributes valuable insights to the ongoing dialogue on sustainable development practices, emphasizing the importance of considering unintended consequences in policy formulation.
http://w3id.org/mlsea/pwc/scientificWork/A%20Causal%20Framework%20to%20Evaluate%20Racial%20Bias%20in%20Law%20Enforcement%20Systems                                                                                  A Causal Framework to Evaluate Racial Bias in Law Enforcement Systems                                                                                  We are interested in developing a data-driven method to evaluate race-induced biases in law enforcement systems. While the recent works have addressed this question in the context of police-civilian interactions using police stop data, they have two key limitations. First, bias can only be properly quantified if true criminality is accounted for in addition to race, but it is absent in prior works. Second, law enforcement systems are multi-stage and hence it is important to isolate the true source of bias within the 'causal chain of interactions' rather than simply focusing on the end outcome; this can help guide reforms. In this work, we address these challenges by presenting a multi-stage causal framework incorporating criminality. We provide a theoretical characterization and an associated data-driven method to evaluate (a) the presence of any form of racial bias, and (b) if so, the primary source of such a bias in terms of race and criminality. Our framework identifies three canonical scenarios with distinct characteristics: in settings like (1) airport security, the primary source of observed bias against a race is likely to be bias in law enforcement against innocents of that race; (2) AI-empowered policing, the primary source of observed bias against a race is likely to be bias in law enforcement against criminals of that race; and (3) police-civilian interaction, the primary source of observed bias against a race could be bias in law enforcement against that race or bias from the general public in reporting against the other race. Through an extensive empirical study using police-civilian interaction data and 911 call data, we find an instance of such a counter-intuitive phenomenon: in New Orleans, the observed bias is against the majority race and the likely reason for it is the over-reporting (via 911 calls) of incidents involving the minority race by the general public.
http://w3id.org/mlsea/pwc/scientificWork/A%20Causal%20Inspired%20Early-Branching%20Structure%20for%20Domain%20Generalization                                                                                  A Causal Inspired Early-Branching Structure for Domain Generalization                                                                                  Learning domain-invariant semantic representations is crucial for achieving domain generalization (DG), where a model is required to perform well on unseen target domains. One critical challenge is that standard training often results in entangled semantic and domain-specific features. Previous works suggest formulating the problem from a causal perspective and solving the entanglement problem by enforcing marginal independence between the causal ( ie semantic) and non-causal ( ie domain-specific) features. Despite its simplicity, the basic marginal independent-based idea alone may be insufficient to identify the causal feature. By d-separation, we observe that the causal feature can be further characterized by being independent of the domain conditioned on the object, and we propose the following two strategies as complements for the basic framework. First, the observation implicitly implies that for the same object, the causal feature should not be associated with the non-causal feature, revealing that the common practice of obtaining the two features with a shared base feature extractor and two lightweight prediction heads might be inappropriate. To meet the constraint, we propose a simple early-branching structure, where the causal and non-causal feature obtaining branches share the first few blocks while diverging thereafter, for better structure design; Second, the observation implies that the causal feature remains invariant across different domains for the same object. To this end, we suggest that augmentation should be incorporated into the framework to better characterize the causal feature, and we further suggest an effective random domain sampling scheme to fulfill the task. Theoretical and experimental results show that the two strategies are beneficial for the basic marginal independent-based framework. Code is available at url{https://github.com/liangchen527/CausEB}.
http://w3id.org/mlsea/pwc/scientificWork/A%20Change%20Detection%20Reality%20Check                                                                                  A Change Detection Reality Check                                                                                  In recent years, there has been an explosion of proposed change detection deep learning architectures in the remote sensing literature. These approaches claim to offer state-of-the-art performance on different standard benchmark datasets. However, has the field truly made significant progress? In this paper we perform experiments which conclude a simple U-Net segmentation baseline without training tricks or complicated architectural changes is still a top performer for the task of change detection.
http://w3id.org/mlsea/pwc/scientificWork/A%20Change%20Point%20Detection%20Integrated%20Remaining%20Useful%20Life%20Estimation%20Model%20under%20Variable%20Operating%20Conditions                                                                                  A Change Point Detection Integrated Remaining Useful Life Estimation Model under Variable Operating Conditions                                                                                  By informing the onset of the degradation process, health status evaluation serves as a significant preliminary step for reliable remaining useful life (RUL) estimation of complex equipment. This paper proposes a novel temporal dynamics learning-based model for detecting change points of individual devices, even under variable operating conditions, and utilises the learnt change points to improve the RUL estimation accuracy. During offline model development, the multivariate sensor data are decomposed to learn fused temporal correlation features that are generalisable and representative of normal operation dynamics across multiple operating conditions. Monitoring statistics and control limit thresholds for normal behaviour are dynamically constructed from these learnt temporal features for the unsupervised detection of device-level change points. The detected change points then inform the degradation data labelling for training a long short-term memory (LSTM)-based RUL estimation model. During online monitoring, the temporal correlation dynamics of a query device is monitored for breach of the control limit derived in offline training. If a change point is detected, the device's RUL is estimated with the well-trained offline model for early preventive action. Using C-MAPSS turbofan engines as the case study, the proposed method improved the accuracy by 5.6 % and 7.5 % for two scenarios with six operating conditions, when compared to existing LSTM-based RUL estimation models that do not consider heterogeneous change points.
http://w3id.org/mlsea/pwc/scientificWork/A%20Class-aware%20Optimal%20Transport%20Approach%20with%20Higher-Order%20Moment%20Matching%20for%20Unsupervised%20Domain%20Adaptation                                                                                  A Class-aware Optimal Transport Approach with Higher-Order Moment Matching for Unsupervised Domain Adaptation                                                                                  Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain. In this paper, we introduce a novel approach called class-aware optimal transport (OT), which measures the OT distance between a distribution over the source class-conditional distributions and a mixture of source and target data distribution. Our class-aware OT leverages a cost function that determines the matching extent between a given data example and a source class-conditional distribution. By optimizing this cost function, we find the optimal matching between target examples and source class-conditional distributions, effectively addressing the data and label shifts that occur between the two domains. To handle the class-aware OT efficiently, we propose an amortization solution that employs deep neural networks to formulate the transportation probabilities and the cost function. Additionally, we propose minimizing class-aware Higher-order Moment Matching (HMM) to align the corresponding class regions on the source and target domains. The class-aware HMM component offers an economical computational approach for accurately evaluating the HMM distance between the two distributions. Extensive experiments on benchmark datasets demonstrate that our proposed method significantly outperforms existing state-of-the-art baselines.
http://w3id.org/mlsea/pwc/scientificWork/A%20Classifier-Based%20Approach%20to%20Multi-Class%20Anomaly%20Detection%20for%20Astronomical%20Transients                                                                                  A Classifier-Based Approach to Multi-Class Anomaly Detection for Astronomical Transients                                                                                  Automating real-time anomaly detection is essential for identifying rare transients in the era of large-scale astronomical surveys. Modern survey telescopes are generating tens of thousands of alerts per night, and future telescopes, such as the Vera C. Rubin Observatory, are projected to increase this number dramatically. Currently, most anomaly detection algorithms for astronomical transients rely either on hand-crafted features extracted from light curves or on features generated through unsupervised representation learning, which are then coupled with standard machine learning anomaly detection algorithms. In this work, we introduce an alternative approach to detecting anomalies: using the penultimate layer of a neural network classifier as the latent space for anomaly detection. We then propose a novel method, named Multi-Class Isolation Forests (MCIF), which trains separate isolation forests for each class to derive an anomaly score for a light curve from the latent space representation given by the classifier. This approach significantly outperforms a standard isolation forest. We also use a simpler input method for real-time transient classifiers which circumvents the need for interpolation in light curves and helps the neural network model inter-passband relationships and handle irregular sampling. Our anomaly detection pipeline identifies rare classes including kilonovae, pair-instability supernovae, and intermediate luminosity transients shortly after trigger on simulated Zwicky Transient Facility light curves. Using a sample of our simulations that matched the population of anomalies expected in nature (54 anomalies and 12,040 common transients), our method was able to discover $41 pm3$ anomalies (~75% recall) after following up the top 2000 (~15%) ranked transients. Our novel method shows that classifiers can be effectively repurposed for real-time anomaly detection.
http://w3id.org/mlsea/pwc/scientificWork/A%20Closer%20Look%20at%20AUROC%20and%20AUPRC%20under%20Class%20Imbalance                                                                                  A Closer Look at AUROC and AUPRC under Class Imbalance                                                                                  In machine learning (ML), a widespread adage is that the area under the precision-recall curve (AUPRC) is a superior metric for model comparison to the area under the receiver operating characteristic (AUROC) for binary classification tasks with class imbalance. This paper challenges this notion through novel mathematical analysis, illustrating that AUROC and AUPRC can be concisely related in probabilistic terms. We demonstrate that AUPRC, contrary to popular belief, is not superior in cases of class imbalance and might even be a harmful metric, given its inclination to unduly favor model improvements in subpopulations with more frequent positive labels. This bias can inadvertently heighten algorithmic disparities. Prompted by these insights, a thorough review of existing ML literature was conducted, utilizing large language models to analyze over 1.5 million papers from arXiv. Our investigation focused on the prevalence and substantiation of the purported AUPRC superiority. The results expose a significant deficit in empirical backing and a trend of misattributions that have fuelled the widespread acceptance of AUPRC's supposed advantages. Our findings represent a dual contribution: a significant technical advancement in understanding metric behaviors and a stark warning about unchecked assumptions in the ML community. All experiments are accessible at https://github.com/mmcdermott/AUC_is_all_you_need.
http://w3id.org/mlsea/pwc/scientificWork/A%20Codesign%20of%20Scheduling%20and%20Parallelization%20for%20Large%20Model%20Training%20in%20Heterogeneous%20Clusters                                                                                  A Codesign of Scheduling and Parallelization for Large Model Training in Heterogeneous Clusters                                                                                  Joint consideration of scheduling and adaptive parallelism offers great opportunities for improving the training efficiency of large models on heterogeneous GPU clusters. However, integrating adaptive parallelism into a cluster scheduler expands the cluster scheduling space. The new space is the product of the original scheduling space and the parallelism exploration space of adaptive parallelism (also a product of pipeline, data, and tensor parallelism). The exponentially enlarged scheduling space and ever-changing optimal parallelism plan from adaptive parallelism together result in the contradiction between low-overhead and accurate performance data acquisition for efficient cluster scheduling. This paper presents Crius, a training system for efficiently scheduling multiple large models with adaptive parallelism in a heterogeneous cluster. Crius proposes a novel scheduling granularity called Cell. It represents a job with deterministic resources and pipeline stages. The exploration space of Cell is shrunk to the product of only data and tensor parallelism, thus exposing the potential for accurate and low-overhead performance estimation. Crius then accurately estimates Cells and efficiently schedules training jobs. When a Cell is selected as a scheduling choice, its represented job runs with the optimal parallelism plan explored. Experimental results show that Crius reduces job completion time by up to 48.9% and schedules large models with up to 1.49x cluster throughput improvement.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comparative%20Analysis%20of%20Microrings%20Based%20Incoherent%20Photonic%20GEMM%20Accelerators                                                                                  A Comparative Analysis of Microrings Based Incoherent Photonic GEMM Accelerators                                                                                  Several microring resonator (MRR) based analog photonic architectures have been proposed to accelerate general matrix-matrix multiplications (GEMMs) in deep neural networks with exceptional throughput and energy efficiency. To implement GEMM functions, these MRR-based architectures, in general, manipulate optical signals in five different ways: (i) Splitting (copying) of multiple optical signals to achieve a certain fan-out, (ii) Aggregation (multiplexing) of multiple optical signals to achieve a certain fan-in, (iii) Modulation of optical signals to imprint input values onto analog signal amplitude, (iv) Weighting of modulated optical signals to achieve analog input-weight multiplication, (v) Summation of optical signals. The MRR-based GEMM accelerators undertake the first four ways of signal manipulation in an arbitrary order ignoring the possible impact of the order of these manipulations on their performance. In this paper, we conduct a detailed analysis of accelerator organizations with three different orders of these manipulations: (1) Modulation-Aggregation-Splitting-Weighting (MASW), (2) Aggregation-Splitting-Modulation-Weighting (ASMW), and (3) Splitting-Modulation-Weighting-Aggregation (SMWA). We show that these organizations affect the crosstalk noise and optical signal losses in different magnitudes, which renders these organizations with different levels of processing parallelism at the circuit level, and different magnitudes of throughput and energy-area efficiency at the system level. Our evaluation results for four CNN models show that SMWA organization achieves up to 4.4$ times$, 5$ times$, and 5.2$ times$ better throughput, energy efficiency, and area-energy efficiency, respectively, compared to ASMW and MASW organizations on average.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comparative%20Study%20of%20Machine%20Learning%20Models%20Predicting%20Energetics%20of%20Interacting%20Defects                                                                                  A Comparative Study of Machine Learning Models Predicting Energetics of Interacting Defects                                                                                  Interacting defect systems are ubiquitous in materials under realistic scenarios, yet gaining an atomic-level understanding of these systems from a computational perspective is challenging - it often demands substantial resources due to the necessity of employing supercell calculations. While machine learning techniques have shown potential in accelerating materials simulations, their application to systems involving interacting defects remains relatively rare. In this work, we present a comparative study of three different methods to predict the free energy change of systems with interacting defects. We leveraging a limited dataset from Density Functional Theory(DFT) calculations to assess the performance models using materials descriptors, graph neural networks and cluster expansion. Our findings indicate that the cluster expansion model can achieve precise energetics predictions even with this limited dataset. Furthermore, with synthetic data generate from cluster expansion model at near-DFT levels, we obtained enlarged dataset to assess the demands on data for training accurate prediction models using graph neural networks for systems featuring interacting defects. A brief discussion of the computational cost for each method is provided at the end. This research provide a preliminary evaluation of applying machine learning techniques in imperfect surface systems.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comparison%20of%20Veterans%20with%20Problematic%20Opioid%20Use%20Identified%20through%20Natural%20Language%20Processing%20of%20Clinical%20Notes%20versus%20Using%20Diagnostic%20Codes                                                                                  A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes                                                                                  Background: Electronic health records (EHRs) are a data source for opioid research. Opioid use disorder is known to be under-coded as a diagnosis, yet problematic opioid use can be documented in clinical notes. Objectives: Our goals were 1) to identify problematic opioid use from a full range of clinical notes; and 2) to compare the characteristics of patients identified as having problematic opioid use, exclusively documented in clinical notes, to those having documented ICD opioid use disorder diagnostic codes. Materials and Methods: We developed and applied a natural language processing (NLP) tool to the clinical notes of a patient cohort (n=222,371) from two Veteran Affairs service regions to identify patients with problematic opioid use. We also used a set of ICD diagnostic codes to identify patients with opioid use disorder from the same cohort. We compared the demographic and clinical characteristics of patients identified only through NLP, to those of patients identified through ICD codes. Results: NLP exclusively identified 57,331 patients; 6,997 patients had positive ICD code identifications. Patients exclusively identified through NLP were more likely to be women. Those identified through ICD codes were more likely to be male, younger, have concurrent benzodiazepine prescriptions, more comorbidities, more care encounters, and less likely to be married. Patients in the NLP and ICD groups had substantially elevated comorbidity levels compared to patients not documented as experiencing problematic opioid use. Conclusions: NLP is a feasible approach for identifying problematic opioid use not otherwise recorded by ICD codes. Clinicians may be reluctant to code for opioid use disorder. It is therefore incumbent on the healthcare team to search for documentation of opioid concerns within clinical notes.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Evaluation%20of%20Neural%20SPARQL%20Query%20Generation%20from%20Natural%20Language%20Questions                                                                                  A Comprehensive Evaluation of Neural SPARQL Query Generation from Natural Language Questions                                                                                  In recent years, the field of neural machine translation (NMT) for SPARQL query generation has witnessed significant growth. Incorporating the copy mechanism with traditional encoder-decoder architectures and using pre-trained encoder-decoders and large language models have set new performance benchmarks. This paper presents various experiments that replicate and expand upon recent NMT-based SPARQL generation studies, comparing pre-trained language models (PLMs), non-pre-trained language models (NPLMs), and large language models (LLMs), highlighting the impact of question annotation and the copy mechanism and testing various fine-tuning methods using LLMs. In particular, we provide a systematic error analysis of the models and test their generalization ability. Our study demonstrates that the copy mechanism yields significant performance enhancements for most PLMs and NPLMs. Annotating the data is pivotal to generating correct URIs, with the 'tag-within' strategy emerging as the most effective approach. Additionally, our findings reveal that the primary source of errors stems from incorrect URIs in SPARQL queries that are sometimes replaced with hallucinated URIs when using base models. This does not happen using the copy mechanism, but it sometimes leads to selecting wrong URIs among candidates. Finally, the performance of the tested LLMs fell short of achieving the desired outcomes.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Guide%20to%20CAN%20IDS%20Data%20%26%20Introduction%20of%20the%20ROAD%20Dataset                                                                                  A Comprehensive Guide to CAN IDS Data & Introduction of the ROAD Dataset                                                                                  Although ubiquitous in modern vehicles, Controller Area Networks (CANs) lack basic security properties and are easily exploitable. A rapidly growing field of CAN security research has emerged that seeks to detect intrusions on CANs. Producing vehicular CAN data with a variety of intrusions is out of reach for most researchers as it requires expensive assets and expertise. To assist researchers, we present the first comprehensive guide to the existing open CAN intrusion datasets, including a quality analysis of each dataset and an enumeration of each's benefits, drawbacks, and suggested use case. Current public CAN IDS datasets are limited to real fabrication (simple message injection) attacks and simulated attacks often in synthetic data, which lack fidelity. In general, the physical effects of attacks on the vehicle are not verified in the available datasets. Only one dataset provides signal-translated data but not a corresponding raw binary version. Overall, the available data pigeon-holes CAN IDS works into testing on limited, often inappropriate data (usually with attacks that are too easily detectable to truly test the method), and this lack data has stymied comparability and reproducibility of results. As our primary contribution, we present the ROAD (Real ORNL Automotive Dynamometer) CAN Intrusion Dataset, consisting of over 3.5 hours of one vehicle's CAN data. ROAD contains ambient data recorded during a diverse set of activities, and attacks of increasing stealth with multiple variants and instances of real fuzzing, fabrication, and unique advanced attacks, as well as simulated masquerade attacks. To facilitate benchmarking CAN IDS methods that require signal-translated inputs, we also provide the signal time series format for many of the CAN captures. Our contributions aim to facilitate appropriate benchmarking and needed comparability in the CAN IDS field.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Review%20of%20Knowledge%20Distillation%20in%20Computer%20Vision                                                                                  A Comprehensive Review of Knowledge Distillation in Computer Vision                                                                                  Deep learning techniques have been demonstrated to surpass preceding cutting-edge machine learning techniques in recent years, with computer vision being one of the most prominent examples. However, deep learning models suffer from significant drawbacks when deployed in resource-constrained environments due to their large model size and high complexity. Knowledge Distillation is one of the prominent solutions to overcome this challenge. This review paper examines the current state of research on knowledge distillation, a technique for compressing complex models into smaller and simpler ones. The paper provides an overview of the major principles and techniques associated with knowledge distillation and reviews the applications of knowledge distillation in the domain of computer vision. The review focuses on the benefits of knowledge distillation, as well as the problems that must be overcome to improve its effectiveness.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Study%20of%20the%20Capabilities%20of%20Large%20Language%20Models%20for%20Vulnerability%20Detection                                                                                  A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection                                                                                  Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasoning about the code, making it a good case study for exploring the limits of LLMs' reasoning capabilities. Although recent work has applied LLMs to vulnerability detection using generic prompting techniques, their full capabilities for this task and the types of errors they make when explaining identified vulnerabilities remain unclear. In this paper, we surveyed eleven LLMs that are state-of-the-art in code generation and commonly used as coding assistants, and evaluated their capabilities for vulnerability detection. We systematically searched for the best-performing prompts, incorporating techniques such as in-context learning and chain-of-thought, and proposed three of our own prompting methods. Our results show that while our prompting methods improved the models' performance, LLMs generally struggled with vulnerability detection. They reported 0.5-0.63 Balanced Accuracy and failed to distinguish between buggy and fixed versions of programs in 76% of cases on average. By comprehensively analyzing and categorizing 287 instances of model reasoning, we found that 57% of LLM responses contained errors, and the models frequently predicted incorrect locations of buggy code and misidentified bug types. LLMs only correctly localized 6 out of 27 bugs in DbgBench, and these 6 bugs were predicted correctly by 70-100% of human participants. These findings suggest that despite their potential for other tasks, LLMs may fail to properly comprehend critical code structures and security-related concepts. Our data and code are available at https://figshare.com/s/78fe02e56e09ec49300b.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Study%20on%20NLP%20Data%20Augmentation%20for%20Hate%20Speech%20Detection%3A%20Legacy%20Methods%2C%20BERT%2C%20and%20LLMs                                                                                  A Comprehensive Study on NLP Data Augmentation for Hate Speech Detection: Legacy Methods, BERT, and LLMs                                                                                  The surge of interest in data augmentation within the realm of NLP has been driven by the need to address challenges posed by hate speech domains, the dynamic nature of social media vocabulary, and the demands for large-scale neural networks requiring extensive training data. However, the prevalent use of lexical substitution in data augmentation has raised concerns, as it may inadvertently alter the intended meaning, thereby impacting the efficacy of supervised machine learning models. In pursuit of suitable data augmentation methods, this study explores both established legacy approaches and contemporary practices such as Large Language Models (LLM), including GPT in Hate Speech detection. Additionally, we propose an optimized utilization of BERT-based encoder models with contextual cosine similarity filtration, exposing significant limitations in prior synonym substitution methods. Our comparative analysis encompasses five popular augmentation techniques: WordNet and Fast-Text synonym replacement, Back-translation, BERT-mask contextual augmentation, and LLM. Our analysis across five benchmarked datasets revealed that while traditional methods like back-translation show low label alteration rates (0.3-1.5%), and BERT-based contextual synonym replacement offers sentence diversity but at the cost of higher label alteration rates (over 6%). Our proposed BERT-based contextual cosine similarity filtration markedly reduced label alteration to just 0.05%, demonstrating its efficacy in 0.7% higher F1 performance. However, augmenting data with GPT-3 not only avoided overfitting with up to sevenfold data increase but also improved embedding space coverage by 15% and classification F1 score by 1.4% over traditional methods, and by 0.8% over our method.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Survey%20of%203D%20Dense%20Captioning%3A%20Localizing%20and%20Describing%20Objects%20in%203D%20Scenes                                                                                  A Comprehensive Survey of 3D Dense Captioning: Localizing and Describing Objects in 3D Scenes                                                                                  Three-Dimensional (3D) dense captioning is an emerging vision-language bridging task that aims to generate multiple detailed and accurate descriptions for 3D scenes. It presents significant potential and challenges due to its closer representation of the real world compared to 2D visual captioning, as well as complexities in data collection and processing of 3D point cloud sources. Despite the popularity and success of existing methods, there is a lack of comprehensive surveys summarizing the advancements in this field, which hinders its progress. In this paper, we provide a comprehensive review of 3D dense captioning, covering task definition, architecture classification, dataset analysis, evaluation metrics, and in-depth prosperity discussions. Based on a synthesis of previous literature, we refine a standard pipeline that serves as a common paradigm for existing methods. We also introduce a clear taxonomy of existing models, summarize technologies involved in different modules, and conduct detailed experiment analysis. Instead of a chronological order introduction, we categorize the methods into different classes to facilitate exploration and analysis of the differences and connections among existing techniques. We also provide a reading guideline to assist readers with different backgrounds and purposes in reading efficiently. Furthermore, we propose a series of promising future directions for 3D dense captioning by identifying challenges and aligning them with the development of related tasks, offering valuable insights and inspiring future research in this field. Our aim is to provide a comprehensive understanding of 3D dense captioning, foster further investigations, and contribute to the development of novel applications in multimedia and related domains.
http://w3id.org/mlsea/pwc/scientificWork/A%20Comprehensive%20Survey%20on%20AI-based%20Methods%20for%20Patents                                                                                  A Comprehensive Survey on AI-based Methods for Patents                                                                                  Recent advancements in Artificial Intelligence (AI) and machine learning have demonstrated transformative capabilities across diverse domains. This progress extends to the field of patent analysis and innovation, where AI-based tools present opportunities to streamline and enhance important tasks in the patent cycle such as classification, retrieval, and valuation prediction. This not only accelerates the efficiency of patent researchers and applicants but also opens new avenues for technological innovation and discovery. Our survey provides a comprehensive summary of recent AI tools in patent analysis from more than 40 papers from 26 venues between 2017 and 2023. Unlike existing surveys, we include methods that work for patent image and text data. Furthermore, we introduce a novel taxonomy for the categorization based on the tasks in the patent life cycle as well as the specifics of the AI methods. This survey aims to serve as a resource for researchers, practitioners, and patent offices in the domain of AI-powered patent analysis.
http://w3id.org/mlsea/pwc/scientificWork/A%20Computational%20Analysis%20of%20Lyric%20Similarity%20Perception                                                                                  A Computational Analysis of Lyric Similarity Perception                                                                                  In musical compositions that include vocals, lyrics significantly contribute to artistic expression. Consequently, previous studies have introduced the concept of a recommendation system that suggests lyrics similar to a user's favorites or personalized preferences, aiding in the discovery of lyrics among millions of tracks. However, many of these systems do not fully consider human perceptions of lyric similarity, primarily due to limited research in this area. To bridge this gap, we conducted a comparative analysis of computational methods for modeling lyric similarity with human perception. Results indicated that computational models based on similarities between embeddings from pre-trained BERT-based models, the audio from which the lyrics are derived, and phonetic components are indicative of perceptual lyric similarity. This finding underscores the importance of semantic, stylistic, and phonetic similarities in human perception about lyric similarity. We anticipate that our findings will enhance the development of similarity-based lyric recommendation systems by offering pseudo-labels for neural network development and introducing objective evaluation metrics.
http://w3id.org/mlsea/pwc/scientificWork/A%20Constrained%20BA%20Algorithm%20for%20Rate-Distortion%20and%20Distortion-Rate%20Functions                                                                                  A Constrained BA Algorithm for Rate-Distortion and Distortion-Rate Functions                                                                                  The Blahut-Arimoto (BA) algorithm has played a fundamental role in the numerical computation of rate-distortion (RD) functions. This algorithm possesses a desirable monotonic convergence property by alternatively minimizing its Lagrangian with a fixed multiplier. In this paper, we propose a novel modification of the BA algorithm, wherein the multiplier is updated through a one-dimensional root-finding step using a monotonic univariate function, efficiently implemented by Newton's method in each iteration. Consequently, the modified algorithm directly computes the RD function for a given target distortion, without exploring the entire RD curve as in the original BA algorithm. Moreover, this modification presents a versatile framework, applicable to a wide range of problems, including the computation of distortion-rate (DR) functions. Theoretical analysis shows that the outputs of the modified algorithms still converge to the solutions of the RD and DR functions with rate $O(1/n)$, where $n$ is the number of iterations. Additionally, these algorithms provide $ varepsilon$-approximation solutions with $O left( frac{MN log N}{ varepsilon}(1+ log | log varepsilon|) right)$ arithmetic operations, where $M,N$ are the sizes of source and reproduced alphabets respectively. Numerical experiments demonstrate that the modified algorithms exhibit significant acceleration compared with the original BA algorithms and showcase commendable performance across classical source distributions such as discretized Gaussian, Laplacian and uniform sources.
http://w3id.org/mlsea/pwc/scientificWork/A%20Continuous-Time%20Stochastic%20Model%20of%20the%20Fiscal%20Theory%20of%20the%20Price%20Level%20and%20Consistency%20of%20Its%20Critique                                                                                  A Continuous-Time Stochastic Model of the Fiscal Theory of the Price Level and Consistency of Its Critique                                                                                  The paper tests the validity of the critique of the fiscal theory of the price level. A stochastic general equilibrium model with continuous time is constructed. An active fiscal policy and a passive monetary policy have been set. Monetary policy manages the interest rate through the Taylor rule. The stochastic default factor in the special form is introduced. A complete definite system of equations is obtained for the detection of equilibrium. It is asserted that the peculiarities of the approach to modeling are of critical importance for verifying the presence of certain hypotheses and formulating conclusions. The results of this work are in support of the fiscal theory of the price level.
http://w3id.org/mlsea/pwc/scientificWork/A%20Control-Recoverable%20Added-Noise-based%20Privacy%20Scheme%20for%20LQ%20Control%20in%20Networked%20Control%20Systems                                                                                  A Control-Recoverable Added-Noise-based Privacy Scheme for LQ Control in Networked Control Systems                                                                                  As networked control systems continue to evolve, ensuring the privacy of sensitive data becomes an increasingly pressing concern, especially in situations where the controller is physically separated from the plant. In this paper, we propose a secure control scheme for computing linear quadratic control in a networked control system utilizing two networked controllers, a privacy encoder and a control restorer. Specifically, the encoder generates two state signals blurred with random noise and sends them to the controllers, while the restorer reconstructs the correct control signal. The proposed design effectively preserves the privacy of the control system's state without sacrificing the control performance. We theoretically quantify the privacy-preserving performance in terms of the state estimation error of the controllers and the disclosure probability. Additionally, the proposed privacy-preserving scheme is also proven to satisfy differential privacy. Moreover, we extend the proposed privacy-preserving scheme and evaluation method to cases where collusion between two controllers occurs. Finally, we verify the validity of our proposed scheme through simulations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Converting%20Autoencoder%20Toward%20Low-latency%20and%20Energy-efficient%20DNN%20Inference%20at%20the%20Edge                                                                                  A Converting Autoencoder Toward Low-latency and Energy-efficient DNN Inference at the Edge                                                                                  Reducing inference time and energy usage while maintaining prediction accuracy has become a significant concern for deep neural networks (DNN) inference on resource-constrained edge devices. To address this problem, we propose a novel approach based on 'converting' autoencoder and lightweight DNNs. This improves upon recent work such as early-exiting framework and DNN partitioning. Early-exiting frameworks spend different amounts of computation power for different input data depending upon their complexity. However, they can be inefficient in real-world scenarios that deal with many hard image samples. On the other hand, DNN partitioning algorithms that utilize the computation power of both the cloud and edge devices can be affected by network delays and intermittent connections between the cloud and the edge. We present CBNet, a low-latency and energy-efficient DNN inference framework tailored for edge devices. It utilizes a 'converting' autoencoder to efficiently transform hard images into easy ones, which are subsequently processed by a lightweight DNN for inference. To the best of our knowledge, such autoencoder has not been proposed earlier. Our experimental results using three popular image-classification datasets on a Raspberry Pi 4, a Google Cloud instance, and an instance with Nvidia Tesla K80 GPU show that CBNet achieves up to 4.8x speedup in inference latency and 79% reduction in energy usage compared to competing techniques while maintaining similar or higher accuracy.
http://w3id.org/mlsea/pwc/scientificWork/A%20Convex%20Optimization%20Framework%20for%20Computing%20Robustness%20Margins%20of%20Kalman%20Filters                                                                                  A Convex Optimization Framework for Computing Robustness Margins of Kalman Filters                                                                                  This paper proposes a novel convex optimization framework for designing robust Kalman filters that guarantee a user-specified steady-state error while maximizing process and sensor noise. The proposed framework simultaneously determines the Kalman gain and the robustness margin in terms of the process and sensor noise. This is the first paper to present such a joint formulation for Kalman filtering. The proposed methodology is validated through two distinct examples: the Clohessy-Wiltshire-Hill equations for a chaser spacecraft in an elliptical orbit and the longitudinal motion model of an F-16 aircraft.
http://w3id.org/mlsea/pwc/scientificWork/A%20Cross-Modal%20Approach%20to%20Silent%20Speech%20with%20LLM-Enhanced%20Recognition                                                                                  A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition                                                                                  Silent Speech Interfaces (SSIs) offer a noninvasive alternative to brain-computer interfaces for soundless verbal communication. We introduce Multimodal Orofacial Neural Audio (MONA), a system that leverages cross-modal alignment through novel loss functions--cross-contrast (crossCon) and supervised temporal contrast (supTcon)--to train a multimodal model with a shared latent representation. This architecture enables the use of audio-only datasets like LibriSpeech to improve silent speech recognition. Additionally, our introduction of Large Language Model (LLM) Integrated Scoring Adjustment (LISA) significantly improves recognition accuracy. Together, MONA LISA reduces the state-of-the-art word error rate (WER) from 28.8% to 12.2% in the Gaddy (2020) benchmark dataset for silent speech on an open vocabulary. For vocal EMG recordings, our method improves the state-of-the-art from 23.3% to 3.7% WER. In the Brain-to-Text 2024 competition, LISA performs best, improving the top WER from 9.8% to 8.9%. To the best of our knowledge, this work represents the first instance where noninvasive silent speech recognition on an open vocabulary has cleared the threshold of 15% WER, demonstrating that SSIs can be a viable alternative to automatic speech recognition (ASR). Our work not only narrows the performance gap between silent and vocalized speech but also opens new possibilities in human-computer interaction, demonstrating the potential of cross-modal approaches in noisy and data-limited regimes.
http://w3id.org/mlsea/pwc/scientificWork/A%20Cross-View%20Hierarchical%20Graph%20Learning%20Hypernetwork%20for%20Skill%20Demand-Supply%20Joint%20Prediction                                                                                  A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction                                                                                  The rapidly changing landscape of technology and industries leads to dynamic skill requirements, making it crucial for employees and employers to anticipate such shifts to maintain a competitive edge in the labor market. Existing efforts in this area either rely on domain-expert knowledge or regarding skill evolution as a simplified time series forecasting problem. However, both approaches overlook the sophisticated relationships among different skills and the inner-connection between skill demand and supply variations. In this paper, we propose a Cross-view Hierarchical Graph learning Hypernetwork (CHGH) framework for joint skill demand-supply prediction. Specifically, CHGH is an encoder-decoder network consisting of i) a cross-view graph encoder to capture the interconnection between skill demand and supply, ii) a hierarchical graph encoder to model the co-evolution of skills from a cluster-wise perspective, and iii) a conditional hyper-decoder to jointly predict demand and supply variations by incorporating historical demand-supply gaps. Extensive experiments on three real-world datasets demonstrate the superiority of the proposed framework compared to seven baselines and the effectiveness of the three modules.
http://w3id.org/mlsea/pwc/scientificWork/A%20Crucial%20Parameter%20for%20Rank-Frequency%20Relation%20in%20Natural%20Languages                                                                                  A Crucial Parameter for Rank-Frequency Relation in Natural Languages                                                                                  $f propto r^{- alpha} cdot (r+ gamma)^{- beta}$ has been empirically shown more precise than a na 'ive power law $f propto r^{- alpha}$ to model the rank-frequency ($r$-$f$) relation of words in natural languages. This work shows that the only crucial parameter in the formulation is $ gamma$, which depicts the resistance to vocabulary growth on a corpus. A method of parameter estimation by searching an optimal $ gamma$ is proposed, where a ``zeroth word'' is introduced technically for the calculation. The formulation and parameters are further discussed with several case studies.
http://w3id.org/mlsea/pwc/scientificWork/A%20Cyber%20Manufacturing%20IoT%20System%20for%20Adaptive%20Machine%20Learning%20Model%20Deployment%20by%20Interactive%20Causality%20Enabled%20Self-Labeling                                                                                  A Cyber Manufacturing IoT System for Adaptive Machine Learning Model Deployment by Interactive Causality Enabled Self-Labeling                                                                                  Machine Learning (ML) has been demonstrated to improve productivity in many manufacturing applications. To host these ML applications, several software and Industrial Internet of Things (IIoT) systems have been proposed for manufacturing applications to deploy ML applications and provide real-time intelligence. Recently, an interactive causality enabled self-labeling method has been proposed to advance adaptive ML applications in cyber-physical systems, especially manufacturing, by automatically adapting and personalizing ML models after deployment to counter data distribution shifts. The unique features of the self-labeling method require a novel software system to support dynamism at various levels. This paper proposes the AdaptIoT system, comprised of an end-to-end data streaming pipeline, ML service integration, and an automated self-labeling service. The self-labeling service consists of causal knowledge bases and automated full-cycle self-labeling workflows to adapt multiple ML models simultaneously. AdaptIoT employs a containerized microservice architecture to deliver a scalable and portable solution for small and medium-sized manufacturers. A field demonstration of a self-labeling adaptive ML application is conducted with a makerspace and shows reliable performance.
http://w3id.org/mlsea/pwc/scientificWork/A%20Data-Driven%20Two-Phase%20Multi-Split%20Causal%20Ensemble%20Model%20for%20Time%20Series                                                                                  A Data-Driven Two-Phase Multi-Split Causal Ensemble Model for Time Series                                                                                  Causal inference is a fundamental research topic for discovering the cause-effect relationships in many disciplines. However, not all algorithms are equally well-suited for a given dataset. For instance, some approaches may only be able to identify linear relationships, while others are applicable for non-linearities. Algorithms further vary in their sensitivity to noise and their ability to infer causal information from coupled vs. non-coupled time series. Therefore, different algorithms often generate different causal relationships for the same input. To achieve a more robust causal inference result, this publication proposes a novel data-driven two-phase multi-split causal ensemble model to combine the strengths of different causality base algorithms. In comparison to existing approaches, the proposed ensemble method reduces the influence of noise through a data partitioning scheme in the first phase. To achieve this, the data are initially divided into several partitions and the base algorithms are applied to each partition. Subsequently, Gaussian mixture models are used to identify the causal relationships derived from the different partitions that are likely to be valid. In the second phase, the identified relationships from each base algorithm are then merged based on three combination rules. The proposed ensemble approach is evaluated using multiple metrics, among them a newly developed evaluation index for causal ensemble approaches. We perform experiments using three synthetic datasets with different volumes and complexity, which are specifically designed to test causality detection methods under different circumstances while knowing the ground truth causal relationships. In these experiments, our causality ensemble outperforms each of its base algorithms. In practical applications, the use of the proposed method could hence lead to more robust and reliable causality results.
http://w3id.org/mlsea/pwc/scientificWork/A%20Decoding%20Scheme%20with%20Successive%20Aggregation%20of%20Multi-Level%20Features%20for%20Light-Weight%20Semantic%20Segmentation                                                                                  A Decoding Scheme with Successive Aggregation of Multi-Level Features for Light-Weight Semantic Segmentation                                                                                  Multi-scale architecture, including hierarchical vision transformer, has been commonly applied to high-resolution semantic segmentation to deal with computational complexity with minimum performance loss. In this paper, we propose a novel decoding scheme for semantic segmentation in this regard, which takes multi-level features from the encoder with multi-scale architecture. The decoding scheme based on a multi-level vision transformer aims to achieve not only reduced computational expense but also higher segmentation accuracy, by introducing successive cross-attention in aggregation of the multi-level features. Furthermore, a way to enhance the multi-level features by the aggregated semantics is proposed. The effort is focused on maintaining the contextual consistency from the perspective of attention allocation and brings improved performance with significantly lower computational cost. Set of experiments on popular datasets demonstrates superiority of the proposed scheme to the state-of-the-art semantic segmentation models in terms of computational cost without loss of accuracy, and extensive ablation studies prove the effectiveness of ideas proposed.
http://w3id.org/mlsea/pwc/scientificWork/A%20Decoupled%20Approach%20for%20Composite%20Sparse-plus-Smooth%20Penalized%20Optimization                                                                                  A Decoupled Approach for Composite Sparse-plus-Smooth Penalized Optimization                                                                                  We consider a linear inverse problem whose solution is expressed as a sum of two components, one of them being smooth while the other presents sparse properties. This problem is solved by minimizing an objective function with a least square data-fidelity term and a different regularization term applied to each of the components. Sparsity is promoted with a $ ell_1$ norm, while the other component is penalized by means of a $ ell_2$ norm. We characterize the solution set of this composite optimization problem by stating a Representer Theorem. Consequently, we identify that solving the optimization problem can be decoupled, first identifying the sparse solution as a solution of a modified single-variable problem, then deducing the smooth component. We illustrate that this decoupled solving method can lead to significant computational speedups in applications, considering the problem of Dirac recovery over a smooth background with two-dimensional partial Fourier measurements.
http://w3id.org/mlsea/pwc/scientificWork/A%20Deep%20Learning%20Method%20for%20Optimal%20Investment%20Under%20Relative%20Performance%20Criteria%20Among%20Heterogeneous%20Agents                                                                                  A Deep Learning Method for Optimal Investment Under Relative Performance Criteria Among Heterogeneous Agents                                                                                  Graphon games have been introduced to study games with many players who interact through a weighted graph of interaction. By passing to the limit, a game with a continuum of players is obtained, in which the interactions are through a graphon. In this paper, we focus on a graphon game for optimal investment under relative performance criteria, and we propose a deep learning method. The method builds upon two key ingredients: first, a characterization of Nash equilibria by forward-backward stochastic differential equations and, second, recent advances of machine learning algorithms for stochastic differential games. We provide numerical experiments on two different financial models. In each model, we compare the effect of several graphons, which correspond to different structures of interactions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Differentiable%20Integer%20Linear%20Programming%20Solver%20for%20Explanation-Based%20Natural%20Language%20Inference                                                                                  A Differentiable Integer Linear Programming Solver for Explanation-Based Natural Language Inference                                                                                  Integer Linear Programming (ILP) has been proposed as a formalism for encoding precise structural and semantic constraints for Natural Language Inference (NLI). However, traditional ILP frameworks are non-differentiable, posing critical challenges for the integration of continuous language representations based on deep learning. In this paper, we introduce a novel approach, named Diff-Comb Explainer, a neuro-symbolic architecture for explanation-based NLI based on Differentiable BlackBox Combinatorial Solvers (DBCS). Differently from existing neuro-symbolic solvers, Diff-Comb Explainer does not necessitate a continuous relaxation of the semantic constraints, enabling a direct, more precise, and efficient incorporation of neural representations into the ILP formulation. Our experiments demonstrate that Diff-Comb Explainer achieves superior performance when compared to conventional ILP solvers, neuro-symbolic black-box solvers, and Transformer-based encoders. Moreover, a deeper analysis reveals that Diff-Comb Explainer can significantly improve the precision, consistency, and faithfulness of the constructed explanations, opening new opportunities for research on neuro-symbolic architectures for explainable and transparent NLI in complex domains.
http://w3id.org/mlsea/pwc/scientificWork/A%20Digital%20Twin%20prototype%20for%20traffic%20sign%20recognition%20of%20a%20learning-enabled%20autonomous%20vehicle                                                                                  A Digital Twin prototype for traffic sign recognition of a learning-enabled autonomous vehicle                                                                                  In this paper, we present a novel digital twin prototype for a learning-enabled self-driving vehicle. The primary objective of this digital twin is to perform traffic sign recognition and lane keeping. The digital twin architecture relies on co-simulation and uses the Functional Mock-up Interface and SystemC Transaction Level Modeling standards. The digital twin consists of four clients, i) a vehicle model that is designed in Amesim tool, ii) an environment model developed in Prescan, iii) a lane-keeping controller designed in Robot Operating System, and iv) a perception and speed control module developed in the formal modeling language of BIP (Behavior, Interaction, Priority). These clients interface with the digital twin platform, PAVE360-Veloce System Interconnect (PAVE360-VSI). PAVE360-VSI acts as the co-simulation orchestrator and is responsible for synchronization, interconnection, and data exchange through a server. The server establishes connections among the different clients and also ensures adherence to the Ethernet protocol. We conclude with illustrative digital twin simulations and recommendations for future work.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dual-Augmentor%20Framework%20for%20Domain%20Generalization%20in%203D%20Human%20Pose%20Estimation                                                                                  A Dual-Augmentor Framework for Domain Generalization in 3D Human Pose Estimation                                                                                  3D human pose data collected in controlled laboratory settings present challenges for pose estimators that generalize across diverse scenarios. To address this, domain generalization is employed. Current methodologies in domain generalization for 3D human pose estimation typically utilize adversarial training to generate synthetic poses for training. Nonetheless, these approaches exhibit several limitations. First, the lack of prior information about the target domain complicates the application of suitable augmentation through a single pose augmentor, affecting generalization on target domains. Moreover, adversarial training's discriminator tends to enforce similarity between source and synthesized poses, impeding the exploration of out-of-source distributions. Furthermore, the pose estimator's optimization is not exposed to domain shifts, limiting its overall generalization ability. To address these limitations, we propose a novel framework featuring two pose augmentors: the weak and the strong augmentors. Our framework employs differential strategies for generation and discrimination processes, facilitating the preservation of knowledge related to source poses and the exploration of out-of-source distributions without prior information about target poses. Besides, we leverage meta-optimization to simulate domain shifts in the optimization process of the pose estimator, thereby improving its generalization ability. Our proposed approach significantly outperforms existing methods, as demonstrated through comprehensive experiments on various benchmark datasets.Our code will be released at url{https://github.com/davidpengucf/DAF-DG}.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dynamic%20Capacitance%20Matching%20%28DCM%29-based%20Current%20Response%20Algorithm%20for%20Signal%20Line%20RC%20Network                                                                                  A Dynamic Capacitance Matching (DCM)-based Current Response Algorithm for Signal Line RC Network                                                                                  This paper proposes a dynamic capacitance matching (DCM)-based RC current response algorithm for calculating the current waveform of a signal line without performing SPICE simulation. Specifically, unlike previous method such as CCS model, driver linear representation, waveform functional fitting or equivalent load capacitance, our algorithm does not rely on fixed reduced model of both standard cell driver and RC load. Instead, our algorithm approaches the current waveform dynamically by computing current responses of the target driver for various load scenarios. Besides, we creatively use symbolic expression to combine the y-parameter of RC network with the pre-characterized driver library in order to perform capacitance matching by considering over/under-shoot effect. Our algorithm is experimentally verified on 40nm CMOS technology and has been partially adopted by latest commercial tool for other nodes. Experimental results show that our algorithm has excellent resolution and promising efficiency compared with traditional methods and SPICE golden result, especially for application in computing delay, power and signal line electromigration.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dynamic%20Programming%20Approach%20for%20Road%20Traffic%20Estimation                                                                                  A Dynamic Programming Approach for Road Traffic Estimation                                                                                  We consider a road network represented by a directed graph. We assume to collect many measurements of traffic flows on all the network arcs, or on a subset of them. We assume that the users are divided into different groups. Each group follows a different path. The flows of all user groups are modeled as a set of independent Poisson processes. Our focus is estimating the paths followed by each user group, and the means of the associated Poisson processes. We present a possible solution based on a Dynamic Programming algorithm. The method relies on the knowledge of high order cumulants. We discuss the theoretical properties of the introduced method. Finally, we present some numerical tests on well-known benchmark networks, using synthetic data.
http://w3id.org/mlsea/pwc/scientificWork/A%20Dynamical%20Model%20of%20Neural%20Scaling%20Laws                                                                                  A Dynamical Model of Neural Scaling Laws                                                                                  On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-width dynamics at a rate $1/ textit{width}$ but at late time exhibit a rate $ textit{width}^{-c}$, where $c$ depends on the structure of the architecture and task. We show that our model exhibits this behavior. Lastly, our theory shows how the gap between training and test loss can gradually build up over time due to repeated reuse of data.
http://w3id.org/mlsea/pwc/scientificWork/A%20Federated%20Parameter%20Aggregation%20Method%20for%20Node%20Classification%20Tasks%20with%20Different%20Graph%20Network%20Structures                                                                                  A Federated Parameter Aggregation Method for Node Classification Tasks with Different Graph Network Structures                                                                                  Over the past few years, federated learning has become widely used in various classical machine learning fields because of its collaborative ability to train data from multiple sources without compromising privacy. However, in the area of graph neural networks, the nodes and network structures of graphs held by clients are different in many practical applications, and the aggregation method that directly shares model gradients cannot be directly applied to this scenario. Therefore, this work proposes a federated aggregation method FLGNN applied to various graph federation scenarios and investigates the aggregation effect of parameter sharing at each layer of the graph neural network model. The effectiveness of the federated aggregation method FLGNN is verified by experiments on real datasets. Additionally, for the privacy security of FLGNN, this paper designs membership inference attack experiments and differential privacy defense experiments. The results show that FLGNN performs good robustness, and the success rate of privacy theft is further reduced by adding differential privacy defense methods.
http://w3id.org/mlsea/pwc/scientificWork/A%20Flexible%20Evolutionary%20Algorithm%20With%20Dynamic%20Mutation%20Rate%20Archive                                                                                  A Flexible Evolutionary Algorithm With Dynamic Mutation Rate Archive                                                                                  We propose a new, flexible approach for dynamically maintaining successful mutation rates in evolutionary algorithms using $k$-bit flip mutations. The algorithm adds successful mutation rates to an archive of promising rates that are favored in subsequent steps. Rates expire when their number of unsuccessful trials has exceeded a threshold, while rates currently not present in the archive can enter it in two ways: (i) via user-defined minimum selection probabilities for rates combined with a successful step or (ii) via a stagnation detection mechanism increasing the value for a promising rate after the current bit-flip neighborhood has been explored with high probability. For the minimum selection probabilities, we suggest different options, including heavy-tailed distributions. We conduct rigorous runtime analysis of the flexible evolutionary algorithm on the OneMax and Jump functions, on general unimodal functions, on minimum spanning trees, and on a class of hurdle-like functions with varying hurdle width that benefit particularly from the archive of promising mutation rates. In all cases, the runtime bounds are close to or even outperform the best known results for both stagnation detection and heavy-tailed mutations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Formal%20Transaction%20Cost-Based%20Analysis%20of%20the%20Economic%20Feasibility%20of%20Ecosystems                                                                                  A Formal Transaction Cost-Based Analysis of the Economic Feasibility of Ecosystems                                                                                  Ecosystems enjoy increasing attention due to their flexibility and innovative power. It is well known, however, that this type of network-based economic governance structures occupies a potentially unstable position between the two stable (governance) endpoints, namely the firm (i.e., hierarchical governance) and the (open) market (i.e., coordination through the monetary system). This paper develops a formal (mathematical) theory of the economic value of (generic) ecosystem by extending transaction costs economics using certain elements from service-dominant logic. Within a first-best setting of rational actors, we derive analytical solutions for the hub-and-spoke and generic ecosystem configurations under some uniformity assumptions of ecosystem participants. Additionally, we are able to infer a generic condition for the welfare-maximizing and utility-maximizing price of the hub-and-spoke configuration in the familiar form of Lerner indices and elasticities. Relinquishing a first-best rational actors approach, we additionally derive several general propositions on (i) necessary conditions for the economic feasibility of ecosystem-based transactions, (ii) scaling requirements for ecosystem stability, and (iii) a generic feasibility condition for arbitrary provider-consumer ecosystems. Finally, we present an algebraic definition of business ecosystems and relate it to existing informal definition attempts. Thereby we demonstrate that the property of 'being an ecosystem' of a network of transacting actors cannot be decided on structural grounds alone.
http://w3id.org/mlsea/pwc/scientificWork/A%20Framework%20for%20Building%20Point%20Cloud%20Cleaning%2C%20Plane%20Detection%20and%20Semantic%20Segmentation                                                                                  A Framework for Building Point Cloud Cleaning, Plane Detection and Semantic Segmentation                                                                                  This paper presents a framework to address the challenges involved in building point cloud cleaning, plane detection, and semantic segmentation, with the ultimate goal of enhancing building modeling. We focus in the cleaning stage on removing outliers from the acquired point cloud data by employing an adaptive threshold technique based on z-score measure. Following the cleaning process, we perform plane detection using the robust RANSAC paradigm. The goal is to carry out multiple plane segmentations, and to classify segments into distinct categories, such as floors, ceilings, and walls. The resulting segments can generate accurate and detailed point clouds representing the building's architectural elements. Moreover, we address the problem of semantic segmentation, which plays a vital role in the identification and classification of different components within the building, such as walls, windows, doors, roofs, and objects. Inspired by the PointNet architecture, we propose a deep learning architecture for efficient semantic segmentation in buildings. The results demonstrate the effectiveness of the proposed framework in handling building modeling tasks, paving the way for improved accuracy and efficiency in the field of building modelization.
http://w3id.org/mlsea/pwc/scientificWork/A%20Framework%20for%20Effective%20AI%20Recommendations%20in%20Cyber-Physical-Human%20Systems                                                                                  A Framework for Effective AI Recommendations in Cyber-Physical-Human Systems                                                                                  Many cyber-physical-human systems (CPHS) involve a human decision-maker who may receive recommendations from an artificial intelligence (AI) platform while holding the ultimate responsibility of making decisions. In such CPHS applications, the human decision-maker may depart from an optimal recommended decision and instead implement a different one for various reasons. In this letter, we develop a rigorous framework to overcome this challenge. In our framework, we consider that humans may deviate from AI recommendations as they perceive and interpret the system's state in a different way than the AI platform. We establish the structural properties of optimal recommendation strategies and develop an approximate human model (AHM) used by the AI. We provide theoretical bounds on the optimality gap that arises from an AHM and illustrate the efficacy of our results in a numerical example.
http://w3id.org/mlsea/pwc/scientificWork/A%20Framework%20for%20Partially%20Observed%20Reward-States%20in%20RLHF                                                                                  A Framework for Partially Observed Reward-States in RLHF                                                                                  The study of reinforcement learning from human feedback (RLHF) has gained prominence in recent years due to its role in the development of LLMs. Neuroscience research shows that human responses to stimuli are known to depend on partially-observed 'internal states.' Unfortunately current models of RLHF do not take take this into consideration. Moreover most RLHF models do not account for intermediate feedback, which is gaining importance in empirical work and can help improve both sample complexity and alignment. To address these limitations, we model RLHF as reinforcement learning with partially observed reward-states (PORRL). We show reductions from the the two dominant forms of human feedback in RLHF - cardinal and dueling feedback to PORRL. For cardinal feedback, we develop generic statistically efficient algorithms and instantiate them to present POR-UCRL and POR-UCBVI. For dueling feedback, we show that a naive reduction to cardinal feedback fails to achieve sublinear dueling regret. We then present the first explicit reduction that converts guarantees for cardinal regret to dueling regret. We show that our models and guarantees in both settings generalize and extend existing ones. Finally, we identify a recursive structure on our model that could improve the statistical and computational tractability of PORRL, giving examples from past work on RLHF as well as learning perfect reward machines, which PORRL subsumes.
http://w3id.org/mlsea/pwc/scientificWork/A%20Functional%20Analysis%20Approach%20to%20Symbolic%20Regression                                                                                  A Functional Analysis Approach to Symbolic Regression                                                                                  Symbolic regression (SR) poses a significant challenge for randomized search heuristics due to its reliance on the synthesis of expressions for input-output mappings. Although traditional genetic programming (GP) algorithms have achieved success in various domains, they exhibit limited performance when tree-based representations are used for SR. To address these limitations, we introduce a novel SR approach called Fourier Tree Growing (FTG) that draws insights from functional analysis. This new perspective enables us to perform optimization directly in a different space, thus avoiding intricate symbolic expressions. Our proposed algorithm exhibits significant performance improvements over traditional GP methods on a range of classical one-dimensional benchmarking problems. To identify and explain limiting factors of GP and FTG, we perform experiments on a large-scale polynomials benchmark with high-order polynomials up to degree 100. To the best of the authors' knowledge, this work represents the pioneering application of functional analysis in addressing SR problems. The superior performance of the proposed algorithm and insights into the limitations of GP open the way for further advancing GP for SR and related areas of explainable machine learning.
http://w3id.org/mlsea/pwc/scientificWork/A%20Gated%20MLP%20Architecture%20for%20Learning%20Topological%20Dependencies%20in%20Spatio-Temporal%20Graphs                                                                                  A Gated MLP Architecture for Learning Topological Dependencies in Spatio-Temporal Graphs                                                                                  Graph Neural Networks (GNNs) and Transformer have been increasingly adopted to learn the complex vector representations of spatio-temporal graphs, capturing intricate spatio-temporal dependencies crucial for applications such as traffic datasets. Although many existing methods utilize multi-head attention mechanisms and message-passing neural networks (MPNNs) to capture both spatial and temporal relations, these approaches encode temporal and spatial relations independently, and reflect the graph's topological characteristics in a limited manner. In this work, we introduce the Cycle to Mixer (Cy2Mixer), a novel spatio-temporal GNN based on topological non-trivial invariants of spatio-temporal graphs with gated multi-layer perceptrons (gMLP). The Cy2Mixer is composed of three blocks based on MLPs: A message-passing block for encapsulating spatial information, a cycle message-passing block for enriching topological information through cyclic subgraphs, and a temporal block for capturing temporal properties. We bolster the effectiveness of Cy2Mixer with mathematical evidence emphasizing that our cycle message-passing block is capable of offering differentiated information to the deep learning model compared to the message-passing block. Furthermore, empirical evaluations substantiate the efficacy of the Cy2Mixer, demonstrating state-of-the-art performances across various traffic benchmark datasets.
http://w3id.org/mlsea/pwc/scientificWork/A%20General%20Benchmark%20Framework%20is%20Dynamic%20Graph%20Neural%20Network%20Need                                                                                  A General Benchmark Framework is Dynamic Graph Neural Network Need                                                                                  Dynamic graph learning is crucial for modeling real-world systems with evolving relationships and temporal dynamics. However, the lack of a unified benchmark framework in current research has led to inaccurate evaluations of dynamic graph models. This paper highlights the significance of dynamic graph learning and its applications in various domains. It emphasizes the need for a standardized benchmark framework that captures temporal dynamics, evolving graph structures, and downstream task requirements. Establishing a unified benchmark will help researchers understand the strengths and limitations of existing models, foster innovation, and advance dynamic graph learning. In conclusion, this paper identifies the lack of a standardized benchmark framework as a current limitation in dynamic graph learning research . Such a framework will facilitate accurate model evaluation, drive advancements in dynamic graph learning techniques, and enable the development of more effective models for real-world applications.
http://w3id.org/mlsea/pwc/scientificWork/A%20General%20Method%20to%20Incorporate%20Spatial%20Information%20into%20Loss%20Functions%20for%20GAN-based%20Super-resolution%20Models                                                                                  A General Method to Incorporate Spatial Information into Loss Functions for GAN-based Super-resolution Models                                                                                  Generative Adversarial Networks (GANs) have shown great performance on super-resolution problems since they can generate more visually realistic images and video frames. However, these models often introduce side effects into the outputs, such as unexpected artifacts and noises. To reduce these artifacts and enhance the perceptual quality of the results, in this paper, we propose a general method that can be effectively used in most GAN-based super-resolution (SR) models by introducing essential spatial information into the training process. We extract spatial information from the input data and incorporate it into the training loss, making the corresponding loss a spatially adaptive (SA) one. After that, we utilize it to guide the training process. We will show that the proposed approach is independent of the methods used to extract the spatial information and independent of the SR tasks and models. This method consistently guides the training process towards generating visually pleasing SR images and video frames, substantially mitigating artifacts and noise, ultimately leading to enhanced perceptual quality.
http://w3id.org/mlsea/pwc/scientificWork/A%20Generative%20Deep%20Learning%20Approach%20for%20Crash%20Severity%20Modeling%20with%20Imbalanced%20Data                                                                                  A Generative Deep Learning Approach for Crash Severity Modeling with Imbalanced Data                                                                                  Crash data is often greatly imbalanced, with the majority of crashes being non-fatal crashes, and only a small number being fatal crashes due to their rarity. Such data imbalance issue poses a challenge for crash severity modeling since it struggles to fit and interpret fatal crash outcomes with very limited samples. Usually, such data imbalance issues are addressed by data resampling methods, such as under-sampling and over-sampling techniques. However, most traditional and deep learning-based data resampling methods, such as synthetic minority oversampling technique (SMOTE) and generative Adversarial Networks (GAN) are designed dedicated to processing continuous variables. Though some resampling methods have improved to handle both continuous and discrete variables, they may have difficulties in dealing with the collapse issue associated with sparse discrete risk factors. Moreover, there is a lack of comprehensive studies that compare the performance of various resampling methods in crash severity modeling. To address the aforementioned issues, the current study proposes a crash data generation method based on the Conditional Tabular GAN. After data balancing, a crash severity model is employed to estimate the performance of classification and interpretation. A comparative study is conducted to assess classification accuracy and distribution consistency of the proposed generation method using a 4-year imbalanced crash dataset collected in Washington State, U.S. Additionally, Monte Carlo simulation is employed to estimate the performance of parameter and probability estimation in both two- and three-class imbalance scenarios. The results indicate that using synthetic data generated by CTGAN-RU for crash severity modeling outperforms using original data or synthetic data generated by other resampling methods.
http://w3id.org/mlsea/pwc/scientificWork/A%20Generative%20Machine%20Learning%20Model%20for%20Material%20Microstructure%203D%20Reconstruction%20and%20Performance%20Evaluation                                                                                  A Generative Machine Learning Model for Material Microstructure 3D Reconstruction and Performance Evaluation                                                                                  The reconstruction of 3D microstructures from 2D slices is considered to hold significant value in predicting the spatial structure and physical properties of materials.The dimensional extension from 2D to 3D is viewed as a highly challenging inverse problem from the current technological perspective.Recently,methods based on generative adversarial networks have garnered widespread attention.However,they are still hampered by numerous limitations,including oversimplified models,a requirement for a substantial number of training samples,and difficulties in achieving model convergence during training.In light of this,a novel generative model that integrates the multiscale properties of U-net with and the generative capabilities of GAN has been proposed.Based on this,the innovative construction of a multi-scale channel aggregation module,a multi-scale hierarchical feature aggregation module and a convolutional block attention mechanism can better capture the properties of the material microstructure and extract the image information.The model's accuracy is further improved by combining the image regularization loss with the Wasserstein distance loss.In addition,this study utilizes the anisotropy index to accurately distinguish the nature of the image,which can clearly determine the isotropy and anisotropy of the image.It is also the first time that the generation quality of material samples from different domains is evaluated and the performance of the model itself is compared.The experimental results demonstrate that the present model not only shows a very high similarity between the generated 3D structures and real samples but is also highly consistent with real data in terms of statistical data analysis.
http://w3id.org/mlsea/pwc/scientificWork/A%20Generic%20Shared%20Attention%20Mechanism%20for%20Various%20Backbone%20Neural%20Networks                                                                                  A Generic Shared Attention Mechanism for Various Backbone Neural Networks                                                                                  The self-attention mechanism has emerged as a critical component for improving the performance of various backbone neural networks. However, current mainstream approaches individually incorporate newly designed self-attention modules (SAMs) into each layer of the network for granted without fully exploiting their parameters' potential. This leads to suboptimal performance and increased parameter consumption as the network depth increases. To improve this paradigm, in this paper, we first present a counterintuitive but inherent phenomenon: SAMs tend to produce strongly correlated attention maps across different layers, with an average Pearson correlation coefficient of up to 0.85. Inspired by this inherent observation, we propose Dense-and-Implicit Attention (DIA), which directly shares SAMs across layers and employs a long short-term memory module to calibrate and bridge the highly correlated attention maps of different layers, thus improving the parameter utilization efficiency of SAMs. This design of DIA is also consistent with the neural network's dynamical system perspective. Through extensive experiments, we demonstrate that our simple yet effective DIA can consistently enhance various network backbones, including ResNet, Transformer, and UNet, across tasks such as image classification, object detection, and image generation using diffusion models.
http://w3id.org/mlsea/pwc/scientificWork/A%20Geometric%20Algorithm%20for%20Tubular%20Shape%20Reconstruction%20from%20Skeletal%20Representation                                                                                  A Geometric Algorithm for Tubular Shape Reconstruction from Skeletal Representation                                                                                  We introduce a novel approach for the reconstruction of tubular shapes from skeletal representations. Our method processes all skeletal points as a whole, eliminating the need for splitting input structure into multiple segments. We represent the tubular shape as a truncated signed distance function (TSDF) in a voxel hashing manner, in which the signed distance between a voxel center and the object is computed through a simple geometric algorithm. Our method does not involve any surface sampling scheme or solving large matrix equations, and therefore is a faster and more elegant solution for tubular shape reconstruction compared to other approaches. Experiments demonstrate the efficiency and effectiveness of the proposed method. Code is avaliable at https://github.com/wlsdzyzl/Dragon.
http://w3id.org/mlsea/pwc/scientificWork/A%20Globally%20Convergent%20Algorithm%20for%20Neural%20Network%20Parameter%20Optimization%20Based%20on%20Difference-of-Convex%20Functions                                                                                  A Globally Convergent Algorithm for Neural Network Parameter Optimization Based on Difference-of-Convex Functions                                                                                  We propose an algorithm for optimizing the parameters of single hidden layer neural networks. Specifically, we derive a blockwise difference-of-convex (DC) functions representation of the objective function. Based on the latter, we propose a block coordinate descent (BCD) approach that we combine with a tailored difference-of-convex functions algorithm (DCA). We prove global convergence of the proposed algorithm. Furthermore, we mathematically analyze the convergence rate of parameters and the convergence rate in value (i.e., the training loss). We give conditions under which our algorithm converges linearly or even faster depending on the local shape of the loss function. We confirm our theoretical derivations numerically and compare our algorithm against state-of-the-art gradient-based solvers in terms of both training loss and test loss.
http://w3id.org/mlsea/pwc/scientificWork/A%20Good%20Score%20Does%20not%20Lead%20to%20A%20Good%20Generative%20Model                                                                                  A Good Score Does not Lead to A Good Generative Model                                                                                  Score-based Generative Models (SGMs) is one leading method in generative modeling, renowned for their ability to generate high-quality samples from complex, high-dimensional data distributions. The method enjoys empirical success and is supported by rigorous theoretical convergence properties. In particular, it has been shown that SGMs can generate samples from a distribution that is close to the ground-truth if the underlying score function is learned well, suggesting the success of SGM as a generative model. We provide a counter-example in this paper. Through the sample complexity argument, we provide one specific setting where the score function is learned well. Yet, SGMs in this setting can only output samples that are Gaussian blurring of training data points, mimicking the effects of kernel density estimation. The finding resonates a series of recent finding that reveal that SGMs can demonstrate strong memorization effect and fail to generate.
http://w3id.org/mlsea/pwc/scientificWork/A%20Heterogeneous%20Dynamic%20Convolutional%20Neural%20Network%20for%20Image%20Super-resolution                                                                                  A Heterogeneous Dynamic Convolutional Neural Network for Image Super-resolution                                                                                  Convolutional neural networks can automatically learn features via deep network architectures and given input samples. However, robustness of obtained models may have challenges in varying scenes. Bigger differences of a network architecture are beneficial to extract more complementary structural information to enhance robustness of an obtained super-resolution model. In this paper, we present a heterogeneous dynamic convolutional network in image super-resolution (HDSRNet). To capture more information, HDSRNet is implemented by a heterogeneous parallel network. The upper network can facilitate more contexture information via stacked heterogeneous blocks to improve effects of image super-resolution. Each heterogeneous block is composed of a combination of a dilated, dynamic, common convolutional layers, ReLU and residual learning operation. It can not only adaptively adjust parameters, according to different inputs, but also prevent long-term dependency problem. The lower network utilizes a symmetric architecture to enhance relations of different layers to mine more structural information, which is complementary with a upper network for image super-resolution. The relevant experimental results show that the proposed HDSRNet is effective to deal with image resolving. The code of HDSRNet can be obtained at https://github.com/hellloxiaotian/HDSRNet.
http://w3id.org/mlsea/pwc/scientificWork/A%20Hierarchical%20Framework%20with%20Spatio-Temporal%20Consistency%20Learning%20for%20Emergence%20Detection%20in%20Complex%20Adaptive%20Systems                                                                                  A Hierarchical Framework with Spatio-Temporal Consistency Learning for Emergence Detection in Complex Adaptive Systems                                                                                  Emergence, a global property of complex adaptive systems (CASs) constituted by interactive agents, is prevalent in real-world dynamic systems, e.g., network-level traffic congestions. Detecting its formation and evaporation helps to monitor the state of a system, allowing to issue a warning signal for harmful emergent phenomena. Since there is no centralized controller of CAS, detecting emergence based on each agent's local observation is desirable but challenging. Existing works are unable to capture emergence-related spatial patterns, and fail to model the nonlinear relationships among agents. This paper proposes a hierarchical framework with spatio-temporal consistency learning to solve these two problems by learning the system representation and agent representations, respectively. Especially, spatio-temporal encoders are tailored to capture agents' nonlinear relationships and the system's complex evolution. Representations of the agents and the system are learned by preserving the intrinsic spatio-temporal consistency in a self-supervised manner. Our method achieves more accurate detection than traditional methods and deep learning methods on three datasets with well-known yet hard-to-detect emergent behaviors. Notably, our hierarchical framework is generic, which can employ other deep learning methods for agent-level and system-level detection.
http://w3id.org/mlsea/pwc/scientificWork/A%20Joint%20Data%20Compression%20and%20Time-Delay%20Estimation%20Method%20For%20Distributed%20Systems%20via%20Extremum%20Encoding                                                                                  A Joint Data Compression and Time-Delay Estimation Method For Distributed Systems via Extremum Encoding                                                                                  Motivated by the proliferation of mobile devices, we consider a basic form of the ubiquitous problem of time-delay estimation (TDE), but with communication constraints between two non co-located sensors. In this setting, when joint processing of the received signals is not possible, a compression technique that is tailored to TDE is desirable. For our basic TDE formulation, we develop such a joint compression-estimation strategy based on the notion of what we term 'extremum encoding', whereby we send the index of the maximum of a finite-length time-series from one sensor to another. Subsequent joint processing of the encoded message with locally observed data gives rise to our proposed time-delay 'maximum-index'-based estimator. We derive an exponentially tight upper bound on its error probability, establishing its consistency with respect to the number of transmitted bits. We further validate our analysis via simulations, and comment on potential extensions and generalizations of the basic methodology.
http://w3id.org/mlsea/pwc/scientificWork/A%20Large-Scale%20Empirical%20Study%20on%20Improving%20the%20Fairness%20of%20Image%20Classification%20Models                                                                                  A Large-Scale Empirical Study on Improving the Fairness of Image Classification Models                                                                                  Fairness has been a critical issue that affects the adoption of deep learning models in real practice. To improve model fairness, many existing methods have been proposed and evaluated to be effective in their own contexts. However, there is still no systematic evaluation among them for a comprehensive comparison under the same context, which makes it hard to understand the performance distinction among them, hindering the research progress and practical adoption of them. To fill this gap, this paper endeavours to conduct the first large-scale empirical study to comprehensively compare the performance of existing state-of-the-art fairness improving techniques. Specifically, we target the widely-used application scenario of image classification, and utilized three different datasets and five commonly-used performance metrics to assess in total 13 methods from diverse categories. Our findings reveal substantial variations in the performance of each method across different datasets and sensitive attributes, indicating over-fitting on specific datasets by many existing methods. Furthermore, different fairness evaluation metrics, due to their distinct focuses, yield significantly different assessment results. Overall, we observe that pre-processing methods and in-processing methods outperform post-processing methods, with pre-processing methods exhibiting the best performance. Our empirical study offers comprehensive recommendations for enhancing fairness in deep learning models. We approach the problem from multiple dimensions, aiming to provide a uniform evaluation platform and inspire researchers to explore more effective fairness solutions via a set of implications.
http://w3id.org/mlsea/pwc/scientificWork/A%20Large-Scale%20Simulation%20Method%20for%20Neuromorphic%20Circuits                                                                                  A Large-Scale Simulation Method for Neuromorphic Circuits                                                                                  Splitting algorithms are well-established in convex optimization and are designed to solve large-scale problems. Using such algorithms to simulate the behavior of nonlinear circuit networks provides scalable methods for the simulation and design of neuromorphic systems. For circuits made of linear capacitors and inductors with nonlinear resistive elements, we propose a splitting that breaks the network into its LTI lossless component and its static resistive component. This splitting has both physical and algorithmic advantages and allows for separate calculations in the time domain and in the frequency domain. To demonstrate the scalability of this approach, a network made from one hundred neurons modeled by the well-known FitzHugh-Nagumo circuit with all-to-all diffusive coupling is simulated.
http://w3id.org/mlsea/pwc/scientificWork/A%20Latent%20Space%20Metric%20for%20Enhancing%20Prediction%20Confidence%20in%20Earth%20Observation%20Data                                                                                  A Latent Space Metric for Enhancing Prediction Confidence in Earth Observation Data                                                                                  This study presents a new approach for estimating confidence in machine learning model predictions, specifically in regression tasks utilizing Earth Observation (EO) data, with a particular focus on mosquito abundance (MA) estimation. We take advantage of a Variational AutoEncoder architecture, to derive a confidence metric by the latent space representations of EO datasets. This methodology is pivotal in establishing a correlation between the Euclidean distance in latent representations and the Absolute Error (AE) in individual MA predictions. Our research focuses on EO datasets from the Veneto region in Italy and the Upper Rhine Valley in Germany, targeting areas significantly affected by mosquito populations. A key finding is a notable correlation of 0.46 between the AE of MA predictions and the proposed confidence metric. This correlation signifies a robust, new metric for quantifying the reliability and enhancing the trustworthiness of the AI model's predictions in the context of both EO data analysis and mosquito abundance studies.
http://w3id.org/mlsea/pwc/scientificWork/A%20Learning-based%20Incentive%20Mechanism%20for%20Mobile%20AIGC%20Service%20in%20Decentralized%20Internet%20of%20Vehicles                                                                                  A Learning-based Incentive Mechanism for Mobile AIGC Service in Decentralized Internet of Vehicles                                                                                  Artificial Intelligence-Generated Content (AIGC) refers to the paradigm of automated content generation utilizing AI models. Mobile AIGC services in the Internet of Vehicles (IoV) network have numerous advantages over traditional cloud-based AIGC services, including enhanced network efficiency, better reconfigurability, and stronger data security and privacy. Nonetheless, AIGC service provisioning frequently demands significant resources. Consequently, resource-constrained roadside units (RSUs) face challenges in maintaining a heterogeneous pool of AIGC services and addressing all user service requests without degrading overall performance. Therefore, in this paper, we propose a decentralized incentive mechanism for mobile AIGC service allocation, employing multi-agent deep reinforcement learning to find the balance between the supply of AIGC services on RSUs and user demand for services within the IoV context, optimizing user experience and minimizing transmission latency. Experimental results demonstrate that our approach achieves superior performance compared to other baseline models.
http://w3id.org/mlsea/pwc/scientificWork/A%20Learning-based%20Model%20Predictive%20Control%20Scheme%20with%20Application%20to%20Temperature%20Control%20Units                                                                                  A Learning-based Model Predictive Control Scheme with Application to Temperature Control Units                                                                                  Temperature control is a complex task due to its often unknown dynamics and disturbances. This paper explores the use of Neural Nonlinear AutoRegressive eXogenous (NNARX) models for nonlinear system identification and model predictive control of a temperature control unit. First, the NNARX model is identified from input-output data collected from the real plant, and a state-space representation with known measurable states consisting of past input and output variables is formulated. Second, a tailored model predictive controller is designed based on the trained NNARX network. The proposed control architecture is experimentally tested on the temperature control units manufactured by Tool-Temp AG. The results achieved are compared with those obtained using a PI controller and a linear MPC. The findings illustrate that the proposed scheme achieves satisfactory tracking performance while incurring the lowest energy cost among the compared controllers.
http://w3id.org/mlsea/pwc/scientificWork/A%20Lexicon%20for%20Studying%20Radicalization%20in%20Incel%20Communities                                                                                  A Lexicon for Studying Radicalization in Incel Communities                                                                                  Incels are an extremist online community of men who believe in an ideology rooted in misogyny, racism, the glorification of violence, and dehumanization. In their online forums, they use an extensive, evolving cryptolect - a set of ingroup terms that have meaning within the group, reflect the ideology, demonstrate membership in the community, and are difficult for outsiders to understand. This paper presents a lexicon with terms and definitions for common incel root words, prefixes, and affixes. The lexicon is text-based for use in automated analysis and is derived via a Qualitative Content Analysis of the most frequent incel words, their structure, and their meaning on five of the most active incel communities from 2016 to 2023. This lexicon will support future work examining radicalization and deradicalization/disengagement within the community.
http://w3id.org/mlsea/pwc/scientificWork/A%20Lightweight%20Inception%20Boosted%20U-Net%20Neural%20Network%20for%20Routability%20Prediction                                                                                  A Lightweight Inception Boosted U-Net Neural Network for Routability Prediction                                                                                  As the modern CPU, GPU, and NPU chip design complexity and transistor counts keep increasing, and with the relentless shrinking of semiconductor technology nodes to nearly 1 nanometer, the placement and routing have gradually become the two most pivotal processes in modern very-large-scale-integrated (VLSI) circuit back-end design. How to evaluate routability efficiently and accurately in advance (at the placement and global routing stages) has grown into a crucial research area in the field of artificial intelligence (AI) assisted electronic design automation (EDA). In this paper, we propose a novel U-Net variant model boosted by an Inception embedded module to predict Routing Congestion (RC) and Design Rule Checking (DRC) hotspots. Experimental results on the recently published CircuitNet dataset benchmark show that our proposed method achieves up to 5% (RC) and 20% (DRC) rate reduction in terms of Avg-NRMSE (Average Normalized Root Mean Square Error) compared to the classic architecture. Furthermore, our approach consistently outperforms the prior model on the SSIM (Structural Similarity Index Measure) metric.
http://w3id.org/mlsea/pwc/scientificWork/A%20Lightweight%20Spatiotemporal%20Network%20for%20Online%20Eye%20Tracking%20with%20Event%20Camera                                                                                  A Lightweight Spatiotemporal Network for Online Eye Tracking with Event Camera                                                                                  Event-based data are commonly encountered in edge computing environments where efficiency and low latency are critical. To interface with such data and leverage their rich temporal features, we propose a causal spatiotemporal convolutional network. This solution targets efficient implementation on edge-appropriate hardware with limited resources in three ways: 1) deliberately targets a simple architecture and set of operations (convolutions, ReLU activations) 2) can be configured to perform online inference efficiently via buffering of layer outputs 3) can achieve more than 90% activation sparsity through regularization during training, enabling very significant efficiency gains on event-based processors. In addition, we propose a general affine augmentation strategy acting directly on the events, which alleviates the problem of dataset scarcity for event-based systems. We apply our model on the AIS 2024 event-based eye tracking challenge, reaching a score of 0.9916 p10 accuracy on the Kaggle private testset.
http://w3id.org/mlsea/pwc/scientificWork/A%20Linguistic%20Comparison%20between%20Human%20and%20ChatGPT-Generated%20Conversations                                                                                  A Linguistic Comparison between Human and ChatGPT-Generated Conversations                                                                                  This study explores linguistic differences between human and LLM-generated dialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the EmpathicDialogues dataset. The research employs Linguistic Inquiry and Word Count (LIWC) analysis, comparing ChatGPT-generated conversations with human conversations across 118 linguistic categories. Results show greater variability and authenticity in human dialogues, but ChatGPT excels in categories such as social processes, analytical style, cognition, attentional focus, and positive emotional tone, reinforcing recent findings of LLMs being 'more human than human.' However, no significant difference was found in positive or negative affect between ChatGPT and human dialogues. Classifier analysis of dialogue embeddings indicates implicit coding of the valence of affect despite no explicit mention of affect in the conversations. The research also contributes a novel, companion ChatGPT-generated dataset of conversations between two independent chatbots, which were designed to replicate a corpus of human conversations available for open access and used widely in AI research on language modeling. Our findings increase understanding of ChatGPT's linguistic capabilities and inform ongoing efforts to distinguish between human and LLM-generated text, which is critical in detecting AI-generated fakes, misinformation, and disinformation.
http://w3id.org/mlsea/pwc/scientificWork/A%20Machine%20Learning%20Approach%20for%20Crop%20Yield%20and%20Disease%20Prediction%20Integrating%20Soil%20Nutrition%20and%20Weather%20Factors                                                                                  A Machine Learning Approach for Crop Yield and Disease Prediction Integrating Soil Nutrition and Weather Factors                                                                                  The development of an intelligent agricultural decision-supporting system for crop selection and disease forecasting in Bangladesh is the main objective of this work. The economy of the nation depends heavily on agriculture. However, choosing crops with better production rates and efficiently controlling crop disease are obstacles that farmers have to face. These issues are addressed in this research by utilizing machine learning methods and real-world datasets. The recommended approach uses a variety of datasets on the production of crops, soil conditions, agro-meteorological regions, crop disease, and meteorological factors. These datasets offer insightful information on disease trends, soil nutrition demand of crops, and agricultural production history. By incorporating this knowledge, the model first recommends the list of primarily selected crops based on the soil nutrition of a particular user location. Then the predictions of meteorological variables like temperature, rainfall, and humidity are made using SARIMAX models. These weather predictions are then used to forecast the possibilities of diseases for the primary crops list by utilizing the support vector classifier. Finally, the developed model makes use of the decision tree regression model to forecast crop yield and provides a final crop list along with associated possible disease forecast. Utilizing the outcome of the model, farmers may choose the best productive crops as well as prevent crop diseases and reduce output losses by taking preventive actions. Consequently, planning and decision-making processes are supported and farmers can predict possible crop yields. Overall, by offering a detailed decision support system for crop selection and disease prediction, this work can play a vital role in advancing agricultural practices in Bangladesh.
http://w3id.org/mlsea/pwc/scientificWork/A%20Market-Clearing-based%20Sensitivity%20Model%20for%20Locational%20Marginal%20and%20Average%20Carbon%20Emission                                                                                  A Market-Clearing-based Sensitivity Model for Locational Marginal and Average Carbon Emission                                                                                  This letter proposes a market-clearing-based locational marginal carbon emission (LMCE) metric to assess the marginal carbon emission effect of nodal load demand. Unlike the prevalent carbon emission flow (CEF) method that relies on a hypothetical power-flow tracking process, the proposed LMCE metric depends on a novel sensitivity analysis of market-clearing results, capable of revealing both energy-dependent and network-dependent impacts on emissions. Additionally, we introduce a locational average carbon emission (LACE) metric, derived from LMCE, to effectively measure the general emission effect. It offers insights into demand-side carbon emission effects, such as a negative LMCE and LACE indicating emission reduction even as load increases. It can also prevent excessive demand-side emission allocations. Overall, the proposed method provides a clear perspective for the ongoing decarbonization policies.
http://w3id.org/mlsea/pwc/scientificWork/A%20Mean%20Field%20Game%20between%20Informed%20Traders%20and%20a%20Broker                                                                                  A Mean Field Game between Informed Traders and a Broker                                                                                  We find closed-form solutions to the stochastic game between a broker and a mean-field of informed traders. In the finite player game, the informed traders observe a common signal and a private signal. The broker, on the other hand, observes the trading speed of each of his clients and provides liquidity to the informed traders. Each player in the game optimises wealth adjusted by inventory penalties. In the mean field version of the game, using a G ^ateaux derivative approach, we characterise the solution to the game with a system of forward-backward stochastic differential equations that we solve explicitly. We find that the optimal trading strategy of the broker is linear on his own inventory, on the average inventory among informed traders, and on the common signal or the average trading speed of the informed traders. The Nash equilibrium we find helps informed traders decide how to use private information, and helps brokers decide how much of the order flow they should externalise or internalise when facing a large number of clients.
http://w3id.org/mlsea/pwc/scientificWork/A%20Measure%20for%20Transparent%20Comparison%20of%20Linguistic%20Diversity%20in%20Multilingual%20NLP%20Data%20Sets                                                                                  A Measure for Transparent Comparison of Linguistic Diversity in Multilingual NLP Data Sets                                                                                  Typologically diverse benchmarks are increasingly created to track the progress achieved in multilingual NLP. Linguistic diversity of these data sets is typically measured as the number of languages or language families included in the sample, but such measures do not consider structural properties of the included languages. In this paper, we propose assessing linguistic diversity of a data set against a reference language sample as a means of maximising linguistic diversity in the long run. We represent languages as sets of features and apply a version of the Jaccard index suitable for comparing sets of measures. In addition to the features extracted from typological data bases, we propose an automatic text-based measure, which can be used as a means of overcoming the well-known problem of data sparsity in manually collected features. Our diversity score is interpretable in terms of linguistic features and can identify the types of languages that are not represented in a data set. Using our method, we analyse a range of popular multilingual data sets (UD, Bible100, mBERT, XTREME, XGLUE, XNLI, XCOPA, TyDiQA, XQuAD). In addition to ranking these data sets, we find, for example, that (poly)synthetic languages are missing in almost all of them.
http://w3id.org/mlsea/pwc/scientificWork/A%20Modular%20Approach%20for%20Multimodal%20Summarization%20of%20TV%20Shows                                                                                  A Modular Approach for Multimodal Summarization of TV Shows                                                                                  In this paper we address the task of summarizing television shows, which touches key areas in AI research: complex reasoning, multiple modalities, and long narratives. We present a modular approach where separate components perform specialized sub-tasks which we argue affords greater flexibility compared to end-to-end methods. Our modules involve detecting scene boundaries, reordering scenes so as to minimize the number of cuts between different events, converting visual information to text, summarizing the dialogue in each scene, and fusing the scene summaries into a final summary for the entire episode. We also present a new metric, PREFS (Precision and Recall Evaluation of Summary FactS), to measure both precision and recall of generated summaries, which we decompose into atomic facts. Tested on the recently released SummScreen3D dataset Papalampidi and Lapata (2023), our method produces higher quality summaries than comparison models, as measured with ROUGE and our new fact-based metric.
http://w3id.org/mlsea/pwc/scientificWork/A%20Modular%20Safety%20Filter%20for%20Safety-Certified%20Cyber-Physical%20Systems                                                                                  A Modular Safety Filter for Safety-Certified Cyber-Physical Systems                                                                                  Nowadays, many control systems are networked and embed communication and computation capabilities. Such control architectures are prone to cyber attacks on the cyberinfrastructure. Consequently, there is an impellent need to develop solutions to preserve the plant's safety against potential attacks. To ensure safety, this paper introduces a modular safety filter approach that is effective for a variety of cyber-attack types. This solution can be implemented in combination with existing control and detection algorithms, effectively separating safety from performance. The safety filter does not require information on the reliability of the received command or the feature of the used anomaly detector. It can be implemented in conjunction with high-performance, resilient controllers, to achieve both high performance during normal operation and safety during an attack. As an illustrative example, we have shown the effectiveness of the proposed design considering a multi-agent formation task involving 20 mobile robots. The simulation results testify that the safety filter operates effectively during false data injection and intelligent attacks.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multi-Area%20Architecture%20for%20Real-Time%20Feedback-Based%20Optimization%20of%20Distribution%20Grids                                                                                  A Multi-Area Architecture for Real-Time Feedback-Based Optimization of Distribution Grids                                                                                  A challenge in transmission-distribution coordination is how to quickly and reliably coordinate Distributed Energy Resources (DERs) across large multi-stakeholder Distribution Networks (DNs) to support the Transmission Network (TN), while ensuring operational constraints continue to be met within the DN. Here we propose a hierarchical feedback-based control architecture for coordination of DERs in DNs, enabling the DN to quickly respond to power set-point requests from the Transmission System Operator (TSO) while maintaining local DN constraints. Our scheme allows for multiple independently-managed areas within the DN to optimize their local resources while coordinating to support the TN, and while maintaining data privacy; the only required inter-area communication is between physically adjacent areas within the DN control hierarchy. We conduct a rigorous stability analysis, establishing intuitive conditions for closed-loop stability, and provide detailed tuning recommendations. The proposal is validated via case studies on multiple feeders, including IEEE-123 and IEEE-8500, using a custom MATLAB-based application which integrates with OpenDSS. The simulation results show that the proposed structure is highly scalable and can quickly coordinate DERs in response to TSO commands, while responding to local disturbances within the DN and maintaining DN operational limits.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multi-Level%20Framework%20for%20Accelerating%20Training%20Transformer%20Models                                                                                  A Multi-Level Framework for Accelerating Training Transformer Models                                                                                  The fast growing capabilities of large-scale deep learning models, such as Bert, GPT and ViT, are revolutionizing the landscape of NLP, CV and many other domains. Training such models, however, poses an unprecedented demand for computing power, which incurs exponentially increasing energy cost and carbon dioxide emissions. It is thus critical to develop efficient training solutions to reduce the training costs. Motivated by a set of key observations of inter- and intra-layer similarities among feature maps and attentions that can be identified from typical training processes, we propose a multi-level framework for training acceleration. Specifically, the framework is based on three basic operators, Coalescing, De-coalescing and Interpolation, which can be orchestrated to build a multi-level training framework. The framework consists of a V-cycle training process, which progressively down- and up-scales the model size and projects the parameters between adjacent levels of models via coalescing and de-coalescing. The key idea is that a smaller model that can be trained for fast convergence and the trained parameters provides high-qualities intermediate solutions for the next level larger network. The interpolation operator is designed to break the symmetry of neurons incurred by de-coalescing for better convergence performance. Our experiments on transformer-based language models (e.g. Bert, GPT) as well as a vision model (e.g. DeiT) prove that the proposed framework reduces the computational cost by about 20% on training BERT/GPT-Base models and up to 51.6% on training the BERT-Large model while preserving the performance.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multi-Perspective%20Machine%20Learning%20Approach%20to%20Evaluate%20Police-Driver%20Interaction%20in%20Los%20Angeles                                                                                  A Multi-Perspective Machine Learning Approach to Evaluate Police-Driver Interaction in Los Angeles                                                                                  Interactions between the government officials and civilians affect public wellbeing and the state legitimacy that is necessary for the functioning of democratic society. Police officers, the most visible and contacted agents of the state, interact with the public more than 20 million times a year during traffic stops. Today, these interactions are regularly recorded by body-worn cameras (BWCs), which are lauded as a means to enhance police accountability and improve police-public interactions. However, the timely analysis of these recordings is hampered by a lack of reliable automated tools that can enable the analysis of these complex and contested police-public interactions. This article proposes an approach to developing new multi-perspective, multimodal machine learning (ML) tools to analyze the audio, video, and transcript information from this BWC footage. Our approach begins by identifying the aspects of communication most salient to different stakeholders, including both community members and police officers. We move away from modeling approaches built around the existence of a single ground truth and instead utilize new advances in soft labeling to incorporate variation in how different observers perceive the same interactions. We argue that this inclusive approach to the conceptualization and design of new ML tools is broadly applicable to the study of communication and development of analytic tools across domains of human interaction, including education, medicine, and the workplace.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multi-population%20Integrated%20Approach%20for%20Capacitated%20Location%20Routing                                                                                  A Multi-population Integrated Approach for Capacitated Location Routing                                                                                  The capacitated location-routing problem involves determining the depots from a set of candidate capacitated depot locations and finding the required routes from the selected depots to serve a set of customers whereas minimizing a cost function that includes the cost of opening the chosen depots, the fixed utilization cost per vehicle used, and the total cost (distance) of the routes. This paper presents a multi-population integrated framework in which a multi-depot edge assembly crossover generates promising offspring solutions from the perspective of both depot location and route edge assembly. The method includes an effective neighborhood-based local search, a feasibility-restoring procedure and a diversification-oriented mutation. Of particular interest is the multi-population scheme which organizes the population into multiple subpopulations based on depot configurations. Extensive experiments on 281 benchmark instances from the literature show that the algorithm performs remarkably well, by improving 101 best-known results (new upper bounds) and matching 84 best-known results. Additional experiments are presented to gain insight into the role of the key elements of the algorithm.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multimodal%20Approach%20for%20Cross-Domain%20Image%20Retrieval                                                                                  A Multimodal Approach for Cross-Domain Image Retrieval                                                                                  Image generators are gaining vast amount of popularity and have rapidly changed how digital content is created. With the latest AI technology, millions of high quality images are being generated by the public, which are constantly motivating the research community to push the limits of generative models to create more complex and realistic images. This paper focuses on Cross-Domain Image Retrieval (CDIR) which can be used as an additional tool to inspect collections of generated images by determining the level of similarity between images in a dataset. An ideal retrieval system would be able to generalize to unseen complex images from multiple domains (e.g., photos, drawings and paintings). To address this goal, we propose a novel caption-matching approach that leverages multimodal language-vision architectures pre-trained on large datasets. The method is tested on DomainNet and Office-Home datasets and consistently achieves state-of-the-art performance over the latest approaches in the literature for cross-domain image retrieval. In order to verify the effectiveness with AI-generated images, the method was also put to test with a database composed by samples collected from Midjourney, which is a widely used generative platform for content creation.
http://w3id.org/mlsea/pwc/scientificWork/A%20Multimodal%20Handover%20Failure%20Detection%20Dataset%20and%20Baselines                                                                                  A Multimodal Handover Failure Detection Dataset and Baselines                                                                                  An object handover between a robot and a human is a coordinated action which is prone to failure for reasons such as miscommunication, incorrect actions and unexpected object properties. Existing works on handover failure detection and prevention focus on preventing failures due to object slip or external disturbances. However, there is a lack of datasets and evaluation methods that consider unpreventable failures caused by the human participant. To address this deficit, we present the multimodal Handover Failure Detection dataset, which consists of failures induced by the human participant, such as ignoring the robot or not releasing the object. We also present two baseline methods for handover failure detection: (i) a video classification method using 3D CNNs and (ii) a temporal action segmentation approach which jointly classifies the human action, robot action and overall outcome of the action. The results show that video is an important modality, but using force-torque data and gripper position help improve failure detection and action segmentation accuracy.
http://w3id.org/mlsea/pwc/scientificWork/A%20Network%20for%20structural%20dense%20displacement%20based%20on%203D%20deformable%20mesh%20model%20and%20optical%20flow                                                                                  A Network for structural dense displacement based on 3D deformable mesh model and optical flow                                                                                  This study proposes a Network to recognize displacement of a RC frame structure from a video by a monocular camera. The proposed Network consists of two modules which is FlowNet2 and POFRN-Net. FlowNet2 is used to generate dense optical flow as well as POFRN-Net is to extract pose parameter H. FlowNet2 convert two video frames into dense optical flow. POFRN-Net is inputted dense optical flow from FlowNet2 to output the pose parameter H. The displacement of any points of structure can be calculated from parameter H. The Fast Fourier Transform (FFT) is applied to obtain frequency domain signal from corresponding displacement signal. Furthermore, the comparison of the truth displacement on the First floor of the First video is shown in this study. Finally, the predicted displacements on four floors of RC frame structure of given three videos are exhibited in the last of this study.
http://w3id.org/mlsea/pwc/scientificWork/A%20Neural%20Rewriting%20System%20to%20Solve%20Algorithmic%20Problems                                                                                  A Neural Rewriting System to Solve Algorithmic Problems                                                                                  Modern neural network architectures still struggle to learn algorithmic procedures that require to systematically apply compositional rules to solve out-of-distribution problem instances. In this work, we propose an original approach to learn algorithmic tasks inspired by rewriting systems, a classic framework in symbolic artificial intelligence. We show that a rewriting system can be implemented as a neural architecture composed by specialized modules: the Selector identifies the target sub-expression to process, the Solver simplifies the sub-expression by computing the corresponding result, and the Combiner produces a new version of the original expression by replacing the sub-expression with the solution provided. We evaluate our model on three types of algorithmic tasks that require simplifying symbolic formulas involving lists, arithmetic, and algebraic expressions. We test the extrapolation capabilities of the proposed architecture using formulas involving a higher number of operands and nesting levels than those seen during training, and we benchmark its performance against the Neural Data Router, a recent model specialized for systematic generalization, and a state-of-the-art large language model (GPT-4) probed with advanced prompting strategies.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Benchmark%20for%20Evaluating%20Automatic%20Speech%20Recognition%20in%20the%20Arabic%20Call%20Domain                                                                                  A New Benchmark for Evaluating Automatic Speech Recognition in the Arabic Call Domain                                                                                  This work is an attempt to introduce a comprehensive benchmark for Arabic speech recognition, specifically tailored to address the challenges of telephone conversations in Arabic language. Arabic, characterized by its rich dialectal diversity and phonetic complexity, presents a number of unique challenges for automatic speech recognition (ASR) systems. These challenges are further amplified in the domain of telephone calls, where audio quality, background noise, and conversational speech styles negatively affect recognition accuracy. Our work aims to establish a robust benchmark that not only encompasses the broad spectrum of Arabic dialects but also emulates the real-world conditions of call-based communications. By incorporating diverse dialectical expressions and accounting for the variable quality of call recordings, this benchmark seeks to provide a rigorous testing ground for the development and evaluation of ASR systems capable of navigating the complexities of Arabic speech in telephonic contexts. This work also attempts to establish a baseline performance evaluation using state-of-the-art ASR technologies.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Dynamic%20Distributed%20Planning%20Approach%3A%20Application%20to%20DPDP%20Problems                                                                                  A New Dynamic Distributed Planning Approach: Application to DPDP Problems                                                                                  In this work, we proposed a new dynamic distributed planning approach that is able to take into account the changes that the agent introduces on his set of actions to be planned in order to take into account the changes that occur in his environment. Our approach fits into the context of distributed planning for distributed plans where each agent can produce its own plans. According to our approach the generation of the plans is based on the satisfaction of the constraints by the use of the genetic algorithms. Our approach is to generate, a new plan by each agent, whenever there is a change in its set of actions to plan. This in order to take into account the new actions introduced in its new plan. In this new plan, the agent takes, each time, as a new action set to plan all the old un-executed actions of the old plan and the new actions engendered by the changes and as a new initial state; the state in which the set of actions of the agent undergoes a change. In our work, we used a concrete case to illustrate and demonstrate the utility of our approach.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Heterogeneous%20Hybrid%20Massive%20MIMO%20Receiver%20with%20An%20Intrinsic%20Ability%20of%20Removing%20Phase%20Ambiguity%20of%20DOA%20Estimation%20via%20Machine%20Learning                                                                                  A New Heterogeneous Hybrid Massive MIMO Receiver with An Intrinsic Ability of Removing Phase Ambiguity of DOA Estimation via Machine Learning                                                                                  Massive multiple input multiple output (MIMO) antenna arrays eventuate a huge amount of circuit costs and computational complexity. To satisfy the needs of high precision and low cost in future green wireless communication, the conventional Hybrid analog and digital MIMO receive structure emerges a natural choice. But it exists an issue of the phase ambiguity in direction of arrival (DOA) estimation and requires at least two time-slots to complete one-time DOA measurement with the first time-slot generating the set of candidate solutions and the remaining ones to find a true direction by received beamforming over this set. This will lead to a low time-efficiency. To address this problem, a new heterogeneous sub-connected hybrid analog and digital (HAD) MIMO structure is proposed with an intrinsic ability of removing phase ambiguity and a corresponding new framework is developed to implement a rapid high-precision DOA estimation using only single time-slot. This framework consists of two steps: 1) form a set of candidate solutions using existing methods like MUSIC) find the class of the true solutions and compute the class mean. To infer the set of true solutions, we propose two new clustering methods: weight global minimum distance (WGMD) and weight local minimum distance (WLMD). And, we also enhance two classic clustering methods: accelerating local weighted k-means (ALW-K-means) and improved density. Additionally, the corresponding closed-form expression of Cramer-Rao lower bound (CRLB) is derived. Simulation results show that the proposed frameworks using the above four clustering can approach the CRLB at almost all SNR regions except for extremely low SNR. Four clustering methods have an accuracy decreasing order as follows: WGMD, improved DBSCAN, ALW-K-means and WLMD.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Hybrid%20Approach%20for%20Identifying%20Obsolescence%20Features%3A%20Applied%20to%20Railway%20Signaling%20Infrastructure                                                                                  A New Hybrid Approach for Identifying Obsolescence Features: Applied to Railway Signaling Infrastructure                                                                                  Electrical component obsolescence poses a major issue especially within systems with large life cycles. Thus, finding the optimal management solution for each obsolescence case is as crucial as knowing what to consider when faced with an obsolescence case. In this paper, a novel hybrid approach for identifying features affecting electrical component obsolescence management is introduced, which combines features engineering techniques and expert knowledge. The method then uses machine learning to predict obsolescence resolution techniques in order to find the optimal resolution. The motivation behind this research is driven by the imperative need for SNCF RESEAU to optimally address and mitigate the challenges posed by electrical component obsolescence in railway infrastructure.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Perspective%20on%20Smiling%20and%20Laughter%20Detection%3A%20Intensity%20Levels%20Matter                                                                                  A New Perspective on Smiling and Laughter Detection: Intensity Levels Matter                                                                                  Smiles and laughs detection systems have attracted a lot of attention in the past decade contributing to the improvement of human-agent interaction systems. But very few considered these expressions as distinct, although no prior work clearly proves them to belong to the same category or not. In this work, we present a deep learning-based multimodal smile and laugh classification system, considering them as two different entities. We compare the use of audio and vision-based models as well as a fusion approach. We show that, as expected, the fusion leads to a better generalization on unseen data. We also present an in-depth analysis of the behavior of these models on the smiles and laughs intensity levels. The analyses on the intensity levels show that the relationship between smiles and laughs might not be as simple as a binary one or even grouping them in a single category, and so, a more complex approach should be taken when dealing with them. We also tackle the problem of limited resources by showing that transfer learning allows the models to improve the detection of confusing intensity levels.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Quantum%20CNN%20Model%20for%20Image%20Classification                                                                                  A New Quantum CNN Model for Image Classification                                                                                  Quantum density matrix represents all the information of the entire quantum system, and novel models of meaning employing density matrices naturally model linguistic phenomena such as hyponymy and linguistic ambiguity, among others in quantum question answering tasks. Naturally, we argue that the quantum density matrix can enhance the image feature information and the relationship between the features for the classical image classification. Specifically, we (i) combine density matrices and CNN to design a new mechanism; (ii) apply the new mechanism to some representative classical image classification tasks. A series of experiments show that the application of quantum density matrix in image classification has the generalization and high efficiency on different datasets. The application of quantum density matrix both in classical question answering tasks and classical image classification tasks show more effective performance.
http://w3id.org/mlsea/pwc/scientificWork/A%20New%20Route%20for%20the%20Determination%20of%20Protein%20Structure%20and%20Function                                                                                  A New Route for the Determination of Protein Structure and Function                                                                                  Understanding complex biological macromolecules, especially proteins, is vital for grasping their diverse chemical functions with direct impact in biology and pharmacology. While techniques like X-ray crystallography and cryo-electron microscopy have been valuable, they face limitations such as radiation damage and difficulties in crystallizing certain proteins. X-ray free-electron lasers (XFELs) offer promising solutions with their ultrafast, high-intensity pulses, potentially enabling structural determination before radiation damage occurs. However, challenges like low signal-to-noise ratio persist, particularly for single protein molecules. To address this, we propose a new method involving engineered protein scaffolds to create ordered arrays of proteins with controlled orientations, aiming at enhancing the signal at the detector. This innovative strategy has the potential to address signal limitations and protein crystallization issues, opening avenues for determining protein structures under physiological conditions. Moreover, it holds promise for studying conformational changes resulting from photo-induced changes, protein-drug and/or protein-protein interactions. Indeed, the prediction of protein-protein interactions, fundamental to numerous biochemical and cellular processes, and the time-dependent conformational changes they undergo, continue to pose a considerable challenge in biology and biochemistry.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Algorithm%20for%20Digital%20Lithological%20Mapping-Case%20Studies%20in%20Sri%20Lanka%27s%20Mineral%20Exploration                                                                                  A Novel Algorithm for Digital Lithological Mapping-Case Studies in Sri Lanka's Mineral Exploration                                                                                  Conventional manual lithological mapping (MLM) through field surveys are resource-extensive and time-consuming. Digital lithological mapping (DLM), harnessing remotely sensed spectral imaging techniques, provides an effective strategy to streamline target locations for MLM or an efficient alternative to MLM. DLM relies on laboratory-generated generic end-member signatures of minerals for spectral analysis. Thus, the accuracy of DLM may be limited due to the presence of site-specific impurities. A strategy, based on a hybrid machine-learning and signal-processing algorithm, is proposed in this paper to tackle this problem of site-specific impurities. In addition, a soil pixel alignment strategy is proposed here to visualize the relative purity of the target minerals. The proposed methodologies are validated via case studies for mapping of Limestone deposits in Jaffna, Ilmenite deposits in Pulmoddai and Mannar, and Montmorillonite deposits in Murunkan, Sri Lanka. The results of satellite-based spectral imaging analysis were corroborated with X-ray diffraction (XRD) and Magnetic Separation (MS) analysis of soil samples collected from those sites via field surveys. There exists a good correspondence between the relative availability of the minerals with the XRD and MS results. In particular, correlation coefficients of 0.8115 and 0.9853 were found for the sites in Pulmoddai and Jaffna respectively.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Audio%20Representation%20for%20Music%20Genre%20Identification%20in%20MIR                                                                                  A Novel Audio Representation for Music Genre Identification in MIR                                                                                  For Music Information Retrieval downstream tasks, the most common audio representation is time-frequency-based, such as Mel spectrograms. In order to identify musical genres, this study explores the possibilities of a new form of audio representation one of the most usual MIR downstream tasks. Therefore, to discretely encoding music using deep vector quantization; a novel audio representation was created for the innovative generative music model i.e. Jukebox. The effectiveness of Jukebox's audio representation is compared to Mel spectrograms using a dataset that is almost equivalent to State-of-the-Art (SOTA) and an almost same transformer design. The results of this study imply that, at least when the transformers are pretrained using a very modest dataset of 20k tracks, Jukebox's audio representation is not superior to Mel spectrograms. This could be explained by the fact that Jukebox's audio representation does not sufficiently take into account the peculiarities of human hearing perception. On the other hand, Mel spectrograms are specifically created with the human auditory sense in mind.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Bi-LSTM%20And%20Transformer%20Architecture%20For%20Generating%20Tabla%20Music                                                                                  A Novel Bi-LSTM And Transformer Architecture For Generating Tabla Music                                                                                  Introduction: Music generation is a complex task that has received significant attention in recent years, and deep learning techniques have shown promising results in this field. Objectives: While extensive work has been carried out on generating Piano and other Western music, there is limited research on generating classical Indian music due to the scarcity of Indian music in machine-encoded formats. In this technical paper, methods for generating classical Indian music, specifically tabla music, is proposed. Initially, this paper explores piano music generation using deep learning architectures. Then the fundamentals are extended to generating tabla music. Methods: Tabla music in waveform (.wav) files are pre-processed using the librosa library in Python. A novel Bi-LSTM with an Attention approach and a transformer model are trained on the extracted features and labels. Results: The models are then used to predict the next sequences of tabla music. A loss of 4.042 and MAE of 1.0814 are achieved with the Bi-LSTM model. With the transformer model, a loss of 55.9278 and MAE of 3.5173 are obtained for tabla music generation. Conclusion: The resulting music embodies a harmonious fusion of novelty and familiarity, pushing the limits of music composition to new horizons.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Decision%20Ensemble%20Framework%3A%20Customized%20Attention-BiLSTM%20and%20XGBoost%20for%20Speculative%20Stock%20Price%20Forecasting                                                                                  A Novel Decision Ensemble Framework: Customized Attention-BiLSTM and XGBoost for Speculative Stock Price Forecasting                                                                                  Forecasting speculative stock prices is essential for effective investment risk management that drives the need for the development of innovative algorithms. However, the speculative nature, volatility, and complex sequential dependencies within financial markets present inherent challenges which necessitate advanced techniques. This paper proposes a novel framework, CAB-XDE (customized attention BiLSTM-XGB decision ensemble), for predicting the daily closing price of speculative stock Bitcoin-USD (BTC-USD). CAB-XDE framework integrates a customized bi-directional long short-term memory (BiLSTM) with the attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages its learning capabilities to capture the complex sequential dependencies and speculative market trends. Additionally, the new attention mechanism dynamically assigns weights to influential features, thereby enhancing interpretability, and optimizing effective cost measures and volatility forecasting. Moreover, XGBoost handles nonlinear relationships and contributes to the proposed CAB-XDE framework robustness. Additionally, the weight determination theory-error reciprocal method further refines predictions. This refinement is achieved by iteratively adjusting model weights. It is based on discrepancies between theoretical expectations and actual errors in individual customized attention BiLSTM and XGBoost models to enhance performance. Finally, the predictions from both XGBoost and customized attention BiLSTM models are concatenated to achieve diverse prediction space and are provided to the ensemble classifier to enhance the generalization capabilities of CAB-XDE. The proposed CAB-XDE framework is empirically validated on volatile Bitcoin market, sourced from Yahoo Finance and outperforms state-of-the-art models with a MAPE of 0.0037, MAE of 84.40, and RMSE of 106.14.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Garment%20Transfer%20Method%20Supervised%20by%20Distilled%20Knowledge%20of%20Virtual%20Try-on%20Model                                                                                  A Novel Garment Transfer Method Supervised by Distilled Knowledge of Virtual Try-on Model                                                                                  This paper proposes a novel garment transfer method supervised with knowledge distillation from virtual try-on. Our method first reasons the transfer parsing to provide shape prior to downstream tasks. We employ a multi-phase teaching strategy to supervise the training of the transfer parsing reasoning model, learning the response and feature knowledge from the try-on parsing reasoning model. To correct the teaching error, it transfers the garment back to its owner to absorb the hard knowledge in the self-study phase. Guided by the transfer parsing, we adjust the position of the transferred garment via STN to prevent distortion. Afterward, we estimate a progressive flow to precisely warp the garment with shape and content correspondences. To ensure warping rationality, we supervise the training of the garment warping model using target shape and warping knowledge from virtual try-on. To better preserve body features in the transfer result, we propose a well-designed training strategy for the arm regrowth task to infer new exposure skin. Experiments demonstrate that our method has state-of-the-art performance compared with other virtual try-on and garment transfer methods in garment transfer, especially for preserving garment texture and body features.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Non-Pyrotechnic%20Radial%20Deployment%20Mechanism%20for%20Payloads%20in%20Sounding%20Rockets                                                                                  A Novel Non-Pyrotechnic Radial Deployment Mechanism for Payloads in Sounding Rockets                                                                                  This research paper introduces an innovative payload deployment mechanism tailored for sounding rockets, addressing a crucial challenge in the field. The problem statement revolves around the need to efficiently and compactly deploy multiple payloads during a single rocket launch. This mechanism, designed to be exceptionally suitable for sounding rockets, features a cylindrical carrier structure equipped with multiple independently operable deployment ports. Powered by a motor, the carrier structure rotates to enable radial ejection of payloads. In this paper, we present the mechanism's design and conduct a comprehensive performance analysis. This analysis encompasses an examination of structural stability, system dynamics, motor torque, and power requirements. Additionally, we develop a simulation model to assess payload deployment behavior under various conditions. Our findings demonstrate the viability and efficiency of this proposed mechanism for deploying multiple payloads within a single sounding rocket launch. Its adaptability to accommodate diverse payload types and sizes enhances its versatility. Moreover, the mechanism's radial deployment capability allows payloads to be released at different altitudes, thereby offering greater flexibility for scientific experiments. In summary, this innovative payload radial deployment mechanism represents a significant advancement in sounding rocket technology and holds promise for a wide array of applications in both scientific and commercial missions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Novel%20Nuanced%20Conversation%20Evaluation%20Framework%20for%20Large%20Language%20Models%20in%20Mental%20Health                                                                                  A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health                                                                                  Understanding the conversation abilities of Large Language Models (LLMs) can help lead to its more cautious and appropriate deployment. This is especially important for safety-critical domains like mental health, where someone's life may depend on the exact wording of a response to an urgent question. In this paper, we propose a novel framework for evaluating the nuanced conversation abilities of LLMs. Within it, we develop a series of quantitative metrics developed from literature on using psychotherapy conversation analysis literature. While we ensure that our framework and metrics are transferable by researchers to relevant adjacent domains, we apply them to the mental health field. We use our framework to evaluate several popular frontier LLMs, including some GPT and Llama models, through a verified mental health dataset. Our results show that GPT4 Turbo can perform significantly more similarly to verified therapists than other selected LLMs. We conduct additional analysis to examine how LLM conversation performance varies across specific mental health topics. Our results indicate that GPT4 Turbo performs well in achieving high correlation with verified therapists in particular topics such as Parenting and Relationships. We believe our contributions will help researchers develop better LLMs that, in turn, will more positively support people's lives.
http://w3id.org/mlsea/pwc/scientificWork/A%20PNP%20ion%20channel%20deep%20learning%20solver%20with%20local%20neural%20network%20and%20finite%20element%20input%20data                                                                                  A PNP ion channel deep learning solver with local neural network and finite element input data                                                                                  In this paper, a deep learning method for solving an improved one-dimensional Poisson-Nernst-Planck ion channel (PNPic) model, called the PNPic deep learning solver, is presented. In particular, it combines a novel local neural network scheme with an effective PNPic finite element solver. Since the input data of the neural network scheme only involves a small local patch of coarse grid solutions, which the finite element solver can quickly produce, the PNPic deep learning solver can be trained much faster than any corresponding conventional global neural network solvers. After properly trained, it can output a predicted PNPic solution in a much higher degree of accuracy than the low cost coarse grid solutions and can reflect different perturbation cases on the parameters, ion channel subregions, and interface and boundary values, etc. Consequently, the PNPic deep learning solver can generate a numerical solution with high accuracy for a family of PNPic models. As an initial study, two types of numerical tests were done by perturbing one and two parameters of the PNPic model, respectively, as well as the tests done by using a few perturbed interface positions of the model as training samples. These tests demonstrate that the PNPic deep learning solver can generate highly accurate PNPic numerical solutions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Parsimonious%20Setup%20for%20Streamflow%20Forecasting%20using%20CNN-LSTM                                                                                  A Parsimonious Setup for Streamflow Forecasting using CNN-LSTM                                                                                  Significant strides have been made in advancing streamflow predictions, notably with the introduction of cutting-edge machine-learning models. Predominantly, Long Short-Term Memories (LSTMs) and Convolution Neural Networks (CNNs) have been widely employed in this domain. While LSTMs are applicable in both rainfall-runoff and time series settings, CNN-LSTMs have primarily been utilized in rainfall-runoff scenarios. In this study, we extend the application of CNN-LSTMs to time series settings, leveraging lagged streamflow data in conjunction with precipitation and temperature data to predict streamflow. Our results show a substantial improvement in predictive performance in 21 out of 32 HUC8 basins in Nebraska, showcasing noteworthy increases in the Kling-Gupta Efficiency (KGE) values. These results highlight the effectiveness of CNN-LSTMs in time series settings, particularly for spatiotemporal hydrological modeling, for more accurate and robust streamflow predictions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Physics-informed%20machine%20learning%20model%20for%20time-dependent%20wave%20runup%20prediction                                                                                  A Physics-informed machine learning model for time-dependent wave runup prediction                                                                                  Wave runup is a critical factor affecting coastal flooding, shoreline changes, and damage to coastal structures. Climate change is also expected to amplify wave runup's impact on coastal areas. Therefore, fast and accurate wave runup estimation is essential for effective coastal engineering design and management. However, predicting the time-dependent wave runup is challenging due to the intrinsic nonlinearities and non-stationarity of the process, even with the use of the most advanced machine learning techniques. In this study, a physics-informed machine learning-based approach is proposed to efficiently and accurately simulate time-series wave runup. The methodology combines the computational efficiency of the Surfbeat (XBSB) mode with the accuracy of the nonhydrostatic (XBNH) mode of the XBeach model. Specifically, a conditional generative adversarial network (cGAN) is used to map the image representation of wave runup from XBSB to the corresponding image from XBNH. These images are generated by first converting wave runup signals into time-frequency scalograms and then transforming them into image representations. The cGAN model achieves improved performance in image-to-image mapping tasks by incorporating physics-based knowledge from XBSB. After training the model, the high-fidelity XBNH-based scalograms can be predicted, which are then employed to reconstruct the time-series wave runup using the inverse wavelet transform. The simulation results underscore the efficiency and robustness of the proposed model in predicting wave runup, suggesting its potential value for applications in risk assessment and management.
http://w3id.org/mlsea/pwc/scientificWork/A%20Power%20Management%20and%20Control%20System%20for%20Portable%20Ecosystem%20Monitoring%20Devices                                                                                  A Power Management and Control System for Portable Ecosystem Monitoring Devices                                                                                  Recent advances in Internet of Things (IoT) and Artificial Intelligence (AI) technologies help ecosystem monitoring to shift towards automated monitoring with low power sensors and embedded vision on powerful processing units. Vision-based monitoring devices need an effective power management and control system (PMCS) with system-adapted power input and output capabilities to achieve power-efficient and self-sustainable operation. Here, we present a universal power management solution for automated ecosystem monitoring devices, compatible with commonly used off-the-shelf edge processing units (EPUs). The proposed design is specifically adapted for battery-powered EPU systems by incorporating power-matched energy harvesting (EH), a power switch with low-power sleep mode, and simple system integration in an MCU-less architecture with automated operation. We use a 4-month environmental case study to monitor plant growth under 4mg microplastic (MP) exposure, demonstrating that the setup achieved continuous and sustainable operation. In this plant phenology case study, our power management module is deployed in an embedded vision camera equipped with a 5W solar panel and five various environmental sensors. This work shows the usability of the power management board in environmentally relevant use cases and for tasks in agricultural applications.
http://w3id.org/mlsea/pwc/scientificWork/A%20Practical%20Guide%20to%20Statistical%20Distances%20for%20Evaluating%20Generative%20Models%20in%20Science                                                                                  A Practical Guide to Statistical Distances for Evaluating Generative Models in Science                                                                                  Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular notions of statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (Fr 'echet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distances are used in practice, we evaluate generative models from different scientific domains, namely a model of decision making and a model generating medical images. We showcase that distinct distances can give different results on similar data. Through this guide, we aim to help researchers to use, interpret, and evaluate statistical distances for generative models in science.
http://w3id.org/mlsea/pwc/scientificWork/A%20Predictive%20Surrogate%20Model%20for%20Heat%20Transfer%20of%20an%20Impinging%20Jet%20on%20a%20Concave%20Surface                                                                                  A Predictive Surrogate Model for Heat Transfer of an Impinging Jet on a Concave Surface                                                                                  This paper aims to comprehensively investigate the efficacy of various Model Order Reduction (MOR) and deep learning techniques in predicting heat transfer in a pulsed jet impinging on a concave surface. Expanding on the previous experimental and numerical research involving pulsed circular jets, this investigation extends to evaluate Predictive Surrogate Models (PSM) for heat transfer across various jet characteristics. To this end, this work introduces two predictive approaches, one employing a Fast Fourier Transformation augmented Artificial Neural Network (FFT-ANN) for predicting the average Nusselt number under constant-frequency scenarios. Moreover, the investigation introduces the Proper Orthogonal Decomposition and Long Short-Term Memory (POD-LSTM) approach for random-frequency impingement jets. The POD-LSTM method proves to be a robust solution for predicting the local heat transfer rate under random-frequency impingement scenarios, capturing both the trend and value of temporal modes. The comparison of these approaches highlights the versatility and efficacy of advanced machine learning techniques in modelling complex heat transfer phenomena.
http://w3id.org/mlsea/pwc/scientificWork/A%20Primal-Dual%20Algorithm%20for%20Faster%20Distributionally%20Robust%20Optimization                                                                                  A Primal-Dual Algorithm for Faster Distributionally Robust Optimization                                                                                  We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses the $f$-DRO, Wasserstein-DRO, and spectral/$L$-risk formulations used in practice. We present Drago, a stochastic primal-dual algorithm that achieves a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems. The method combines both randomized and cyclic components with mini-batching, which effectively handles the unique asymmetric nature of the primal and dual problems in DRO. We support our theoretical results with numerical benchmarks in classification and regression.
http://w3id.org/mlsea/pwc/scientificWork/A%20Probabilistic%20Model%20to%20explain%20Self-Supervised%20Representation%20Learning                                                                                  A Probabilistic Model to explain Self-Supervised Representation Learning                                                                                  Self-supervised learning (SSL) learns representations by leveraging an auxiliary unsupervised task, such as classifying semantically related samples, e.g. different data augmentations or modalities. Of the many approaches to SSL, contrastive methods, e.g. SimCLR, CLIP and VicREG, have gained attention for learning representations that achieve downstream performance close to that of supervised learning. However, a theoretical understanding of the mechanism behind these methods eludes. We propose a generative latent variable model for the data and show that several families of discriminative self-supervised algorithms, including contrastive methods, approximately induce its latent structure over representations, providing a unifying theoretical framework. We also justify links to mutual information and the use of a projection head. Fitting our model generatively, as SimVE, improves performance over previous VAE methods on common benchmarks (e.g. FashionMNIST, CIFAR10, CelebA), narrows the gap to discriminative methods on _content_ classification and, as our analysis predicts, outperforms them where _style_ information is required, taking a step toward task-agnostic representations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Python%20library%20for%20efficient%20computation%20of%20molecular%20fingerprints                                                                                  A Python library for efficient computation of molecular fingerprints                                                                                  Machine learning solutions are very popular in the field of chemoinformatics, where they have numerous applications, such as novel drug discovery or molecular property prediction. Molecular fingerprints are algorithms commonly used for vectorizing chemical molecules as a part of preprocessing in this kind of solution. However, despite their popularity, there are no libraries that implement them efficiently for large datasets, utilizing modern, multicore architectures. On top of that, most of them do not provide the user with an intuitive interface, or one that would be compatible with other machine learning tools. In this project, we created a Python library that computes molecular fingerprints efficiently and delivers an interface that is comprehensive and enables the user to easily incorporate the library into their existing machine learning workflow. The library enables the user to perform computation on large datasets using parallelism. Because of that, it is possible to perform such tasks as hyperparameter tuning in a reasonable time. We describe tools used in implementation of the library and asses its time performance on example benchmark datasets. Additionally, we show that using molecular fingerprints we can achieve results comparable to state-of-the-art ML solutions even with very simple models.
http://w3id.org/mlsea/pwc/scientificWork/A%20Quantitative%20Discourse%20Analysis%20of%20Asian%20Workers%20in%20the%20US%20Historical%20Newspapers                                                                                  A Quantitative Discourse Analysis of Asian Workers in the US Historical Newspapers                                                                                  Warning: This paper contains examples of offensive language targetting marginalized population. The digitization of historical texts invites researchers to explore the large-scale corpus of historical texts with computational methods. In this study, we present computational text analysis on a relatively understudied topic of how Asian workers are represented in historical newspapers in the United States. We found that the word 'coolie' was semantically different in some States (e.g., Massachusetts, Rhode Island, Wyoming, Oklahoma, and Arkansas) with the different discourses around coolie. We also found that then-Confederate newspapers and then-Union newspapers formed distinctive discourses by measuring over-represented words. Newspapers from then-Confederate States associated coolie with slavery-related words. In addition, we found Asians were perceived to be inferior to European immigrants and subjected to the target of racism. This study contributes to supplementing the qualitative analysis of racism in the United States with quantitative discourse analysis.
http://w3id.org/mlsea/pwc/scientificWork/A%20Quantum%20Fuzzy-based%20Approach%20for%20Real-Time%20Detection%20of%20Solar%20Coronal%20Holes                                                                                  A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal Holes                                                                                  The detection and analysis of the solar coronal holes (CHs) is an important field of study in the domain of solar physics. Mainly, it is required for the proper prediction of the geomagnetic storms which directly or indirectly affect various space and ground-based systems. For the detection of CHs till date, the solar scientist depends on manual hand-drawn approaches. However, with the advancement of image processing technologies, some automated image segmentation methods have been used for the detection of CHs. In-spite of this, fast and accurate detection of CHs are till a major issues. Here in this work, a novel quantum computing-based fast fuzzy c-mean technique has been developed for fast detection of the CHs region. The task has been carried out in two stages, in first stage the solar image has been segmented using a quantum computing based fast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted out from the segmented image based on image morphological operation. In the work, quantum computing has been used to optimize the cost function of the fast fuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm (QAOA) has been used to optimize the quadratic part of the cost function. The proposed method has been tested for 193 AA{} SDO/AIA full-disk solar image datasets and has been compared with the existing techniques. The outcome shows the comparable performance of the proposed method with the existing one within a very lesser time.
http://w3id.org/mlsea/pwc/scientificWork/A%20Real-Time%20Framework%20for%20Domain-Adaptive%20Underwater%20Object%20Detection%20with%20Image%20Enhancement                                                                                  A Real-Time Framework for Domain-Adaptive Underwater Object Detection with Image Enhancement                                                                                  In recent years, significant progress has been made in the field of underwater image enhancement (UIE). However, its practical utility for high-level vision tasks, such as underwater object detection (UOD) in Autonomous Underwater Vehicles (AUVs), remains relatively unexplored. It may be attributed to several factors: (1) Existing methods typically employ UIE as a pre-processing step, which inevitably introduces considerable computational overhead and latency. (2) The process of enhancing images prior to training object detectors may not necessarily yield performance improvements. (3) The complex underwater environments can induce significant domain shifts across different scenarios, seriously deteriorating the UOD performance. To address these challenges, we introduce EnYOLO, an integrated real-time framework designed for simultaneous UIE and UOD with domain-adaptation capability. Specifically, both the UIE and UOD task heads share the same network backbone and utilize a lightweight design. Furthermore, to ensure balanced training for both tasks, we present a multi-stage training strategy aimed at consistently enhancing their performance. Additionally, we propose a novel domain-adaptation strategy to align feature embeddings originating from diverse underwater environments. Comprehensive experiments demonstrate that our framework not only achieves state-of-the-art (SOTA) performance in both UIE and UOD tasks, but also shows superior adaptability when applied to different underwater scenarios. Our efficiency analysis further highlights the substantial potential of our framework for onboard deployment.
http://w3id.org/mlsea/pwc/scientificWork/A%20Real-time%20Anomaly%20Detection%20Using%20Convolutional%20Autoencoder%20with%20Dynamic%20Threshold                                                                                  A Real-time Anomaly Detection Using Convolutional Autoencoder with Dynamic Threshold                                                                                  The majority of modern consumer-level energy is generated by real-time smart metering systems. These frequently contain anomalies, which prevent reliable estimates of the series' evolution. This work introduces a hybrid modeling approach combining statistics and a Convolutional Autoencoder with a dynamic threshold. The threshold is determined based on Mahalanobis distance and moving averages. It has been tested using real-life energy consumption data collected from smart metering systems. The solution includes a real-time, meter-level anomaly detection system that connects to an advanced monitoring system. This makes a substantial contribution by detecting unusual data movements and delivering an early warning. Early detection and subsequent troubleshooting can financially benefit organizations and consumers and prevent disasters from occurring.
http://w3id.org/mlsea/pwc/scientificWork/A%20Reproducibility%20Study%20of%20Goldilocks%3A%20Just-Right%20Tuning%20of%20BERT%20for%20TAR                                                                                  A Reproducibility Study of Goldilocks: Just-Right Tuning of BERT for TAR                                                                                  Screening documents is a tedious and time-consuming aspect of high-recall retrieval tasks, such as compiling a systematic literature review, where the goal is to identify all relevant documents for a topic. To help streamline this process, many Technology-Assisted Review (TAR) methods leverage active learning techniques to reduce the number of documents requiring review. BERT-based models have shown high effectiveness in text classification, leading to interest in their potential use in TAR workflows. In this paper, we investigate recent work that examined the impact of further pre-training epochs on the effectiveness and efficiency of a BERT-based active learning pipeline. We first report that we could replicate the original experiments on two specific TAR datasets, confirming some of the findings: importantly, that further pre-training is critical to high effectiveness, but requires attention in terms of selecting the correct training epoch. We then investigate the generalisability of the pipeline on a different TAR task, that of medical systematic reviews. In this context, we show that there is no need for further pre-training if a domain-specific BERT backbone is used within the active learning pipeline. This finding provides practical implications for using the studied active learning pipeline within domain-specific TAR tasks.
http://w3id.org/mlsea/pwc/scientificWork/A%20Review%20of%20the%20GIC%20Blocker%20Placement%20Problem                                                                                  A Review of the GIC Blocker Placement Problem                                                                                  Space weather poses a tremendous threat to power systems: geomagnetic disturbances could result in widespread disruptions and long-duration blackouts, including severe damage to system components. To mitigate their impacts, a handful of strategies exist, with the most promising being the deployment of transformer neutral blocking devices. The high cost of these devices, however, precludes their installation at all substations; this motivates the development of effective solutions for the cost-effective placement of such devices. While the current state-of-the-art in blocker placement methods is insufficient to be applied to real-sized power grids, ongoing research continues to increase the size of networks for which the placement problem remains tractable. Along these lines, the contributions of this paper are two fold: first, a comprehensive overview of the current state-of-the-art in blocker placement methods is provided; and second, a complete optimization formulation - implemented and benchmarked in an open-source software - for the blocker placement problem is presented.
http://w3id.org/mlsea/pwc/scientificWork/A%20Safe%20Preference%20Learning%20Approach%20for%20Personalization%20with%20Applications%20to%20Autonomous%20Vehicles                                                                                  A Safe Preference Learning Approach for Personalization with Applications to Autonomous Vehicles                                                                                  This work introduces a preference learning method that ensures adherence to given specifications, with an application to autonomous vehicles. Our approach incorporates the priority ordering of Signal Temporal Logic (STL) formulas describing traffic rules into a learning framework. By leveraging Parametric Weighted Signal Temporal Logic (PWSTL), we formulate the problem of safety-guaranteed preference learning based on pairwise comparisons and propose an approach to solve this learning problem. Our approach finds a feasible valuation for the weights of the given PWSTL formula such that, with these weights, preferred signals have weighted quantitative satisfaction measures greater than their non-preferred counterparts. The feasible valuation of weights given by our approach leads to a weighted STL formula that can be used in correct-and-custom-by-construction controller synthesis. We demonstrate the performance of our method with a pilot human subject study in two different simulated driving scenarios involving a stop sign and a pedestrian crossing. Our approach yields competitive results compared to existing preference learning methods in terms of capturing preferences and notably outperforms them when safety is considered.
http://w3id.org/mlsea/pwc/scientificWork/A%20Segmentation%20Foundation%20Model%20for%20Diverse-type%20Tumors                                                                                  A Segmentation Foundation Model for Diverse-type Tumors                                                                                  Large pre-trained models with their numerous model parameters and extensive training datasets have shown excellent performance in various tasks. Many publicly available medical image datasets do not have a sufficient amount of data so there are few large-scale models in medical imaging. We propose a large-scale Tumor Segmentation Foundation Model (TSFM) with 1.6 billion parameters using Resblock-backbone and Transformer-bottleneck,which has good transfer ability for downstream tasks. To make TSFM exhibit good performance in tumor segmentation, we make full use of the strong spatial correlation between tumors and organs in the medical image, innovatively fuse 7 tumor datasets and 3 multi-organ datasets to build a 3D medical dataset pool, including 2779 cases with totally 300k medical images, whose size currently exceeds many other single publicly available datasets. TSFM is the pre-trained model for medical image segmentation, which also can be transferred to multiple downstream tasks for fine-tuning learning. The average performance of our pre-trained model is 2% higher than that of nnU-Net across various tumor types. In the transfer learning task, TSFM only needs 5% training epochs of nnU-Net to achieve similar performance and can surpass nnU-Net by 2% on average with 10% training epoch. Pre-trained TSFM and its code will be released soon.
http://w3id.org/mlsea/pwc/scientificWork/A%20Selective%20Review%20on%20Statistical%20Methods%20for%20Massive%20Data%20Computation%3A%20Distributed%20Computing%2C%20Subsampling%2C%20and%20Minibatch%20Techniques                                                                                  A Selective Review on Statistical Methods for Massive Data Computation: Distributed Computing, Subsampling, and Minibatch Techniques                                                                                  This paper presents a selective review of statistical computation methods for massive data analysis. A huge amount of statistical methods for massive data computation have been rapidly developed in the past decades. In this work, we focus on three categories of statistical computation methods: (1) distributed computing, (2) subsampling methods, and (3) minibatch gradient techniques. The first class of literature is about distributed computing and focuses on the situation, where the dataset size is too huge to be comfortably handled by one single computer. In this case, a distributed computation system with multiple computers has to be utilized. The second class of literature is about subsampling methods and concerns about the situation, where the sample size of dataset is small enough to be placed on one single computer but too large to be easily processed by its memory as a whole. The last class of literature studies those minibatch gradient related optimization techniques, which have been extensively used for optimizing various deep learning models.
http://w3id.org/mlsea/pwc/scientificWork/A%20Semantic%20Segmentation-guided%20Approach%20for%20Ground-to-Aerial%20Image%20Matching                                                                                  A Semantic Segmentation-guided Approach for Ground-to-Aerial Image Matching                                                                                  Nowadays the accurate geo-localization of ground-view images has an important role across domains as diverse as journalism, forensics analysis, transports, and Earth Observation. This work addresses the problem of matching a query ground-view image with the corresponding satellite image without GPS data. This is done by comparing the features from a ground-view image and a satellite one, innovatively leveraging the corresponding latter's segmentation mask through a three-stream Siamese-like network. The proposed method, Semantic Align Net (SAN), focuses on limited Field-of-View (FoV) and ground panorama images (images with a FoV of 360{ deg}). The novelty lies in the fusion of satellite images in combination with their semantic segmentation masks, aimed at ensuring that the model can extract useful features and focus on the significant parts of the images. This work shows how SAN through semantic analysis of images improves the performance on the unlabelled CVUSA dataset for all the tested FoVs.
http://w3id.org/mlsea/pwc/scientificWork/A%20Semantic%20Social%20Network%20Analysis%20Tool%20for%20Sensitivity%20Analysis%20and%20What-If%20Scenario%20Testing%20in%20Alcohol%20Consumption%20Studies                                                                                  A Semantic Social Network Analysis Tool for Sensitivity Analysis and What-If Scenario Testing in Alcohol Consumption Studies                                                                                  Social Network Analysis (SNA) is a set of techniques developed in the field of social and behavioral sciences research, in order to characterize and study the social relationships that are established among a set of individuals. When building a social network for performing an SNA analysis, an initial process of data gathering is achieved in order to extract the characteristics of the individuals and their relationships. This is usually done by completing a questionnaire containing different types of questions that will be later used to obtain the SNA measures needed to perform the study. There are, then, a great number of different possible network generating questions and also many possibilities for mapping the responses to the corresponding characteristics and relationships. Many variations may be introduced into these questions (the way they are posed, the weights given to each of the responses, etc.) that may have an effect on the resulting networks. All these different variations are difficult to achieve manually, because the process is time-consuming and error prone. The tool described in this paper uses semantic knowledge representation techniques in order to facilitate this kind of sensitivity studies. The base of the tool is a conceptual structure, called 'ontology' that is able to represent the different concepts and their definitions. The tool is compared to other similar ones, and the advantages of the approach are highlighted, giving some particular examples from an ongoing SNA study about alcohol consumption habits in adolescents.
http://w3id.org/mlsea/pwc/scientificWork/A%20Semantic-Aware%20Multiple%20Access%20Scheme%20for%20Distributed%2C%20Dynamic%206G-Based%20Applications                                                                                  A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic 6G-Based Applications                                                                                  The emergence of the semantic-aware paradigm presents opportunities for innovative services, especially in the context of 6G-based applications. Although significant progress has been made in semantic extraction techniques, the incorporation of semantic information into resource allocation decision-making is still in its early stages, lacking consideration of the requirements and characteristics of future systems. In response, this paper introduces a novel formulation for the problem of multiple access to the wireless spectrum. It aims to optimize the utilization-fairness trade-off, using the $ alpha$-fairness metric, while accounting for user data correlation by introducing the concepts of self- and assisted throughputs. Initially, the problem is analyzed to identify its optimal solution. Subsequently, a Semantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL) technique is proposed. This method is grounded in Model-free Multi-Agent Deep Reinforcement Learning (MADRL), enabling the user equipment to autonomously make decisions regarding wireless spectrum access based solely on their local individual observations. The efficiency of the proposed technique is evaluated through two scenarios: single-channel and multi-channel. The findings illustrate that, across a spectrum of $ alpha$ values, association matrices, and channels, SAMA-D3QL consistently outperforms alternative approaches. This establishes it as a promising candidate for facilitating the realization of future federated, dynamically evolving applications.
http://w3id.org/mlsea/pwc/scientificWork/A%20Simple-but-effective%20Baseline%20for%20Training-free%20Class-Agnostic%20Counting                                                                                  A Simple-but-effective Baseline for Training-free Class-Agnostic Counting                                                                                  Class-Agnostic Counting (CAC) seeks to accurately count objects in a given image with only a few reference examples. While previous methods achieving this relied on additional training, recent efforts have shown that it's possible to accomplish this without training by utilizing pre-existing foundation models, particularly the Segment Anything Model (SAM), for counting via instance-level segmentation. Although promising, current training-free methods still lag behind their training-based counterparts in terms of performance. In this research, we present a straightforward training-free solution that effectively bridges this performance gap, serving as a strong baseline. The primary contribution of our work lies in the discovery of four key technologies that can enhance performance. Specifically, we suggest employing a superpixel algorithm to generate more precise initial point prompts, utilizing an image encoder with richer semantic knowledge to replace the SAM encoder for representing candidate objects, and adopting a multiscale mechanism and a transductive prototype scheme to update the representation of reference examples. By combining these four technologies, our approach achieves significant improvements over existing training-free methods and delivers performance on par with training-based ones.
http://w3id.org/mlsea/pwc/scientificWork/A%20Smoothing%20Algorithm%20for%20l1%20Support%20Vector%20Machines                                                                                  A Smoothing Algorithm for l1 Support Vector Machines                                                                                  A smoothing algorithm is presented for solving the soft-margin Support Vector Machine (SVM) optimization problem with an $ ell^{1}$ penalty. This algorithm is designed to require a modest number of passes over the data, which is an important measure of its cost for very large datasets. The algorithm uses smoothing for the hinge-loss function, and an active set approach for the $ ell^{1}$ penalty. The smoothing parameter $ alpha$ is initially large, but typically halved when the smoothed problem is solved to sufficient accuracy. Convergence theory is presented that shows $ mathcal{O}(1+ log(1+ log_+(1/ alpha)))$ guarded Newton steps for each value of $ alpha$ except for asymptotic bands $ alpha= Theta(1)$ and $ alpha= Theta(1/N)$, with only one Newton step provided $ eta alpha gg1/N$, where $N$ is the number of data points and the stopping criterion that the predicted reduction is less than $ eta alpha$. The experimental results show that our algorithm is capable of strong test accuracy without sacrificing training speed.
http://w3id.org/mlsea/pwc/scientificWork/A%20Sparsity%20Principle%20for%20Partially%20Observable%20Causal%20Representation%20Learning                                                                                  A Sparsity Principle for Partially Observable Causal Representation Learning                                                                                  Causal representation learning aims at identifying high-level causal variables from perceptual data. Most methods assume that all latent causal variables are captured in the high-dimensional observations. We instead consider a partially observed setting, in which each measurement only provides information about a subset of the underlying causal state. Prior work has studied this setting with multiple domains or views, each depending on a fixed subset of latents. Here, we focus on learning from unpaired observations from a dataset with an instance-dependent partial observability pattern. Our main contribution is to establish two identifiability results for this setting: one for linear mixing functions without parametric assumptions on the underlying causal model, and one for piecewise linear mixing functions with Gaussian latent causal variables. Based on these insights, we propose two methods for estimating the underlying causal variables by enforcing sparsity in the inferred representation. Experiments on different simulated datasets and established benchmarks highlight the effectiveness of our approach in recovering the ground-truth latents.
http://w3id.org/mlsea/pwc/scientificWork/A%20Spatial-Temporal%20Progressive%20Fusion%20Network%20for%20Breast%20Lesion%20Segmentation%20in%20Ultrasound%20Videos                                                                                  A Spatial-Temporal Progressive Fusion Network for Breast Lesion Segmentation in Ultrasound Videos                                                                                  Ultrasound video-based breast lesion segmentation provides a valuable assistance in early breast lesion detection and treatment. However, existing works mainly focus on lesion segmentation based on ultrasound breast images which usually can not be adapted well to obtain desirable results on ultrasound videos. The main challenge for ultrasound video-based breast lesion segmentation is how to exploit the lesion cues of both intra-frame and inter-frame simultaneously. To address this problem, we propose a novel Spatial-Temporal Progressive Fusion Network (STPFNet) for video based breast lesion segmentation problem. The main aspects of the proposed STPFNet are threefold. First, we propose to adopt a unified network architecture to capture both spatial dependences within each ultrasound frame and temporal correlations between different frames together for ultrasound data representation. Second, we propose a new fusion module, termed Multi-Scale Feature Fusion (MSFF), to fuse spatial and temporal cues together for lesion detection. MSFF can help to determine the boundary contour of lesion region to overcome the issue of lesion boundary blurring. Third, we propose to exploit the segmentation result of previous frame as the prior knowledge to suppress the noisy background and learn more robust representation. In particular, we introduce a new publicly available ultrasound video breast lesion segmentation dataset, termed UVBLS200, which is specifically dedicated to breast lesion segmentation. It contains 200 videos, including 80 videos of benign lesions and 120 videos of malignant lesions. Experiments on the proposed dataset demonstrate that the proposed STPFNet achieves better breast lesion detection performance than state-of-the-art methods.
http://w3id.org/mlsea/pwc/scientificWork/A%20Spectral%20Library%20and%20Method%20for%20Sparse%20Unmixing%20of%20Hyperspectral%20Images%20in%20Fluorescence%20Guided%20Resection%20of%20Brain%20Tumors                                                                                  A Spectral Library and Method for Sparse Unmixing of Hyperspectral Images in Fluorescence Guided Resection of Brain Tumors                                                                                  Through spectral unmixing, hyperspectral imaging (HSI) in fluorescence-guided brain tumor surgery has enabled detection and classification of tumor regions invisible to the human eye. Prior unmixing work has focused on determining a minimal set of viable fluorophore spectra known to be present in the brain and effectively reconstructing human data without overfitting. With these endmembers, non-negative least squares regression (NNLS) was used to compute the abundances. However, HSI images are heterogeneous, so one small set of endmember spectra may not fit all pixels well. Additionally, NNLS is the maximum likelihood estimator only if the measurement is normally distributed, and it does not enforce sparsity, which leads to overfitting and unphysical results. Here, we analyzed 555666 HSI fluorescence spectra from 891 ex vivo measurements of patients with brain tumors to show that a Poisson distribution models the measured data 82% better than a Gaussian in terms of the Kullback-Leibler divergence and that the endmember abundance vectors are sparse. With this knowledge, we introduce (1) a library of 9 endmember spectra, (2) a sparse, non-negative Poisson regression algorithm to perform physics-informed unmixing with this library without overfitting, and (3) a highly realistic spectral measurement simulation with known endmember abundances. The new unmixing method was then tested on the human and simulated data and compared to four other candidate methods. It outperforms previous methods with 25% lower error in the computed abundances on the simulated data than NNLS, lower reconstruction error on human data, beUer sparsity, and 31 times faster runtime than state-of-the-art Poisson regression. This method and library of endmember spectra can enable more accurate spectral unmixing to beUer aid the surgeon during brain tumor resection.
http://w3id.org/mlsea/pwc/scientificWork/A%20Stable%2C%20Fast%2C%20and%20Fully%20Automatic%20Learning%20Algorithm%20for%20Predictive%20Coding%20Networks                                                                                  A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks                                                                                  Predictive coding networks are neuroscience-inspired models with roots in both Bayesian statistics and neuroscience. Training such models, however, is quite inefficient and unstable. In this work, we show how by simply changing the temporal scheduling of the update rule for the synaptic weights leads to an algorithm that is much more efficient and stable than the original one, and has theoretical guarantees in terms of convergence. The proposed algorithm, that we call incremental predictive coding (iPC) is also more biologically plausible than the original one, as it it fully automatic. In an extensive set of experiments, we show that iPC constantly performs better than the original formulation on a large number of benchmarks for image classification, as well as for the training of both conditional and masked language models, in terms of test accuracy, efficiency, and convergence with respect to a large set of hyperparameters.
http://w3id.org/mlsea/pwc/scientificWork/A%20Statistical%20Model%20of%20Bursty%20Mixed%20Gaussian-impulsive%20Noise%3A%20Model%20and%20Parameter%20Estimation                                                                                  A Statistical Model of Bursty Mixed Gaussian-impulsive Noise: Model and Parameter Estimation                                                                                  Non-Gaussian impulsive noise (IN) with memory exists in many practical applications. When it is mixed with white Gaussian noise (WGN), the resultant mixed noise will be bursty. The performance of communication systems will degrade significantly under bursty mixed noise if the bursty characteristic is ignored. A proper model for the bursty mixed noise and corresponding algorithms needs to be designed to obtain desirable performance but there is no such model reported to the best of our knowledge. The important problem is addressed in the two-part paper. In the first part, we propose a closed-form heavy-tailed multivariate probability density function (PDF) that to model the bursty mixed noise. This model is the weighted addition of gaussian distribution and student distribution. Then, we present the parameter estimation method based on the empirical characteristic function of the proposed model and analyze the performance of the parameter estimation. Numerical results show that our proposed bursty mixed noise model matches the measured bursty noise well. Meanwhile, the parameters of the proposed noise model can be accurately estimated in terms of mean square error (MSE).
http://w3id.org/mlsea/pwc/scientificWork/A%20StrongREJECT%20for%20Empty%20Jailbreaks                                                                                  A StrongREJECT for Empty Jailbreaks                                                                                  The rise of large language models (LLMs) has drawn attention to the existence of 'jailbreaks' that allow the models to be used maliciously. However, there is no standard benchmark for measuring the severity of a jailbreak, leaving authors of jailbreak papers to create their own. We show that these benchmarks often include vague or unanswerable questions and use grading criteria that are biased towards overestimating the misuse potential of low-quality model responses. Some jailbreak techniques make the problem worse by decreasing the quality of model responses even on benign questions: we show that several jailbreaking techniques substantially reduce the zero-shot performance of GPT-4 on MMLU. Jailbreaks can also make it harder to elicit harmful responses from an 'uncensored' open-source model. We present a new benchmark, StrongREJECT, which better discriminates between effective and ineffective jailbreaks by using a higher-quality question set and a more accurate response grading algorithm. We show that our new grading scheme better accords with human judgment of response quality and overall jailbreak effectiveness, especially on the sort of low-quality responses that contribute the most to over-estimation of jailbreak performance on existing benchmarks. We release our code and data at https://github.com/alexandrasouly/strongreject.
http://w3id.org/mlsea/pwc/scientificWork/A%20Study%20on%20Training%20and%20Developing%20Large%20Language%20Models%20for%20Behavior%20Tree%20Generation                                                                                  A Study on Training and Developing Large Language Models for Behavior Tree Generation                                                                                  This paper presents an innovative exploration of the application potential of large language models (LLM) in addressing the challenging task of automatically generating behavior trees (BTs) for complex tasks. The conventional manual BT generation method is inefficient and heavily reliant on domain expertise. On the other hand, existing automatic BT generation technologies encounter bottlenecks related to task complexity, model adaptability, and reliability. In order to overcome these challenges, we propose a novel methodology that leverages the robust representation and reasoning abilities of LLMs. The core contribution of this paper lies in the design of a BT generation framework based on LLM, which encompasses the entire process, from data synthesis and model training to application developing and data verification. Synthetic data is introduced to train the BT generation model (BTGen model), enhancing its understanding and adaptability to various complex tasks, thereby significantly improving its overall performance. In order to ensure the effectiveness and executability of the generated BTs, we emphasize the importance of data verification and introduce a multilevel verification strategy. Additionally, we explore a range of agent design and development schemes with LLM as the central element. We hope that the work in this paper may provide a reference for the researchers who are interested in BT generation based on LLMs.
http://w3id.org/mlsea/pwc/scientificWork/A%20Surprising%20Failure%3F%20Multimodal%20LLMs%20and%20the%20NLVR%20Challenge                                                                                  A Surprising Failure? Multimodal LLMs and the NLVR Challenge                                                                                  This study evaluates three state-of-the-art MLLMs -- GPT-4V, Gemini Pro, and the open-source model IDEFICS -- on the compositional natural language vision reasoning task NLVR. Given a human-written sentence paired with a synthetic image, this task requires the model to determine the truth value of the sentence with respect to the image. Despite the strong performance demonstrated by these models, we observe they perform poorly on NLVR, which was constructed to require compositional and spatial reasoning, and to be robust for semantic and systematic biases.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20for%20Foundation%20Models%20in%20Autonomous%20Driving                                                                                  A Survey for Foundation Models in Autonomous Driving                                                                                  The advent of foundation models has revolutionized the fields of natural language processing and computer vision, paving the way for their application in autonomous driving (AD). This survey presents a comprehensive review of more than 40 research papers, demonstrating the role of foundation models in enhancing AD. Large language models contribute to planning and simulation in AD, particularly through their proficiency in reasoning, code generation and translation. In parallel, vision foundation models are increasingly adapted for critical tasks such as 3D object detection and tracking, as well as creating realistic driving scenarios for simulation and testing. Multi-modal foundation models, integrating diverse inputs, exhibit exceptional visual understanding and spatial reasoning, crucial for end-to-end AD. This survey not only provides a structured taxonomy, categorizing foundation models based on their modalities and functionalities within the AD domain but also delves into the methods employed in current research. It identifies the gaps between existing foundation models and cutting-edge AD approaches, thereby charting future research directions and proposing a roadmap for bridging these gaps.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Explainable%20Knowledge%20Tracing                                                                                  A Survey of Explainable Knowledge Tracing                                                                                  With the long term accumulation of high quality educational data, artificial intelligence has shown excellent performance in knowledge tracing. However, due to the lack of interpretability and transparency of some algorithms, this approach will result in reduced stakeholder trust and a decreased acceptance of intelligent decisions. Therefore, algorithms need to achieve high accuracy, and users need to understand the internal operating mechanism and provide reliable explanations for decisions. This paper thoroughly analyzes the interpretability of KT algorithms. First, the concepts and common methods of explainable artificial intelligence and knowledge tracing are introduced. Next, explainable knowledge tracing models are classified into two categories: transparent models and black box models. Then, the interpretable methods used are reviewed from three stages: ante hoc interpretable methods, post hoc interpretable methods, and other dimensions. It is worth noting that current evaluation methods for explainable knowledge tracing are lacking. Hence, contrast and deletion experiments are conducted to explain the prediction results of the deep knowledge tracing model on the ASSISTment2009 by using three XAI methods. Moreover, this paper offers some insights into evaluation methods from the perspective of educational stakeholders. This paper provides a detailed and comprehensive review of the research on explainable knowledge tracing, aiming to offer some basis and inspiration for researchers interested in the interpretability of knowledge tracing.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Knowledge%20Tracing%3A%20Models%2C%20Variants%2C%20and%20Applications                                                                                  A Survey of Knowledge Tracing: Models, Variants, and Applications                                                                                  Modern online education has the capacity to provide intelligent educational services by automatically analyzing substantial amounts of student behavioral data. Knowledge Tracing (KT) is one of the fundamental tasks for student behavioral data analysis, aiming to monitor students' evolving knowledge state during their problem-solving process. In recent years, a substantial number of studies have concentrated on this rapidly growing field, significantly contributing to its advancements. In this survey, we will conduct a thorough investigation of these progressions. Firstly, we present three types of fundamental KT models with distinct technical routes. Subsequently, we review extensive variants of the fundamental KT models that consider more stringent learning assumptions. Moreover, the development of KT cannot be separated from its applications, thereby we present typical KT applications in various scenarios. To facilitate the work of researchers and practitioners in this field, we have developed two open-source algorithm libraries: EduData that enables the download and preprocessing of KT-related datasets, and EduKTM that provides an extensible and unified implementation of existing mainstream KT models. Finally, we discuss potential directions for future research in this rapidly growing field. We hope that the current survey will assist both researchers and practitioners in fostering the development of KT, thereby benefiting a broader range of students.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Learned%20Indexes%20for%20the%20Multi-dimensional%20Space                                                                                  A Survey of Learned Indexes for the Multi-dimensional Space                                                                                  A recent research trend involves treating database index structures as Machine Learning (ML) models. In this domain, single or multiple ML models are trained to learn the mapping from keys to positions inside a data set. This class of indexes is known as 'Learned Indexes.' Learned indexes have demonstrated improved search performance and reduced space requirements for one-dimensional data. The concept of one-dimensional learned indexes has naturally been extended to multi-dimensional (e.g., spatial) data, leading to the development of 'Learned Multi-dimensional Indexes'. This survey focuses on learned multi-dimensional index structures. Specifically, it reviews the current state of this research area, explains the core concepts behind each proposed method, and classifies these methods based on several well-defined criteria. We present a taxonomy that classifies and categorizes each learned multi-dimensional index, and survey the existing literature on learned multi-dimensional indexes according to this taxonomy. Additionally, we present a timeline to illustrate the evolution of research on learned indexes. Finally, we highlight several open challenges and future research directions in this emerging and highly active field.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Neural%20Code%20Intelligence%3A%20Paradigms%2C%20Advances%20and%20Beyond                                                                                  A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond                                                                                  Neural Code Intelligence -- leveraging deep learning to understand, generate, and optimize code -- holds immense potential for transformative impacts on the whole society. Bridging the gap between Natural Language and Programming Language, this domain has drawn significant attention from researchers in both research communities over the past few years. This survey presents a systematic and chronological review of the advancements in code intelligence, encompassing over 50 representative models and their variants, more than 20 categories of tasks, and an extensive coverage of over 680 related works. We follow the historical progression to trace the paradigm shifts across different research phases (e.g., from modeling code with recurrent neural networks to the era of Large Language Models). Concurrently, we highlight the major technical transitions in models, tasks, and evaluations spanning through different stages. For applications, we also observe a co-evolving shift. It spans from initial endeavors to tackling specific scenarios, through exploring a diverse array of tasks during its rapid expansion, to currently focusing on tackling increasingly complex and varied real-world challenges. Building on our examination of the developmental trajectories, we further investigate the emerging synergies between code intelligence and broader machine intelligence, uncovering new cross-domain opportunities and illustrating the substantial influence of code intelligence across various domains. Finally, we delve into both the opportunities and challenges associated with this field, alongside elucidating our insights on the most promising research directions. An ongoing, dynamically updated project and resources associated with this survey have been released at https://github.com/QiushiSun/NCISurvey.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Neural%20Network%20Robustness%20Assessment%20in%20Image%20Recognition                                                                                  A Survey of Neural Network Robustness Assessment in Image Recognition                                                                                  In recent years, there has been significant attention given to the robustness assessment of neural networks. Robustness plays a critical role in ensuring reliable operation of artificial intelligence (AI) systems in complex and uncertain environments. Deep learning's robustness problem is particularly significant, highlighted by the discovery of adversarial attacks on image classification models. Researchers have dedicated efforts to evaluate robustness in diverse perturbation conditions for image recognition tasks. Robustness assessment encompasses two main techniques: robustness verification/ certification for deliberate adversarial attacks and robustness testing for random data corruptions. In this survey, we present a detailed examination of both adversarial robustness (AR) and corruption robustness (CR) in neural network assessment. Analyzing current research papers and standards, we provide an extensive overview of robustness assessment in image recognition. Three essential aspects are analyzed: concepts, metrics, and assessment methods. We investigate the perturbation metrics and range representations used to measure the degree of perturbations on images, as well as the robustness metrics specifically for the robustness conditions of classification models. The strengths and limitations of the existing methods are also discussed, and some potential directions for future research are provided.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Privacy%20Threats%20and%20Defense%20in%20Vertical%20Federated%20Learning%3A%20From%20Model%20Life%20Cycle%20Perspective                                                                                  A Survey of Privacy Threats and Defense in Vertical Federated Learning: From Model Life Cycle Perspective                                                                                  Vertical Federated Learning (VFL) is a federated learning paradigm where multiple participants, who share the same set of samples but hold different features, jointly train machine learning models. Although VFL enables collaborative machine learning without sharing raw data, it is still susceptible to various privacy threats. In this paper, we conduct the first comprehensive survey of the state-of-the-art in privacy attacks and defenses in VFL. We provide taxonomies for both attacks and defenses, based on their characterizations, and discuss open challenges and future research directions. Specifically, our discussion is structured around the model's life cycle, by delving into the privacy threats encountered during different stages of machine learning and their corresponding countermeasures. This survey not only serves as a resource for the research community but also offers clear guidance and actionable insights for practitioners to safeguard data privacy throughout the model's life cycle.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20of%20Privacy-Preserving%20Model%20Explanations%3A%20Privacy%20Risks%2C%20Attacks%2C%20and%20Countermeasures                                                                                  A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures                                                                                  As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorisation of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have established an online resource repository, which will be continuously updated with new and relevant findings. Interested readers are encouraged to access our repository at https://github.com/tamlhp/awesome-privex.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%203D%20Skeleton%20Based%20Person%20Re-Identification%3A%20Approaches%2C%20Designs%2C%20Challenges%2C%20and%20Future%20Directions                                                                                  A Survey on 3D Skeleton Based Person Re-Identification: Approaches, Designs, Challenges, and Future Directions                                                                                  Person re-identification via 3D skeletons is an important emerging research area that triggers great interest in the pattern recognition community. With distinctive advantages for many application scenarios, a great diversity of 3D skeleton based person re-identification (SRID) methods have been proposed in recent years, effectively addressing prominent problems in skeleton modeling and feature learning. Despite recent advances, to the best of our knowledge, little effort has been made to comprehensively summarize these studies and their challenges. In this paper, we attempt to fill this gap by providing a systematic survey on current SRID approaches, model designs, challenges, and future directions. Specifically, we first formulate the SRID problem, and propose a taxonomy of SRID research with a summary of benchmark datasets, commonly-used model architectures, and an analytical review of different methods' characteristics. Then, we elaborate on the design principles of SRID models from multiple aspects to offer key insights for model improvement. Finally, we identify critical challenges confronting current studies and discuss several promising directions for future research of SRID.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Hallucination%20in%20Large%20Vision-Language%20Models                                                                                  A Survey on Hallucination in Large Vision-Language Models                                                                                  Recent development of Large Vision-Language Models (LVLMs) has attracted growing attention within the AI landscape for its practical implementation potential. However, ``hallucination'', or more specifically, the misalignment between factual visual content and corresponding textual generation, poses a significant challenge of utilizing LVLMs. In this comprehensive survey, we dissect LVLM-related hallucinations in an attempt to establish an overview and facilitate future mitigation. Our scrutiny starts with a clarification of the concept of hallucinations in LVLMs, presenting a variety of hallucination symptoms and highlighting the unique challenges inherent in LVLM hallucinations. Subsequently, we outline the benchmarks and methodologies tailored specifically for evaluating hallucinations unique to LVLMs. Additionally, we delve into an investigation of the root causes of these hallucinations, encompassing insights from the training data and model components. We also critically review existing methods for mitigating hallucinations. The open questions and future directions pertaining to hallucinations within LVLMs are discussed to conclude this survey.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Quantum%20Reinforcement%20Learning                                                                                  A Survey on Quantum Reinforcement Learning                                                                                  Quantum reinforcement learning is an emerging field at the intersection of quantum computing and machine learning. While we intend to provide a broad overview of the literature on quantum reinforcement learning - our interpretation of this term will be clarified below - we put particular emphasis on recent developments. With a focus on already available noisy intermediate-scale quantum devices, these include variational quantum circuits acting as function approximators in an otherwise classical reinforcement learning setting. In addition, we survey quantum reinforcement learning algorithms based on future fault-tolerant hardware, some of which come with a provable quantum advantage. We provide both a birds-eye-view of the field, as well as summaries and reviews for selected parts of the literature.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Retrieval-Augmented%20Text%20Generation%20for%20Large%20Language%20Models                                                                                  A Survey on Retrieval-Augmented Text Generation for Large Language Models                                                                                  Retrieval-Augmented Generation (RAG) merges retrieval methods with deep learning advancements to address the static limitations of large language models (LLMs) by enabling the dynamic integration of up-to-date external information. This methodology, focusing primarily on the text domain, provides a cost-effective solution to the generation of plausible but incorrect responses by LLMs, thereby enhancing the accuracy and reliability of their outputs through the use of real-world data. As RAG grows in complexity and incorporates multiple concepts that can influence its performance, this paper organizes the RAG paradigm into four categories: pre-retrieval, retrieval, post-retrieval, and generation, offering a detailed perspective from the retrieval viewpoint. It outlines RAG's evolution and discusses the field's progression through the analysis of significant studies. Additionally, the paper introduces evaluation methods for RAG, addressing the challenges faced and proposing future research directions. By offering an organized framework and categorization, the study aims to consolidate existing research on RAG, clarify its technological underpinnings, and highlight its potential to broaden the adaptability and applications of LLMs.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20Temporal%20Knowledge%20Graph%3A%20Representation%20Learning%20and%20Applications                                                                                  A Survey on Temporal Knowledge Graph: Representation Learning and Applications                                                                                  Knowledge graphs have garnered significant research attention and are widely used to enhance downstream applications. However, most current studies mainly focus on static knowledge graphs, whose facts do not change with time, and disregard their dynamic evolution over time. As a result, temporal knowledge graphs have attracted more attention because a large amount of structured knowledge exists only within a specific period. Knowledge graph representation learning aims to learn low-dimensional vector embeddings for entities and relations in a knowledge graph. The representation learning of temporal knowledge graphs incorporates time information into the standard knowledge graph framework and can model the dynamics of entities and relations over time. In this paper, we conduct a comprehensive survey of temporal knowledge graph representation learning and its applications. We begin with an introduction to the definitions, datasets, and evaluation metrics for temporal knowledge graph representation learning. Next, we propose a taxonomy based on the core technologies of temporal knowledge graph representation learning methods, and provide an in-depth analysis of different methods in each category. Finally, we present various downstream applications related to the temporal knowledge graphs. In the end, we conclude the paper and have an outlook on the future research directions in this area.
http://w3id.org/mlsea/pwc/scientificWork/A%20Survey%20on%20the%20Applications%20of%20Frontier%20AI%2C%20Foundation%20Models%2C%20and%20Large%20Language%20Models%20to%20Intelligent%20Transportation%20Systems                                                                                  A Survey on the Applications of Frontier AI, Foundation Models, and Large Language Models to Intelligent Transportation Systems                                                                                  This survey paper explores the transformative influence of frontier AI, foundation models, and Large Language Models (LLMs) in the realm of Intelligent Transportation Systems (ITS), emphasizing their integral role in advancing transportation intelligence, optimizing traffic management, and contributing to the realization of smart cities. Frontier AI refers to the forefront of AI technology, encompassing the latest advancements, innovations, and experimental techniques in the field, especially AI foundation models and LLMs. Foundation models, like GPT-4, are large, general-purpose AI models that provide a base for a wide range of applications. They are characterized by their versatility and scalability. LLMs are obtained from finetuning foundation models with a specific focus on processing and generating natural language. They excel in tasks like language understanding, text generation, translation, and summarization. By leveraging vast textual data, including traffic reports and social media interactions, LLMs extract critical insights, fostering the evolution of ITS. The survey navigates the dynamic synergy between LLMs and ITS, delving into applications in traffic management, integration into autonomous vehicles, and their role in shaping smart cities. It provides insights into ongoing research, innovations, and emerging trends, aiming to inspire collaboration at the intersection of language, intelligence, and mobility for safer, more efficient, and sustainable transportation systems. The paper further surveys interactions between LLMs and various aspects of ITS, exploring roles in traffic management, facilitating autonomous vehicles, and contributing to smart city development, while addressing challenges brought by frontier AI and foundation models. This paper offers valuable inspiration for future research and innovation in the transformative domain of intelligent transportation.
http://w3id.org/mlsea/pwc/scientificWork/A%20Synchronized%20Layer-by-layer%20Growing%20Approach%20for%20Plausible%20Neuronal%20Morphology%20Generation                                                                                  A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation                                                                                  Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As the acquiring of real-world morphology data is expensive, computational approaches especially learning-based ones e.g. MorphVAE for morphology generation were recently studied, which are often conducted in a way of randomly augmenting a given authentic morphology to achieve plausibility. Under such a setting, this paper proposes textbf{MorphGrower} which aims to generate more plausible morphology samples by mimicking the natural growth mechanism instead of a one-shot treatment as done in MorphVAE. Specifically, MorphGrower generates morphologies layer by layer synchronously and chooses a pair of sibling branches as the basic generation block, and the generation of each layer is conditioned on the morphological structure of previous layers and then generate morphologies via a conditional variational autoencoder with spherical latent space. Extensive experimental results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Our code will be publicly available to facilitate future research.
http://w3id.org/mlsea/pwc/scientificWork/A%20System%20Level%20Analysis%20for%20Integrated%20Sensing%20and%20Communication                                                                                  A System Level Analysis for Integrated Sensing and Communication                                                                                  In this work, we provide a system level analysis of integrated sensing and communication (ISAC) systems, where a setup with a mono-static dual-functional radar communication base station is assumed. We derive the ISAC signal-to-noise ratio (SNR) equation that relates communication and radar SNR for different distances. We also derive the ISAC range equation, which can be used for sensing-assisted beamforming applications. Specifically, we show that increasing the frequency and bandwidth is more favorable to the radar application in terms of relative SNR and range while increasing the transmit power is more favorable to communications. Numerical examples reveal that if the range for communication and radar is desired to be in the same order, the ISAC system should operate in mmWave or sub-THz bands, whereas sub-6GHz allows scenarios where the communication range is of orders of magnitude higher than that of radar.
http://w3id.org/mlsea/pwc/scientificWork/A%20Systematic%20Analysis%20of%20Subwords%20and%20Cross-Lingual%20Transfer%20in%20Multilingual%20Translation                                                                                  A Systematic Analysis of Subwords and Cross-Lingual Transfer in Multilingual Translation                                                                                  Multilingual modelling can improve machine translation for low-resource languages, partly through shared subword representations. This paper studies the role of subword segmentation in cross-lingual transfer. We systematically compare the efficacy of several subword methods in promoting synergy and preventing interference across different linguistic typologies. Our findings show that subword regularisation boosts synergy in multilingual modelling, whereas BPE more effectively facilitates transfer during cross-lingual fine-tuning. Notably, our results suggest that differences in orthographic word boundary conventions (the morphological granularity of written words) may impede cross-lingual transfer more significantly than linguistic unrelatedness. Our study confirms that decisions around subword modelling can be key to optimising the benefits of multilingual modelling.
http://w3id.org/mlsea/pwc/scientificWork/A%20Systematic%20Review%20of%20Available%20Datasets%20in%20Additive%20Manufacturing                                                                                  A Systematic Review of Available Datasets in Additive Manufacturing                                                                                  In-situ monitoring incorporating data from visual and other sensor technologies, allows the collection of extensive datasets during the Additive Manufacturing (AM) process. These datasets have potential for determining the quality of the manufactured output and the detection of defects through the use of Machine Learning during the manufacturing process. Open and annotated datasets derived from AM processes are necessary for the machine learning community to address this opportunity, which creates difficulties in the application of computer vision-related machine learning in AM. This systematic review investigates the availability of open image-based datasets originating from AM processes that align with a number of pre-defined selection criteria. The review identifies existing gaps among the current image-based datasets in the domain of AM, and points to the need for greater availability of open datasets in order to allow quality assessment and defect detection during additive manufacturing, to develop.
http://w3id.org/mlsea/pwc/scientificWork/A%20Systems%20Theoretic%20Approach%20to%20Online%20Machine%20Learning                                                                                  A Systems Theoretic Approach to Online Machine Learning                                                                                  The machine learning formulation of online learning is incomplete from a systems theoretic perspective. Typically, machine learning research emphasizes domains and tasks, and a problem solving worldview. It focuses on algorithm parameters, features, and samples, and neglects the perspective offered by considering system structure and system behavior or dynamics. Online learning is an active field of research and has been widely explored in terms of statistical theory and computational algorithms, however, in general, the literature still lacks formal system theoretical frameworks for modeling online learning systems and resolving systems-related concept drift issues. Furthermore, while the machine learning formulation serves to classify methods and literature, the systems theoretic formulation presented herein serves to provide a framework for the top-down design of online learning systems, including a novel definition of online learning and the identification of key design parameters. The framework is formulated in terms of input-output systems and is further divided into system structure and system behavior. Concept drift is a critical challenge faced in online learning, and this work formally approaches it as part of the system behavior characteristics. Healthcare provider fraud detection using machine learning is used as a case study throughout the paper to ground the discussion in a real-world online learning challenge.
http://w3id.org/mlsea/pwc/scientificWork/A%20Technique%20for%20Classifying%20Static%20Gestures%20Using%20UWB%20Radar                                                                                  A Technique for Classifying Static Gestures Using UWB Radar                                                                                  Our paper presents a robust framework for UWB-based static gesture recognition, leveraging proprietary UWB radar sensor technology. Extensive data collection efforts were undertaken to compile datasets containing five commonly used gestures. Our approach involves a comprehensive data pre-processing pipeline that encompasses outlier handling, aspect ratio-preserving resizing, and false-color image transformation. Both CNN and MobileNet models were trained on the processed images. Remarkably, our best-performing model achieved an accuracy of 96.78%. Additionally, we developed a user-friendly GUI framework to assess the model's system resource usage and processing times, which revealed low memory utilization and real-time task completion in under one second. This research marks a significant step towards enhancing static gesture recognition using UWB technology, promising practical applications in various domains.
http://w3id.org/mlsea/pwc/scientificWork/A%20Theory%20of%20Complex%20Adaptive%20Learning%20Behavior%20in%20Complex%20Adaptive%20Systems%20and%20a%20Non-Localized%20Wave%20Equation%20in%20Quantum%20Mechanics                                                                                  A Theory of Complex Adaptive Learning Behavior in Complex Adaptive Systems and a Non-Localized Wave Equation in Quantum Mechanics                                                                                  Complex adaptive learning behavior is intelligent. It is adaptive, learns in feedback loops, and generates hidden patterns as many individuals, elements or particles interact in complex adaptive systems (CASs). CASs highlight adaptation in life and lifeless complex systems cutting across all traditional natural and social sciences disciplines. However, discovering a universal law in CASs and understanding the formation mechanism, such as quantum entanglement or complex quantum coherent adaptation, remains highly challenging. Quantifying the uncertainty of CASs by probability waves, the authors explore the inherent logical relationship between Schr 'odinger's wave equation in quantum mechanics and Shi's trading volume-price probability wave equation in finance. The authors find a non-localized wave equation in quantum mechanics if cumulative observable in a time interval represents momentum or momentum force in Skinner-Shi (reinforcement-frequency-interaction) coordinates. It supports the assumption that a universal law or an invariance of interaction exists in quantum mechanics and finance. The authors conclude that quantum entanglement is a coherent interaction between opposite, adaptive, and complementary forces instead of a superposition of two coherent states that mainstream Copenhagen interprets. The interactively coherent forces generate particles with two opposite properties in a bipartite complex adaptive quantum system, suggesting the second revolution in quantum theory. Keywords: complex adaptive systems, complex adaptive learning, universal law, non-localized wave equation, interactively coherent entanglement, interactively coherent adaptation PACS: 89.75.-k (Complex Systems); 89.65.Gh (Economics, Econophysics, Financial Markets, Business and Management); 03.65.Ud (Entanglement and Quantum Nonlocality)
http://w3id.org/mlsea/pwc/scientificWork/A%20Theory%20of%20Intelligences                                                                                  A Theory of Intelligences                                                                                  Intelligence is a human construct to represent the ability to achieve goals. Given this wide berth, intelligence has been defined countless times, studied in a variety of ways and represented using numerous measures. Understanding intelligence ultimately requires theory and quantification, both of which have proved elusive. I develop a framework -- the Theory of Intelligences (TIS) -- that applies across all systems from physics, to biology, humans and AI. TIS likens intelligence to a calculus, differentiating, correlating and integrating information. Intelligence operates at many levels and scales and TIS distils these into a parsimonious macroscopic framework centered on solving, planning and their optimization to accomplish goals. Notably, intelligence can be expressed in informational units or in units relative to goal difficulty, the latter defined as complexity relative to system (individual or benchmarked) ability. I present general equations for intelligence and its components, and a simple expression for the evolution of intelligence traits. The measures developed here could serve to gauge different facets of intelligence for any step-wise transformation of information. I argue that proxies such as environment, technology, society and collectives are essential to a general theory of intelligence and to possible evolutionary transitions in intelligence, particularly in humans. I conclude with testable predictions of TIS and offer several speculations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Thorough%20Examination%20of%20Decoding%20Methods%20in%20the%20Era%20of%20LLMs                                                                                  A Thorough Examination of Decoding Methods in the Era of LLMs                                                                                  Decoding methods play an indispensable role in converting language models from next-token predictors into practical task solvers. Prior research on decoding methods, primarily focusing on task-specific models, may not extend to the current era of general-purpose large language models (LLMs). Moreover, the recent influx of decoding strategies has further complicated this landscape. This paper provides a comprehensive and multifaceted analysis of various decoding methods within the context of LLMs, evaluating their performance, robustness to hyperparameter changes, and decoding speeds across a wide range of tasks, models, and deployment environments. Our findings reveal that decoding method performance is notably task-dependent and influenced by factors such as alignment, model size, and quantization. Intriguingly, sensitivity analysis exposes that certain methods achieve superior performance at the cost of extensive hyperparameter tuning, highlighting the trade-off between attaining optimal results and the practicality of implementation in varying contexts.
http://w3id.org/mlsea/pwc/scientificWork/A%20Transfer%20Learning%20Causal%20Approach%20to%20Evaluate%20Racial%2FEthnic%20and%20Geographic%20Variation%20in%20Outcomes%20Following%20Congenital%20Heart%20Surgery                                                                                  A Transfer Learning Causal Approach to Evaluate Racial/Ethnic and Geographic Variation in Outcomes Following Congenital Heart Surgery                                                                                  Congenital heart defects (CHD) are the most prevalent birth defects in the United States and surgical outcomes vary considerably across the country. The outcomes of treatment for CHD differ for specific patient subgroups, with non-Hispanic Black and Hispanic populations experiencing higher rates of mortality and morbidity. A valid comparison of outcomes within racial/ethnic subgroups is difficult given large differences in case-mix and small subgroup sizes. We propose a causal inference framework for outcome assessment and leverage advances in transfer learning to incorporate data from both target and source populations to help estimate causal effects while accounting for different sources of risk factor and outcome differences across populations. Using the Society of Thoracic Surgeons' Congenital Heart Surgery Database (STS-CHSD), we focus on a national cohort of patients undergoing the Norwood operation from 2016-2022 to assess operative mortality and morbidity outcomes across U.S. geographic regions by race/ethnicity. We find racial and ethnic outcome differences after controlling for potential confounding factors. While geography does not have a causal effect on outcomes for non-Hispanic Caucasian patients, non-Hispanic Black patients experience wide variability in outcomes with estimated 30-day mortality ranging from 5.9% (standard error 2.2%) to 21.6% (4.4%) across U.S. regions.
http://w3id.org/mlsea/pwc/scientificWork/A%20Tunable%20Universal%20Formula%20for%20Safety-Critical%20Control                                                                                  A Tunable Universal Formula for Safety-Critical Control                                                                                  Sontag's universal formula is a widely-used technique for stabilizing control through control Lyapunov functions, and it has been extended to address safety-critical control in recent years by incorporating control barrier functions (CBFs). However, how to derive a universal formula that satisfies requirements on essential properties, including safety, robustness, and smoothness, is still an open problem. To address this challenge, this paper introduces a novel solution - a tunable universal formula - incorporating a (state-dependent) tunable scaling term into Sontag's universal formula. This tunable scaling term enables the regulation of safety control performances, allowing the attainment of desired properties through a proper selection. Furthermore, we extend this tunable universal formula to address safety-critical control problems with norm-bounded input constraints, showcasing its applicability across diverse control scenarios. Finally, we demonstrate the efficacy of our method through a collision avoidance example, investigating the essential properties including safety, robustness, and smoothness under various tunable scaling terms.
http://w3id.org/mlsea/pwc/scientificWork/A%20Two%20Time-Scale%20Joint%20Optimization%20Approach%20for%20UAV-assisted%20MEC                                                                                  A Two Time-Scale Joint Optimization Approach for UAV-assisted MEC                                                                                  Unmanned aerial vehicles (UAV)-assisted mobile edge computing (MEC) is emerging as a promising paradigm to provide aerial-terrestrial computing services close to mobile devices (MDs). However, meeting the demands of computation-intensive and delay-sensitive tasks for MDs poses several challenges, including the demand-supply contradiction between MDs and MEC servers, the demand-supply heterogeneity between MDs and MEC servers, the trajectory control requirements on energy efficiency and timeliness, and the different time-scale dynamics of the network. To address these issues, we first present a hierarchical architecture by incorporating terrestrial-aerial computing capabilities and leveraging UAV flexibility. Furthermore, we formulate a joint computing resource allocation, computation offloading, and trajectory control problem to maximize the system utility. Since the problem is a non-convex mixed integer nonlinear programming (MINLP), we propose a two time-scale joint computing resource allocation, computation offloading, and trajectory control (TJCCT) approach. In the short time scale, we propose a price-incentive method for on-demand computing resource allocation and a matching mechanism-based method for computation offloading. In the long time scale, we propose a convex optimization-based method for UAV trajectory control. Besides, we prove the stability, optimality, and polynomial complexity of TJCCT. Simulation results demonstrate that TJCCT outperforms the comparative algorithms in terms of the utility of the system, the QoE of MDs, and the revenue of MEC servers.
http://w3id.org/mlsea/pwc/scientificWork/A%20Two-Scale%20Complexity%20Measure%20for%20Deep%20Learning%20Models                                                                                  A Two-Scale Complexity Measure for Deep Learning Models                                                                                  We introduce a novel capacity measure 2sED for statistical models based on the effective dimension. The new quantity provably bounds the generalization error under mild assumptions on the model. Furthermore, simulations on standard data sets and popular model architectures show that 2sED correlates well with the training error. For Markovian models, we show how to efficiently approximate 2sED from below through a layerwise iterative approach, which allows us to tackle deep learning models with a large number of parameters. Simulation results suggest that the approximation is good for different prominent models and data sets.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Combination%20Framework%20for%20Dependent%20Tests%20with%20Applications%20to%20Microbiome%20Association%20Studies                                                                                  A Unified Combination Framework for Dependent Tests with Applications to Microbiome Association Studies                                                                                  We introduce a novel meta-analysis framework to combine dependent tests under a general setting, and utilize it to synthesize various microbiome association tests that are calculated from the same dataset. Our development builds upon the classical meta-analysis methods of aggregating $p$-values and also a more recent general method of combining confidence distributions, but makes generalizations to handle dependent tests. The proposed framework ensures rigorous statistical guarantees, and we provide a comprehensive study and compare it with various existing dependent combination methods. Notably, we demonstrate that the widely used Cauchy combination method for dependent tests, referred to as the vanilla Cauchy combination in this article, can be viewed as a special case within our framework. Moreover, the proposed framework provides a way to address the problem when the distributional assumptions underlying the vanilla Cauchy combination are violated. Our numerical results demonstrate that ignoring the dependence among the to-be-combined components may lead to a severe size distortion phenomenon. Compared to the existing $p$-value combination methods, including the vanilla Cauchy combination method, the proposed combination framework can handle the dependence accurately and utilizes the information efficiently to construct tests with accurate size and enhanced power. The development is applied to Microbiome Association Studies, where we aggregate information from multiple existing tests using the same dataset. The combined tests harness the strengths of each individual test across a wide range of alternative spaces, %resulting in a significant enhancement of testing power across a wide range of alternative spaces, enabling more efficient and meaningful discoveries of vital microbiome associations.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Diffusion%20Framework%20for%20Scene-aware%20Human%20Motion%20Estimation%20from%20Sparse%20Signals                                                                                  A Unified Diffusion Framework for Scene-aware Human Motion Estimation from Sparse Signals                                                                                  Estimating full-body human motion via sparse tracking signals from head-mounted displays and hand controllers in 3D scenes is crucial to applications in AR/VR. One of the biggest challenges to this task is the one-to-many mapping from sparse observations to dense full-body motions, which endowed inherent ambiguities. To help resolve this ambiguous problem, we introduce a new framework to combine rich contextual information provided by scenes to benefit full-body motion tracking from sparse observations. To estimate plausible human motions given sparse tracking signals and 3D scenes, we develop $ text{S}^2$Fusion, a unified framework fusing underline{S}cene and sparse underline{S}ignals with a conditional dif underline{Fusion} model. $ text{S}^2$Fusion first extracts the spatial-temporal relations residing in the sparse signals via a periodic autoencoder, and then produces time-alignment feature embedding as additional inputs. Subsequently, by drawing initial noisy motion from a pre-trained prior, $ text{S}^2$Fusion utilizes conditional diffusion to fuse scene geometry and sparse tracking signals to generate full-body scene-aware motions. The sampling procedure of $ text{S}^2$Fusion is further guided by a specially designed scene-penetration loss and phase-matching loss, which effectively regularizes the motion of the lower body even in the absence of any tracking signals, making the generated motion much more plausible and coherent. Extensive experimental results have demonstrated that our $ text{S}^2$Fusion outperforms the state-of-the-art in terms of estimation quality and smoothness.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Framework%20for%20Microscopy%20Defocus%20Deblur%20with%20Multi-Pyramid%20Transformer%20and%20Contrastive%20Learning                                                                                  A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning                                                                                  Defocus blur is a persistent problem in microscope imaging that poses harm to pathology interpretation and medical intervention in cell microscopy and microscope surgery. To address this problem, a unified framework including multi-pyramid transformer (MPT) and extended frequency contrastive regularization (EFCR) is proposed to tackle two outstanding challenges in microscopy deblur: longer attention span and feature deficiency. The MPT employs an explicit pyramid structure at each network stage that integrates the cross-scale window attention (CSWA), the intra-scale channel attention (ISCA), and the feature-enhancing feed-forward network (FEFN) to capture long-range cross-scale spatial interaction and global channel context. The EFCR addresses the feature deficiency problem by exploring latent deblur signals from different frequency bands. It also enables deblur knowledge transfer to learn cross-domain information from extra data, improving deblur performance for labeled and unlabeled data. Extensive experiments and downstream task validation show the framework achieves state-of-the-art performance across multiple datasets. Project page: https://github.com/PieceZhang/MPT-CataBlur.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Model%20for%20Active%20Battery%20Equalization%20Systems                                                                                  A Unified Model for Active Battery Equalization Systems                                                                                  Lithium-ion battery packs demand effective active equalization systems to enhance their usable capacity and lifetime. Despite numerous topologies and control schemes proposed in the literature, conducting quantitative analyses, comprehensive comparisons, and systematic optimization of their performance remains challenging due to the absence of a unified mathematical model at the pack level. To address this gap, we introduce a novel, hypergraph-based approach to establish the first unified model for various active battery equalization systems. This model reveals the intrinsic relationship between battery cells and equalizers by representing them as the vertices and hyperedges of hypergraphs, respectively. With the developed model, we identify the necessary condition for all equalization systems to achieve balance through controllability analysis, offering valuable insights for selecting the number of equalizers. Moreover, we prove that the battery equalization time is inversely correlated with the second smallest eigenvalue of the hypergraph's Laplacian matrix of each equalization system. This significantly simplifies the selection and optimized design of equalization systems, obviating the need for extensive experiments or simulations to derive the equalization time. Illustrative results demonstrate the efficiency of the proposed model and validate our findings.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Model%20for%20Spatio-Temporal%20Prediction%20Queries%20with%20Arbitrary%20Modifiable%20Areal%20Units                                                                                  A Unified Model for Spatio-Temporal Prediction Queries with Arbitrary Modifiable Areal Units                                                                                  Spatio-Temporal (ST) prediction is crucial for making informed decisions in urban location-based applications like ride-sharing. However, existing ST models often require region partition as a prerequisite, resulting in two main pitfalls. Firstly, location-based services necessitate ad-hoc regions for various purposes, requiring multiple ST models with varying scales and zones, which can be costly to support. Secondly, different ST models may produce conflicting outputs, resulting in confusing predictions. In this paper, we propose One4All-ST, a framework that can conduct ST prediction for arbitrary modifiable areal units using only one model. To reduce the cost of getting multi-scale predictions, we design an ST network with hierarchical spatial modeling and scale normalization modules to efficiently and equally learn multi-scale representations. To address prediction inconsistencies across scales, we propose a dynamic programming scheme to solve the formulated optimal combination problem, minimizing predicted error through theoretical analysis. Besides, we suggest using an extended quad-tree to index the optimal combinations for quick response to arbitrary modifiable areal units in practical online scenarios. Extensive experiments on two real-world datasets verify the efficiency and effectiveness of One4All-ST in ST prediction for arbitrary modifiable areal units. The source codes and data of this work are available at https://github.com/uctb/One4All-ST.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Multiscale%20Encoder-Decoder%20Transformer%20for%20Video%20Segmentation                                                                                  A Unified Multiscale Encoder-Decoder Transformer for Video Segmentation                                                                                  In this paper, we present an end-to-end trainable unified multiscale encoder-decoder transformer that is focused on dense prediction tasks in video. The presented Multiscale Encoder-Decoder Video Transformer (MED-VT) uses multiscale representation throughout and employs an optional input beyond video (e.g., audio), when available, for multimodal processing (MED-VT++). Multiscale representation at both encoder and decoder yields three key benefits: (i) implicit extraction of spatiotemporal features at different levels of abstraction for capturing dynamics without reliance on input optical flow, (ii) temporal consistency at encoding and (iii) coarse-to-fine detection for high-level (e.g., object) semantics to guide precise localization at decoding. Moreover, we present a transductive learning scheme through many-to-many label propagation to provide temporally consistent video predictions. We showcase MED-VT/MED-VT++ on three unimodal video segmentation tasks (Automatic Video Object Segmentation (AVOS), actor-action segmentation and Video Semantic Segmentation (VSS)) as well as a multimodal segmentation task (Audio-Visual Segmentation (AVS)). Results show that the proposed architecture outperforms alternative state-of-the-art approaches on multiple benchmarks using only video (and optional audio) as input, without reliance on optical flow. Finally, to document details of the model's internal learned representations, we present a detailed interpretability study, encompassing both quantitative and qualitative analyses.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unified%20Optimal%20Transport%20Framework%20for%20Cross-Modal%20Retrieval%20with%20Noisy%20Labels                                                                                  A Unified Optimal Transport Framework for Cross-Modal Retrieval with Noisy Labels                                                                                  Cross-modal retrieval (CMR) aims to establish interaction between different modalities, among which supervised CMR is emerging due to its flexibility in learning semantic category discrimination. Despite the remarkable performance of previous supervised CMR methods, much of their success can be attributed to the well-annotated data. However, even for unimodal data, precise annotation is expensive and time-consuming, and it becomes more challenging with the multimodal scenario. In practice, massive multimodal data are collected from the Internet with coarse annotation, which inevitably introduces noisy labels. Training with such misleading labels would bring two key challenges -- enforcing the multimodal samples to emph{align incorrect semantics} and emph{widen the heterogeneous gap}, resulting in poor retrieval performance. To tackle these challenges, this work proposes UOT-RCL, a Unified framework based on Optimal Transport (OT) for Robust Cross-modal Retrieval. First, we propose a semantic alignment based on partial OT to progressively correct the noisy labels, where a novel cross-modal consistent cost function is designed to blend different modalities and provide precise transport cost. Second, to narrow the discrepancy in multi-modal data, an OT-based relation alignment is proposed to infer the semantic-level cross-modal matching. Both of these two components leverage the inherent correlation among multi-modal data to facilitate effective cost function. The experiments on three widely-used cross-modal retrieval datasets demonstrate that our UOT-RCL surpasses the state-of-the-art approaches and significantly improves the robustness against noisy labels.
http://w3id.org/mlsea/pwc/scientificWork/A%20Unifying%20Approach%20for%20the%20Pricing%20of%20Debt%20Securities                                                                                  A Unifying Approach for the Pricing of Debt Securities                                                                                  We propose a unifying framework for the pricing of debt securities under general time-inhomogeneous short-rate diffusion processes. The pricing of bonds, bond options, callable/putable bonds, and convertible bonds (CBs) are covered. Using continuous-time Markov chain (CTMC) approximation, we obtain closed-form matrix expressions to approximate the price of bonds and bond options under general one-dimensional short-rate processes. A simple and efficient algorithm is also developed to price callable/putable debts. The availability of a closed-form expression for the price of zero-coupon bonds allows for the perfect fit of the approximated model to the current market term structure of interest rates, regardless of the complexity of the underlying diffusion process selected. We further consider the pricing of CBs under general bi-dimensional time-inhomogeneous diffusion processes to model equity and short-rate dynamics. Credit risk is also incorporated into the model using the approach of Tsiveriotis and Fernandes (1998). Based on a two-layer CTMC method, an efficient algorithm is developed to approximate the price of convertible bonds. When conversion is only allowed at maturity, a closed-form matrix expression is obtained. Numerical experiments show the accuracy and efficiency of the method across a wide range of model parameters and short-rate models.
http://w3id.org/mlsea/pwc/scientificWork/A%20Usage-centric%20Take%20on%20Intent%20Understanding%20in%20E-Commerce                                                                                  A Usage-centric Take on Intent Understanding in E-Commerce                                                                                  Identifying and understanding user intents is a pivotal task for E-Commerce. Despite its popularity, intent understanding has not been consistently defined or accurately benchmarked. In this paper, we focus on predicative user intents as 'how a customer uses a product', and pose intent understanding as a natural language reasoning task, independent of product ontologies. We identify two weaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph, that limit its capacity to reason about user intents and to recommend diverse useful products. Following these observations, we introduce a Product Recovery Benchmark including a novel evaluation framework and an example dataset. We further validate the above FolkScope weaknesses on this benchmark.
http://w3id.org/mlsea/pwc/scientificWork/A%20V2X-based%20Privacy%20Preserving%20Federated%20Measuring%20and%20Learning%20System                                                                                  A V2X-based Privacy Preserving Federated Measuring and Learning System                                                                                  Future autonomous vehicles (AVs) will use a variety of sensors that generate a vast amount of data. Naturally, this data not only serves self-driving algorithms; but can also assist other vehicles or the infrastructure in real-time decision-making. Consequently, vehicles shall exchange their measurement data over Vehicle-to-Everything (V2X) technologies. Moreover, predicting the state of the road network might be beneficial too. With such a prediction, we might mitigate road congestion, balance parking lot usage, or optimize the traffic flow. That would decrease transportation costs as well as reduce its environmental impact. In this paper, we propose a federated measurement and learning system that provides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V) communication while also operating a federated learning (FL) scheme over the Vehicle-to-Network (V2N) link to create a predictive model of the transportation network. As we are yet to have real-world AV data, we model it with a non-IID (independent and identically distributed) dataset to evaluate the capabilities of the proposed system in terms of performance and privacy. Results indicate that the proposed FL scheme improves learning performance and prevents eavesdropping at the aggregator server side.
http://w3id.org/mlsea/pwc/scientificWork/A%20Volumetric%20Saliency%20Guided%20Image%20Summarization%20for%20RGB-D%20Indoor%20Scene%20Classification                                                                                  A Volumetric Saliency Guided Image Summarization for RGB-D Indoor Scene Classification                                                                                  Image summary, an abridged version of the original visual content, can be used to represent the scene. Thus, tasks such as scene classification, identification, indexing, etc., can be performed efficiently using the unique summary. Saliency is the most commonly used technique for generating the relevant image summary. However, the definition of saliency is subjective in nature and depends upon the application. Existing saliency detection methods using RGB-D data mainly focus on color, texture, and depth features. Consequently, the generated summary contains either foreground objects or non-stationary objects. However, applications such as scene identification require stationary characteristics of the scene, unlike state-of-the-art methods. This paper proposes a novel volumetric saliency-guided framework for indoor scene classification. The results highlight the efficacy of the proposed method.
http://w3id.org/mlsea/pwc/scientificWork/A%20case%20study%20of%20sending%20graph%20neural%20networks%20back%20to%20the%20test%20bench%20for%20applications%20in%20high-energy%20particle%20physics                                                                                  A case study of sending graph neural networks back to the test bench for applications in high-energy particle physics                                                                                  In high-energy particle collisions, the primary collision products usually decay further resulting in tree-like, hierarchical structures with a priori unknown multiplicity. At the stable-particle level all decay products of a collision form permutation invariant sets of final state objects. The analogy to mathematical graphs gives rise to the idea that graph neural networks (GNNs), which naturally resemble these properties, should be best-suited to address many tasks related to high-energy particle physics. In this paper we describe a benchmark test of a typical GNN against neural networks of the well-established deep fully-connected feed-forward architecture. We aim at performing this comparison maximally unbiased in terms of nodes, hidden layers, or trainable parameters of the neural networks under study. As physics case we use the classification of the final state X produced in association with top quark-antiquark pairs in proton-proton collisions at the Large Hadron Collider at CERN, where X stands for a bottom quark-antiquark pair produced either non-resonantly or through the decay of an intermediately produced Z or Higgs boson.
http://w3id.org/mlsea/pwc/scientificWork/A%20chaotic%20maps-based%20privacy-preserving%20distributed%20deep%20learning%20for%20incomplete%20and%20Non-IID%20datasets                                                                                  A chaotic maps-based privacy-preserving distributed deep learning for incomplete and Non-IID datasets                                                                                  Federated Learning is a machine learning approach that enables the training of a deep learning model among several participants with sensitive data that wish to share their own knowledge without compromising the privacy of their data. In this research, the authors employ a secured Federated Learning method with an additional layer of privacy and proposes a method for addressing the non-IID challenge. Moreover, differential privacy is compared with chaotic-based encryption as layer of privacy. The experimental approach assesses the performance of the federated deep learning model with differential privacy using both IID and non-IID data. In each experiment, the Federated Learning process improves the average performance metrics of the deep neural network, even in the case of non-IID data.
http://w3id.org/mlsea/pwc/scientificWork/A%20closer%20look%20at%20the%20chemical%20potential%20of%20an%20ideal%20agent%20system                                                                                  A closer look at the chemical potential of an ideal agent system                                                                                  Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $ mu$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory.
http://w3id.org/mlsea/pwc/scientificWork/A%20comparative%20study%20on%20wearables%20and%20single-camera%20video%20for%20upper-limb%20out-of-thelab%20activity%20recognition%20with%20different%20deep%20learning%20architectures                                                                                  A comparative study on wearables and single-camera video for upper-limb out-of-thelab activity recognition with different deep learning architectures                                                                                  The use of a wide range of computer vision solutions, and more recently high-end Inertial Measurement Units (IMU) have become increasingly popular for assessing human physical activity in clinical and research settings. Nevertheless, to increase the feasibility of patient tracking in out-of-the-lab settings, it is necessary to use a reduced number of devices for movement acquisition. Promising solutions in this context are IMU-based wearables and single camera systems. Additionally, the development of machine learning systems able to recognize and digest clinically relevant data in-the-wild is needed, and therefore determining the ideal input to those is crucial.
http://w3id.org/mlsea/pwc/scientificWork/A%20comprehensive%20review%20of%20Quantum%20Machine%20Learning%3A%20from%20NISQ%20to%20Fault%20Tolerance                                                                                  A comprehensive review of Quantum Machine Learning: from NISQ to Fault Tolerance                                                                                  Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.
http://w3id.org/mlsea/pwc/scientificWork/A%20comprehensive%20review%20of%20electricity%20storage%20applications%20in%20island%20systems                                                                                  A comprehensive review of electricity storage applications in island systems                                                                                  Electricity storage is crucial for power systems to achieve higher levels of renewable energy penetration. This is especially significant for non-interconnected island (NII) systems, which are electrically isolated and vulnerable to the fluctuations of intermittent renewable generation. This paper comprehensively reviews existing literature on electricity storage in island systems, documenting relevant storage applications worldwide and emphasizing the role of storage in transitioning NII towards a fossil-fuel-independent electricity sector. On this topic, the literature review indicates that the implementation of storage is a prerequisite for attaining renewable penetration rates of over 50% due to the amplified requirements for system flexibility and renewable energy arbitrage. The analysis also identifies potential storage services and classifies applicable storage architectures for islands. Amongst the available storage designs, two have emerged as particularly important for further investigation; standalone, centrally managed storage stations and storage combined with renewables to form a hybrid plant that operates indivisibly in the market. For each design, the operating principles, remuneration schemes, investment feasibility, and applications discussed in the literature are presented in-depth, while possible implementation barriers are acknowledged. The literature on hybrid power plants mainly focuses on wind-powered pumped-hydro stations. However, recently, PV-powered battery-based hybrid plants have gained momentum due to the decreasing cost of Li-ion technology. On the other hand, standalone storage establishments rely heavily on battery technology and are mainly used to provide flexibility to the island grid. Nevertheless, these investments often suffer from insufficient remunerating frameworks, making it challenging for storage projects to be financially secure.
http://w3id.org/mlsea/pwc/scientificWork/A%20comprehensive%20survey%20on%20deep%20active%20learning%20in%20medical%20image%20analysis                                                                                  A comprehensive survey on deep active learning in medical image analysis                                                                                  Deep learning has achieved widespread success in medical image analysis, leading to an increasing demand for large-scale expert-annotated medical image datasets. Yet, the high cost of annotating medical images severely hampers the development of deep learning in this field. To reduce annotation costs, active learning aims to select the most informative samples for annotation and train high-performance models with as few labeled samples as possible. In this survey, we review the core methods of active learning, including the evaluation of informativeness and sampling strategy. For the first time, we provide a detailed summary of the integration of active learning with other label-efficient techniques, such as semi-supervised, self-supervised learning, and so on. We also summarize active learning works that are specifically tailored to medical image analysis. Additionally, we conduct a thorough comparative analysis of the performance of different AL methods in medical image analysis with experiments. In the end, we offer our perspectives on the future trends and challenges of active learning and its applications in medical image analysis.
http://w3id.org/mlsea/pwc/scientificWork/A%20computational%20approach%20to%20visual%20ecology%20with%20deep%20reinforcement%20learning                                                                                  A computational approach to visual ecology with deep reinforcement learning                                                                                  Animal vision is thought to optimize various objectives from metabolic efficiency to discrimination performance, yet its ultimate objective is to facilitate the survival of the animal within its ecological niche. However, modeling animal behavior in complex environments has been challenging. To study how environments shape and constrain visual processing, we developed a deep reinforcement learning framework in which an agent moves through a 3-d environment that it perceives through a vision model, where its only goal is to survive. Within this framework we developed a foraging task where the agent must gather food that sustains it, and avoid food that harms it. We first established that the complexity of the vision model required for survival on this task scaled with the variety and visual complexity of the food in the environment. Moreover, we showed that a recurrent network architecture was necessary to fully exploit complex vision models on the most visually demanding tasks. Finally, we showed how different network architectures learned distinct representations of the environment and task, and lead the agent to exhibit distinct behavioural strategies. In summary, this paper lays the foundation for a computational approach to visual ecology, provides extensive benchmarks for future work, and demonstrates how representations and behaviour emerge from an agent's drive for survival.
http://w3id.org/mlsea/pwc/scientificWork/A%20debiasing%20technique%20for%20place-based%20algorithmic%20patrol%20management                                                                                  A debiasing technique for place-based algorithmic patrol management                                                                                  In recent years, there has been a revolution in data-driven policing. With that has come scrutiny on how bias in historical data affects algorithmic decision making. In this exploratory work, we introduce a debiasing technique for place-based algorithmic patrol management systems. We show that the technique efficiently eliminates racially biased features while retaining high accuracy in the models. Finally, we provide a lengthy list of potential future research in the realm of fairness and data-driven policing which this work uncovered.
http://w3id.org/mlsea/pwc/scientificWork/A%20drug%20classification%20pipeline%20for%20Medicaid%20claims%20using%20RxNorm                                                                                  A drug classification pipeline for Medicaid claims using RxNorm                                                                                  Objective: Freely preprocess drug codes recorded in electronic health records and insurance claims to drug classes that may then be used in biomedical research. Materials and Methods: We developed a drug classification pipeline for linking National Drug Codes to the World Health Organization Anatomical Therapeutic Chemical classification. To implement our solution, we created an R package interface to the National Library of Medicine's RxNorm API. Results: Using the classification pipeline, 59.4% of all unique NDC were linked to an ATC, resulting in 95.5% of all claims being successfully linked to a drug classification. We identified 12,004 unique NDC codes that were classified as being an opioid or non-opioid prescription for treating pain. Discussion: Our proposed pipeline performed similarly well to other NDC classification routines using commercial databases. A check of a small, random sample of non-active NDC found the pipeline to be accurate for classifying these codes. Conclusion: The RxNorm NDC classification pipeline is a practical and reliable tool for categorizing drugs in large-scale administrative claims data.
http://w3id.org/mlsea/pwc/scientificWork/A%20fast%20horizon%20detector%20and%20a%20new%20annotated%20dataset%20for%20maritime%20video%20processing                                                                                  A fast horizon detector and a new annotated dataset for maritime video processing                                                                                  Accurate and fast sea horizon detection is vital for tasks in autonomous navigation and maritime security, such as video stabilization, target region reduction, precise tracking, and obstacle avoidance. This paper introduces a novel sea horizon detector from RGB videos, focusing on rapid and effective sea noise suppression while preserving weak horizon edges. Line fitting methods are subsequently employed on filtered edges for horizon detection. We address the filtering problem by extracting line segments with a very low edge threshold, ensuring the detection of line segments even in low-contrast horizon conditions. We show that horizon line segments have simple and relevant properties in RGB images, which we exploit to suppress noisy segments. Then we use the surviving segments to construct a filtered edge map and infer the horizon from the filtered edges. We propose a careful incorporation of temporal information for horizon inference and experimentally show its effectiveness. We address the computational constraint by providing a vectorized implementation for efficient CPU execution, and leveraging image downsizing with minimal loss of accuracy on the original size. Moreover, we contribute a public horizon line dataset to enrich existing data resources. Our algorithm's performance is rigorously evaluated against state-of-the-art methods, and its components are validated through ablation experiments. Source code and dataset files are available at:
http://w3id.org/mlsea/pwc/scientificWork/A%20fast%20score-based%20search%20algorithm%20for%20maximal%20ancestral%20graphs%20using%20entropy                                                                                  A fast score-based search algorithm for maximal ancestral graphs using entropy                                                                                   emph{Maximal ancestral graph} (MAGs) is a class of graphical model that extend the famous emph{directed acyclic graph} in the presence of latent confounders. Most score-based approaches to learn the unknown MAG from empirical data rely on BIC score which suffers from instability and heavy computations. We propose to use the framework of imsets citep{studeny2006probabilistic} to score MAGs using empirical entropy estimation and the newly proposed emph{refined Markov property} citep{hu2023towards}. Our graphical search procedure is similar to citet{claassen2022greedy} but improved from our theoretical results. We show that our search algorithm is polynomial in number of nodes by restricting degree, maximal head size and number of discriminating paths. In simulated experiment, our algorithm shows superior performance compared to other state of art MAG learning algorithms.
http://w3id.org/mlsea/pwc/scientificWork/A%20first%20passage%20model%20of%20intravitreal%20drug%20delivery%20and%20residence%20time%2C%20in%20relation%20to%20ocular%20geometry%2C%20individual%20variability%2C%20and%20injection%20location                                                                                  A first passage model of intravitreal drug delivery and residence time, in relation to ocular geometry, individual variability, and injection location                                                                                  Purpose: Standard of care for various retinal diseases involves recurrent intravitreal injections. This motivates mathematical modelling efforts to identify influential factors for drug residence time, aiming to minimise administration frequency. We sought to describe the vitreal diffusion of therapeutics in nonclinical species used during drug development assessments. In human eyes, we investigated the impact of variability in vitreous cavity size and eccentricity, and in injection location, on drug elimination. Methods: Using a first passage time approach, we modelled the transport-controlled distribution of two standard therapeutic protein formats (Fab and IgG) and elimination through anterior and posterior pathways. Detailed anatomical 3D geometries of mouse, rat, rabbit, cynomolgus monkey, and human eyes were constructed using ocular images and biometry datasets. A scaling relationship was derived for comparison with experimental ocular half-lives. Results: Model simulations revealed a dependence of residence time on ocular size and injection location. Delivery to the posterior vitreous resulted in increased vitreal half-life and retinal permeation. Interindividual variability in human eyes had a significant influence on residence time (half-life range of 5-7 days), showing a strong correlation to axial length and vitreal volume. Anterior exit was the predominant route of drug elimination. Contribution of the posterior pathway displayed a small (3%) difference between protein formats, but varied between species (10-30%). Conclusions: The modelling results suggest that experimental variability in ocular half-life is partially attributed to anatomical differences and injection site location. Simulations further suggest a potential role of the posterior pathway permeability in determining species differences in ocular pharmacokinetics.
http://w3id.org/mlsea/pwc/scientificWork/A%20generalised%20sigmoid%20population%20growth%20model%20with%20energy%20dependence%3A%20application%20to%20quantify%20the%20tipping%20point%20for%20Antarctic%20shallow%20seabed%20algae                                                                                  A generalised sigmoid population growth model with energy dependence: application to quantify the tipping point for Antarctic shallow seabed algae                                                                                  Sigmoid growth models are often used to study population dynamics. The size of a population at equilibrium commonly depends explicitly on the availability of resources, such as an energy or nutrient source, which is not explicit in standard sigmoid growth models. A simple generalised extension of sigmoid growth models is introduced that can explicitly account for this resource-dependence, demonstrated by three examples of this family of models of increasing mathematical complexity. Each model is calibrated and compared to observed data for algae under sea-ice in Antarctic coastal waters. It was found that through careful construction, models satisfying the proposed framework can estimate key properties of a sea-ice break-out controlled tipping point for the algae, which cannot be estimated using standard sigmoid growth models. The proposed broader family of energy-dependent sigmoid growth models likely has usage in many population growth contexts where resources limit population size.
http://w3id.org/mlsea/pwc/scientificWork/A%20learning-based%20solution%20approach%20to%20the%20application%20placement%20problem%20in%20mobile%20edge%20computing%20under%20uncertainty                                                                                  A learning-based solution approach to the application placement problem in mobile edge computing under uncertainty                                                                                  Placing applications in mobile edge computing servers presents a complex challenge involving many servers, users, and their requests. Existing algorithms take a long time to solve high-dimensional problems with significant uncertainty scenarios. Therefore, an efficient approach is required to maximize the quality of service while considering all technical constraints. One of these approaches is machine learning, which emulates optimal solutions for application placement in edge servers. Machine learning models are expected to learn how to allocate user requests to servers based on the spatial positions of users and servers. In this study, the problem is formulated as a two-stage stochastic programming. A sufficient amount of training records is generated by varying parameters such as user locations, their request rates, and solving the optimization model. Then, based on the distance features of each user from the available servers and their request rates, machine learning models generate decision variables for the first stage of the stochastic optimization model, which is the user-to-server request allocation, and are employed as independent decision agents that reliably mimic the optimization model. Support Vector Machines (SVM) and Multi-layer Perceptron (MLP) are used in this research to achieve practical decisions from the stochastic optimization models. The performance of each model has shown an execution effectiveness of over 80%. This research aims to provide a more efficient approach for tackling high-dimensional problems and scenarios with uncertainties in mobile edge computing by leveraging machine learning models for optimal decision-making in request allocation to edge servers. These results suggest that machine-learning models can significantly improve solution times compared to conventional approaches.
http://w3id.org/mlsea/pwc/scientificWork/A%20many-to-one%20job%20market%3A%20more%20about%20the%20core%20and%20the%20competitive%20salaries                                                                                  A many-to-one job market: more about the core and the competitive salaries                                                                                  This paper studies many-to-one assignment markets, or matching markets with wages. Although it is well-known that the core of this model is non-empty, the structure of the core has not been fully investigated. To the known dissimilarities with the one-to-one assignment game, we add that the bargaining set does not coincide with the core and the kernel may not be included in the core. Besides, not all extreme core allocations can be obtained by means of a lexicographic maximization or a lexicographic minimization procedure, as it is the case in the one-to-one assignment game. The maximum and minimum competitive salaries are characterized in two ways: axiomatically and by means of easily verifiable properties of an associated directed graph. Regarding the remaining extreme core allocations of the many-to-one assignment game, we propose a lexicographic procedure that, for each order on the set of workers, sequentially maximizes or minimizes each worker's competitive salary. This procedure provides all extreme vectors of competitive salaries, that is all extreme core allocations.
http://w3id.org/mlsea/pwc/scientificWork/A%20mathematical%20model%20for%20fibrous%20dysplasia%3A%20The%20role%20of%20the%20flow%20of%20mutant%20cells                                                                                  A mathematical model for fibrous dysplasia: The role of the flow of mutant cells                                                                                  Fibrous dysplasia (FD) is a mosaic non-inheritable genetic disorder of the skeleton in which normal bone is replaced by structurally unsound fibro-osseous tissue. There is no curative treatment for FD, partly because its pathophysiology is not yet fully known. We present a simple mathematical model of the disease incorporating its basic known biology, to gain insight on the dynamics of the involved bone-cell populations, and shed light on its pathophysiology. Our mathematical models account for the dynamic evolution over time of several interacting populations of bone cells averaged over a volume of bone of sufficient size in order to obtain consistent results. We develop an analytical study of the model and study its basic properties. The existence and stability of steady states are studied, an analysis of sensitivity on the model parameters is done, and different numerical simulations provide findings in agreement with the analytical results. We discuss the model dynamics match with known facts on the disease, and how some open questions could be addressed using the model.
http://w3id.org/mlsea/pwc/scientificWork/A%20mathematical%20model%20for%20simultaneous%20personnel%20shift%20planning%20and%20unrelated%20parallel%20machine%20scheduling                                                                                  A mathematical model for simultaneous personnel shift planning and unrelated parallel machine scheduling                                                                                  This paper addresses a production scheduling problem derived from an industrial use case, focusing on unrelated parallel machine scheduling with the personnel availability constraint. The proposed model optimizes the production plan over a multi-period scheduling horizon, accommodating variations in personnel shift hours within each time period. It assumes shared personnel among machines, with one personnel required per machine for setup and supervision during job processing. Available personnel are fewer than the machines, thus limiting the number of machines that can operate in parallel. The model aims to minimize the total production time considering machine-dependent processing times and sequence-dependent setup times. The model handles practical scenarios like machine eligibility constraints and production time windows. A Mixed Integer Linear Programming (MILP) model is introduced to formulate the problem, taking into account both continuous and district variables. A two-step solution approach enhances computational speed, first maximizing accepted jobs and then minimizing production time. Validation with synthetic problem instances and a real industrial case study of a food processing plant demonstrates the performance of the model and its usefulness in personnel shift planning. The findings offer valuable insights for practical managerial decision-making in the context of production scheduling.
http://w3id.org/mlsea/pwc/scientificWork/A%20mathematical%20theory%20of%20power                                                                                  A mathematical theory of power                                                                                  This paper proposes a new approach to power in Game Theory. Cooperation and conflict are simulated with a mechanism of payoff alteration, called F-game. Using convex combinations of preferences, an F-game can measure players' attitude to cooperate. We can then define actual and potential power as special relations between different states of the system.
http://w3id.org/mlsea/pwc/scientificWork/A%20micro-founded%20comparison%20of%20fiscal%20policies%20between%20indirect%20and%20direct%20job%20creation                                                                                  A micro-founded comparison of fiscal policies between indirect and direct job creation                                                                                  The purpose of this paper is to provide a micro-economic foundation for an argument that the direct employment by the government is more desirable than the government purchase of private goods to eliminate unemployment. A general equilibrium model with monopolistic competition is devised, and the effects of policies (government purchase, tax rate operation, and government employment) on macroeconomic variables (consumption, price, and profit) are investigated. It is shown that 1) the government purchase is inflationary in the sense that additional effective demand by the government not only increases private employment but also raises prices; 2) the government employment can achieve full employment without causing a rise in prices.
http://w3id.org/mlsea/pwc/scientificWork/A%20minimal%20model%20of%20cognition%20based%20on%20oscillatory%20and%20reinforcement%20processes                                                                                  A minimal model of cognition based on oscillatory and reinforcement processes                                                                                  Building mathematical models of brains is difficult because of the sheer complexity of the problem. One potential approach is to start by identifying models of basal cognition, which give an abstract representation of a range organisms without central nervous systems, including fungi, slime moulds and bacteria. We propose one such model, demonstrating how a combination of oscillatory and current-based reinforcement processes can be used to couple resources in an efficient manner. We first show that our model connects resources in an efficient manner when the environment is constant. We then show that in an oscillatory environment our model builds efficient solutions, provided the environmental oscillations are sufficiently out of phase. We show that amplitude differences can promote efficient solutions and that the system is robust to frequency differences. We identify connections between our model and basal cognition in biological systems and slime moulds, in particular, showing how oscillatory and problem-solving properties of these systems are captured by our model.
http://w3id.org/mlsea/pwc/scientificWork/A%20multiscale%20sensorimotor%20model%20of%20experience-dependent%20behavior%20in%20a%20minimal%20organism                                                                                  A multiscale sensorimotor model of experience-dependent behavior in a minimal organism                                                                                  To survive in ever-changing environments, living organisms need to continuously combine the ongoing external inputs they receive, representing present conditions, with their dynamical internal state, which includes influences of past experiences. It is still unclear in general, however, (i) how this happens at the molecular and cellular levels, and (ii) how the corresponding molecular and cellular processes are integrated with the behavioral responses of the organism. Here we address these issues by modeling mathematically a particular behavioral paradigm in a minimal model organism, namely chemotaxis in the nematode C. elegans. Specifically, we use a long-standing collection of elegant experiments on salt chemotaxis in this animal, in which the migration direction varies depending on its previous experience. Our model integrates the molecular, cellular and organismal levels to reproduce the experimentally observed experience-dependent behavior. The model proposes specific molecular mechanisms for the encoding of current conditions and past experiences in key neurons associated with this response, predicting the behavior of various mutants associated with those molecular circuits.
http://w3id.org/mlsea/pwc/scientificWork/A%20new%20approach%20for%20solving%20global%20optimization%20and%20engineering%20problems%20based%20on%20modified%20Sea%20Horse%20Optimizer                                                                                  A new approach for solving global optimization and engineering problems based on modified Sea Horse Optimizer                                                                                  Sea Horse Optimizer (SHO) is a noteworthy metaheuristic algorithm that emulates various intelligent behaviors exhibited by sea horses, encompassing feeding patterns, male reproductive strategies, and intricate movement patterns. To mimic the nuanced locomotion of sea horses, SHO integrates the logarithmic helical equation and Levy flight, effectively incorporating both random movements with substantial step sizes and refined local exploitation. Additionally, the utilization of Brownian motion facilitates a more comprehensive exploration of the search space. This study introduces a robust and high-performance variant of the SHO algorithm named mSHO. The enhancement primarily focuses on bolstering SHO's exploitation capabilities by replacing its original method with an innovative local search strategy encompassing three distinct steps: a neighborhood-based local search, a global non-neighbor-based search, and a method involving circumnavigation of the existing search region. These techniques improve mSHO algorithm's search capabilities, allowing it to navigate the search space and converge toward optimal solutions efficiently. The comprehensive results distinctly establish the supremacy and efficiency of the mSHO method as an exemplary tool for tackling an array of optimization quandaries. The results show that the proposed mSHO algorithm has a total rank of 1 for CEC'2020 test functions. In contrast, the mSHO achieved the best value for the engineering problems, recording a value of 0.012665, 2993.634, 0.01266, 1.724967, 263.8915, 0.032255, 58507.14, 1.339956, and 0.23524 for the pressure vessel design, speed reducer design, tension/compression spring, welded beam design, three-bar truss engineering design, industrial refrigeration system, multi-Product batch plant, cantilever beam problem, multiple disc clutch brake problems, respectively.
http://w3id.org/mlsea/pwc/scientificWork/A%20new%20social%20welfare%20function%20with%20a%20number%20of%20desirable%20properties                                                                                  A new social welfare function with a number of desirable properties                                                                                  By relaxing the dominating set in three ways (e.g., from 'each member beats every non-member' to 'each member beats or ties every non-member, with an additional requirement that at least one member beat every non-member'), we propose a new social welfare function, which satisfies a number of desirable properties including Condorcet winner principle, Condorcet loser principle, strong Gehrlein-stability (hence Smith set principle), anonymity, neutrality, weak Pareto, strong Pareto, non-dictatorship, and [independence of irrelevant alternatives (IIA) when the pairwise majority relation is an ordering on the alternative set]. If the pairwise majority relation is complete and transitive, the proposed method yields a collective preference relation that coincides with the input majority relation. It thus shares the same collective preference function on the dichotomous domain with the approval voting and the majority voting. It runs in polynomial time and thus possesses a competitive advantage over a number of computationally intractable voting rules such as the Dodgson's rule, the Kemeny's rule, the Slater's rule, the Banks rule, and the Schwartz's tournament equilibrium set (TEQ) rule. When it is used in tournaments, its winner belongs to the uncovered set, the top cycle set, the Smith set, and the Schwartz set. In addition, in a tournament where the number of alternatives is not more than 4, its winner set is a subset, sometimes proper, of the Copeland winner set. Whether this attractive argument is still valid in four-more-alternative tournaments remains an open question.
http://w3id.org/mlsea/pwc/scientificWork/A%20note%20on%20heterogeneity%2C%20trade%20integration%20and%20spatial%20inequality                                                                                  A note on heterogeneity, trade integration and spatial inequality                                                                                  We study the impact of economic integration on spatial development in a model where all consumers are inter-regionally mobile and have heterogeneous preferences regarding their residential location choices. This heterogeneity is the unique dispersion force in the model. We show that, under reasonable values for the elasticity of substitution among varieties of consumption goods, a higher trade integration always promotes more symmetric patterns, irrespective of the functional form of the dispersion force. We also show that an increase in the degree of heterogeneity in preferences for location leads to less spatial inequality.
http://w3id.org/mlsea/pwc/scientificWork/A%20note%20on%20incorrect%20inferences%20in%20non-binary%20qualitative%20probabilistic%20networks                                                                                  A note on incorrect inferences in non-binary qualitative probabilistic networks                                                                                  Qualitative probabilistic networks (QPNs) combine the conditional independence assumptions of Bayesian networks with the qualitative properties of positive and negative dependence. They formalise various intuitive properties of positive dependence to allow inferences over a large network of variables. However, we will demonstrate in this paper that, due to an incorrect symmetry property, many inferences obtained in non-binary QPNs are not mathematically true. We will provide examples of such incorrect inferences and briefly discuss possible resolutions.
http://w3id.org/mlsea/pwc/scientificWork/A%20note%20on%20the%20capacity%20of%20the%20binary%20perceptron                                                                                  A note on the capacity of the binary perceptron                                                                                  Determining the capacity $ alpha_c$ of the Binary Perceptron is a long-standing problem. Krauth and Mezard (1989) conjectured an explicit value of $ alpha_c$, approximately equal to .833, and a rigorous lower bound matching this prediction was recently established by Ding and Sun (2019). Regarding the upper bound, Kim and Roche (1998) and Talagrand (1999) independently showed that $ alpha_c$ < .996, while Krauth and Mezard outlined an argument which can be used to show that $ alpha_c$ < .847. The purpose of this expository note is to record a complete proof of the bound $ alpha_c$ < .847. The proof is a conditional first moment method combined with known results on the spherical perceptron
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20Fourier%20neural%20operator%20framework%20for%20classification%20of%20multi-sized%20images%3A%20Application%20to%20three%20dimensional%20digital%20porous%20media                                                                                  A novel Fourier neural operator framework for classification of multi-sized images: Application to three dimensional digital porous media                                                                                  Fourier neural operators (FNOs) are invariant with respect to the size of input images, and thus images with any size can be fed into FNO-based frameworks without any modification of network architectures, in contrast to traditional convolutional neural networks (CNNs). Leveraging the advantage of FNOs, we propose a novel deep-learning framework for classifying images with varying sizes. Particularly, we simultaneously train the proposed network on multi-sized images. As a practical application, we consider the problem of predicting the label (e.g., permeability) of three-dimensional digital porous media. To construct the framework, an intuitive approach is to connect FNO layers to a classifier using adaptive max pooling. First, we show that this approach is only effective for porous media with fixed sizes, whereas it fails for porous media of varying sizes. To overcome this limitation, we introduce our approach: instead of using adaptive max pooling, we use static max pooling with the size of channel width of FNO layers. Since the channel width of the FNO layers is independent of input image size, the introduced framework can handle multi-sized images during training. We show the effectiveness of the introduced framework and compare its performance with the intuitive approach through the example of the classification of three-dimensional digital porous media of varying sizes.
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20data%20generation%20scheme%20for%20surrogate%20modelling%20with%20deep%20operator%20networks                                                                                  A novel data generation scheme for surrogate modelling with deep operator networks                                                                                  Operator-based neural network architectures such as DeepONets have emerged as a promising tool for the surrogate modeling of physical systems. In general, towards operator surrogate modeling, the training data is generated by solving the PDEs using techniques such as Finite Element Method (FEM). The computationally intensive nature of data generation is one of the biggest bottleneck in deploying these surrogate models for practical applications. In this study, we propose a novel methodology to alleviate the computational burden associated with training data generation for DeepONets. Unlike existing literature, the proposed framework for data generation does not use any partial differential equation integration strategy, thereby significantly reducing the computational cost associated with generating training dataset for DeepONet. In the proposed strategy, first, the output field is generated randomly, satisfying the boundary conditions using Gaussian Process Regression (GPR). From the output field, the input source field can be calculated easily using finite difference techniques. The proposed methodology can be extended to other operator learning methods, making the approach widely applicable. To validate the proposed approach, we employ the heat equations as the model problem and develop the surrogate model for numerous boundary value problems.
http://w3id.org/mlsea/pwc/scientificWork/A%20novel%20framework%20for%20adaptive%20stress%20testing%20of%20autonomous%20vehicles%20in%20highways                                                                                  A novel framework for adaptive stress testing of autonomous vehicles in highways                                                                                  Guaranteeing the safe operations of autonomous vehicles (AVs) is crucial for their widespread adoption and public acceptance. It is thus of a great significance to not only assess the AV against the standard safety tests, but also discover potential corner cases of the AV under test that could lead to unsafe behaviour or scenario. In this paper, we propose a novel framework to systematically explore corner cases that can result in safety concerns in a highway traffic scenario. The framework is based on an adaptive stress testing (AST) approach, an emerging validation method that leverages a Markov decision process to formulate the scenarios and deep reinforcement learning (DRL) to discover the desirable patterns representing corner cases. To this end, we develop a new reward function for DRL to guide the AST in identifying crash scenarios based on the collision probability estimate between the AV under test (i.e., the ego vehicle) and the trajectory of other vehicles on the highway. The proposed framework is further integrated with a new driving model enabling us to create more realistic traffic scenarios capturing both the longitudinal and lateral movements of vehicles on the highway. In our experiment, we calibrate our model using real-world crash statistics involving automated vehicles in California, and then we analyze the characteristics of the AV and the framework. Quantitative and qualitative analyses of our experimental results demonstrate that our framework outperforms other existing AST schemes. The study can help discover crash scenarios of AV that are unknown or absent in human driving, thereby enhancing the safety and trustworthiness of AV technology.
http://w3id.org/mlsea/pwc/scientificWork/A%20practical%20existence%20theorem%20for%20reduced%20order%20models%20based%20on%20convolutional%20autoencoders                                                                                  A practical existence theorem for reduced order models based on convolutional autoencoders                                                                                  In recent years, deep learning has gained increasing popularity in the fields of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM), providing domain practitioners with new powerful data-driven techniques such as Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context, deep autoencoders based on Convolutional Neural Networks (CNNs) have proven extremely effective, outperforming established techniques, such as the reduced basis method, when dealing with complex nonlinear problems. However, despite the empirical success of CNN-based autoencoders, there are only a few theoretical results supporting these architectures, usually stated in the form of universal approximation theorems. In particular, although the existing literature provides users with guidelines for designing convolutional autoencoders, the subsequent challenge of learning the latent features has been barely investigated. Furthermore, many practical questions remain unanswered, e.g., the number of snapshots needed for convergence or the neural network training strategy. In this work, using recent techniques from sparse high-dimensional function approximation, we fill some of these gaps by providing a new practical existence theorem for CNN-based autoencoders when the parameter-to-solution map is holomorphic. This regularity assumption arises in many relevant classes of parametric PDEs, such as the parametric diffusion equation, for which we discuss an explicit application of our general theory.
http://w3id.org/mlsea/pwc/scientificWork/A%20provable%20control%20of%20sensitivity%20of%20neural%20networks%20through%20a%20direct%20parameterization%20of%20the%20overall%20bi-Lipschitzness                                                                                  A provable control of sensitivity of neural networks through a direct parameterization of the overall bi-Lipschitzness                                                                                  While neural networks can enjoy an outstanding flexibility and exhibit unprecedented performance, the mechanism behind their behavior is still not well-understood. To tackle this fundamental challenge, researchers have tried to restrict and manipulate some of their properties in order to gain new insights and better control on them. Especially, throughout the past few years, the concept of emph{bi-Lipschitzness} has been proved as a beneficial inductive bias in many areas. However, due to its complexity, the design and control of bi-Lipschitz architectures are falling behind, and a model that is precisely designed for bi-Lipschitzness realizing a direct and simple control of the constants along with solid theoretical analysis is lacking. In this work, we investigate and propose a novel framework for bi-Lipschitzness that can achieve such a clear and tight control based on convex neural networks and the Legendre-Fenchel duality. Its desirable properties are illustrated with concrete experiments. We also apply this framework to uncertainty estimation and monotone problem settings to illustrate its broad range of applications.
http://w3id.org/mlsea/pwc/scientificWork/A%20proximal%20policy%20optimization%20based%20intelligent%20home%20solar%20management                                                                                  A proximal policy optimization based intelligent home solar management                                                                                  In the smart grid, the prosumers can sell unused electricity back to the power grid, assuming the prosumers own renewable energy sources and storage units. The maximizing of their profits under a dynamic electricity market is a problem that requires intelligent planning. To address this, we propose a framework based on Proximal Policy Optimization (PPO) using recurrent rewards. By using the information about the rewards modeled effectively with PPO to maximize our objective, we were able to get over 30 % improvement over the other naive algorithms in accumulating total profits. This shows promise in getting reinforcement learning algorithms to perform tasks required to plan their actions in complex domains like financial markets. We also introduce a novel method for embedding longs based on soliton waves that outperformed normal embedding in our use case with random floating point data augmentation.
http://w3id.org/mlsea/pwc/scientificWork/A%20reinforcement%20learning%20guided%20hybrid%20evolutionary%20algorithm%20for%20the%20latency%20location%20routing%20problem                                                                                  A reinforcement learning guided hybrid evolutionary algorithm for the latency location routing problem                                                                                  The latency location routing problem integrates the facility location problem and the multi-depot cumulative capacitated vehicle routing problem. This problem involves making simultaneous decisions about depot locations and vehicle routes to serve customers while aiming to minimize the sum of waiting (arriving) times for all customers. To address this computationally challenging problem, we propose a reinforcement learning guided hybrid evolutionary algorithm following the framework of the memetic algorithm. The proposed algorithm relies on a diversity-enhanced multi-parent edge assembly crossover to build promising offspring and a reinforcement learning guided variable neighborhood descent to determine the exploration order of multiple neighborhoods. Additionally, strategic oscillation is used to achieve a balanced exploration of both feasible and infeasible solutions. The competitiveness of the algorithm against state-of-the-art methods is demonstrated by experimental results on the three sets of 76 popular instances, including 51 improved best solutions (new upper bounds) for the 59 instances with unknown optima and equal best results for the remaining instances. We also conduct additional experiments to shed light on the key components of the algorithm.
http://w3id.org/mlsea/pwc/scientificWork/A%20secure%20and%20private%20ensemble%20matcher%20using%20multi-vault%20obfuscated%20templates                                                                                  A secure and private ensemble matcher using multi-vault obfuscated templates                                                                                  Given the irrevocability of biometric samples and mounting privacy concerns, biometric template security and secure matching are among the essential features of any well-designed modern biometric system. In this paper, we propose an obfuscation method that hides the biometric template information with just enough chaff. The main idea is to reduce the number of chaff points to a practical level by creating n sub-templates from the original template and hiding each sub-template with m chaff points. During verification, s closest vectors to the biometric query are retrieved from each vault and then combined to generate hash values that are compared with the stored hash value. We demonstrate the effectiveness of synthetic facial images, generated by a Generative Adversarial Network (GAN), as ``random chaff points'' within a secure-vault authorization system. This approach safeguards user identities during training and deployment. We tested our protocol using the AT&T, GT, and LFW face datasets, with the ROC areas under the curve being 0.99, 0.99, and 0.90, respectively. These numbers were close to those of the unprotected templates, showing that our method does not adversely affect accuracy.
http://w3id.org/mlsea/pwc/scientificWork/A%20self-supervised%20CNN%20for%20image%20watermark%20removal                                                                                  A self-supervised CNN for image watermark removal                                                                                  Popular convolutional neural networks mainly use paired images in a supervised way for image watermark removal. However, watermarked images do not have reference images in the real world, which results in poor robustness of image watermark removal techniques. In this paper, we propose a self-supervised convolutional neural network (CNN) in image watermark removal (SWCNN). SWCNN uses a self-supervised way to construct reference watermarked images rather than given paired training samples, according to watermark distribution. A heterogeneous U-Net architecture is used to extract more complementary structural information via simple components for image watermark removal. Taking into account texture information, a mixed loss is exploited to improve visual effects of image watermark removal. Besides, a watermark dataset is conducted. Experimental results show that the proposed SWCNN is superior to popular CNNs in image watermark removal.
http://w3id.org/mlsea/pwc/scientificWork/A%20single-snapshot%20inverse%20solver%20for%20two-species%20graph%20model%20of%20tau%20pathology%20spreading%20in%20human%20Alzheimer%20disease                                                                                  A single-snapshot inverse solver for two-species graph model of tau pathology spreading in human Alzheimer disease                                                                                  We propose a method that uses a two-species ordinary differential equation (ODE) biophysical model to characterize misfolded tau (or simply tau) protein spreading in Alzheimer disease (AD) and calibrates it from clinical data. The unknown model parameters are the initial condition (IC) for tau and three scalar parameters representing the migration, proliferation, and clearance of tau proteins. Driven by imaging data, these parameters are estimated by formulating a constrained optimization problem with a sparsity regularization for the IC. This optimization problem is solved with a projection-based quasi-Newton algorithm. We investigate the sensitivity of our method to different algorithm parameters. We evaluate the performance of our method on both synthetic and clinical data. The latter comprises cases from the AD Neuroimaging Initiative (ADNI) and Harvard Aging Brain Study (HABS) datasets: 455 cognitively normal (CN), 212 mild cognitive impairment (MCI), and 45 AD subjects. We compare the performance of our approach to the commonly used Fisher-Kolmogorov (FK) model with a fixed IC at the entorhinal cortex (EC). Our method demonstrates an average improvement of 25.7% relative error compared to the FK model on the AD dataset. HFK also achieves an R-squared score of 0.664 for fitting AD data compared with 0.55 from FK model results. Furthermore, for cases that have longitudinal data, we estimate a subject-specific AD onset time.
http://w3id.org/mlsea/pwc/scientificWork/A%20singular%20Riemannian%20Geometry%20Approach%20to%20Deep%20Neural%20Networks%20III.%20Piecewise%20Differentiable%20Layers%20and%20Random%20Walks%20on%20%24n%24-dimensional%20Classes                                                                                  A singular Riemannian Geometry Approach to Deep Neural Networks III. Piecewise Differentiable Layers and Random Walks on $n$-dimensional Classes                                                                                  Neural networks are playing a crucial role in everyday life, with the most modern generative models able to achieve impressive results. Nonetheless, their functioning is still not very clear, and several strategies have been adopted to study how and why these model reach their outputs. A common approach is to consider the data in an Euclidean settings: recent years has witnessed instead a shift from this paradigm, moving thus to more general framework, namely Riemannian Geometry. Two recent works introduced a geometric framework to study neural networks making use of singular Riemannian metrics. In this paper we extend these results to convolutional, residual and recursive neural networks, studying also the case of non-differentiable activation functions, such as ReLU. We illustrate our findings with some numerical experiments on classification of images and thermodynamic problems.
http://w3id.org/mlsea/pwc/scientificWork/A%20spiking-domain%20implementation%20of%20electronic%20structure%20theory                                                                                  A spiking-domain implementation of electronic structure theory                                                                                  Electronic Structure Theory (EST) describes the behavior of electrons in matter and is used to predict material properties. Conventionally, this involves forming a Hamiltonian and solving the Schr 'odinger equation through discrete computation. Here, a new perspective to EST is provided by treating a perfectly crystalline material as a Linear Translation Invariant (LTI) system. The validity of this LTI-EST formalism is demonstrated by determining band structures for a one-dimensional chain of atoms, including the phenomenon of band structure folding in super cells. The proposed formalism allows for analytical traceability of band structure folding and offers computational advantage by bypassing the O(N) eigenvalue calculations. The spike-based computing nature of the proposed LTI-EST formalism is highlighted; thereby implying potential for material simulations solely in the spiking domain.
http://w3id.org/mlsea/pwc/scientificWork/A%20standardised%20open%20science%20framework%20for%20sharing%20and%20re-analysing%20neural%20data%20acquired%20to%20continuous%20stimuli                                                                                  A standardised open science framework for sharing and re-analysing neural data acquired to continuous stimuli                                                                                  Neurophysiology research has demonstrated that it is possible and valuable to investigate sensory processing in scenarios involving continuous sensory streams, such as speech and music. Over the past 10 years or so, novel analytic frameworks combined with the growing participation in data sharing has led to a surge of publicly available datasets involving continuous sensory experiments. However, open science efforts in this domain of research remain scattered, lacking a cohesive set of guidelines. This paper presents an end-to-end open science framework for the storage, analysis, sharing, and re-analysis of neural data recorded during continuous sensory experiments. The framework has been designed to interface easily with existing toolboxes, such as EelBrain, NapLib, MNE, and the mTRF-Toolbox. We present guidelines by taking both the user view (how to rapidly re-analyse existing data) and the experimenter view (how to store, analyse, and share), making the process as straightforward and accessible as possible for all users. Additionally, we introduce a web-based data browser that enables the effortless replication of published results and data re-analysis.
http://w3id.org/mlsea/pwc/scientificWork/A%20survey%20on%20recent%20advances%20in%20named%20entity%20recognition                                                                                  A survey on recent advances in named entity recognition                                                                                  Named Entity Recognition seeks to extract substrings within a text that name real-world objects and to determine their type (for example, whether they refer to persons or organizations). In this survey, we first present an overview of recent popular approaches, but we also look at graph- and transformer- based methods including Large Language Models (LLMs) that have not had much coverage in other surveys. Second, we focus on methods designed for datasets with scarce annotations. Third, we evaluate the performance of the main NER implementations on a variety of datasets with differing characteristics (as regards their domain, their size, and their number of classes). We thus provide a deep comparison of algorithms that are never considered together. Our experiments shed some light on how the characteristics of datasets affect the behavior of the methods that we compare.
http://w3id.org/mlsea/pwc/scientificWork/A%20systematic%20investigation%20of%20learnability%20from%20single%20child%20linguistic%20input                                                                                  A systematic investigation of learnability from single child linguistic input                                                                                  Language models (LMs) have demonstrated remarkable proficiency in generating linguistically coherent text, sparking discussions about their relevance to understanding human language learnability. However, a significant gap exists between the training data for these models and the linguistic input a child receives. LMs are typically trained on data that is orders of magnitude larger and fundamentally different from child-directed speech (Warstadt and Bowman, 2022; Warstadt et al., 2023; Frank, 2023a). Addressing this discrepancy, our research focuses on training LMs on subsets of a single child's linguistic input. Previously, Wang, Vong, Kim, and Lake (2023) found that LMs trained in this setting can form syntactic and semantic word clusters and develop sensitivity to certain linguistic phenomena, but they only considered LSTMs and simpler neural networks trained from just one single-child dataset. Here, to examine the robustness of learnability from single-child input, we systematically train six different model architectures on five datasets (3 single-child and 2 baselines). We find that the models trained on single-child datasets showed consistent results that matched with previous work, underscoring the robustness of forming meaningful syntactic and semantic representations from a subset of a child's linguistic input.
http://w3id.org/mlsea/pwc/scientificWork/A%20topological%20characterization%20of%20the%20existence%20of%20w-stable%20sets                                                                                  A topological characterization of the existence of w-stable sets                                                                                  The theory of optimal choice sets is a solution theory that has a long and well-established tradition in social choice and game theories. Some of important general solution concepts of choice problems when the set of best alternatives does not exist (this problem occurs when the preferences yielded by an economic process are cyclic) is the Stable Set (Von Neumann-Morgenstern set) and its variants (Generalized Stable set, Extended Stable set, m-Stable set and w-Stable set). The theory of w-stable sets solution is more realistic because: (1) It solves the existence problem of solution; (2) It expands the notions of maximal alternative set and (3) The concept of stability is defined in such a way as to prevent a chosen alternative from being dominated by another alternative and sets this stability within the solution. In this paper, we present a topological characterization of the existence of w-Stable sets solution of arbitrary binary relations over non-finite sets of alternatives.
http://w3id.org/mlsea/pwc/scientificWork/A%20unified%20framework%20of%20non-local%20parametric%20methods%20for%20image%20denoising                                                                                  A unified framework of non-local parametric methods for image denoising                                                                                  We propose a unified view of non-local methods for single-image denoising, for which BM3D is the most popular representative, that operate by gathering noisy patches together according to their similarities in order to process them collaboratively. Our general estimation framework is based on the minimization of the quadratic risk, which is approximated in two steps, and adapts to photon and electronic noises. Relying on unbiased risk estimation (URE) for the first step and on ``internal adaptation'', a concept borrowed from deep learning theory, for the second, we show that our approach enables to reinterpret and reconcile previous state-of-the-art non-local methods. Within this framework, we propose a novel denoiser called NL-Ridge that exploits linear combinations of patches. While conceptually simpler, we show that NL-Ridge can outperform well-established state-of-the-art single-image denoisers.
http://w3id.org/mlsea/pwc/scientificWork/A%20unifying%20primary%20framework%20for%20quantum%20graph%20neural%20networks%20from%20quantum%20graph%20states                                                                                  A unifying primary framework for quantum graph neural networks from quantum graph states                                                                                  Graph states are used to represent mathematical graphs as quantum states on quantum computers. They can be formulated through stabilizer codes or directly quantum gates and quantum states. In this paper we show that a quantum graph neural network model can be understood and realized based on graph states. We show that they can be used either as a parameterized quantum circuits to represent neural networks or as an underlying structure to construct graph neural networks on quantum computers.
http://w3id.org/mlsea/pwc/scientificWork/AAPMT%3A%20AGI%20Assessment%20Through%20Prompt%20and%20Metric%20Transformer                                                                                  AAPMT: AGI Assessment Through Prompt and Metric Transformer                                                                                  The emergence of text-to-image models marks a significant milestone in the evolution of AI-generated images (AGIs), expanding their use in diverse domains like design, entertainment, and more. Despite these breakthroughs, the quality of AGIs often remains suboptimal, highlighting the need for effective evaluation methods. These methods are crucial for assessing the quality of images relative to their textual descriptions, and they must accurately mirror human perception. Substantial progress has been achieved in this domain, with innovative techniques such as BLIP and DBCNN contributing significantly. However, recent studies, including AGIQA-3K, reveal a notable discrepancy between current methods and state-of-the-art (SOTA) standards. This gap emphasizes the necessity for a more sophisticated and precise evaluation metric. In response, our objective is to develop a model that could give ratings for metrics, which focuses on parameters like perceptual quality, authenticity, and the correspondence between text and image, that more closely aligns with human perception. In our paper, we introduce a range of effective methods, including prompt designs and the Metric Transformer. The Metric Transformer is a novel structure inspired by the complex interrelationships among various AGI quality metrics. The code is available at https://github.com/huskydoge/CS3324-Digital-Image-Processing/tree/main/Assignment1
http://w3id.org/mlsea/pwc/scientificWork/AC4%3A%20Algebraic%20Computation%20Checker%20for%20Circuit%20Constraints%20in%20ZKPs                                                                                  AC4: Algebraic Computation Checker for Circuit Constraints in ZKPs                                                                                  ZKP systems have surged attention and held a fundamental role in contemporary cryptography. Zk-SNARK protocols dominate the ZKP usage, often implemented through arithmetic circuit programming paradigm. However, underconstrained or overconstrained circuits may lead to bugs. Underconstrained circuits refer to circuits that lack the necessary constraints, resulting in unexpected solutions in the circuit and causing the verifier to accept a bogus witness. Overconstrained circuits refer to circuits that are constrained excessively, resulting in the circuit lacking necessary solutions and causing the verifier to accept no witness, rendering the circuit meaningless. This paper introduces a novel approach for pinpointing two distinct types of bugs in ZKP circuits. The method involves encoding the arithmetic circuit constraints to polynomial equation systems and solving polynomial equation systems over a finite field by algebraic computation. The classification of verification results is refined, greatly enhancing the expressive power of the system. We proposed a tool, AC4, to represent the implementation of this method. Experiments demonstrate that AC4 represents a substantial 29% increase in the checked ratio compared to prior work. Within a solvable range, the checking time of AC4 has also exhibited noticeable improvement, demonstrating a magnitude increase compared to previous efforts.
http://w3id.org/mlsea/pwc/scientificWork/ACE%20%3A%20Off-Policy%20Actor-Critic%20with%20Causality-Aware%20Entropy%20Regularization                                                                                  ACE : Off-Policy Actor-Critic with Causality-Aware Entropy Regularization                                                                                  The varying significance of distinct primitive behaviors during the policy learning process has been overlooked by prior model-free RL algorithms. Leveraging this insight, we explore the causal relationship between different action dimensions and rewards to evaluate the significance of various primitive behaviors during training. We introduce a causality-aware entropy term that effectively identifies and prioritizes actions with high potential impacts for efficient exploration. Furthermore, to prevent excessive focus on specific primitive behaviors, we analyze the gradient dormancy phenomenon and introduce a dormancy-guided reset mechanism to further enhance the efficacy of our method. Our proposed algorithm, ACE: Off-policy Actor-critic with Causality-aware Entropy regularization, demonstrates a substantial performance advantage across 29 diverse continuous control tasks spanning 7 domains compared to model-free RL baselines, which underscores the effectiveness, versatility, and efficient sample efficiency of our approach. Benchmark results and videos are available at https://ace-rl.github.io/.
http://w3id.org/mlsea/pwc/scientificWork/ACT-Diffusion%3A%20Efficient%20Adversarial%20Consistency%20Training%20for%20One-step%20Diffusion%20Models                                                                                  ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models                                                                                  Though diffusion models excel in image generation, their step-by-step denoising leads to slow generation speeds. Consistency training addresses this issue with single-step sampling but often produces lower-quality generations and requires high training costs. In this paper, we show that optimizing consistency training loss minimizes the Wasserstein distance between target and generated distributions. As timestep increases, the upper bound accumulates previous consistency training losses. Therefore, larger batch sizes are needed to reduce both current and accumulated losses. We propose Adversarial Consistency Training (ACT), which directly minimizes the Jensen-Shannon (JS) divergence between distributions at each timestep using a discriminator. Theoretically, ACT enhances generation quality, and convergence. By incorporating a discriminator into the consistency training framework, our method achieves improved FID scores on CIFAR10 and ImageNet 64$ times$64 and LSUN Cat 256$ times$256 datasets, retains zero-shot image inpainting capabilities, and uses less than $1/6$ of the original batch size and fewer than $1/2$ of the model parameters and training steps compared to the baseline method, this leads to a substantial reduction in resource consumption. Our code is available:https://github.com/kong13661/ACT
http://w3id.org/mlsea/pwc/scientificWork/ACT-MNMT%20Auto-Constriction%20Turning%20for%20Multilingual%20Neural%20Machine%20Translation                                                                                  ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation                                                                                  Large language model (LLM) has achieved promising performance in multilingual machine translation tasks through zero/few-shot prompts or prompt-tuning. However, due to the mixture of multilingual data during the pre-training of LLM, the LLM-based translation models face the off-target issue in both prompt-based methods, including a series of phenomena, namely instruction misunderstanding, translation with wrong language and over-generation. For this issue, this paper introduces an textbf{ underline{A}}uto- textbf{ underline{C}}onstriction textbf{ underline{T}}urning mechanism for textbf{ underline{M}}ultilingual textbf{ underline{N}}eural textbf{ underline{M}}achine textbf{ underline{T}}ranslation ( model), which is a novel supervised fine-tuning mechanism and orthogonal to the traditional prompt-based methods. In this method, model automatically constructs a constrained template in the target side by adding trigger tokens ahead of the ground truth. Furthermore, trigger tokens can be arranged and combined freely to represent different task semantics, and they can be iteratively updated to maximize the label likelihood. Experiments are performed on WMT test sets with multiple metrics, and the experimental results demonstrate that model achieves substantially improved performance across multiple translation directions and reduce the off-target phenomena in the translation.
http://w3id.org/mlsea/pwc/scientificWork/ADF%20%26%20TransApp%3A%20A%20Transformer-Based%20Framework%20for%20Appliance%20Detection%20Using%20Smart%20Meter%20Consumption%20Series                                                                                  ADF & TransApp: A Transformer-Based Framework for Appliance Detection Using Smart Meter Consumption Series                                                                                  Over the past decade, millions of smart meters have been installed by electricity suppliers worldwide, allowing them to collect a large amount of electricity consumption data, albeit sampled at a low frequency (one point every 30min). One of the important challenges these suppliers face is how to utilize these data to detect the presence/absence of different appliances in the customers' households. This valuable information can help them provide personalized offers and recommendations to help customers towards the energy transition. Appliance detection can be cast as a time series classification problem. However, the large amount of data combined with the long and variable length of the consumption series pose challenges when training a classifier. In this paper, we propose ADF, a framework that uses subsequences of a client consumption series to detect the presence/absence of appliances. We also introduce TransApp, a Transformer-based time series classifier that is first pretrained in a self-supervised way to enhance its performance on appliance detection tasks. We test our approach on two real datasets, including a publicly available one. The experimental results with two large real datasets show that the proposed approach outperforms current solutions, including state-of-the-art time series classifiers applied to appliance detection. This paper appeared in VLDB 2024.
http://w3id.org/mlsea/pwc/scientificWork/AETTA%3A%20Label-Free%20Accuracy%20Estimation%20for%20Test-Time%20Adaptation                                                                                  AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation                                                                                  Test-time adaptation (TTA) has emerged as a viable solution to adapt pre-trained models to domain shifts using unlabeled test data. However, TTA faces challenges of adaptation failures due to its reliance on blind adaptation to unknown test samples in dynamic scenarios. Traditional methods for out-of-distribution performance estimation are limited by unrealistic assumptions in the TTA context, such as requiring labeled data or re-training models. To address this issue, we propose AETTA, a label-free accuracy estimation algorithm for TTA. We propose the prediction disagreement as the accuracy estimate, calculated by comparing the target model prediction with dropout inferences. We then improve the prediction disagreement to extend the applicability of AETTA under adaptation failures. Our extensive evaluation with four baselines and six TTA methods demonstrates that AETTA shows an average of 19.8%p more accurate estimation compared with the baselines. We further demonstrate the effectiveness of accuracy estimation with a model recovery case study, showcasing the practicality of our model recovery based on accuracy estimation. The source code is available at https://github.com/taeckyung/AETTA.
http://w3id.org/mlsea/pwc/scientificWork/AFLoRA%3A%20Adaptive%20Freezing%20of%20Low%20Rank%20Adaptation%20in%20Parameter%20Efficient%20Fine-Tuning%20of%20Large%20Models                                                                                  AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models                                                                                  We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as Adaptive Freezing of Low Rank Adaptation (AFLoRA). Specifically, for each pre-trained frozen weight tensor, we add a parallel path of trainable low-rank matrices, namely a down-projection and an up-projection matrix, each of which is followed by a feature transformation vector. Based on a novel freezing score, we the incrementally freeze these projection matrices during fine-tuning to reduce the computation and alleviate over-fitting. Our experimental results demonstrate that we can achieve state-of-the-art performance with an average improvement of up to $0.85 %$ as evaluated on GLUE benchmark while yeilding up to $9.5 times$ fewer average trainable parameters. While compared in terms of runtime, AFLoRA can yield up to $1.86 times$ improvement as opposed to similar PEFT alternatives. Besides the practical utility of our approach, we provide insights on the trainability requirements of LoRA paths at different modules and the freezing schedule for the different projection matrices. Code will be released.
http://w3id.org/mlsea/pwc/scientificWork/AFSD-Physics%3A%20Exploring%20the%20governing%20equations%20of%20temperature%20evolution%20during%20additive%20friction%20stir%20deposition%20by%20a%20human-AI%20teaming%20approach                                                                                  AFSD-Physics: Exploring the governing equations of temperature evolution during additive friction stir deposition by a human-AI teaming approach                                                                                  This paper presents a modeling effort to explore the underlying physics of temperature evolution during additive friction stir deposition (AFSD) by a human-AI teaming approach. AFSD is an emerging solid-state additive manufacturing technology that deposits materials without melting. However, both process modeling and modeling of the AFSD tool are at an early stage. In this paper, a human-AI teaming approach is proposed to combine models based on first principles with AI. The resulting human-informed machine learning method, denoted as AFSD-Physics, can effectively learn the governing equations of temperature evolution at the tool and the build from in-process measurements. Experiments are designed and conducted to collect in-process measurements for the deposition of aluminum 7075 with a total of 30 layers. The acquired governing equations are physically interpretable models with low computational cost and high accuracy. Model predictions show good agreement with the measurements. Experimental validation with new process parameters demonstrates the model's generalizability and potential for use in tool temperature control and process optimization.
http://w3id.org/mlsea/pwc/scientificWork/AI%20Ethics%3A%20A%20Bibliometric%20Analysis%2C%20Critical%20Issues%2C%20and%20Key%20Gaps                                                                                  AI Ethics: A Bibliometric Analysis, Critical Issues, and Key Gaps                                                                                  Artificial intelligence (AI) ethics has emerged as a burgeoning yet pivotal area of scholarly research. This study conducts a comprehensive bibliometric analysis of the AI ethics literature over the past two decades. The analysis reveals a discernible tripartite progression, characterized by an incubation phase, followed by a subsequent phase focused on imbuing AI with human-like attributes, culminating in a third phase emphasizing the development of human-centric AI systems. After that, they present seven key AI ethics issues, encompassing the Collingridge dilemma, the AI status debate, challenges associated with AI transparency and explainability, privacy protection complications, considerations of justice and fairness, concerns about algocracy and human enfeeblement, and the issue of superintelligence. Finally, they identify two notable research gaps in AI ethics regarding the large ethics model (LEM) and AI identification and extend an invitation for further scholarly research.
http://w3id.org/mlsea/pwc/scientificWork/AI%20Literacy%20in%20Low-Resource%20Languages%3AInsights%20from%20creating%20AI%20in%20Yoruba%20videos                                                                                  AI Literacy in Low-Resource Languages:Insights from creating AI in Yoruba videos                                                                                  To effectively navigate the AI revolution, AI literacy is crucial. However, content predominantly exists in dominant languages, creating a gap for low-resource languages like Yoruba (41 million native speakers). This case study explores bridging this gap by creating and distributing AI videos in Yoruba.The project developed 26 videos covering foundational, intermediate, and advanced AI concepts, leveraging storytelling and accessible explanations. These videos were created using a cost-effective methodology and distributed across YouTube, LinkedIn, and Twitter, reaching an estimated global audience of 22 countries. Analysis of YouTube reveals insights into viewing patterns, with the 25-44 age group contributing the most views. Notably, over half of the traffic originated from external sources, highlighting the potential of cross-platform promotion.This study demonstrates the feasibility and impact of creating AI literacy content in low-resource languages. It emphasizes that accurate interpretation requires both technical expertise in AI and fluency in the target language. This work contributes a replicable methodology, a 22-word Yoruba AI vocabulary, and data-driven insights into audience demographics and acquisition channel
http://w3id.org/mlsea/pwc/scientificWork/AI%20Safety%3A%20Necessary%2C%20but%20insufficient%20and%20possibly%20problematic                                                                                  AI Safety: Necessary, but insufficient and possibly problematic                                                                                  This article critically examines the recent hype around AI safety. We first start with noting the nature of the AI safety hype as being dominated by governments and corporations, and contrast it with other avenues within AI research on advancing social good. We consider what 'AI safety' actually means, and outline the dominant concepts that the digital footprint of AI safety aligns with. We posit that AI safety has a nuanced and uneasy relationship with transparency and other allied notions associated with societal good, indicating that it is an insufficient notion if the goal is that of societal good in a broad sense. We note that the AI safety debate has already influenced some regulatory efforts in AI, perhaps in not so desirable directions. We also share our concerns on how AI safety may normalize AI that advances structural harm through providing exploitative and harmful AI with a veneer of safety.
http://w3id.org/mlsea/pwc/scientificWork/AI%20enhanced%20data%20assimilation%20and%20uncertainty%20quantification%20applied%20to%20Geological%20Carbon%20Storage                                                                                  AI enhanced data assimilation and uncertainty quantification applied to Geological Carbon Storage                                                                                  This study investigates the integration of machine learning (ML) and data assimilation (DA) techniques, focusing on implementing surrogate models for Geological Carbon Storage (GCS) projects while maintaining high fidelity physical results in posterior states. Initially, we evaluate the surrogate modeling capability of two distinct machine learning models, Fourier Neural Operators (FNOs) and Transformer UNet (T-UNet), in the context of CO$_2$ injection simulations within channelized reservoirs. We introduce the Surrogate-based hybrid ESMDA (SH-ESMDA), an adaptation of the traditional Ensemble Smoother with Multiple Data Assimilation (ESMDA). This method uses FNOs and T-UNet as surrogate models and has the potential to make the standard ESMDA process at least 50% faster or more, depending on the number of assimilation steps. Additionally, we introduce Surrogate-based Hybrid RML (SH-RML), a variational data assimilation approach that relies on the randomized maximum likelihood (RML) where both the FNO and the T-UNet enable the computation of gradients for the optimization of the objective function, and a high-fidelity model is employed for the computation of the posterior states. Our comparative analyses show that SH-RML offers better uncertainty quantification compared to conventional ESMDA for the case study.
http://w3id.org/mlsea/pwc/scientificWork/AI%20for%20Biomedicine%20in%20the%20Era%20of%20Large%20Language%20Models                                                                                  AI for Biomedicine in the Era of Large Language Models                                                                                  The capabilities of AI for biomedicine span a wide spectrum, from the atomic level, where it solves partial differential equations for quantum systems, to the molecular level, predicting chemical or protein structures, and further extending to societal predictions like infectious disease outbreaks. Recent advancements in large language models, exemplified by models like ChatGPT, have showcased significant prowess in natural language tasks, such as translating languages, constructing chatbots, and answering questions. When we consider biomedical data, we observe a resemblance to natural language in terms of sequences: biomedical literature and health records presented as text, biological sequences or sequencing data arranged in sequences, or sensor data like brain signals as time series. The question arises: Can we harness the potential of recent large language models to drive biomedical knowledge discoveries? In this survey, we will explore the application of large language models to three crucial categories of biomedical data: 1) textual data, 2) biological sequences, and 3) brain signals. Furthermore, we will delve into large language model challenges in biomedical research, including ensuring trustworthiness, achieving personalization, and adapting to multi-modal data representation
http://w3id.org/mlsea/pwc/scientificWork/AI%20for%20social%20science%20and%20social%20science%20of%20AI%3A%20A%20Survey                                                                                  AI for social science and social science of AI: A Survey                                                                                  Recent advancements in artificial intelligence, particularly with the emergence of large language models (LLMs), have sparked a rethinking of artificial general intelligence possibilities. The increasing human-like capabilities of AI are also attracting attention in social science research, leading to various studies exploring the combination of these two fields. In this survey, we systematically categorize previous explorations in the combination of AI and social science into two directions that share common technical approaches but differ in their research objectives. The first direction is focused on AI for social science, where AI is utilized as a powerful tool to enhance various stages of social science research. While the second direction is the social science of AI, which examines AI agents as social entities with their human-like cognitive and linguistic capabilities. By conducting a thorough review, particularly on the substantial progress facilitated by recent advancements in large language models, this paper introduces a fresh perspective to reassess the relationship between AI and social science, provides a cohesive framework that allows researchers to understand the distinctions and connections between AI for social science and social science of AI, and also summarized state-of-art experiment simulation platforms to facilitate research in these two directions. We believe that as AI technology continues to advance and intelligent agents find increasing applications in our daily lives, the significance of the combination of AI and social science will become even more prominent.
http://w3id.org/mlsea/pwc/scientificWork/AI%20prediction%20of%20cardiovascular%20events%20using%20opportunistic%20epicardial%20adipose%20tissue%20assessments%20from%20CT%20calcium%20score                                                                                  AI prediction of cardiovascular events using opportunistic epicardial adipose tissue assessments from CT calcium score                                                                                  Background: Recent studies have used basic epicardial adipose tissue (EAT) assessments (e.g., volume and mean HU) to predict risk of atherosclerosis-related, major adverse cardiovascular events (MACE). Objectives: Create novel, hand-crafted EAT features, 'fat-omics', to capture the pathophysiology of EAT and improve MACE prediction. Methods: We segmented EAT using a previously-validated deep learning method with optional manual correction. We extracted 148 radiomic features (morphological, spatial, and intensity) and used Cox elastic-net for feature reduction and prediction of MACE. Results: Traditional fat features gave marginal prediction (EAT-volume/EAT-mean-HU/ BMI gave C-index 0.53/0.55/0.57, respectively). Significant improvement was obtained with 15 fat-omics features (C-index=0.69, test set). High-risk features included volume-of-voxels-having-elevated-HU-[-50, -30-HU] and HU-negative-skewness, both of which assess high HU, which as been implicated in fat inflammation. Other high-risk features include kurtosis-of-EAT-thickness, reflecting the heterogeneity of thicknesses, and EAT-volume-in-the-top-25%-of-the-heart, emphasizing adipose near the proximal coronary arteries. Kaplan-Meyer plots of Cox-identified, high- and low-risk patients were well separated with the median of the fat-omics risk, while high-risk group having HR 2.4 times that of the low-risk group (P<0.001). Conclusion: Preliminary findings indicate an opportunity to use more finely tuned, explainable assessments on EAT for improved cardiovascular risk prediction.
http://w3id.org/mlsea/pwc/scientificWork/AI-Assisted%20Causal%20Pathway%20Diagram%20for%20Human-Centered%20Design                                                                                  AI-Assisted Causal Pathway Diagram for Human-Centered Design                                                                                  This paper explores the integration of causal pathway diagrams (CPD) into human-centered design (HCD), investigating how these diagrams can enhance the early stages of the design process. A dedicated CPD plugin for the online collaborative whiteboard platform Miro was developed to streamline diagram creation and offer real-time AI-driven guidance. Through a user study with designers (N=20), we found that CPD's branching and its emphasis on causal connections supported both divergent and convergent processes during design. CPD can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers' cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs.
http://w3id.org/mlsea/pwc/scientificWork/AI-Assisted%20Writing%20in%20Education%3A%20Ecosystem%20Risks%20and%20Mitigations                                                                                  AI-Assisted Writing in Education: Ecosystem Risks and Mitigations                                                                                  While the excitement around the capabilities of technological advancements is giving rise to new AI-based writing assistants, the overarching ecosystem plays a crucial role in how they are adopted in educational practice. In this paper, we point to key ecological aspects for consideration. We draw insights from extensive research integrated with practice on a writing feedback tool over 9 years at a university, and we highlight potential risks when these are overlooked. It informs the design of educational writing support tools to be better aligned within broader contexts to balance innovation with practical impact.
http://w3id.org/mlsea/pwc/scientificWork/AI-Enhanced%20Virtual%20Reality%20in%20Medicine%3A%20A%20Comprehensive%20Survey                                                                                  AI-Enhanced Virtual Reality in Medicine: A Comprehensive Survey                                                                                  With the rapid advance of computer graphics and artificial intelligence technologies, the ways we interact with the world have undergone a transformative shift. Virtual Reality (VR) technology, aided by artificial intelligence (AI), has emerged as a dominant interaction media in multiple application areas, thanks to its advantage of providing users with immersive experiences. Among those applications, medicine is considered one of the most promising areas. In this paper, we present a comprehensive examination of the burgeoning field of AI-enhanced VR applications in medical care and services. By introducing a systematic taxonomy, we meticulously classify the pertinent techniques and applications into three well-defined categories based on different phases of medical diagnosis and treatment: Visualization Enhancement, VR-related Medical Data Processing, and VR-assisted Intervention. This categorization enables a structured exploration of the diverse roles that AI-powered VR plays in the medical domain, providing a framework for a more comprehensive understanding and evaluation of these technologies. To our best knowledge, this is the first systematic survey of AI-powered VR systems in medical settings, laying a foundation for future research in this interdisciplinary domain.
http://w3id.org/mlsea/pwc/scientificWork/AIGCs%20Confuse%20AI%20Too%3A%20Investigating%20and%20Explaining%20Synthetic%20Image-induced%20Hallucinations%20in%20Large%20Vision-Language%20Models                                                                                  AIGCs Confuse AI Too: Investigating and Explaining Synthetic Image-induced Hallucinations in Large Vision-Language Models                                                                                  The evolution of Artificial Intelligence Generated Contents (AIGCs) is advancing towards higher quality. The growing interactions with AIGCs present a new challenge to the data-driven AI community: While AI-generated contents have played a crucial role in a wide range of AI models, the potential hidden risks they introduce have not been thoroughly examined. Beyond human-oriented forgery detection, AI-generated content poses potential issues for AI models originally designed to process natural data. In this study, we underscore the exacerbated hallucination phenomena in Large Vision-Language Models (LVLMs) caused by AI-synthetic images. Remarkably, our findings shed light on a consistent AIGC textbf{hallucination bias}: the object hallucinations induced by synthetic images are characterized by a greater quantity and a more uniform position distribution, even these synthetic images do not manifest unrealistic or additional relevant visual features compared to natural images. Moreover, our investigations on Q-former and Linear projector reveal that synthetic images may present token deviations after visual projection, thereby amplifying the hallucination bias.
http://w3id.org/mlsea/pwc/scientificWork/AINS%3A%20Affordable%20Indoor%20Navigation%20Solution%20via%20Line%20Color%20Identification%20Using%20Mono-Camera%20for%20Autonomous%20Vehicles                                                                                  AINS: Affordable Indoor Navigation Solution via Line Color Identification Using Mono-Camera for Autonomous Vehicles                                                                                  Recently, researchers have been exploring various ways to improve the effectiveness and efficiency of autonomous vehicles by researching new methods, especially for indoor scenarios. Autonomous Vehicles in indoor navigation systems possess many challenges especially the limited accuracy of GPS in indoor scenarios. Several, robust methods have been explored for autonomous vehicles in indoor scenarios to solve this problem, but the ineffectiveness of the proposed methods is the high deployment cost. To address the above-mentioned problems we have presented A low-cost indoor navigation method for autonomous vehicles called Affordable Indoor Navigation Solution (AINS) which is based on based on Monocular Camera. Our proposed solution is mainly based on a mono camera without relying on various huge or power-inefficient sensors to find the path, such as range finders and other navigation sensors. Our proposed method shows that we can deploy autonomous vehicles indoor navigation systems while taking into consideration the cost. We can observe that the results shown by our solution are better than existing solutions and we can reduce the estimated error and time consumption.
http://w3id.org/mlsea/pwc/scientificWork/AIx%20Speed%3A%20Playback%20Speed%20Optimization%20Using%20Listening%20Comprehension%20of%20Speech%20Recognition%20Models                                                                                  AIx Speed: Playback Speed Optimization Using Listening Comprehension of Speech Recognition Models                                                                                  Since humans can listen to audio and watch videos at faster speeds than actually observed, we often listen to or watch these pieces of content at higher playback speeds to increase the time efficiency of content comprehension. To further utilize this capability, systems that automatically adjust the playback speed according to the user's condition and the type of content to assist in more efficient comprehension of time-series content have been developed. However, there is still room for these systems to further extend human speed-listening ability by generating speech with playback speed optimized for even finer time units and providing it to humans. In this study, we determine whether humans can hear the optimized speech and propose a system that automatically adjusts playback speed at units as small as phonemes while ensuring speech intelligibility. The system uses the speech recognizer score as a proxy for how well a human can hear a certain unit of speech and maximizes the speech playback speed to the extent that a human can hear. This method can be used to produce fast but intelligible speech. In the evaluation experiment, we compared the speech played back at a constant fast speed and the flexibly speed-up speech generated by the proposed method in a blind test and confirmed that the proposed method produced speech that was easier to listen to.
http://w3id.org/mlsea/pwc/scientificWork/AKBR%3A%20Learning%20Adaptive%20Kernel-based%20Representations%20for%20Graph%20Classification                                                                                  AKBR: Learning Adaptive Kernel-based Representations for Graph Classification                                                                                  In this paper, we propose a new model to learn Adaptive Kernel-based Representations (AKBR) for graph classification. Unlike state-of-the-art R-convolution graph kernels that are defined by merely counting any pair of isomorphic substructures between graphs and cannot provide an end-to-end learning mechanism for the classifier, the proposed AKBR approach aims to define an end-to-end representation learning model to construct an adaptive kernel matrix for graphs. To this end, we commence by leveraging a novel feature-channel attention mechanism to capture the interdependencies between different substructure invariants of original graphs. The proposed AKBR model can thus effectively identify the structural importance of different substructures, and compute the R-convolution kernel between pairwise graphs associated with the more significant substructures specified by their structural attentions. Since each row of the resulting kernel matrix can be theoretically seen as the embedding vector of a sample graph, the proposed AKBR model is able to directly employ the resulting kernel matrix as the graph feature matrix and input it into the classifier for classification (i.e., the SoftMax layer), naturally providing an end-to-end learning architecture between the kernel computation as well as the classifier. Experimental results show that the proposed AKBR model outperforms existing state-of-the-art graph kernels and deep learning methods on standard graph benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/ALISON%3A%20Fast%20and%20Effective%20Stylometric%20Authorship%20Obfuscation                                                                                  ALISON: Fast and Effective Stylometric Authorship Obfuscation                                                                                  Authorship Attribution (AA) and Authorship Obfuscation (AO) are two competing tasks of increasing importance in privacy research. Modern AA leverages an author's consistent writing style to match a text to its author using an AA classifier. AO is the corresponding adversarial task, aiming to modify a text in such a way that its semantics are preserved, yet an AA model cannot correctly infer its authorship. To address privacy concerns raised by state-of-the-art (SOTA) AA methods, new AO methods have been proposed but remain largely impractical to use due to their prohibitively slow training and obfuscation speed, often taking hours. To this challenge, we propose a practical AO method, ALISON, that (1) dramatically reduces training/obfuscation time, demonstrating more than 10x faster obfuscation than SOTA AO methods, (2) achieves better obfuscation success through attacking three transformer-based AA methods on two benchmark datasets, typically performing 15% better than competing methods, (3) does not require direct signals from a target AA classifier during obfuscation, and (4) utilizes unique stylometric features, allowing sound model interpretation for explainable obfuscation. We also demonstrate that ALISON can effectively prevent four SOTA AA methods from accurately determining the authorship of ChatGPT-generated texts, all while minimally changing the original text semantics. To ensure the reproducibility of our findings, our code and data are available at: https://github.com/EricX003/ALISON.
http://w3id.org/mlsea/pwc/scientificWork/ALIVE%3A%20A%20Low-Cost%20Interactive%20Vaccine%20Storage%20Environment%20Module%20ensuring%20easy%20portability%20and%20remote%20tracking%20of%20operational%20logistics%20to%20the%20last%20mile                                                                                  ALIVE: A Low-Cost Interactive Vaccine Storage Environment Module ensuring easy portability and remote tracking of operational logistics to the last mile                                                                                  The COVID-19 pandemic has profoundly reshaped our lives, prompting a search for solutions to its far-reaching effects. Vaccines emerged as a beacon of hope, yet reaching remote areas faces last-mile hurdles and cost issues due to loss of vaccine potency due to poor temperature regulation of the storage units and unanticipated vaccine wastage en route, a common occurrence in conventional vaccine transportation methods. We introduce ALIVE, a low-cost Interactive Vaccine Storage Environment module. ALIVE provides an off-grid, self-sufficient solution for vaccine storage and transport, enabled by active cooling technology. ALIVE's innovation lies in its integration with the Internet of Things (IoT), allowing real-time monitoring and control. This IoT-enabled Application Programming Interface (API) features a data acquisition and environment parameter control system, managing oversight and decision-making. ALIVE's compact, lightweight design makes it adaptable to various logistical scenarios, while its versatility enables it to maintain both time-invariant and time-dependent thermophysical and spatial parameters. Operationalized through a PID algorithm, ALIVE ensures precise temperature control within the vaccine chamber. Its dynamic features, such as remote actuation and data sharing, demonstrate its adaptability and potential applications. Despite the frugal nature of development, the system promises significant benefits, including reduced vaccine loss and remote monitoring advantages. Collaborations with healthcare partners seek to further enhance ALIVE's readiness and expand its impact. ALIVE revolutionizes vaccine logistics, offering scalable, cost-effective solutions for bridging accessibility gaps in challenging distribution scenarios. Its adaptability positions it for widespread application, from last-mile vaccine delivery to environment-controlled supply chains and beyond.
http://w3id.org/mlsea/pwc/scientificWork/ALTO%3A%20An%20Efficient%20Network%20Orchestrator%20for%20Compound%20AI%20Systems                                                                                  ALTO: An Efficient Network Orchestrator for Compound AI Systems                                                                                  We present ALTO, a network orchestrator for efficiently serving compound AI systems such as pipelines of language models. ALTO achieves high throughput and low latency by taking advantage of an optimization opportunity specific to generative language models: streaming intermediate outputs. As language models produce outputs token by token, ALTO exposes opportunities to stream intermediate outputs between stages when possible. We highlight two new challenges of correctness and load balancing which emerge when streaming intermediate data across distributed pipeline stage instances. We also motivate the need for an aggregation-aware routing interface and distributed prompt-aware scheduling to address these challenges. We demonstrate the impact of ALTO's partial output streaming on a complex chatbot verification pipeline, increasing throughput by up to 3x for a fixed latency target of 4 seconds / request while also reducing tail latency by 1.8x compared to a baseline serving approach.
http://w3id.org/mlsea/pwc/scientificWork/AM-SORT%3A%20Adaptable%20Motion%20Predictor%20with%20Historical%20Trajectory%20Embedding%20for%20Multi-Object%20Tracking                                                                                  AM-SORT: Adaptable Motion Predictor with Historical Trajectory Embedding for Multi-Object Tracking                                                                                  Many multi-object tracking (MOT) approaches, which employ the Kalman Filter as a motion predictor, assume constant velocity and Gaussian-distributed filtering noises. These assumptions render the Kalman Filter-based trackers effective in linear motion scenarios. However, these linear assumptions serve as a key limitation when estimating future object locations within scenarios involving non-linear motion and occlusions. To address this issue, we propose a motion-based MOT approach with an adaptable motion predictor, called AM-SORT, which adapts to estimate non-linear uncertainties. AM-SORT is a novel extension of the SORT-series trackers that supersedes the Kalman Filter with the transformer architecture as a motion predictor. We introduce a historical trajectory embedding that empowers the transformer to extract spatio-temporal features from a sequence of bounding boxes. AM-SORT achieves competitive performance compared to state-of-the-art trackers on DanceTrack, with 56.3 IDF1 and 55.6 HOTA. We conduct extensive experiments to demonstrate the effectiveness of our method in predicting non-linear movement under occlusions.
http://w3id.org/mlsea/pwc/scientificWork/AMP%3A%20Autoregressive%20Motion%20Prediction%20Revisited%20with%20Next%20Token%20Prediction%20for%20Autonomous%20Driving                                                                                  AMP: Autoregressive Motion Prediction Revisited with Next Token Prediction for Autonomous Driving                                                                                  As an essential task in autonomous driving (AD), motion prediction aims to predict the future states of surround objects for navigation. One natural solution is to estimate the position of other agents in a step-by-step manner where each predicted time-step is conditioned on both observed time-steps and previously predicted time-steps, i.e., autoregressive prediction. Pioneering works like SocialLSTM and MFP design their decoders based on this intuition. However, almost all state-of-the-art works assume that all predicted time-steps are independent conditioned on observed time-steps, where they use a single linear layer to generate positions of all time-steps simultaneously. They dominate most motion prediction leaderboards due to the simplicity of training MLPs compared to autoregressive networks. In this paper, we introduce the GPT style next token prediction into motion forecasting. In this way, the input and output could be represented in a unified space and thus the autoregressive prediction becomes more feasible. However, different from language data which is composed of homogeneous units -words, the elements in the driving scene could have complex spatial-temporal and semantic relations. To this end, we propose to adopt three factorized attention modules with different neighbors for information aggregation and different position encoding styles to capture their relations, e.g., encoding the transformation between coordinate systems for spatial relativity while adopting RoPE for temporal relativity. Empirically, by equipping with the aforementioned tailored designs, the proposed method achieves state-of-the-art performance in the Waymo Open Motion and Waymo Interaction datasets. Notably, AMP outperforms other recent autoregressive motion prediction methods: MotionLM and StateTransformer, which demonstrates the effectiveness of the proposed designs.
http://w3id.org/mlsea/pwc/scientificWork/ANALYTiC%3A%20Understanding%20Decision%20Boundaries%20and%20Dimensionality%20Reduction%20in%20Machine%20Learning                                                                                  ANALYTiC: Understanding Decision Boundaries and Dimensionality Reduction in Machine Learning                                                                                  The advent of compact, handheld devices has given us a pool of tracked movement data that could be used to infer trends and patterns that can be made to use. With this flooding of various trajectory data of animals, humans, vehicles, etc., the idea of ANALYTiC originated, using active learning to infer semantic annotations from the trajectories by learning from sets of labeled data. This study explores the application of dimensionality reduction and decision boundaries in combination with the already present active learning, highlighting patterns and clusters in data. We test these features with three different trajectory datasets with objective of exploiting the the already labeled data and enhance their interpretability. Our experimental analysis exemplifies the potential of these combined methodologies in improving the efficiency and accuracy of trajectory labeling. This study serves as a stepping-stone towards the broader integration of machine learning and visual methods in context of movement data analysis.
http://w3id.org/mlsea/pwc/scientificWork/ANAct%3A%20Adaptive%20Normalization%20for%20Activation%20Functions                                                                                  ANAct: Adaptive Normalization for Activation Functions                                                                                  In this paper, we investigate the negative effect of activation functions on forward and backward propagation and how to counteract this effect. First, We examine how activation functions affect the forward and backward propagation of neural networks and derive a general form for gradient variance that extends the previous work in this area. We try to use mini-batch statistics to dynamically update the normalization factor to ensure the normalization property throughout the training process, rather than only accounting for the state of the neural network after weight initialization. Second, we propose ANAct, a method that normalizes activation functions to maintain consistent gradient variance across layers and demonstrate its effectiveness through experiments. We observe that the convergence rate is roughly related to the normalization property. We compare ANAct with several common activation functions on CNNs and residual networks and show that ANAct consistently improves their performance. For instance, normalized Swish achieves 1.4 % higher top-1 accuracy than vanilla Swish on ResNet50 with the Tiny ImageNet dataset and more than 1.2 % higher with CIFAR-100.
http://w3id.org/mlsea/pwc/scientificWork/ANGO%3A%20A%20Next-Level%20Evaluation%20Benchmark%20For%20Generation-Oriented%20Language%20Models%20In%20Chinese%20Domain                                                                                  ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain                                                                                  Recently, various Large Language Models (LLMs) evaluation datasets have emerged, but most of them have issues with distorted rankings and difficulty in model capabilities analysis. Addressing these concerns, this paper introduces ANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes Keypoint categorization standard for the first time, each question in ANGO can correspond to multiple keypoints, effectively enhancing interpretability of evaluation results. Base on performance of real humans, we build a quantifiable question difficulty standard and divide ANGO questions into 9 difficulty levels, which provide more precise guidance for model training. To minimize data leakage impact and fully leverage ANGO's innovative features, we have engineered exclusive sampling strategies and a new evaluation framework that support swift testset iteration. Our experiments demonstrate that ANGO poses a stronger challenge to models and reveals more details in evaluation result compared to existing benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/ANN-based%20position%20and%20speed%20sensorless%20estimation%20for%20BLDC%20motors                                                                                  ANN-based position and speed sensorless estimation for BLDC motors                                                                                  BLDC motor applications require precise position and speed measurements, traditionally obtained with sensors. This article presents a method for estimating those measurements without position sensors using terminal phase voltages with attenuated spurious, acquired with a FPGA that also operates a PWM-controlled inverter. Voltages are labelled with electrical and virtual rotor states using an encoder that provides training and testing data for two three-layer ANNs with perceptron-based cascade topology. The first ANN estimates the position from features of voltages with incremental timestamps, and the second ANN estimates the speed from features of position differentials considering timestamps in an acquisition window. Sensor-based training and sensorless testing at 125 to 1,500 rpm with a loaded 8-pole-pair motor obtained absolute errors of 0.8 electrical degrees and 22 rpm. Results conclude that the overall position estimation significantly improved conventional and advanced methods, and the speed estimation slightly improved conventional methods, but was worse than in advanced ones.
http://w3id.org/mlsea/pwc/scientificWork/API%20Pack%3A%20A%20Massive%20Multilingual%20Dataset%20for%20API%20Call%20Generation                                                                                  API Pack: A Massive Multilingual Dataset for API Call Generation                                                                                  We introduce API Pack, a multilingual dataset featuring over one million instruction-API call pairs aimed at advancing large language models' API call generation capabilities. Through experiments, we demonstrate API Pack's efficacy in enhancing models for this specialized task while maintaining their overall proficiency at general coding. Fine-tuning CodeLlama-13B on just 20,000 Python instances yields over 10% and 5% higher accuracy than GPT-3.5 and GPT-4 respectively in generating unseen API calls. Scaling to 100k examples improves generalization to new APIs not seen during training. In addition, cross-lingual API call generation is achieved without needing extensive data per language. The dataset, fine-tuned models, and overall code base are publicly available at https://github.com/zguo0525/API-Pack.
http://w3id.org/mlsea/pwc/scientificWork/ARED%3A%20Argentina%20Real%20Estate%20Dataset                                                                                  ARED: Argentina Real Estate Dataset                                                                                  The Argentinian real estate market presents a unique case study characterized by its unstable and rapidly shifting macroeconomic circumstances over the past decades. Despite the existence of a few datasets for price prediction, there is a lack of mixed modality datasets specifically focused on Argentina. In this paper, the first edition of ARED is introduced. A comprehensive real estate price prediction dataset series, designed for the Argentinian market. This edition contains information solely for Jan-Feb 2024. It was found that despite the short time range captured by this zeroth edition (44 days), time dependent phenomena has been occurring mostly on a market level (market as a whole). Nevertheless future editions of this dataset, will most likely contain historical data. Each listing in ARED comprises descriptive features, and variable-length sets of images.
http://w3id.org/mlsea/pwc/scientificWork/ARIA%3A%20On%20the%20Interaction%20Between%20Architectures%2C%20Initialization%20and%20Aggregation%20Methods%20for%20Federated%20Visual%20Classification                                                                                  ARIA: On the Interaction Between Architectures, Initialization and Aggregation Methods for Federated Visual Classification                                                                                  Federated Learning (FL) is a collaborative training paradigm that allows for privacy-preserving learning of cross-institutional models by eliminating the exchange of sensitive data and instead relying on the exchange of model parameters between the clients and a server. Despite individual studies on how client models are aggregated, and, more recently, on the benefits of ImageNet pre-training, there is a lack of understanding of the effect the architecture chosen for the federation has, and of how the aforementioned elements interconnect. To this end, we conduct the first joint ARchitecture-Initialization-Aggregation study and benchmark ARIAs across a range of medical image classification tasks. We find that, contrary to current practices, ARIA elements have to be chosen together to achieve the best possible performance. Our results also shed light on good choices for each element depending on the task, the effect of normalisation layers, and the utility of SSL pre-training, pointing to potential directions for designing FL-specific architectures and training pipelines.
http://w3id.org/mlsea/pwc/scientificWork/ARIN%3A%20Adaptive%20Resampling%20and%20Instance%20Normalization%20for%20Robust%20Blind%20Inpainting%20of%20Dunhuang%20Cave%20Paintings                                                                                  ARIN: Adaptive Resampling and Instance Normalization for Robust Blind Inpainting of Dunhuang Cave Paintings                                                                                  Image enhancement algorithms are very useful for real world computer vision tasks where image resolution is often physically limited by the sensor size. While state-of-the-art deep neural networks show impressive results for image enhancement, they often struggle to enhance real-world images. In this work, we tackle a real-world setting: inpainting of images from Dunhuang caves. The Dunhuang dataset consists of murals, half of which suffer from corrosion and aging. These murals feature a range of rich content, such as Buddha statues, bodhisattvas, sponsors, architecture, dance, music, and decorative patterns designed by different artists spanning ten centuries, which makes manual restoration challenging. We modify two different existing methods (CAR, HINet) that are based upon state-of-the-art (SOTA) super resolution and deblurring networks. We show that those can successfully inpaint and enhance these deteriorated cave paintings. We further show that a novel combination of CAR and HINet, resulting in our proposed inpainting network (ARIN), is very robust to external noise, especially Gaussian noise. To this end, we present a quantitative and qualitative comparison of our proposed approach with existing SOTA networks and winners of the Dunhuang challenge. One of the proposed methods HINet) represents the new state of the art and outperforms the 1st place of the Dunhuang Challenge, while our combination ARIN, which is robust to noise, is comparable to the 1st place. We also present and discuss qualitative results showing the impact of our method for inpainting on Dunhuang cave images.
http://w3id.org/mlsea/pwc/scientificWork/ARL2%3A%20Aligning%20Retrievers%20for%20Black-box%20Large%20Language%20Models%20via%20Self-guided%20Adaptive%20Relevance%20Labeling                                                                                  ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling                                                                                  Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with LLMs due to their separate training processes and the black-box nature of LLMs. To address this challenge, we propose ARL2, a retriever learning technique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and score relevant evidence, enabling learning the retriever from robust LLM supervision. Furthermore, ARL2 uses an adaptive self-training strategy for curating high-quality and diverse relevance data, which can effectively reduce the annotation cost. Extensive experiments demonstrate the effectiveness of ARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared to the state-of-the-art methods. Additionally, ARL2 exhibits robust transfer learning capabilities and strong zero-shot generalization abilities. Our code will be published at url{https://github.com/zhanglingxi-cs/ARL2}.
http://w3id.org/mlsea/pwc/scientificWork/ARNN%3A%20Attentive%20Recurrent%20Neural%20Network%20for%20Multi-channel%20EEG%20Signals%20to%20Identify%20Epileptic%20Seizures                                                                                  ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals to Identify Epileptic Seizures                                                                                  We proposed an Attentive Recurrent Neural Network (ARNN), which recurrently applies attention layers along a sequence and has linear complexity with respect to the sequence length. The proposed model operates on multi-channel EEG signals rather than single channel signals and leverages parallel computation. In this cell, the attention layer is a computational unit that efficiently applies self-attention and cross-attention mechanisms to compute a recurrent function over a wide number of state vectors and input signals. Our architecture is inspired in part by the attention layer and long short-term memory (LSTM) cells, and it uses long-short style gates, but it scales this typical cell up by several orders to parallelize for multi-channel EEG signals. It inherits the advantages of attention layers and LSTM gate while avoiding their respective drawbacks. We evaluated the model effectiveness through extensive experiments with heterogeneous datasets, including the CHB-MIT and UPenn and Mayos Clinic, CHB-MIT datasets. The empirical findings suggest that the ARNN model outperforms baseline methods such as LSTM, Vision Transformer (ViT), Compact Convolution Transformer (CCT), and R-Transformer (RT), showcasing superior performance and faster processing capabilities across a wide range of tasks. The code has been made publicly accessible at url{https://github.com/Salim-Lysiun/ARNN}.
http://w3id.org/mlsea/pwc/scientificWork/AROT-COV23%3A%20A%20Dataset%20of%20500K%20Original%20Arabic%20Tweets%20on%20COVID-19                                                                                  AROT-COV23: A Dataset of 500K Original Arabic Tweets on COVID-19                                                                                  This paper presents a dataset called AROT-COV23 (ARabic Original Tweets on COVID-19 as of 2023) containing about 500,000 original Arabic COVID-19-related tweets from January 2020 to January 2023. The dataset has been analyzed using a corpus-based approach to identify common themes and trends in the data and gain insights into the ways in which Arabic Twitter users have discussed the pandemic. The results of the analysis are also presented and discussed in terms of their implications for the field of Natural Language Processing (NLP) in Africa and for understanding the role of Twitter in the spread of COVID-19-related information in the region.
http://w3id.org/mlsea/pwc/scientificWork/ASEM%3A%20Enhancing%20Empathy%20in%20Chatbot%20through%20Attention-based%20Sentiment%20and%20Emotion%20Modeling                                                                                  ASEM: Enhancing Empathy in Chatbot through Attention-based Sentiment and Emotion Modeling                                                                                  Effective feature representations play a critical role in enhancing the performance of text generation models that rely on deep neural networks. However, current approaches suffer from several drawbacks, such as the inability to capture the deep semantics of language and sensitivity to minor input variations, resulting in significant changes in the generated text. In this paper, we present a novel solution to these challenges by employing a mixture of experts, multiple encoders, to offer distinct perspectives on the emotional state of the user's utterance while simultaneously enhancing performance. We propose an end-to-end model architecture called ASEM that performs emotion analysis on top of sentiment analysis for open-domain chatbots, enabling the generation of empathetic responses that are fluent and relevant. In contrast to traditional attention mechanisms, the proposed model employs a specialized attention strategy that uniquely zeroes in on sentiment and emotion nuances within the user's utterance. This ensures the generation of context-rich representations tailored to the underlying emotional tone and sentiment intricacies of the text. Our approach outperforms existing methods for generating empathetic embeddings, providing empathetic and diverse responses. The performance of our proposed model significantly exceeds that of existing models, enhancing emotion detection accuracy by 6.2% and lexical diversity by 1.4%.
http://w3id.org/mlsea/pwc/scientificWork/AV-GAN%3A%20Attention-Based%20Varifocal%20Generative%20Adversarial%20Network%20for%20Uneven%20Medical%20Image%20Translation                                                                                  AV-GAN: Attention-Based Varifocal Generative Adversarial Network for Uneven Medical Image Translation                                                                                  Different types of staining highlight different structures in organs, thereby assisting in diagnosis. However, due to the impossibility of repeated staining, we cannot obtain different types of stained slides of the same tissue area. Translating the slide that is easy to obtain (e.g., H&E) to slides of staining types difficult to obtain (e.g., MT, PAS) is a promising way to solve this problem. However, some regions are closely connected to other regions, and to maintain this connection, they often have complex structures and are difficult to translate, which may lead to wrong translations. In this paper, we propose the Attention-Based Varifocal Generative Adversarial Network (AV-GAN), which solves multiple problems in pathologic image translation tasks, such as uneven translation difficulty in different regions, mutual interference of multiple resolution information, and nuclear deformation. Specifically, we develop an Attention-Based Key Region Selection Module, which can attend to regions with higher translation difficulty. We then develop a Varifocal Module to translate these regions at multiple resolutions. Experimental results show that our proposed AV-GAN outperforms existing image translation methods with two virtual kidney tissue staining tasks and improves FID values by 15.9 and 4.16 respectively in the H&E-MT and H&E-PAS tasks.
http://w3id.org/mlsea/pwc/scientificWork/AVI-Talking%3A%20Learning%20Audio-Visual%20Instructions%20for%20Expressive%203D%20Talking%20Face%20Generation                                                                                  AVI-Talking: Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation                                                                                  While considerable progress has been made in achieving accurate lip synchronization for 3D speech-driven talking face generation, the task of incorporating expressive facial detail synthesis aligned with the speaker's speaking status remains challenging. Our goal is to directly leverage the inherent style information conveyed by human speech for generating an expressive talking face that aligns with the speaking status. In this paper, we propose AVI-Talking, an Audio-Visual Instruction system for expressive Talking face generation. This system harnesses the robust contextual reasoning and hallucination capability offered by Large Language Models (LLMs) to instruct the realistic synthesis of 3D talking faces. Instead of directly learning facial movements from human speech, our two-stage strategy involves the LLMs first comprehending audio information and generating instructions implying expressive facial details seamlessly corresponding to the speech. Subsequently, a diffusion-based generative network executes these instructions. This two-stage process, coupled with the incorporation of LLMs, enhances model interpretability and provides users with flexibility to comprehend instructions and specify desired operations or modifications. Extensive experiments showcase the effectiveness of our approach in producing vivid talking faces with expressive facial movements and consistent emotional status.
http://w3id.org/mlsea/pwc/scientificWork/AXOLOTL%3A%20Fairness%20through%20Assisted%20Self-Debiasing%20of%20Large%20Language%20Model%20Outputs                                                                                  AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs                                                                                  Pre-trained Large Language Models (LLMs) have significantly advanced natural language processing capabilities but are susceptible to biases present in their training data, leading to unfair outcomes in various applications. While numerous strategies have been proposed to mitigate bias, they often require extensive computational resources and may compromise model performance. In this work, we introduce AXOLOTL, a novel post-processing framework, which operates agnostically across tasks and models, leveraging public APIs to interact with LLMs without direct access to internal parameters. Through a three-step process resembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions, and guides the model to self-debias its outputs. This approach minimizes computational costs and preserves model performance, making AXOLOTL a promising tool for debiasing LLM outputs with broad applicability and ease of use.
http://w3id.org/mlsea/pwc/scientificWork/Absolute%20convergence%20and%20error%20thresholds%20in%20non-active%20adaptive%20sampling                                                                                  Absolute convergence and error thresholds in non-active adaptive sampling                                                                                  Non-active adaptive sampling is a way of building machine learning models from a training data base which are supposed to dynamically and automatically derive guaranteed sample size. In this context and regardless of the strategy used in both scheduling and generating of weak predictors, a proposal for calculating absolute convergence and error thresholds is described. We not only make it possible to establish when the quality of the model no longer increases, but also supplies a proximity condition to estimate in absolute terms how close it is to achieving such a goal, thus supporting decision making for fine-tuning learning parameters in model selection. The technique proves its correctness and completeness with respect to our working hypotheses, in addition to strengthening the robustness of the sampling scheme. Tests meet our expectations and illustrate the proposal in the domain of natural language processing, taking the generation of part-of-speech taggers as case study.
http://w3id.org/mlsea/pwc/scientificWork/Abstract%20Weighted%20Based%20Gradual%20Semantics%20in%20Argumentation%20Theory                                                                                  Abstract Weighted Based Gradual Semantics in Argumentation Theory                                                                                  Weighted gradual semantics provide an acceptability degree to each argument representing the strength of the argument, computed based on factors including background evidence for the argument, and taking into account interactions between this argument and others. We introduce four important problems linking gradual semantics and acceptability degrees. First, we reexamine the inverse problem, seeking to identify the argument weights of the argumentation framework which lead to a specific final acceptability degree. Second, we ask whether the function mapping between argument weights and acceptability degrees is injective or a homeomorphism onto its image. Third, we ask whether argument weights can be found when preferences, rather than acceptability degrees for arguments are considered. Fourth, we consider the topology of the space of valid acceptability degrees, asking whether gaps exist in this space. While different gradual semantics have been proposed in the literature, in this paper, we identify a large family of weighted gradual semantics, called abstract weighted based gradual semantics. These generalise many of the existing semantics while maintaining desirable properties such as convergence to a unique fixed point. We also show that a sub-family of the weighted gradual semantics, called abstract weighted (Lp,lambda,mu,A)-based gradual semantics and which include well-known semantics, solve all four of the aforementioned problems.
http://w3id.org/mlsea/pwc/scientificWork/AcME-AD%3A%20Accelerated%20Model%20Explanations%20for%20Anomaly%20Detection                                                                                  AcME-AD: Accelerated Model Explanations for Anomaly Detection                                                                                  Pursuing fast and robust interpretability in Anomaly Detection is crucial, especially due to its significance in practical applications. Traditional Anomaly Detection methods excel in outlier identification but are often black-boxes, providing scant insights into their decision-making process. This lack of transparency compromises their reliability and hampers their adoption in scenarios where comprehending the reasons behind anomaly detection is vital. At the same time, getting explanations quickly is paramount in practical scenarios. To bridge this gap, we present AcME-AD, a novel approach rooted in Explainable Artificial Intelligence principles, designed to clarify Anomaly Detection models for tabular data. AcME-AD transcends the constraints of model-specific or resource-heavy explainability techniques by delivering a model-agnostic, efficient solution for interoperability. It offers local feature importance scores and a what-if analysis tool, shedding light on the factors contributing to each anomaly, thus aiding root cause analysis and decision-making. This paper elucidates AcME-AD's foundation, its benefits over existing methods, and validates its effectiveness with tests on both synthetic and real datasets. AcME-AD's implementation and experiment replication code is accessible in a public repository.
http://w3id.org/mlsea/pwc/scientificWork/Accelerate%20adversarial%20training%20with%20loss%20guided%20propagation%20for%20robust%20image%20classification                                                                                  Accelerate adversarial training with loss guided propagation for robust image classification                                                                                  Adversarial training is effective to train robust image classification models. To improve the robustness, existing approaches often use many propagations to generate adversarial examples, which have high time consumption. In this work, we propose an efficient adversarial training method with loss guided propagation (ATLGP) to accelerate the adversarial training process. ATLGP takes the loss value of generated adversarial examples as guidance to control the number of propagations for each training instance at different training stages, which decreases the computation while keeping the strength of generated adversarial examples. In this way, our method can achieve comparable robustness with less time than traditional training methods. It also has good generalization ability and can be easily combined with other efficient training methods. We conduct comprehensive experiments on CIFAR10 and MNIST, the standard datasets for several benchmarks. The experimental results show that ATLGP reduces 30% to 60% training time compared with other baseline methods while achieving similar robustness against various adversarial attacks. The combination of ATLGP and ATTA (an efficient adversarial training method) achieves superior acceleration potential when robustness meets high requirements. The statistical propagation in different training stages and ablation studies prove the effectiveness of applying loss guided propagation for each training instance. The acceleration technique can more easily extend adversarial training methods to large-scale datasets and more diverse model architectures such as vision transformers.
http://w3id.org/mlsea/pwc/scientificWork/Accelerating%20Graph%20Neural%20Networks%20on%20Real%20Processing-In-Memory%20Systems                                                                                  Accelerating Graph Neural Networks on Real Processing-In-Memory Systems                                                                                  Graph Neural Networks (GNNs) are emerging ML models to analyze graph-structure data. Graph Neural Network (GNN) execution involves both compute-intensive and memory-intensive kernels, the latter dominates the total time, being significantly bottlenecked by data movement between memory and processors. Processing-In-Memory (PIM) systems can alleviate this data movement bottleneck by placing simple processors near or inside to memory arrays. In this work, we introduce PyGim, an efficient ML framework that accelerates GNNs on real PIM systems. We propose intelligent parallelization techniques for memory-intensive kernels of GNNs tailored for real PIM systems, and develop handy Python API for them. We provide hybrid GNN execution, in which the compute-intensive and memory-intensive kernels are executed in processor-centric and memory-centric computing systems, respectively, to match their algorithmic nature. We extensively evaluate PyGim on a real-world PIM system with 1992 PIM cores using emerging GNN models, and demonstrate that it outperforms its state-of-the-art CPU counterpart on Intel Xeon by on average 3.04x, and achieves higher resource utilization than CPU and GPU systems. Our work provides useful recommendations for software, system and hardware designers. PyGim will be open-sourced to enable the widespread use of PIM systems in GNNs.
http://w3id.org/mlsea/pwc/scientificWork/Accelerating%20Transformer%20Pre-Training%20with%202%3A4%20Sparsity                                                                                  Accelerating Transformer Pre-Training with 2:4 Sparsity                                                                                  Training large Transformers is slow, but recent innovations on GPU architecture gives us an advantage. NVIDIA Ampere GPUs can execute a fine-grained 2:4 sparse matrix multiplication twice as fast as its dense equivalent. In the light of this property, we comprehensively investigate the feasibility of accelerating feed-forward networks (FFNs) of Transformers in pre-training. First, we define a 'flip rate' to monitor the stability of a 2:4 training process. Utilizing this metric, we suggest two techniques to preserve accuracy: to modify the sparse-refined straight-through estimator by applying the mask decay term on gradients, and to enhance the model's quality by a simple yet effective dense fine-tuning procedure near the end of pre-training. Besides, we devise two effective techniques to practically accelerate training: to calculate transposable 2:4 mask by convolution, and to accelerate gated activation functions by reducing GPU L2 cache miss. Experiments show that a combination of our methods reaches the best performance on multiple Transformers among different 2:4 training methods, while actual acceleration can be observed on different shapes of Transformer block.
http://w3id.org/mlsea/pwc/scientificWork/Accelerating%20hyperbolic%20t-SNE                                                                                  Accelerating hyperbolic t-SNE                                                                                  The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, Euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This paper introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We compare our approach with existing methods and demonstrate that it computes embeddings of similar quality in significantly less time. Implementation and scripts for the experiments can be found at https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.
http://w3id.org/mlsea/pwc/scientificWork/Accelerating%20materials%20discovery%20for%20polymer%20solar%20cells%3A%20Data-driven%20insights%20enabled%20by%20natural%20language%20processing                                                                                  Accelerating materials discovery for polymer solar cells: Data-driven insights enabled by natural language processing                                                                                  We present a natural language processing pipeline that was used to extract polymer solar cell property data from the literature and simulate various active learning strategies. While data-driven methods have been well established to discover novel materials faster than Edisonian trial-and-error approaches, their benefits have not been quantified. Our approach demonstrates a potential reduction in discovery time by approximately 75 %, equivalent to a 15 year acceleration in material innovation. Our pipeline enables us to extract data from more than 3300 papers which is ~5 times larger than similar data sets reported by others. We also trained machine learning models to predict the power conversion efficiency and used our model to identify promising donor-acceptor combinations that are as yet unreported. We thus demonstrate a workflow that goes from published literature to extracted material property data which in turn is used to obtain data-driven insights. Our insights include active learning strategies that can simultaneously optimize the material system and train strong predictive models of material properties. This work provides a valuable framework for research in material science.
http://w3id.org/mlsea/pwc/scientificWork/AccentFold%3A%20A%20Journey%20through%20African%20Accents%20for%20Zero-Shot%20ASR%20Adaptation%20to%20Target%20Accents                                                                                  AccentFold: A Journey through African Accents for Zero-Shot ASR Adaptation to Target Accents                                                                                  Despite advancements in speech recognition, accented speech remains challenging. While previous approaches have focused on modeling techniques or creating accented speech datasets, gathering sufficient data for the multitude of accents, particularly in the African context, remains impractical due to their sheer diversity and associated budget constraints. To address these challenges, we propose AccentFold, a method that exploits spatial relationships between learned accent embeddings to improve downstream Automatic Speech Recognition (ASR). Our exploratory analysis of speech embeddings representing 100+ African accents reveals interesting spatial accent relationships highlighting geographic and genealogical similarities, capturing consistent phonological, and morphological regularities, all learned empirically from speech. Furthermore, we discover accent relationships previously uncharacterized by the Ethnologue. Through empirical evaluation, we demonstrate the effectiveness of AccentFold by showing that, for out-of-distribution (OOD) accents, sampling accent subsets for training based on AccentFold information outperforms strong baselines a relative WER improvement of 4.6%. AccentFold presents a promising approach for improving ASR performance on accented speech, particularly in the context of African accents, where data scarcity and budget constraints pose significant challenges. Our findings emphasize the potential of leveraging linguistic relationships to improve zero-shot ASR adaptation to target accents.
http://w3id.org/mlsea/pwc/scientificWork/Accuracy-Preserving%20Calibration%20via%20Statistical%20Modeling%20on%20Probability%20Simplex                                                                                  Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex                                                                                  Classification models based on deep neural networks (DNNs) must be calibrated to measure the reliability of predictions. Some recent calibration methods have employed a probabilistic model on the probability simplex. However, these calibration methods cannot preserve the accuracy of pre-trained models, even those with a high classification accuracy. We propose an accuracy-preserving calibration method using the Concrete distribution as the probabilistic model on the probability simplex. We theoretically prove that a DNN model trained on cross-entropy loss has optimality as the parameter of the Concrete distribution. We also propose an efficient method that synthetically generates samples for training probabilistic models on the probability simplex. We demonstrate that the proposed method can outperform previous methods in accuracy-preserving calibration tasks using benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/Accurate%20and%20Data-Efficient%20Micro-XRD%20Phase%20Identification%20Using%20Multi-Task%20Learning%3A%20Application%20to%20Hydrothermal%20Fluids                                                                                  Accurate and Data-Efficient Micro-XRD Phase Identification Using Multi-Task Learning: Application to Hydrothermal Fluids                                                                                  Traditional analysis of highly distorted micro-X-ray diffraction ({ mu}-XRD) patterns from hydrothermal fluid environments is a time-consuming process, often requiring substantial data preprocessing and labeled experimental data. This study demonstrates the potential of deep learning with a multitask learning (MTL) architecture to overcome these limitations. We trained MTL models to identify phase information in { mu}-XRD patterns, minimizing the need for labeled experimental data and masking preprocessing steps. Notably, MTL models showed superior accuracy compared to binary classification CNNs. Additionally, introducing a tailored cross-entropy loss function improved MTL model performance. Most significantly, MTL models tuned to analyze raw and unmasked XRD patterns achieved close performance to models analyzing preprocessed data, with minimal accuracy differences. This work indicates that advanced deep learning architectures like MTL can automate arduous data handling tasks, streamline the analysis of distorted XRD patterns, and reduce the reliance on labor-intensive experimental datasets.
http://w3id.org/mlsea/pwc/scientificWork/Accurate%20and%20Well-Calibrated%20ICD%20Code%20Assignment%20Through%20Attention%20Over%20Diverse%20Label%20Embeddings                                                                                  Accurate and Well-Calibrated ICD Code Assignment Through Attention Over Diverse Label Embeddings                                                                                  Although the International Classification of Diseases (ICD) has been adopted worldwide, manually assigning ICD codes to clinical text is time-consuming, error-prone, and expensive, motivating the development of automated approaches. This paper describes a novel approach for automated ICD coding, combining several ideas from previous related work. We specifically employ a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, we explored either (a) adapting the base encoder model into a Longformer, or (b) dividing the text into chunks and processing each chunk independently. The representations produced by the encoder are combined with a label embedding mechanism that explores diverse ICD code synonyms. Experiments with different splits of the MIMIC-III dataset show that the proposed approach outperforms the current state-of-the-art models in ICD coding, with the label embeddings significantly contributing to the good performance. Our approach also leads to properly calibrated classification results, which can effectively inform downstream tasks such as quantification.
http://w3id.org/mlsea/pwc/scientificWork/Accurately%20Predicting%20Probabilities%20of%20Safety-Critical%20Rare%20Events%20for%20Intelligent%20Systems                                                                                  Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems                                                                                  Intelligent systems are increasingly integral to our daily lives, yet rare safety-critical events present significant latent threats to their practical deployment. Addressing this challenge hinges on accurately predicting the probability of safety-critical events occurring within a given time step from the current state, a metric we define as 'criticality'. The complexity of predicting criticality arises from the extreme data imbalance caused by rare events in high dimensional variables associated with the rare events, a challenge we refer to as the curse of rarity. Existing methods tend to be either overly conservative or prone to overlooking safety-critical events, thus struggling to achieve both high precision and recall rates, which severely limits their applicability. This study endeavors to develop a criticality prediction model that excels in both precision and recall rates for evaluating the criticality of safety-critical autonomous systems. We propose a multi-stage learning framework designed to progressively densify the dataset, mitigating the curse of rarity across stages. To validate our approach, we evaluate it in two cases: lunar lander and bipedal walker scenarios. The results demonstrate that our method surpasses traditional approaches, providing a more accurate and dependable assessment of criticality in intelligent systems.
http://w3id.org/mlsea/pwc/scientificWork/ActFormer%3A%20Scalable%20Collaborative%20Perception%20via%20Active%20Queries                                                                                  ActFormer: Scalable Collaborative Perception via Active Queries                                                                                  Collaborative perception leverages rich visual observations from multiple robots to extend a single robot's perception ability beyond its field of view. Many prior works receive messages broadcast from all collaborators, leading to a scalability challenge when dealing with a large number of robots and sensors. In this work, we aim to address textit{scalable camera-based collaborative perception} with a Transformer-based architecture. Our key idea is to enable a single robot to intelligently discern the relevance of the collaborators and their associated cameras according to a learned spatial prior. This proactive understanding of the visual features' relevance does not require the transmission of the features themselves, enhancing both communication and computation efficiency. Specifically, we present ActFormer, a Transformer that learns bird's eye view (BEV) representations by using predefined BEV queries to interact with multi-robot multi-camera inputs. Each BEV query can actively select relevant cameras for information aggregation based on pose information, instead of interacting with all cameras indiscriminately. Experiments on the V2X-Sim dataset demonstrate that ActFormer improves the detection performance from 29.89% to 45.15% in terms of AP@0.7 with about 50% fewer queries, showcasing the effectiveness of ActFormer in multi-agent collaborative 3D object detection.
http://w3id.org/mlsea/pwc/scientificWork/ActionHub%3A%20A%20Large-scale%20Action%20Video%20Description%20Dataset%20for%20Zero-shot%20Action%20Recognition                                                                                  ActionHub: A Large-scale Action Video Description Dataset for Zero-shot Action Recognition                                                                                  Zero-shot action recognition (ZSAR) aims to learn an alignment model between videos and class descriptions of seen actions that is transferable to unseen actions. The text queries (class descriptions) used in existing ZSAR works, however, are often short action names that fail to capture the rich semantics in the videos, leading to misalignment. With the intuition that video content descriptions (e.g., video captions) can provide rich contextual information of visual concepts in videos, we propose to utilize human annotated video descriptions to enrich the semantics of the class descriptions of each action. However, all existing action video description datasets are limited in terms of the number of actions, the semantics of video descriptions, etc. To this end, we collect a large-scale action video descriptions dataset named ActionHub, which covers a total of 1,211 common actions and provides 3.6 million action video descriptions. With the proposed ActionHub dataset, we further propose a novel Cross-modality and Cross-action Modeling (CoCo) framework for ZSAR, which consists of a Dual Cross-modality Alignment module and a Cross-action Invariance Mining module. Specifically, the Dual Cross-modality Alignment module utilizes both action labels and video descriptions from ActionHub to obtain rich class semantic features for feature alignment. The Cross-action Invariance Mining module exploits a cycle-reconstruction process between the class semantic feature spaces of seen actions and unseen actions, aiming to guide the model to learn cross-action invariant representations. Extensive experimental results demonstrate that our CoCo framework significantly outperforms the state-of-the-art on three popular ZSAR benchmarks (i.e., Kinetics-ZSAR, UCF101 and HMDB51) under two different learning protocols in ZSAR. We will release our code, models, and the proposed ActionHub dataset.
http://w3id.org/mlsea/pwc/scientificWork/Activation%20Steering%20for%20Robust%20Type%20Prediction%20in%20CodeLLMs                                                                                  Activation Steering for Robust Type Prediction in CodeLLMs                                                                                  Contemporary LLMs pretrained on code are capable of succeeding at a wide variety of programming tasks. However, their performance is very sensitive to syntactic features, such as the names of variables and types, the structure of code, and presence of type hints. We contribute an inference-time technique to make CodeLLMs more robust to syntactic distractors that are semantically irrelevant. Our methodology relies on activation steering, which involves editing internal model activations to steer the model towards the correct prediction. We contribute a novel way to construct steering vectors by taking inspiration from mutation testing, which constructs minimal semantics-breaking code edits. In contrast, we construct steering vectors from semantics-preserving code edits. We apply our approach to the task of type prediction for the gradually typed languages Python and TypeScript. This approach corrects up to 90% of type mispredictions. Finally, we show that steering vectors calculated from Python activations reliably correct type mispredictions in TypeScript, and vice versa. This result suggests that LLMs may be learning to transfer knowledge of types across programming languages.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Causal%20Learning%20for%20Decoding%20Chemical%20Complexities%20with%20Targeted%20Interventions                                                                                  Active Causal Learning for Decoding Chemical Complexities with Targeted Interventions                                                                                  Predicting and enhancing inherent properties based on molecular structures is paramount to design tasks in medicine, materials science, and environmental management. Most of the current machine learning and deep learning approaches have become standard for predictions, but they face challenges when applied across different datasets due to reliance on correlations between molecular representation and target properties. These approaches typically depend on large datasets to capture the diversity within the chemical space, facilitating a more accurate approximation, interpolation, or extrapolation of the chemical behavior of molecules. In our research, we introduce an active learning approach that discerns underlying cause-effect relationships through strategic sampling with the use of a graph loss function. This method identifies the smallest subset of the dataset capable of encoding the most information representative of a much larger chemical space. The identified causal relations are then leveraged to conduct systematic interventions, optimizing the design task within a chemical space that the models have not encountered previously. While our implementation focused on the QM9 quantum-chemical dataset for a specific design task-finding molecules with a large dipole moment-our active causal learning approach, driven by intelligent sampling and interventions, holds potential for broader applications in molecular, materials design and discovery.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Continual%20Learning%3A%20On%20Balancing%20Knowledge%20Retention%20and%20Learnability                                                                                  Active Continual Learning: On Balancing Knowledge Retention and Learnability                                                                                  Acquiring new knowledge without forgetting what has been learned in a sequence of tasks is the central focus of continual learning (CL). While tasks arrive sequentially, the training data are often prepared and annotated independently, leading to the CL of incoming supervised learning tasks. This paper considers the under-explored problem of active continual learning (ACL) for a sequence of active learning (AL) tasks, where each incoming task includes a pool of unlabelled data and an annotation budget. We investigate the effectiveness and interplay between several AL and CL algorithms in the domain, class and task-incremental scenarios. Our experiments reveal the trade-off between two contrasting goals of not forgetting the old knowledge and the ability to quickly learn new knowledge in CL and AL, respectively. While conditioning the AL query strategy on the annotations collected for the previous tasks leads to improved task performance on the domain and task incremental learning, our proposed forgetting-learning profile suggests a gap in balancing the effect of AL and CL for the class-incremental scenario.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Learning%20of%20Dynamics%20Using%20Prior%20Domain%20Knowledge%20in%20the%20Sampling%20Process                                                                                  Active Learning of Dynamics Using Prior Domain Knowledge in the Sampling Process                                                                                  We present an active learning algorithm for learning dynamics that leverages side information by explicitly incorporating prior domain knowledge into the sampling process. Our proposed algorithm guides the exploration toward regions that demonstrate high empirical discrepancy between the observed data and an imperfect prior model of the dynamics derived from side information. Through numerical experiments, we demonstrate that this strategy explores regions of high discrepancy and accelerates learning while simultaneously reducing model uncertainty. We rigorously prove that our active learning algorithm yields a consistent estimate of the underlying dynamics by providing an explicit rate of convergence for the maximum predictive variance. We demonstrate the efficacy of our approach on an under-actuated pendulum system and on the half-cheetah MuJoCo environment.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Restoration%20of%20Lost%20Audio%20Signals%20Using%20Machine%20Learning%20and%20Latent%20Information                                                                                  Active Restoration of Lost Audio Signals Using Machine Learning and Latent Information                                                                                  Digital audio signal reconstruction of a lost or corrupt segment using deep learning algorithms has been explored intensively in recent years. Nevertheless, prior traditional methods with linear interpolation, phase coding and tone insertion techniques are still in vogue. However, we found no research work on reconstructing audio signals with the fusion of dithering, steganography, and machine learning regressors. Therefore, this paper proposes the combination of steganography, halftoning (dithering), and state-of-the-art shallow and deep learning methods. The results (including comparing the SPAIN, Autoregressive, deep learning-based, graph-based, and other methods) are evaluated with three different metrics. The observations from the results show that the proposed solution is effective and can enhance the reconstruction of audio signals performed by the side information (e.g., Latent representation) steganography provides. Moreover, this paper proposes a novel framework for reconstruction from heavily compressed embedded audio data using halftoning (i.e., dithering) and machine learning, which we termed the HCR (halftone-based compression and reconstruction). This work may trigger interest in optimising this approach and/or transferring it to different domains (i.e., image reconstruction). Compared to existing methods, we show improvement in the inpainting performance in terms of signal-to-noise ratio (SNR), the objective difference grade (ODG) and Hansen's audio quality metric. In particular, our proposed framework outperformed the learning-based methods (D2WGAN and SG) and the traditional statistical algorithms (e.g., SPAIN, TDC, WCP).
http://w3id.org/mlsea/pwc/scientificWork/Active%20Simultaneously%20Transmitting%20and%20Reflecting%20Surface%20Assisted%20NOMA%20Networks                                                                                  Active Simultaneously Transmitting and Reflecting Surface Assisted NOMA Networks                                                                                  The novel active simultaneously transmitting and reflecting surface (ASTARS) has recently received a lot of attention due to its capability to conquer the multiplicative fading loss and achieve full-space smart radio environments. This paper introduces the ASTARS to assist non-orthogonal multiple access (NOMA) communications, where the stochastic geometry theory is used to model the spatial positions of pairing users. We design the independent reflection/transmission phase-shift controllers of ASTARS to align the phases of cascaded channels at pairing users. We derive new closed-form and asymptotic expressions of the outage probability and ergodic data rate for ASTARS-NOMA networks in the presence of perfect/imperfect successive interference cancellation (pSIC). The diversity orders and multiplexing gains for ASTARS-NOMA are derived to provide more insights. Furthermore, the system throughputs of ASTARS-NOMA are investigated in both delay-tolerant and delay-limited transmission modes. The numerical results are presented and show that: 1) ASTARS-NOMA with pSIC outperforms ASTARS assisted-orthogonal multiple access (ASTARS-OMA) in terms of outage probability and ergodic data rate; 2) The outage probability of ASTARS-NOMA can be further reduced within a certain range by increasing the power amplification factors; 3) The system throughputs of ASTARS-NOMA are superior to that of ASTARS-OMA in both delay-limited and delay-tolerant transmission modes.
http://w3id.org/mlsea/pwc/scientificWork/Active%20Statistical%20Inference                                                                                  Active Statistical Inference                                                                                  Inspired by the concept of active learning, we propose active inference$ unicode{x2013}$a methodology for statistical inference with machine-learning-assisted data collection. Assuming a budget on the number of labels that can be collected, the methodology uses a machine learning model to identify which data points would be most beneficial to label, thus effectively utilizing the budget. It operates on a simple yet powerful intuition: prioritize the collection of labels for data points where the model exhibits uncertainty, and rely on the model's predictions where it is confident. Active inference constructs provably valid confidence intervals and hypothesis tests while leveraging any black-box machine learning model and handling any data distribution. The key point is that it achieves the same level of accuracy with far fewer samples than existing baselines relying on non-adaptively-collected data. This means that for the same number of collected samples, active inference enables smaller confidence intervals and more powerful p-values. We evaluate active inference on datasets from public opinion research, census analysis, and proteomics.
http://w3id.org/mlsea/pwc/scientificWork/Ada-LEval%3A%20Evaluating%20long-context%20LLMs%20with%20length-adaptable%20benchmarks                                                                                  Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks                                                                                  Recently, the large language model (LLM) community has shown increasing interest in enhancing LLMs' capability to handle extremely long documents. As various long-text techniques and model architectures emerge, the precise and detailed evaluation of models' long-text capabilities has become increasingly important. Existing long-text evaluation benchmarks, such as L-Eval and LongBench, construct long-text test sets based on open-source datasets, focusing mainly on QA and summarization tasks. These datasets include test samples of varying lengths (from 2k to 32k+) entangled together, making it challenging to assess model capabilities across different length ranges. Moreover, they do not cover the ultralong settings (100k+ tokens) that the latest LLMs claim to achieve. In this paper, we introduce Ada-LEval, a length-adaptable benchmark for evaluating the long-context understanding of LLMs. Ada-LEval includes two challenging subsets, TSort and BestAnswer, which enable a more reliable evaluation of LLMs' long context capabilities. These benchmarks support intricate manipulation of the length of test cases, and can easily produce text samples up to 128k tokens. We evaluate 4 state-of-the-art closed-source API models and 6 open-source models with Ada-LEval. The evaluation results demonstrate the limitations of current LLMs, especially in ultra-long-context settings. Our code is available at https://github.com/open-compass/Ada-LEval.
http://w3id.org/mlsea/pwc/scientificWork/AdaContour%3A%20Adaptive%20Contour%20Descriptor%20with%20Hierarchical%20Representation                                                                                  AdaContour: Adaptive Contour Descriptor with Hierarchical Representation                                                                                  Existing angle-based contour descriptors suffer from lossy representation for non-starconvex shapes. By and large, this is the result of the shape being registered with a single global inner center and a set of radii corresponding to a polar coordinate parameterization. In this paper, we propose AdaContour, an adaptive contour descriptor that uses multiple local representations to desirably characterize complex shapes. After hierarchically encoding object shapes in a training set and constructing a contour matrix of all subdivided regions, we compute a robust low-rank robust subspace and approximate each local contour by linearly combining the shared basis vectors to represent an object. Experiments show that AdaContour is able to represent shapes more accurately and robustly than other descriptors while retaining effectiveness. We validate AdaContour by integrating it into off-the-shelf detectors to enable instance segmentation which demonstrates faithful performance. The code is available at https://github.com/tding1/AdaContour.
http://w3id.org/mlsea/pwc/scientificWork/AdaDemo%3A%20Data-Efficient%20Demonstration%20Expansion%20for%20Generalist%20Robotic%20Agent                                                                                  AdaDemo: Data-Efficient Demonstration Expansion for Generalist Robotic Agent                                                                                  Encouraged by the remarkable achievements of language and vision foundation models, developing generalist robotic agents through imitation learning, using large demonstration datasets, has become a prominent area of interest in robot learning. The efficacy of imitation learning is heavily reliant on the quantity and quality of the demonstration datasets. In this study, we aim to scale up demonstrations in a data-efficient way to facilitate the learning of generalist robotic agents. We introduce AdaDemo (Adaptive Online Demonstration Expansion), a general framework designed to improve multi-task policy learning by actively and continually expanding the demonstration dataset. AdaDemo strategically collects new demonstrations to address the identified weakness in the existing policy, ensuring data efficiency is maximized. Through a comprehensive evaluation on a total of 22 tasks across two robotic manipulation benchmarks (RLBench and Adroit), we demonstrate AdaDemo's capability to progressively improve policy performance by guiding the generation of high-quality demonstration datasets in a data-efficient manner.
http://w3id.org/mlsea/pwc/scientificWork/AdaEmbed%3A%20Semi-supervised%20Domain%20Adaptation%20in%20the%20Embedding%20Space                                                                                  AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space                                                                                  Semi-supervised domain adaptation (SSDA) presents a critical hurdle in computer vision, especially given the frequent scarcity of labeled data in real-world settings. This scarcity often causes foundation models, trained on extensive datasets, to underperform when applied to new domains. AdaEmbed, our newly proposed methodology for SSDA, offers a promising solution to these challenges. Leveraging the potential of unlabeled data, AdaEmbed facilitates the transfer of knowledge from a labeled source domain to an unlabeled target domain by learning a shared embedding space. By generating accurate and uniform pseudo-labels based on the established embedding space, the model overcomes the limitations of conventional SSDA, thus enhancing performance significantly. Our method's effectiveness is validated through extensive experiments on benchmark datasets such as DomainNet, Office-Home, and VisDA-C, where AdaEmbed consistently outperforms all the baselines, setting a new state of the art for SSDA. With its straightforward implementation and high data efficiency, AdaEmbed stands out as a robust and pragmatic solution for real-world scenarios, where labeled data is scarce. To foster further research and application in this area, we are sharing the codebase of our unified framework for semi-supervised domain adaptation.
http://w3id.org/mlsea/pwc/scientificWork/AdaFish%3A%20Fast%20low-rank%20parameter-efficient%20fine-tuning%20by%20using%20second-order%20information                                                                                  AdaFish: Fast low-rank parameter-efficient fine-tuning by using second-order information                                                                                  Recent advancements in large-scale pretrained models have significantly improved performance across a variety of tasks in natural language processing and computer vision. However, the extensive number of parameters in these models necessitates substantial memory and computational resources for full training. To adapt these models for downstream tasks or specific application-oriented datasets, parameter-efficient fine-tuning methods leveraging pretrained parameters have gained considerable attention. However, it can still be time-consuming due to lots of parameters and epochs. In this work, we introduce AdaFish, an efficient algorithm of the second-order type designed to expedite the training process within low-rank decomposition-based fine-tuning frameworks. Our key observation is that the associated generalized Fisher information matrix is either low-rank or extremely small-scaled. Such a generalized Fisher information matrix is shown to be equivalent to the Hessian matrix. Moreover, we prove the global convergence of AdaFish, along with its iteration/oracle complexity. Numerical experiments show that our algorithm is quite competitive with the state-of-the-art AdamW method.
http://w3id.org/mlsea/pwc/scientificWork/AdaGossip%3A%20Adaptive%20Consensus%20Step-size%20for%20Decentralized%20Deep%20Learning%20with%20Communication%20Compression                                                                                  AdaGossip: Adaptive Consensus Step-size for Decentralized Deep Learning with Communication Compression                                                                                  Decentralized learning is crucial in supporting on-device learning over large distributed datasets, eliminating the need for a central server. However, the communication overhead remains a major bottleneck for the practical realization of such decentralized setups. To tackle this issue, several algorithms for decentralized training with compressed communication have been proposed in the literature. Most of these algorithms introduce an additional hyper-parameter referred to as consensus step-size which is tuned based on the compression ratio at the beginning of the training. In this work, we propose AdaGossip, a novel technique that adaptively adjusts the consensus step-size based on the compressed model differences between neighboring agents. We demonstrate the effectiveness of the proposed method through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, Imagenette, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves superior performance ($0-2 %$ improvement in test accuracy) compared to the current state-of-the-art method for decentralized learning with communication compression.
http://w3id.org/mlsea/pwc/scientificWork/AdaIR%3A%20Exploiting%20Underlying%20Similarities%20of%20Image%20Restoration%20Tasks%20with%20Adapters                                                                                  AdaIR: Exploiting Underlying Similarities of Image Restoration Tasks with Adapters                                                                                  Existing image restoration approaches typically employ extensive networks specifically trained for designated degradations. Despite being effective, such methods inevitably entail considerable storage costs and computational overheads due to the reliance on task-specific networks. In this work, we go beyond this well-established framework and exploit the inherent commonalities among image restoration tasks. The primary objective is to identify components that are shareable across restoration tasks and augment the shared components with modules specifically trained for individual tasks. Towards this goal, we propose AdaIR, a novel framework that enables low storage cost and efficient training without sacrificing performance. Specifically, a generic restoration network is first constructed through self-supervised pre-training using synthetic degradations. Subsequent to the pre-training phase, adapters are trained to adapt the pre-trained network to specific degradations. AdaIR requires solely the training of lightweight, task-specific modules, ensuring a more efficient storage and training regimen. We have conducted extensive experiments to validate the effectiveness of AdaIR and analyze the influence of the pre-training strategy on discovering shareable components. Extensive experimental results show that AdaIR achieves outstanding results on multi-task restoration while utilizing significantly fewer parameters (1.9 MB) and less training time (7 hours) for each restoration task. The source codes and trained models will be released.
http://w3id.org/mlsea/pwc/scientificWork/AdaTrans%3A%20Feature-wise%20and%20Sample-wise%20Adaptive%20Transfer%20Learning%20for%20High-dimensional%20Regression                                                                                  AdaTrans: Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Regression                                                                                  We consider the transfer learning problem in the high dimensional setting, where the feature dimension is larger than the sample size. To learn transferable information, which may vary across features or the source samples, we propose an adaptive transfer learning method that can detect and aggregate the feature-wise (F-AdaTrans) or sample-wise (S-AdaTrans) transferable structures. We achieve this by employing a novel fused-penalty, coupled with weights that can adapt according to the transferable structure. To choose the weight, we propose a theoretically informed, data-driven procedure, enabling F-AdaTrans to selectively fuse the transferable signals with the target while filtering out non-transferable signals, and S-AdaTrans to obtain the optimal combination of information transferred from each source sample. The non-asymptotic rates are established, which recover existing near-minimax optimal rates in special cases. The effectiveness of the proposed method is validated using both synthetic and real data.
http://w3id.org/mlsea/pwc/scientificWork/Adapting%20Visual-Language%20Models%20for%20Generalizable%20Anomaly%20Detection%20in%20Medical%20Images                                                                                  Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images                                                                                  Recent advancements in large-scale visual-language pre-trained models have led to significant progress in zero-/few-shot anomaly detection within natural image domains. However, the substantial domain divergence between natural and medical images limits the effectiveness of these methodologies in medical anomaly detection. This paper introduces a novel lightweight multi-level adaptation and comparison framework to repurpose the CLIP model for medical anomaly detection. Our approach integrates multiple residual adapters into the pre-trained visual encoder, enabling a stepwise enhancement of visual features across different levels. This multi-level adaptation is guided by multi-level, pixel-wise visual-language feature alignment loss functions, which recalibrate the model's focus from object semantics in natural imagery to anomaly identification in medical images. The adapted features exhibit improved generalization across various medical data types, even in zero-shot scenarios where the model encounters unseen medical modalities and anatomical regions during training. Our experiments on medical anomaly detection benchmarks demonstrate that our method significantly surpasses current state-of-the-art models, with an average AUC improvement of 6.24% and 7.33% for anomaly classification, 2.03% and 2.37% for anomaly segmentation, under the zero-shot and few-shot settings, respectively. Source code is available at: https://github.com/MediaBrain-SJTU/MVFA-AD
http://w3id.org/mlsea/pwc/scientificWork/Adapting%20the%20Segment%20Anything%20Model%20During%20Usage%20in%20Novel%20Situations                                                                                  Adapting the Segment Anything Model During Usage in Novel Situations                                                                                  The interactive segmentation task consists in the creation of object segmentation masks based on user interactions. The most common way to guide a model towards producing a correct segmentation consists in clicks on the object and background. The recently published Segment Anything Model (SAM) supports a generalized version of the interactive segmentation problem and has been trained on an object segmentation dataset which contains 1.1B masks. Though being trained extensively and with the explicit purpose of serving as a foundation model, we show significant limitations of SAM when being applied for interactive segmentation on novel domains or object types. On the used datasets, SAM displays a failure rate $ text{FR}_{30}@90$ of up to $72.6 %$. Since we still want such foundation models to be immediately applicable, we present a framework that can adapt SAM during immediate usage. For this we will leverage the user interactions and masks, which are constructed during the interactive segmentation process. We use this information to generate pseudo-labels, which we use to compute a loss function and optimize a part of the SAM model. The presented method causes a relative reduction of up to $48.1 %$ in the $ text{FR}_{20}@85$ and $46.6 %$ in the $ text{FR}_{30}@90$ metrics.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Activation%20Functions%20for%20Predictive%20Modeling%20with%20Sparse%20Experimental%20Data                                                                                  Adaptive Activation Functions for Predictive Modeling with Sparse Experimental Data                                                                                  A pivotal aspect in the design of neural networks lies in selecting activation functions, crucial for introducing nonlinear structures that capture intricate input-output patterns. While the effectiveness of adaptive or trainable activation functions has been studied in domains with ample data, like image classification problems, significant gaps persist in understanding their influence on classification accuracy and predictive uncertainty in settings characterized by limited data availability. This research aims to address these gaps by investigating the use of two types of adaptive activation functions. These functions incorporate shared and individual trainable parameters per hidden layer and are examined in three testbeds derived from additive manufacturing problems containing fewer than one hundred training instances. Our investigation reveals that adaptive activation functions, such as Exponential Linear Unit (ELU) and Softplus, with individual trainable parameters, result in accurate and confident prediction models that outperform fixed-shape activation functions and the less flexible method of using identical trainable activation functions in a hidden layer. Therefore, this work presents an elegant way of facilitating the design of adaptive neural networks in scientific and engineering problems.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Batch%20Sizes%20for%20Active%20Learning%20A%20Probabilistic%20Numerics%20Approach                                                                                  Adaptive Batch Sizes for Active Learning A Probabilistic Numerics Approach                                                                                  Active learning parallelization is widely used, but typically relies on fixing the batch size throughout experimentation. This fixed approach is inefficient because of a dynamic trade-off between cost and speed -- larger batches are more costly, smaller batches lead to slower wall-clock run-times -- and the trade-off may change over the run (larger batches are often preferable earlier). To address this trade-off, we propose a novel Probabilistic Numerics framework that adaptively changes batch sizes. By framing batch selection as a quadrature task, our integration-error-aware algorithm facilitates the automatic tuning of batch sizes to meet predefined quadrature precision objectives, akin to how typical optimizers terminate based on convergence thresholds. This approach obviates the necessity for exhaustive searches across all potential batch sizes. We also extend this to scenarios with constrained active learning and constrained optimization, interpreting constraint violations as reductions in the precision requirement, to subsequently adapt batch construction. Through extensive experiments, we demonstrate that our approach significantly enhances learning efficiency and flexibility in diverse Bayesian batch active learning and Bayesian optimization applications.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Block%20Sparse%20Regularization%20under%20Arbitrary%20Linear%20Transform                                                                                  Adaptive Block Sparse Regularization under Arbitrary Linear Transform                                                                                  We propose a convex and fast signal reconstruction method for block sparsity under arbitrary linear transform with unknown block structure. The proposed method is a generalization of the similar existing method and can reconstruct signals with block sparsity under non-invertible transforms, unlike the existing method. Our work broadens the scope of block sparse regularization, enabling more versatile and powerful applications across various signal processing domains. We derive an iterative algorithm for solving proposed method and provide conditions for its convergence to the optimal solution. Numerical experiments demonstrate the effectiveness of the proposed method.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Deep%20Learning%20for%20Efficient%20Visual%20Pose%20Estimation%20aboard%20Ultra-low-power%20Nano-drones                                                                                  Adaptive Deep Learning for Efficient Visual Pose Estimation aboard Ultra-low-power Nano-drones                                                                                  Sub-10cm diameter nano-drones are gaining momentum thanks to their applicability in scenarios prevented to bigger flying drones, such as in narrow environments and close to humans. However, their tiny form factor also brings their major drawback: ultra-constrained memory and processors for the onboard execution of their perception pipelines. Therefore, lightweight deep learning-based approaches are becoming increasingly popular, stressing how computational efficiency and energy-saving are paramount as they can make the difference between a fully working closed-loop system and a failing one. In this work, to maximize the exploitation of the ultra-limited resources aboard nano-drones, we present a novel adaptive deep learning-based mechanism for the efficient execution of a vision-based human pose estimation task. We leverage two State-of-the-Art (SoA) convolutional neural networks (CNNs) with different regression performance vs. computational costs trade-offs. By combining these CNNs with three novel adaptation strategies based on the output's temporal consistency and on auxiliary tasks to swap the CNN being executed proactively, we present six different systems. On a real-world dataset and the actual nano-drone hardware, our best-performing system, compared to executing only the bigger and most accurate SoA model, shows 28% latency reduction while keeping the same mean absolute error (MAE), 3% MAE reduction while being iso-latency, and the absolute peak performance, i.e., 6% better than SoA model.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Discovering%20and%20Merging%20for%20Incremental%20Novel%20Class%20Discovery                                                                                  Adaptive Discovering and Merging for Incremental Novel Class Discovery                                                                                  One important desideratum of lifelong learning aims to discover novel classes from unlabelled data in a continuous manner. The central challenge is twofold: discovering and learning novel classes while mitigating the issue of catastrophic forgetting of established knowledge. To this end, we introduce a new paradigm called Adaptive Discovering and Merging (ADM) to discover novel categories adaptively in the incremental stage and integrate novel knowledge into the model without affecting the original knowledge. To discover novel classes adaptively, we decouple representation learning and novel class discovery, and use Triple Comparison (TC) and Probability Regularization (PR) to constrain the probability discrepancy and diversity for adaptive category assignment. To merge the learned novel knowledge adaptively, we propose a hybrid structure with base and novel branches named Adaptive Model Merging (AMM), which reduces the interference of the novel branch on the old classes to preserve the previous knowledge, and merges the novel branch to the base model without performance loss and parameter growth. Extensive experiments on several datasets show that ADM significantly outperforms existing class-incremental Novel Class Discovery (class-iNCD) approaches. Moreover, our AMM also benefits the class-incremental Learning (class-IL) task by alleviating the catastrophic forgetting problem.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Fast%20XGBoost%20for%20Multiclass%20Classification                                                                                  Adaptive Fast XGBoost for Multiclass Classification                                                                                  The popularization of sensoring and connectivity technologies like 5G and IoT are boosting the generation of data streams. Such kinds of data are one of the last frontiers of data mining applications. However, data streams are massive and unbounded sequences of non-stationary data objects that are continuously generated at rapid rates. To deal with these challenges, the learning algorithms should analyze the data just once and update their classifiers to handle the concept drifts. The literature presents some algorithms to deal with the classification of multiclass data streams. However, most of them have high processing time. Therefore, this work proposes a XGBoost-based classifier called AFXGB-MC to fast classify non-stationary data streams with multiple classes. We compared it with the six state-of-the-art algorithms for multiclass classification found in the literature. The results pointed out that AFXGB-MC presents similar accuracy performance, but with faster processing time, being twice faster than the second fastest algorithm from the literature, and having fast drift recovery time.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Federated%20Learning%20Over%20the%20Air                                                                                  Adaptive Federated Learning Over the Air                                                                                  We propose a federated version of adaptive gradient methods, particularly AdaGrad and Adam, within the framework of over-the-air model training. This approach capitalizes on the inherent superposition property of wireless channels, facilitating fast and scalable parameter aggregation. Meanwhile, it enhances the robustness of the model training process by dynamically adjusting the stepsize in accordance with the global gradient update. We derive the convergence rate of the training algorithms, encompassing the effects of channel fading and interference, for a broad spectrum of nonconvex loss functions. Our analysis shows that the AdaGrad-based algorithm converges to a stationary point at the rate of $ mathcal{O}( ln{(T)} /{ T^{ 1 - frac{1}{ alpha} } } )$, where $ alpha$ represents the tail index of the electromagnetic interference. This result indicates that the level of heavy-tailedness in interference distribution plays a crucial role in the training efficiency: the heavier the tail, the slower the algorithm converges. In contrast, an Adam-like algorithm converges at the $ mathcal{O}( 1/T )$ rate, demonstrating its advantage in expediting the model training process. We conduct extensive experiments that corroborate our theoretical findings and affirm the practical efficacy of our proposed federated adaptive gradient methods.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Hierarchical%20Certification%20for%20Segmentation%20using%20Randomized%20Smoothing                                                                                  Adaptive Hierarchical Certification for Segmentation using Randomized Smoothing                                                                                  Common certification methods operate on a flat pre-defined set of fine-grained classes. In this paper, however, we propose a novel, more general, and practical setting, namely adaptive hierarchical certification for image semantic segmentation. In this setting, the certification can be within a multi-level hierarchical label space composed of fine to coarse levels. Unlike classic methods where the certification would abstain for unstable components, our approach adaptively relaxes the certification to a coarser level within the hierarchy. This relaxation lowers the abstain rate whilst providing more certified semantically meaningful information. We mathematically formulate the problem setup and introduce, for the first time, an adaptive hierarchical certification algorithm for image semantic segmentation, that certifies image pixels within a hierarchy and prove the correctness of its guarantees. Since certified accuracy does not take the loss of information into account when traversing into a coarser hierarchy level, we introduce a novel evaluation paradigm for adaptive hierarchical certification, namely the certified information gain metric, which is proportional to the class granularity level. Our evaluation experiments on real-world challenging datasets such as Cityscapes and ACDC demonstrate that our adaptive algorithm achieves a higher certified information gain and a lower abstain rate compared to the current state-of-the-art certification method, as well as other non-adaptive versions of it.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Least%20Mean%20Squares%20Graph%20Neural%20Networks%20and%20Online%20Graph%20Signal%20Estimation                                                                                  Adaptive Least Mean Squares Graph Neural Networks and Online Graph Signal Estimation                                                                                  The online prediction of multivariate signals, existing simultaneously in space and time, from noisy partial observations is a fundamental task in numerous applications. We propose an efficient Neural Network architecture for the online estimation of time-varying graph signals named the Adaptive Least Mean Squares Graph Neural Networks (LMS-GNN). LMS-GNN aims to capture the time variation and bridge the cross-space-time interactions under the condition that signals are corrupted by noise and missing values. The LMS-GNN is a combination of adaptive graph filters and Graph Neural Networks (GNN). At each time step, the forward propagation of LMS-GNN is similar to adaptive graph filters where the output is based on the error between the observation and the prediction similar to GNN. The filter coefficients are updated via backpropagation as in GNN. Experimenting on real-world temperature data reveals that our LMS-GNN achieves more accurate online predictions compared to graph-based methods like adaptive graph filters and graph convolutional neural networks.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Neural-Operator%20Backstepping%20Control%20of%20a%20Benchmark%20Hyperbolic%20PDE                                                                                  Adaptive Neural-Operator Backstepping Control of a Benchmark Hyperbolic PDE                                                                                  To stabilize PDEs, feedback controllers require gain kernel functions, which are themselves governed by PDEs. Furthermore, these gain-kernel PDEs depend on the PDE plants' functional coefficients. The functional coefficients in PDE plants are often unknown. This requires an adaptive approach to PDE control, i.e., an estimation of the plant coefficients conducted concurrently with control, where a separate PDE for the gain kernel must be solved at each timestep upon the update in the plant coefficient function estimate. Solving a PDE at each timestep is computationally expensive and a barrier to the implementation of real-time adaptive control of PDEs. Recently, results in neural operator (NO) approximations of functional mappings have been introduced into PDE control, for replacing the computation of the gain kernel with a neural network that is trained, once offline, and reused in real-time for rapid solution of the PDEs. In this paper, we present the first result on applying NOs in adaptive PDE control, presented for a benchmark 1-D hyperbolic PDE with recirculation. We establish global stabilization via Lyapunov analysis, in the plant and parameter error states, and also present an alternative approach, via passive identifiers, which avoids the strong assumptions on kernel differentiability. We then present numerical simulations demonstrating stability and observe speedups up to three orders of magnitude, highlighting the real-time efficacy of neural operators in adaptive control. Our code (Github) is made publicly available for future researchers.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Online%20Learning%20of%20Separable%20Path%20Graph%20Transforms%20for%20Intra-prediction                                                                                  Adaptive Online Learning of Separable Path Graph Transforms for Intra-prediction                                                                                  Current video coding standards, including H.264/AVC, HEVC, and VVC, employ discrete cosine transform (DCT), discrete sine transform (DST), and secondary to Karhunen-Loeve transforms (KLTs) decorrelate the intra-prediction residuals. However, the efficiency of these transforms in decorrelation can be limited when the signal has a non-smooth and non-periodic structure, such as those occurring in textures with intricate patterns. This paper introduces a novel adaptive separable path graph-based transform (GBT) that can provide better decorrelation than the DCT for intra-predicted texture data. The proposed GBT is learned in an online scenario with sequential K-means clustering, which groups similar blocks during encoding and decoding to adaptively learn the GBT for the current block from previously reconstructed areas with similar characteristics. A signaling overhead is added to the bitstream of each coding block to indicate the usage of the proposed graph-based transform. We assess the performance of this method combined with H.264/AVC intra-coding tools and demonstrate that it can significantly outperform H.264/AVC DCT for intra-predicted texture data.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Regret%20for%20Bandits%20Made%20Possible%3A%20Two%20Queries%20Suffice                                                                                  Adaptive Regret for Bandits Made Possible: Two Queries Suffice                                                                                  Fast changing states or volatile environments pose a significant challenge to online optimization, which needs to perform rapid adaptation under limited observation. In this paper, we give query and regret optimal bandit algorithms under the strict notion of strongly adaptive regret, which measures the maximum regret over any contiguous interval $I$. Due to its worst-case nature, there is an almost-linear $ Omega(|I|^{1- epsilon})$ regret lower bound, when only one query per round is allowed [Daniely el al, ICML 2015]. Surprisingly, with just two queries per round, we give Strongly Adaptive Bandit Learner (StABL) that achieves $ tilde{O}( sqrt{n|I|})$ adaptive regret for multi-armed bandits with $n$ arms. The bound is tight and cannot be improved in general. Our algorithm leverages a multiplicative update scheme of varying stepsizes and a carefully chosen observation distribution to control the variance. Furthermore, we extend our results and provide optimal algorithms in the bandit convex optimization setting. Finally, we empirically demonstrate the superior performance of our algorithms under volatile environments and for downstream tasks, such as algorithm selection for hyperparameter optimization.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Testing%20Environment%20Generation%20for%20Connected%20and%20Automated%20Vehicles%20with%20Dense%20Reinforcement%20Learning                                                                                  Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning                                                                                  The assessment of safety performance plays a pivotal role in the development and deployment of connected and automated vehicles (CAVs). A common approach involves designing testing scenarios based on prior knowledge of CAVs (e.g., surrogate models), conducting tests in these scenarios, and subsequently evaluating CAVs' safety performances. However, substantial differences between CAVs and the prior knowledge can significantly diminish the evaluation efficiency. In response to this issue, existing studies predominantly concentrate on the adaptive design of testing scenarios during the CAV testing process. Yet, these methods have limitations in their applicability to high-dimensional scenarios. To overcome this challenge, we develop an adaptive testing environment that bolsters evaluation robustness by incorporating multiple surrogate models and optimizing the combination coefficients of these surrogate models to enhance evaluation efficiency. We formulate the optimization problem as a regression task utilizing quadratic programming. To efficiently obtain the regression target via reinforcement learning, we propose the dense reinforcement learning method and devise a new adaptive policy with high sample efficiency. Essentially, our approach centers on learning the values of critical scenes displaying substantial surrogate-to-real gaps. The effectiveness of our method is validated in high-dimensional overtaking scenarios, demonstrating that our approach achieves notable evaluation efficiency.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20Text%20Watermark%20for%20Large%20Language%20Models                                                                                  Adaptive Text Watermark for Large Language Models                                                                                  The advancement of Large Language Models (LLMs) has led to increasing concerns about the misuse of AI-generated text, and watermarking for LLM-generated text has emerged as a potential solution. However, it is challenging to generate high-quality watermarked text while maintaining strong security, robustness, and the ability to detect watermarks without prior knowledge of the prompt or model. This paper proposes an adaptive watermarking strategy to address this problem. To improve the text quality and maintain robustness, we adaptively add watermarking to token distributions with high entropy measured using an auxiliary model and keep the low entropy token distributions untouched. For the sake of security and to further minimize the watermark's impact on text quality, instead of using a fixed green/red list generated from a random secret key, which can be vulnerable to decryption and forgery, we adaptively scale up the output logits in proportion based on the semantic embedding of previously generated text using a well designed semantic mapping model. Our experiments involving various LLMs demonstrate that our approach achieves comparable robustness performance to existing watermark methods. Additionally, the text generated by our method has perplexity comparable to that of emph{un-watermarked} LLMs while maintaining security even under various attacks.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive%20scheduling%20for%20adaptive%20sampling%20in%20POS%20taggers%20construction                                                                                  Adaptive scheduling for adaptive sampling in POS taggers construction                                                                                  We introduce an adaptive scheduling for adaptive sampling as a novel way of machine learning in the construction of part-of-speech taggers. The goal is to speed up the training on large data sets, without significant loss of performance with regard to an optimal configuration. In contrast to previous methods using a random, fixed or regularly rising spacing between the instances, ours analyzes the shape of the learning curve geometrically in conjunction with a functional model to increase or decrease it at any time. The algorithm proves to be formally correct regarding our working hypotheses. Namely, given a case, the following one is the nearest ensuring a net gain of learning ability from the former, it being possible to modulate the level of requirement for this condition. We also improve the robustness of sampling by paying greater attention to those regions of the training data base subject to a temporary inflation in performance, thus preventing the learning from stopping prematurely. The proposal has been evaluated on the basis of its reliability to identify the convergence of models, corroborating our expectations. While a concrete halting condition is used for testing, users can choose any condition whatsoever to suit their own specific needs.
http://w3id.org/mlsea/pwc/scientificWork/Adaptive-avg-pooling%20based%20Attention%20Vision%20Transformer%20for%20Face%20Anti-spoofing                                                                                  Adaptive-avg-pooling based Attention Vision Transformer for Face Anti-spoofing                                                                                  Traditional vision transformer consists of two parts: transformer encoder and multi-layer perception (MLP). The former plays the role of feature learning to obtain better representation, while the latter plays the role of classification. Here, the MLP is constituted of two fully connected (FC) layers, average value computing, FC layer and softmax layer. However, due to the use of average value computing module, some useful information may get lost, which we plan to preserve by the use of alternative framework. In this work, we propose a novel vision transformer referred to as adaptive-avg-pooling based attention vision transformer (AAViT) that uses modules of adaptive average pooling and attention to replace the module of average value computing. We explore the proposed AAViT for the studies on face anti-spoofing using Replay-Attack database. The experiments show that the AAViT outperforms vision transformer in face anti-spoofing by producing a reduced equal error rate. In addition, we found that the proposed AAViT can perform much better than some commonly used neural networks such as ResNet and some other known systems on the Replay-Attack corpus.
http://w3id.org/mlsea/pwc/scientificWork/Addressing%20Shortcomings%20in%20Fair%20Graph%20Learning%20Datasets%3A%20Towards%20a%20New%20Benchmark                                                                                  Addressing Shortcomings in Fair Graph Learning Datasets: Towards a New Benchmark                                                                                  Fair graph learning plays a pivotal role in numerous practical applications. Recently, many fair graph learning methods have been proposed; however, their evaluation often relies on poorly constructed semi-synthetic datasets or substandard real-world datasets. In such cases, even a basic Multilayer Perceptron (MLP) can outperform Graph Neural Networks (GNNs) in both utility and fairness. In this work, we illustrate that many datasets fail to provide meaningful information in the edges, which may challenge the necessity of using graph structures in these problems. To address these issues, we develop and introduce a collection of synthetic, semi-synthetic, and real-world datasets that fulfill a broad spectrum of requirements. These datasets are thoughtfully designed to include relevant graph structures and bias information crucial for the fair evaluation of models. The proposed synthetic and semi-synthetic datasets offer the flexibility to create data with controllable bias parameters, thereby enabling the generation of desired datasets with user-defined bias values with ease. Moreover, we conduct systematic evaluations of these proposed datasets and establish a unified evaluation approach for fair graph learning models. Our extensive experimental results with fair graph learning methods across our datasets demonstrate their effectiveness in benchmarking the performance of these methods. Our datasets and the code for reproducing our experiments are available at https://github.com/XweiQ/Benchmark-GraphFairness.
http://w3id.org/mlsea/pwc/scientificWork/Addressing%20cognitive%20bias%20in%20medical%20language%20models                                                                                  Addressing cognitive bias in medical language models                                                                                  There is increasing interest in the application large language models (LLMs) to the medical field, in part because of their impressive performance on medical exam questions. While promising, exam questions do not reflect the complexity of real patient-doctor interactions. In reality, physicians' decisions are shaped by many complex factors, such as patient compliance, personal experience, ethical beliefs, and cognitive bias. Taking a step toward understanding this, our hypothesis posits that when LLMs are confronted with clinical questions containing cognitive biases, they will yield significantly less accurate responses compared to the same questions presented without such biases. In this study, we developed BiasMedQA, a benchmark for evaluating cognitive biases in LLMs applied to medical tasks. Using BiasMedQA we evaluated six LLMs, namely GPT-4, Mixtral-8x70B, GPT-3.5, PaLM-2, Llama 2 70B-chat, and the medically specialized PMC Llama 13B. We tested these models on 1,273 questions from the US Medical Licensing Exam (USMLE) Steps 1, 2, and 3, modified to replicate common clinically-relevant cognitive biases. Our analysis revealed varying effects for biases on these LLMs, with GPT-4 standing out for its resilience to bias, in contrast to Llama 2 70B-chat and PMC Llama 13B, which were disproportionately affected by cognitive bias. Our findings highlight the critical need for bias mitigation in the development of medical LLMs, pointing towards safer and more reliable applications in healthcare.
http://w3id.org/mlsea/pwc/scientificWork/Adjacent-Level%20Feature%20Cross-Fusion%20With%203-D%20CNN%20for%20Remote%20Sensing%20Image%20Change%20Detection                                                                                  Adjacent-Level Feature Cross-Fusion With 3-D CNN for Remote Sensing Image Change Detection                                                                                  Deep learning-based change detection (CD) using remote sensing images has received increasing attention in recent years. However, how to effectively extract and fuse the deep features of bi-temporal images for improving the accuracy of CD is still a challenge. To address that, a novel adjacent-level feature fusion network with 3D convolution (named AFCF3D-Net) is proposed in this article. First, through the inner fusion property of 3D convolution, we design a new feature fusion way that can simultaneously extract and fuse the feature information from bi-temporal images. Then, to alleviate the semantic gap between low-level features and high-level features, we propose an adjacent-level feature cross-fusion (AFCF) module to aggregate complementary feature information between the adjacent levels. Furthermore, the full-scale skip connection strategy is introduced to improve the capability of pixel-wise prediction and the compactness of changed objects in the results. Finally, the proposed AFCF3D-Net has been validated on the three challenging remote sensing CD datasets: the Wuhan building dataset (WHU-CD), the LEVIR building dataset (LEVIR-CD), and the Sun Yat-Sen University dataset (SYSU-CD). The results of quantitative analysis and qualitative comparison demonstrate that the proposed AFCF3D-Net achieves better performance compared to other state-of-the-art methods. The code for this work is available at https://github.com/wm-Githuber/AFCF3D-Net.
http://w3id.org/mlsea/pwc/scientificWork/Adjoint%20Sensitivities%20of%20Chaotic%20Flows%20without%20Adjoint%20Solvers%3A%20A%20Data-Driven%20Approach                                                                                  Adjoint Sensitivities of Chaotic Flows without Adjoint Solvers: A Data-Driven Approach                                                                                  In one calculation, adjoint sensitivity analysis provides the gradient of a quantity of interest with respect to all system's parameters. Conventionally, adjoint solvers need to be implemented by differentiating computational models, which can be a cumbersome task and is code-specific. To propose an adjoint solver that is not code-specific, we develop a data-driven strategy. We demonstrate its application on the computation of gradients of long-time averages of chaotic flows. First, we deploy a parameter-aware echo state network (ESN) to accurately forecast and simulate the dynamics of a dynamical system for a range of system's parameters. Second, we derive the adjoint of the parameter-aware ESN. Finally, we combine the parameter-aware ESN with its adjoint version to compute the sensitivities to the system parameters. We showcase the method on a prototypical chaotic system. Because adjoint sensitivities in chaotic regimes diverge for long integration times, we analyse the application of ensemble adjoint method to the ESN. We find that the adjoint sensitivities obtained from the ESN match closely with the original system. This work opens possibilities for sensitivity analysis without code-specific adjoint solvers.
http://w3id.org/mlsea/pwc/scientificWork/Admission%20Prediction%20in%20Undergraduate%20Applications%3A%20an%20Interpretable%20Deep%20Learning%20Approach                                                                                  Admission Prediction in Undergraduate Applications: an Interpretable Deep Learning Approach                                                                                  This article addresses the challenge of validating the admission committee's decisions for undergraduate admissions. In recent years, the traditional review process has struggled to handle the overwhelmingly large amount of applicants' data. Moreover, this traditional assessment often leads to human bias, which might result in discrimination among applicants. Although classical machine learning-based approaches exist that aim to verify the quantitative assessment made by the application reviewers, these methods lack scalability and suffer from performance issues when a large volume of data is in place. In this context, we propose deep learning-based classifiers, namely Feed-Forward and Input Convex neural networks, which overcome the challenges faced by the existing methods. Furthermore, we give additional insights into our model by incorporating an interpretability module, namely LIME. Our training and test datasets comprise applicants' data with a wide range of variables and information. Our models achieve higher accuracy compared to the best-performing traditional machine learning-based approach by a considerable margin of 3.03 %. Additionally, we show the sensitivity of different features and their relative impacts on the overall admission decision using the LIME technique.
http://w3id.org/mlsea/pwc/scientificWork/Adolescent%20relational%20behaviour%20and%20the%20obesity%20pandemic%3A%20A%20descriptive%20study%20applying%20social%20network%20analysis%20and%20machine%20learning%20techniques                                                                                  Adolescent relational behaviour and the obesity pandemic: A descriptive study applying social network analysis and machine learning techniques                                                                                  Aim: To study the existence of subgroups by exploring the similarities between the attributes of the nodes of the groups, in relation to diet and gender and, to analyse the connectivity between groups based on aspects of similarities between them through SNA and artificial intelligence techniques. Methods: 235 students from 5 different educational centres participate in this study between March and December 2015. Data analysis carried out is divided into two blocks: social network analysis and unsupervised machine learning techniques. As for the social network analysis, the Girvan-Newman technique was applied to find the best number of cohesive groups within each of the friendship networks of the different classes analysed. Results: After applying Girvan-Newman in the three classes, the best division into clusters was respectively 2 for classroom A, 7 for classroom B and 6 for classroom C. There are significant differences between the groups and the gender and diet variables. After applying K-means using population diet as an input variable, a K-means clustering of 2 clusters for class A, 3 clusters for class B and 3 clusters for class C is obtained. Conclusion: Adolescents form subgroups within their classrooms. Subgroup cohesion is defined by the fact that nodes share similarities in aspects that influence obesity, they share attributes related to food quality and gender. The concept of homophily, related to SNA, justifies our results. Artificial intelligence techniques together with the application of the Girvan-Newman provide robustness to the structural analysis of similarities and cohesion between subgroups.
http://w3id.org/mlsea/pwc/scientificWork/Advanced%20Millimeter-Wave%20Radar%20System%20for%20Real-Time%20Multiple%20Human%20Tracking%20and%20Fall%20Detection                                                                                  Advanced Millimeter-Wave Radar System for Real-Time Multiple Human Tracking and Fall Detection                                                                                  This study explores an indoor system for tracking multiple humans and detecting falls, employing three Millimeter-Wave radars from Texas Instruments placed on x-y-z surfaces. Compared to wearables and camera methods, Millimeter-Wave radar is not plagued by mobility inconvenience, lighting conditions, or privacy issues. We establish a real-time framework to integrate signals received from these radars, allowing us to track the position and body status of human targets non-intrusively. To ensure the overall accuracy of our system, we conduct an initial evaluation of radar characteristics, covering aspects such as resolution, interference between radars, and coverage area. Additionally, we introduce innovative strategies, including Dynamic DBSCAN clustering based on signal energy levels, a probability matrix for enhanced target tracking, target status prediction for fall detection, and a feedback loop for noise reduction. We conduct an extensive evaluation using over 300 minutes of data, which equates to approximately 360,000 frames. Our prototype system exhibits remarkable performance, achieving a precision of 98.9% for tracking a single target and 96.5% and 94.0% for tracking two and three targets in human tracking scenarios, respectively. Moreover, in the field of human fall detection, the system demonstrates a high accuracy of 98.2%, underscoring its effectiveness in distinguishing falls from other statuses.
http://w3id.org/mlsea/pwc/scientificWork/Advanced%20monitoring%20of%20rail%20breakage%20in%20double-track%20railway%20lines%20by%20means%20of%20PCA%20techniques                                                                                  Advanced monitoring of rail breakage in double-track railway lines by means of PCA techniques                                                                                  This work describes a classifier designed to identify rail breakages in double-track railway lines, completing the electronic equipment carried out by authors. The main objective of this proposal is to guarantee the integrity of tracks before the railway traffic starts working. In addition, it facilitates maintenance tasks providing information about possible breakages. The detection of breakages is based on the analysis of eight currents provided by the electronic equipment, one per rail, at the ends of the section (emitting and receiving nodes). The imbalance that occurs among the value of these currents implies that there is at least a breakage in the track section under analysis. This analysis is conducted according to three phases. The first one identifies whether there is a breakage, and, in that case, the damaged track is identified. The second phase provides information about which rail is broken (internal, external or both of them) in the previously identified track. Finally, if there is only one breakage, the third phase estimates its most likely zone along the track section. This situation is considered as a classification problem, and solved by means of the Principal Component Analysis technique. This means that a significant number of measurements is required for every breakage pattern (types of breakages) to be considered. Due to the difficulty of having real data, the proposal has been validated using an 8km-long double-track hardware simulator specially designed by the authors, with specific localizations for breakages.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%206D%20Pose%20Estimation%20in%20Augmented%20Reality%20--%20Overcoming%20Projection%20Ambiguity%20with%20Uncontrolled%20Imagery                                                                                  Advancing 6D Pose Estimation in Augmented Reality -- Overcoming Projection Ambiguity with Uncontrolled Imagery                                                                                  This study addresses the challenge of accurate 6D pose estimation in Augmented Reality (AR), a critical component for seamlessly integrating virtual objects into real-world environments. Our research primarily addresses the difficulty of estimating 6D poses from uncontrolled RGB images, a common scenario in AR applications, which lacks metadata such as focal length. We propose a novel approach that strategically decomposes the estimation of z-axis translation and focal length, leveraging the neural-render and compare strategy inherent in the FocalPose architecture. This methodology not only streamlines the 6D pose estimation process but also significantly enhances the accuracy of 3D object overlaying in AR settings. Our experimental results demonstrate a marked improvement in 6D pose estimation accuracy, with promising applications in manufacturing and robotics. Here, the precise overlay of AR visualizations and the advancement of robotic vision systems stand to benefit substantially from our findings.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Anomaly%20Detection%3A%20An%20Adaptation%20Model%20and%20a%20New%20Dataset                                                                                  Advancing Anomaly Detection: An Adaptation Model and a New Dataset                                                                                  Industry surveillance is widely applicable in sectors like retail, manufacturing, education, and smart cities, each presenting unique anomalies requiring specialized detection. However, adapting anomaly detection models to novel viewpoints within the same scenario poses challenges. Extending these models to entirely new scenarios necessitates retraining or fine-tuning, a process that can be time consuming. To address these challenges, we propose the Scenario-Adaptive Anomaly Detection (SA2D) method, leveraging the few-shot learning framework for faster adaptation of pre-trained models to new concepts. Despite this approach, a significant challenge emerges from the absence of a comprehensive dataset with diverse scenarios and camera views. In response, we introduce the Multi-Scenario Anomaly Detection (MSAD) dataset, encompassing 14 distinct scenarios captured from various camera views. This real-world dataset is the first high-resolution anomaly detection dataset, offering a solid foundation for training superior models. MSAD includes diverse normal motion patterns, incorporating challenging variations like different lighting and weather conditions. Through experimentation, we validate the efficacy of SA2D, particularly when trained on the MSAD dataset. Our results show that SA2D not only excels under novel viewpoints within the same scenario but also demonstrates competitive performance when faced with entirely new scenarios. This highlights our method's potential in addressing challenges in detecting anomalies across diverse and evolving surveillance scenarios.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Biomedical%20Text%20Mining%20with%20Community%20Challenges                                                                                  Advancing Biomedical Text Mining with Community Challenges                                                                                  The field of biomedical research has witnessed a significant increase in the accumulation of vast amounts of textual data from various sources such as scientific literatures, electronic health records, clinical trial reports, and social media. However, manually processing and analyzing these extensive and complex resources is time-consuming and inefficient. To address this challenge, biomedical text mining, also known as biomedical natural language processing, has garnered great attention. Community challenge evaluation competitions have played an important role in promoting technology innovation and interdisciplinary collaboration in biomedical text mining research. These challenges provide platforms for researchers to develop state-of-the-art solutions for data mining and information processing in biomedical research. In this article, we review the recent advances in community challenges specific to Chinese biomedical text mining. Firstly, we collect the information of these evaluation tasks, such as data sources and task types. Secondly, we conduct systematic summary and comparative analysis, including named entity recognition, entity normalization, attribute extraction, relation extraction, event extraction, text classification, text similarity, knowledge graph construction, question answering, text generation, and large language model evaluation. Then, we summarize the potential clinical applications of these community challenge tasks from translational informatics perspective. Finally, we discuss the contributions and limitations of these community challenges, while highlighting future directions in the era of large language models.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Extrapolative%20Predictions%20of%20Material%20Properties%20through%20Learning%20to%20Learn                                                                                  Advancing Extrapolative Predictions of Material Properties through Learning to Learn                                                                                  Recent advancements in machine learning have showcased its potential to significantly accelerate the discovery of new materials. Central to this progress is the development of rapidly computable property predictors, enabling the identification of novel materials with desired properties from vast material spaces. However, the limited availability of data resources poses a significant challenge in data-driven materials research, particularly hindering the exploration of innovative materials beyond the boundaries of existing data. While machine learning predictors are inherently interpolative, establishing a general methodology to create an extrapolative predictor remains a fundamental challenge, limiting the search for innovative materials beyond existing data boundaries. In this study, we leverage an attention-based architecture of neural networks and meta-learning algorithms to acquire extrapolative generalization capability. The meta-learners, experienced repeatedly with arbitrarily generated extrapolative tasks, can acquire outstanding generalization capability in unexplored material spaces. Through the tasks of predicting the physical properties of polymeric materials and hybrid organic--inorganic perovskites, we highlight the potential of such extrapolatively trained models, particularly with their ability to rapidly adapt to unseen material domains in transfer learning scenarios.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Generative%20Model%20Evaluation%3A%20A%20Novel%20Algorithm%20for%20Realistic%20Image%20Synthesis%20and%20Comparison%20in%20OCR%20System                                                                                  Advancing Generative Model Evaluation: A Novel Algorithm for Realistic Image Synthesis and Comparison in OCR System                                                                                  This research addresses a critical challenge in the field of generative models, particularly in the generation and evaluation of synthetic images. Given the inherent complexity of generative models and the absence of a standardized procedure for their comparison, our study introduces a pioneering algorithm to objectively assess the realism of synthetic images. This approach significantly enhances the evaluation methodology by refining the Fr 'echet Inception Distance (FID) score, allowing for a more precise and subjective assessment of image quality. Our algorithm is particularly tailored to address the challenges in generating and evaluating realistic images of Arabic handwritten digits, a task that has traditionally been near-impossible due to the subjective nature of realism in image generation. By providing a systematic and objective framework, our method not only enables the comparison of different generative models but also paves the way for improvements in their design and output. This breakthrough in evaluation and comparison is crucial for advancing the field of OCR, especially for scripts that present unique complexities, and sets a new standard in the generation and assessment of high-quality synthetic images.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Investment%20Frontiers%3A%20Industry-grade%20Deep%20Reinforcement%20Learning%20for%20Portfolio%20Optimization                                                                                  Advancing Investment Frontiers: Industry-grade Deep Reinforcement Learning for Portfolio Optimization                                                                                  This research paper delves into the application of Deep Reinforcement Learning (DRL) in asset-class agnostic portfolio optimization, integrating industry-grade methodologies with quantitative finance. At the heart of this integration is our robust framework that not only merges advanced DRL algorithms with modern computational techniques but also emphasizes stringent statistical analysis, software engineering and regulatory compliance. To the best of our knowledge, this is the first study integrating financial Reinforcement Learning with sim-to-real methodologies from robotics and mathematical physics, thus enriching our frameworks and arguments with this unique perspective. Our research culminates with the introduction of AlphaOptimizerNet, a proprietary Reinforcement Learning agent (and corresponding library). Developed from a synthesis of state-of-the-art (SOTA) literature and our unique interdisciplinary methodology, AlphaOptimizerNet demonstrates encouraging risk-return optimization across various asset classes with realistic constraints. These preliminary results underscore the practical efficacy of our frameworks. As the finance sector increasingly gravitates towards advanced algorithmic solutions, our study bridges theoretical advancements with real-world applicability, offering a template for ensuring safety and robust standards in this technologically driven future.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Legal%20Reasoning%3A%20The%20Integration%20of%20AI%20to%20Navigate%20Complexities%20and%20Biases%20in%20Global%20Jurisprudence%20with%20Semi-Automated%20Arbitration%20Processes%20%28SAAPs%29                                                                                  Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)                                                                                  This study consists of a novel approach toward the analysis of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (AI) and legal analysis, emphasizing the role of AI (specifically generative AI) in identifying human biases and facilitating automated, valid, and coherent multisided argumentation of court judgments with the goal of ensuring consistent application of laws in and across various jurisdictions. By incorporating Advanced Language Models (ALMs) and a newly introduced human-AI collaborative framework, this paper seeks to analyze Grounded Theory-based research design with Advanced Language Models (ALMs) in the practice of law. SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT technology), focusing on detecting logical inconsistencies and biases across various legal decisions. SHIRLEY analysis is aggregated and is accompanied by a comparison-oriented AI-based application called SAM (also an ALM) to identify relative deviations in SHIRLEY bias detections. Further, a CRITIC is generated within semi-autonomous arbitration process via the ALM, SARA. A novel approach is introduced in the utilization of an AI arbitrator to critically evaluate biases and qualitative-in-nature nuances identified by the aforementioned AI applications (SAM in concert with SHIRLEY), based on the Hague Rules on Business and Human Rights Arbitration. This Semi-Automated Arbitration Process (SAAP) aims to uphold the integrity and fairness of legal judgments by ensuring a nuanced debate-resultant 'understanding' through a hybrid system of AI and human-based collaborative analysis.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Multilingual%20Handwritten%20Numeral%20Recognition%20with%20Attention-driven%20Transfer%20Learning                                                                                  Advancing Multilingual Handwritten Numeral Recognition with Attention-driven Transfer Learning                                                                                  As deep learning continues to evolve, we have observed huge breakthroughs in the fields of medical imaging, video and frame generation, optical character recognition (OCR), and other domains. In the field of data analysis and document processing, the recognition of handwritten numerals plays a crucial role. This work has led to remarkable changes in OCR, historical handwritten document analysis, and postal automation. In this study, we present a novel framework to overcome this challenge, going beyond digit recognition in only one language. Unlike common methods that focus on a limited set of languages, our method provides a comprehensive solution for recognition of handwritten digit images in 12 different languages. These specific languages are chosen because most of them have fairly distant representations in latent space. We utilize transfer learning, as it reduces the computational cost and maintains the quality of enhanced images and the models’ recognition accuracy. Another strength of our approach is the innovative attention-based module called the MRA module. Our experiments confirm that by applying this module, major progress is made in both image quality and the accuracy of handwritten digit recognition. Notably, we reached high precisions, surpassing nearly 2% improvement in specific languages compared to earlier techniques. In this work, we present a robust and cost-effective approach that handles multilingual handwritten numeral recognition across a wide range of languages. The code and further implementation details are available at https://github.com/CVLab-SHUT/HandWrittenDigitRecognition.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20NLP%20Models%20with%20Strategic%20Text%20Augmentation%3A%20A%20Comprehensive%20Study%20of%20Augmentation%20Methods%20and%20Curriculum%20Strategies                                                                                  Advancing NLP Models with Strategic Text Augmentation: A Comprehensive Study of Augmentation Methods and Curriculum Strategies                                                                                  This study conducts a thorough evaluation of text augmentation techniques across a variety of datasets and natural language processing (NLP) tasks to address the lack of reliable, generalized evidence for these methods. It examines the effectiveness of these techniques in augmenting training sets to improve performance in tasks such as topic classification, sentiment analysis, and offensive language detection. The research emphasizes not only the augmentation methods, but also the strategic order in which real and augmented instances are introduced during training. A major contribution is the development and evaluation of Modified Cyclical Curriculum Learning (MCCL) for augmented datasets, which represents a novel approach in the field. Results show that specific augmentation methods, especially when integrated with MCCL, significantly outperform traditional training approaches in NLP model performance. These results underscore the need for careful selection of augmentation techniques and sequencing strategies to optimize the balance between speed and quality improvement in various NLP tasks. The study concludes that the use of augmentation methods, especially in conjunction with MCCL, leads to improved results in various classification tasks, providing a foundation for future advances in text augmentation strategies in NLP.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20Social%20Intelligence%20in%20AI%20Agents%3A%20Technical%20Challenges%20and%20Open%20Questions                                                                                  Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions                                                                                  Building socially-intelligent AI agents (Social-AI) is a multidisciplinary, multimodal research goal that involves creating agents that can sense, perceive, reason about, learn from, and respond to affect, behavior, and cognition of other agents (human or artificial). Progress towards Social-AI has accelerated in the past decade across several computing communities, including natural language processing, machine learning, robotics, human-machine interaction, computer vision, and speech. Natural language processing, in particular, has been prominent in Social-AI research, as language plays a key role in constructing the social world. In this position paper, we identify a set of underlying technical challenges and open questions for researchers across computing communities to advance Social-AI. We anchor our discussion in the context of social intelligence concepts and prior progress in Social-AI research.
http://w3id.org/mlsea/pwc/scientificWork/Advancing%20sleep%20detection%20by%20modelling%20weak%20label%20sets%3A%20A%20novel%20weakly%20supervised%20learning%20approach                                                                                  Advancing sleep detection by modelling weak label sets: A novel weakly supervised learning approach                                                                                  Understanding sleep and activity patterns plays a crucial role in physical and mental health. This study introduces a novel approach for sleep detection using weakly supervised learning for scenarios where reliable ground truth labels are unavailable. The proposed method relies on a set of weak labels, derived from the predictions generated by conventional sleep detection algorithms. Introducing a novel approach, we suggest a novel generalised non-linear statistical model in which the number of weak sleep labels is modelled as outcome of a binomial distribution. The probability of sleep in the binomial distribution is linked to the outcomes of neural networks trained to detect sleep based on actigraphy. We show that maximizing the likelihood function of the model, is equivalent to minimizing the soft cross-entropy loss. Additionally, we explored the use of the Brier score as a loss function for weak labels. The efficacy of the suggested modelling framework was demonstrated using the Multi-Ethnic Study of Atherosclerosis dataset. A gls{lstm} trained on the soft cross-entropy outperformed conventional sleep detection algorithms, other neural network architectures and loss functions in accuracy and model calibration. This research not only advances sleep detection techniques in scenarios where ground truth data is scarce but also contributes to the broader field of weakly supervised learning by introducing innovative approach in modelling sets of weak labels.
http://w3id.org/mlsea/pwc/scientificWork/Advantage-Aware%20Policy%20Optimization%20for%20Offline%20Reinforcement%20Learning                                                                                  Advantage-Aware Policy Optimization for Offline Reinforcement Learning                                                                                  Offline Reinforcement Learning (RL) endeavors to leverage offline datasets to craft effective agent policy without online interaction, which imposes proper conservative constraints with the support of behavior policies to tackle the Out-Of-Distribution (OOD) problem. However, existing works often suffer from the constraint conflict issue when offline datasets are collected from multiple behavior policies, i.e., different behavior policies may exhibit inconsistent actions with distinct returns across the state space. To remedy this issue, recent Advantage-Weighted (AW) methods prioritize samples with high advantage values for agent training while inevitably leading to overfitting on these samples. In this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO) method to explicitly construct advantage-aware policy constraints for offline learning under mixed-quality datasets. Specifically, A2PO employs a Conditional Variational Auto-Encoder (CVAE) to disentangle the action distributions of intertwined behavior policies by modeling the advantage values of all training data as conditional variables. Then the agent can follow such disentangled action distribution constraints to optimize the advantage-aware policy towards high advantage values. Extensive experiments conducted on both the single-quality and mixed-quality datasets of the D4RL benchmark demonstrate that A2PO yields results superior to state-of-the-art counterparts. Our code will be made publicly available.
http://w3id.org/mlsea/pwc/scientificWork/Adverb%20Is%20the%20Key%3A%20Simple%20Text%20Data%20Augmentation%20with%20Adverb%20Deletion                                                                                  Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion                                                                                  In the field of text data augmentation, rule-based methods are widely adopted for real-world applications owing to their cost-efficiency. However, conventional rule-based approaches suffer from the possibility of losing the original semantics of the given text. We propose a novel text data augmentation strategy that avoids such phenomena through a straightforward deletion of adverbs, which play a subsidiary role in the sentence. Our comprehensive experiments demonstrate the efficiency and effectiveness of our proposed approach for not just single text classification, but also natural language inference that requires semantic preservation. We publicly released our source code for reproducibility.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Examples%20are%20Misaligned%20in%20Diffusion%20Model%20Manifolds                                                                                  Adversarial Examples are Misaligned in Diffusion Model Manifolds                                                                                  In recent years, diffusion models (DMs) have drawn significant attention for their success in approximating data distributions, yielding state-of-the-art generative results. Nevertheless, the versatility of these models extends beyond their generative capabilities to encompass various vision applications, such as image inpainting, segmentation, adversarial robustness, among others. This study is dedicated to the investigation of adversarial attacks through the lens of diffusion models. However, our objective does not involve enhancing the adversarial robustness of image classifiers. Instead, our focus lies in utilizing the diffusion model to detect and analyze the anomalies introduced by these attacks on images. To that end, we systematically examine the alignment of the distributions of adversarial examples when subjected to the process of transformation using diffusion models. The efficacy of this approach is assessed across CIFAR-10 and ImageNet datasets, including varying image sizes in the latter. The results demonstrate a notable capacity to discriminate effectively between benign and attacked images, providing compelling evidence that adversarial instances do not align with the learned manifold of the DMs.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Feature%20Alignment%3A%20Balancing%20Robustness%20and%20Accuracy%20in%20Deep%20Learning%20via%20Adversarial%20Training                                                                                  Adversarial Feature Alignment: Balancing Robustness and Accuracy in Deep Learning via Adversarial Training                                                                                  Deep learning models continue to advance in accuracy, yet they remain vulnerable to adversarial attacks, which often lead to the misclassification of adversarial examples. Adversarial training is used to mitigate this problem by increasing robustness against these attacks. However, this approach typically reduces a model's standard accuracy on clean, non-adversarial samples. The necessity for deep learning models to balance both robustness and accuracy for security is obvious, but achieving this balance remains challenging, and the underlying reasons are yet to be clarified. This paper proposes a novel adversarial training method called Adversarial Feature Alignment (AFA), to address these problems. Our research unveils an intriguing insight: misalignment within the feature space often leads to misclassification, regardless of whether the samples are benign or adversarial. AFA mitigates this risk by employing a novel optimization algorithm based on contrastive learning to alleviate potential feature misalignment. Through our evaluations, we demonstrate the superior performance of AFA. The baseline AFA delivers higher robust accuracy than previous adversarial contrastive learning methods while minimizing the drop in clean accuracy to 1.86% and 8.91% on CIFAR10 and CIFAR100, respectively, in comparison to cross-entropy. We also show that joint optimization of AFA and TRADES, accompanied by data augmentation using a recent diffusion model, achieves state-of-the-art accuracy and robustness.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Feature%20Map%20Pruning%20for%20Backdoor                                                                                  Adversarial Feature Map Pruning for Backdoor                                                                                  Deep neural networks have been widely used in many critical applications, such as autonomous vehicles and medical diagnosis. However, their security is threatened by backdoor attacks, which are achieved by adding artificial patterns to specific training data. Existing defense strategies primarily focus on using reverse engineering to reproduce the backdoor trigger generated by attackers and subsequently repair the DNN model by adding the trigger into inputs and fine-tuning the model with ground-truth labels. However, once the trigger generated by the attackers is complex and invisible, the defender cannot reproduce the trigger successfully then the DNN model will not be repaired, as the trigger is not effectively removed. In this work, we propose Adversarial Feature Map Pruning for Backdoor (FMP) to mitigate backdoor from the DNN. Unlike existing defense strategies, which focus on reproducing backdoor triggers, FMP attempts to prune backdoor feature maps, which are trained to extract backdoor information from inputs. After pruning these backdoor feature maps, FMP will fine-tune the model with a secure subset of training data. Our experiments demonstrate that, compared to existing defense strategies, FMP can effectively reduce the Attack Success Rate (ASR) even against the most complex and invisible attack triggers (e.g., FMP decreases the ASR to 2.86 % in CIFAR10, which is 19.2 % to 65.41 % lower than baselines). Second, unlike conventional defense methods that tend to exhibit low robust accuracy (that is, the accuracy of the model on poisoned data), FMP achieves a higher RA, indicating its superiority in maintaining model performance while mitigating the effects of backdoor attacks (e.g., FMP obtains 87.40 % RA in CIFAR10). Our code is publicly available at: https://github.com/retsuh-bqw/FMP.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Graph%20Disentanglement                                                                                  Adversarial Graph Disentanglement                                                                                  A real-world graph has a complex topological structure, which is often formed by the interaction of different latent factors. However, most existing methods lack consideration of the intrinsic differences in relations between nodes caused by factor entanglement. In this paper, we propose an underline{ textbf{A}}dversarial underline{ textbf{D}}isentangled underline{ textbf{G}}raph underline{ textbf{C}}onvolutional underline{ textbf{N}}etwork (ADGCN) for disentangled graph representation learning. To begin with, we point out two aspects of graph disentanglement that need to be considered, i.e., micro-disentanglement and macro-disentanglement. For them, a component-specific aggregation approach is proposed to achieve micro-disentanglement by inferring latent components that cause the links between nodes. On the basis of micro-disentanglement, we further propose a macro-disentanglement adversarial regularizer to improve the separability among component distributions, thus restricting the interdependence among components. Additionally, to reveal the topological graph structure, a diversity-preserving node sampling approach is proposed, by which the graph structure can be progressively refined in a way of local structure awareness. The experimental results on various real-world graph data verify that our ADGCN obtains more favorable performance over currently available alternatives. The source codes of ADGCN are available at textit{ url{https://github.com/SsGood/ADGCN}}.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Robustness%20Limits%20via%20Scaling-Law%20and%20Human-Alignment%20Studies                                                                                  Adversarial Robustness Limits via Scaling-Law and Human-Alignment Studies                                                                                  This paper revisits the simple, long-studied, yet still unsolved problem of making image classifiers robust to imperceptible perturbations. Taking CIFAR10 as an example, SOTA clean accuracy is about $100$%, but SOTA robustness to $ ell_{ infty}$-norm bounded perturbations barely exceeds $70$%. To understand this gap, we analyze how model size, dataset size, and synthetic data quality affect robustness by developing the first scaling laws for adversarial training. Our scaling laws reveal inefficiencies in prior art and provide actionable feedback to advance the field. For instance, we discovered that SOTA methods diverge notably from compute-optimal setups, using excess compute for their level of robustness. Leveraging a compute-efficient setup, we surpass the prior SOTA with $20$% ($70$%) fewer training (inference) FLOPs. We trained various compute-efficient models, with our best achieving $74$% AutoAttack accuracy ($+3$% gain). However, our scaling laws also predict robustness slowly grows then plateaus at $90$%: dwarfing our new SOTA by scaling is impractical, and perfect robustness is impossible. To better understand this predicted limit, we carry out a small-scale human evaluation on the AutoAttack data that fools our top-performing model. Concerningly, we estimate that human performance also plateaus near $90$%, which we show to be attributable to $ ell_{ infty}$-constrained attacks' generation of invalid images not consistent with their original labels. Having characterized limiting roadblocks, we outline promising paths for future research.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Robustness%20Through%20Artifact%20Design                                                                                  Adversarial Robustness Through Artifact Design                                                                                  Adversarial examples arose as a challenge for machine learning. To hinder them, most defenses alter how models are trained (e.g., adversarial training) or inference is made (e.g., randomized smoothing). Still, while these approaches markedly improve models' adversarial robustness, models remain highly susceptible to adversarial examples. Identifying that, in certain domains such as traffic-sign recognition, objects are implemented per standards specifying how artifacts (e.g., signs) should be designed, we propose a novel approach for improving adversarial robustness. Specifically, we offer a method to redefine standards, making minor changes to existing ones, to defend against adversarial examples. We formulate the problem of artifact design as a robust optimization problem, and propose gradient-based and greedy search methods to solve it. We evaluated our approach in the domain of traffic-sign recognition, allowing it to alter traffic-sign pictograms (i.e., symbols within the signs) and their colors. We found that, combined with adversarial training, our approach led to up to 25.18 % higher robust accuracy compared to state-of-the-art methods against two adversary types, while further increasing accuracy on benign inputs.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Sparse%20Teacher%3A%20Defense%20Against%20Distillation-Based%20Model%20Stealing%20Attacks%20Using%20Adversarial%20Examples                                                                                  Adversarial Sparse Teacher: Defense Against Distillation-Based Model Stealing Attacks Using Adversarial Examples                                                                                  Knowledge Distillation (KD) facilitates the transfer of discriminative capabilities from an advanced teacher model to a simpler student model, ensuring performance enhancement without compromising accuracy. It is also exploited for model stealing attacks, where adversaries use KD to mimic the functionality of a teacher model. Recent developments in this domain have been influenced by the Stingy Teacher model, which provided empirical analysis showing that sparse outputs can significantly degrade the performance of student models. Addressing the risk of intellectual property leakage, our work introduces an approach to train a teacher model that inherently protects its logits, influenced by the Nasty Teacher concept. Differing from existing methods, we incorporate sparse outputs of adversarial examples with standard training data to strengthen the teacher's defense against student distillation. Our approach carefully reduces the relative entropy between the original and adversarially perturbed outputs, allowing the model to produce adversarial logits with minimal impact on overall performance. The source codes will be made publicly available soon.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Testing%20for%20Visual%20Grounding%20via%20Image-Aware%20Property%20Reduction                                                                                  Adversarial Testing for Visual Grounding via Image-Aware Property Reduction                                                                                  Due to the advantages of fusing information from various modalities, multimodal learning is gaining increasing attention. Being a fundamental task of multimodal learning, Visual Grounding (VG), aims to locate objects in images through natural language expressions. Ensuring the quality of VG models presents significant challenges due to the complex nature of the task. In the black box scenario, existing adversarial testing techniques often fail to fully exploit the potential of both modalities of information. They typically apply perturbations based solely on either the image or text information, disregarding the crucial correlation between the two modalities, which would lead to failures in test oracles or an inability to effectively challenge VG models. To this end, we propose PEELING, a text perturbation approach via image-aware property reduction for adversarial testing of the VG model. The core idea is to reduce the property-related information in the original expression meanwhile ensuring the reduced expression can still uniquely describe the original object in the image. To achieve this, PEELING first conducts the object and properties extraction and recombination to generate candidate property reduction expressions. It then selects the satisfied expressions that accurately describe the original object while ensuring no other objects in the image fulfill the expression, through querying the image with a visual understanding technique. We evaluate PEELING on the state-of-the-art VG model, i.e. OFA-VG, involving three commonly used datasets. Results show that the adversarial tests generated by PEELING achieves 21.4% in MultiModal Impact score (MMI), and outperforms state-of-the-art baselines for images and texts by 8.2%--15.1%.
http://w3id.org/mlsea/pwc/scientificWork/Adversarial%20Training%20with%20OCR%20Modality%20Perturbation%20for%20Scene-Text%20Visual%20Question%20Answering                                                                                  Adversarial Training with OCR Modality Perturbation for Scene-Text Visual Question Answering                                                                                  Scene-Text Visual Question Answering (ST-VQA) aims to understand scene text in images and answer questions related to the text content. Most existing methods heavily rely on the accuracy of Optical Character Recognition (OCR) systems, and aggressive fine-tuning based on limited spatial location information and erroneous OCR text information often leads to inevitable overfitting. In this paper, we propose a multimodal adversarial training architecture with spatial awareness capabilities. Specifically, we introduce an Adversarial OCR Enhancement (AOE) module, which leverages adversarial training in the embedding space of OCR modality to enhance fault-tolerant representation of OCR texts, thereby reducing noise caused by OCR errors. Simultaneously, We add a Spatial-Aware Self-Attention (SASA) mechanism to help the model better capture the spatial relationships among OCR tokens. Various experiments demonstrate that our method achieves significant performance improvements on both the ST-VQA and TextVQA datasets and provides a novel paradigm for multimodal adversarial training.
http://w3id.org/mlsea/pwc/scientificWork/Adversarially%20Robust%20Signed%20Graph%20Contrastive%20Learning%20from%20Balance%20Augmentation                                                                                  Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation                                                                                  Signed graphs consist of edges and signs, which can be separated into structural information and balance-related information, respectively. Existing signed graph neural networks (SGNNs) typically rely on balance-related information to generate embeddings. Nevertheless, the emergence of recent adversarial attacks has had a detrimental impact on the balance-related information. Similar to how structure learning can restore unsigned graphs, balance learning can be applied to signed graphs by improving the balance degree of the poisoned graph. However, this approach encounters the challenge 'Irreversibility of Balance-related Information' - while the balance degree improves, the restored edges may not be the ones originally affected by attacks, resulting in poor defense effectiveness. To address this challenge, we propose a robust SGNN framework called Balance Augmented-Signed Graph Contrastive Learning (BA-SGCL), which combines Graph Contrastive Learning principles with balance augmentation techniques. Experimental results demonstrate that BA-SGCL not only enhances robustness against existing adversarial attacks but also achieves superior performance on link sign prediction task across various datasets.
http://w3id.org/mlsea/pwc/scientificWork/Aesthetic%20Preference%20Prediction%20in%20Interior%20Design%3A%20Fuzzy%20Approach                                                                                  Aesthetic Preference Prediction in Interior Design: Fuzzy Approach                                                                                  Interior design is all about creating spaces that look and feel good. However, the subjective nature of aesthetic preferences presents a significant challenge in defining and quantifying what makes an interior design visually appealing. The current paper addresses this gap by introducing a novel methodology for quantifying and predicting aesthetic preferences in interior design. Our study combines fuzzy logic with image processing techniques. We collected a dataset of interior design images from social media platforms, focusing on essential visual attributes such as color harmony, lightness, and complexity. We integrate these features using weighted average to compute a general aesthetic score. Our approach considers individual color preferences in calculating the overall aesthetic preference. We initially gather user ratings for primary colors like red, brown, and others to understand their preferences. Then, we use the pixel count of the top five dominant colors in the image to get the color scheme preference. The color scheme preference and the aesthetic score are then passed as inputs to the fuzzy inference system to calculate an overall preference score. This score represents a comprehensive measure of the user's preference for a particular interior design, considering their color choices and general aesthetic appeal. We used the 2AFC (Two-Alternative Forced Choice) method to validate our methodology, achieving a notable hit rate of 0.7. This study can help designers and professionals better understand and meet people's interior design preferences, especially in a world that relies heavily on digital media.
http://w3id.org/mlsea/pwc/scientificWork/Affective-NLI%3A%20Towards%20Accurate%20and%20Interpretable%20Personality%20Recognition%20in%20Conversation                                                                                  Affective-NLI: Towards Accurate and Interpretable Personality Recognition in Conversation                                                                                  Personality Recognition in Conversation (PRC) aims to identify the personality traits of speakers through textual dialogue content. It is essential for providing personalized services in various applications of Human-Computer Interaction (HCI), such as AI-based mental therapy and companion robots for the elderly. Most recent studies analyze the dialog content for personality classification yet overlook two major concerns that hinder their performance. First, crucial implicit factors contained in conversation, such as emotions that reflect the speakers' personalities are ignored. Second, only focusing on the input dialog content disregards the semantic understanding of personality itself, which reduces the interpretability of the results. In this paper, we propose Affective Natural Language Inference (Affective-NLI) for accurate and interpretable PRC. To utilize affectivity within dialog content for accurate personality recognition, we fine-tuned a pre-trained language model specifically for emotion recognition in conversations, facilitating real-time affective annotations for utterances. For interpretability of recognition results, we formulate personality recognition as an NLI problem by determining whether the textual description of personality labels is entailed by the dialog content. Extensive experiments on two daily conversation datasets suggest that Affective-NLI significantly outperforms (by 6%-7%) state-of-the-art approaches. Additionally, our Flow experiment demonstrates that Affective-NLI can accurately recognize the speaker's personality in the early stages of conversations by surpassing state-of-the-art methods with 22%-34%.
http://w3id.org/mlsea/pwc/scientificWork/AffordanceLLM%3A%20Grounding%20Affordance%20from%20Vision%20Language%20Models                                                                                  AffordanceLLM: Grounding Affordance from Vision Language Models                                                                                  Affordance grounding refers to the task of finding the area of an object with which one can interact. It is a fundamental but challenging task, as a successful solution requires the comprehensive understanding of a scene in multiple aspects including detection, localization, and recognition of objects with their parts, of geo-spatial configuration/layout of the scene, of 3D shapes and physics, as well as of the functionality and potential interaction of the objects and humans. Much of the knowledge is hidden and beyond the image content with the supervised labels from a limited training set. In this paper, we make an attempt to improve the generalization capability of the current affordance grounding by taking the advantage of the rich world, abstract, and human-object-interaction knowledge from pretrained large-scale vision language models. Under the AGD20K benchmark, our proposed model demonstrates a significant performance gain over the competing methods for in-the-wild object affordance grounding. We further demonstrate it can ground affordance for objects from random Internet images, even if both objects and actions are unseen during training. Project site: https://jasonqsy.github.io/AffordanceLLM/
http://w3id.org/mlsea/pwc/scientificWork/Against%20Filter%20Bubbles%3A%20Diversified%20Music%20Recommendation%20via%20Weighted%20Hypergraph%20Embedding%20Learning                                                                                  Against Filter Bubbles: Diversified Music Recommendation via Weighted Hypergraph Embedding Learning                                                                                  Recommender systems serve a dual purpose for users: sifting out inappropriate or mismatched information while accurately identifying items that align with their preferences. Numerous recommendation algorithms are designed to provide users with a personalized array of information tailored to their preferences. Nevertheless, excessive personalization can confine users within a 'filter bubble'. Consequently, achieving the right balance between accuracy and diversity in recommendations is a pressing concern. To address this challenge, exemplified by music recommendation, we introduce the Diversified Weighted Hypergraph music Recommendation algorithm (DWHRec). In the DWHRec algorithm, the initial connections between users and listened tracks are represented by a weighted hypergraph. Simultaneously, associations between artists, albums and tags with tracks are also appended to the hypergraph. To explore users' latent preferences, a hypergraph-based random walk embedding method is applied to the constructed hypergraph. In our investigation, accuracy is gauged by the alignment between the user and the track, whereas the array of recommended track types measures diversity. We rigorously compared DWHRec against seven state-of-the-art recommendation algorithms using two real-world music datasets. The experimental results validate DWHRec as a solution that adeptly harmonizes accuracy and diversity, delivering a more enriched musical experience. Beyond music recommendation, DWHRec can be extended to cater to other scenarios with similar data structures.
http://w3id.org/mlsea/pwc/scientificWork/Age-of-Information-Aware%20Distributed%20Task%20Offloading%20and%20Resource%20Allocation%20in%20Mobile%20Edge%20Computing%20Networks                                                                                  Age-of-Information-Aware Distributed Task Offloading and Resource Allocation in Mobile Edge Computing Networks                                                                                  The growth in artificial intelligence (AI) technology has attracted substantial interests in age-of-information (AoI)-aware task offloading of mobile edge computing (MEC)-namely, minimizing service latency. Additionally, the use of MEC systems poses an additional problem arising from limited battery resources of MDs. This paper tackles the pressing challenge of AoI-aware distributed task offloading optimization, where user association (UA), resource allocation (RA), full-task offloading, and battery of mobile devices (MDs) are jointly considered. In existing studies, joint optimization of overall task offloading and UA is seldom considered due to the complexity of combinatorial optimization problems, and in cases where it is considered, linear objective functions such as power consumption are adopted. Revolutionizing the realm of MEC, our objective includes all major components contributing to users' quality of experience, including AoI and energy consumption. To achieve this, we first formulate an NP-hard combinatorial problem, where the objective function comprises three elements: communication latency, computation latency, and battery usage. We derive a closed-form RA solution of the problem; next, we provide a distributed pricing-based UA solution. We simulate the proposed algorithm for various vision and language AI tasks. Our numerical results show that the proposed method Pareto-dominates baseline methods. More specifically, the results demonstrate that the proposed method can outperform baseline methods by 1.62 times smaller AoI with 41.2% less energy consumption.
http://w3id.org/mlsea/pwc/scientificWork/Agent-Specific%20Effects%3A%20A%20Causal%20Effect%20Propagation%20Analysis%20in%20Multi-Agent%20MDPs                                                                                  Agent-Specific Effects: A Causal Effect Propagation Analysis in Multi-Agent MDPs                                                                                  Establishing causal relationships between actions and outcomes is fundamental for accountable multi-agent decision-making. However, interpreting and quantifying agents' contributions to such relationships pose significant challenges. These challenges are particularly prominent in the context of multi-agent sequential decision-making, where the causal effect of an agent's action on the outcome depends on how other agents respond to that action. In this paper, our objective is to present a systematic approach for attributing the causal effects of agents' actions to the influence they exert on other agents. Focusing on multi-agent Markov decision processes, we introduce agent-specific effects (ASE), a novel causal quantity that measures the effect of an agent's action on the outcome that propagates through other agents. We then turn to the counterfactual counterpart of ASE (cf-ASE), provide a sufficient set of conditions for identifying cf-ASE, and propose a practical sampling-based algorithm for estimating it. Finally, we experimentally evaluate the utility of cf-ASE through a simulation-based testbed, which includes a sepsis management environment.
http://w3id.org/mlsea/pwc/scientificWork/Aggregated%20distribution%20grid%20flexibilities%20in%20subtransmission%20grid%20operational%20management                                                                                  Aggregated distribution grid flexibilities in subtransmission grid operational management                                                                                  Aggregated flexibilities or PQ-capabilities (active and reactive power capabilities) are termed in literature as Feasible Operating Regions (FORs). The FORs from underlying active distribution grids can effectively contribute to the operational management at the HV grid level. The HV buses are allocated aggregated FORs from the underlying MV grids, which are inherently nonlinear and non-convex. Therefore, two approaches are proposed in the paper to apply the FOR constraints in the HV grid operational management. First, a mixed integer linear programming (MILP) based optimization approach for alleviating the HV grid constraint violations is proposed, which addresses the non-convexity of the FOR using piecewise segmentation. Furthermore, the MILP method is enhanced to consider the influence of the HV bus voltage on the underlying MV grid flexibilities resulting in a three dimensional PQ(V)-FOR. Second, a convexification approach is proposed, which uses a convex approximation of the non-convex 3D PQ(V)-FOR shape for implementation in a linear optimization method. Results reveal a robust utilization of the distribution flexibilities to maintain grid security and reliability at the HV grid level. Comparisons present increased computation times for the MILP method which are significantly improved using the convexification based approach.
http://w3id.org/mlsea/pwc/scientificWork/AiGen-FoodReview%3A%20A%20Multimodal%20Dataset%20of%20Machine-Generated%20Restaurant%20Reviews%20and%20Images%20on%20Social%20Media                                                                                  AiGen-FoodReview: A Multimodal Dataset of Machine-Generated Restaurant Reviews and Images on Social Media                                                                                  Online reviews in the form of user-generated content (UGC) significantly impact consumer decision-making. However, the pervasive issue of not only human fake content but also machine-generated content challenges UGC's reliability. Recent advances in Large Language Models (LLMs) may pave the way to fabricate indistinguishable fake generated content at a much lower cost. Leveraging OpenAI's GPT-4-Turbo and DALL-E-2 models, we craft AiGen-FoodReview, a multi-modal dataset of 20,144 restaurant review-image pairs divided into authentic and machine-generated. We explore unimodal and multimodal detection models, achieving 99.80% multimodal accuracy with FLAVA. We use attributes from readability and photographic theories to score reviews and images, respectively, demonstrating their utility as hand-crafted features in scalable and interpretable detection models, with comparable performance. The paper contributes by open-sourcing the dataset and releasing fake review detectors, recommending its use in unimodal and multimodal fake review detection tasks, and evaluating linguistic and visual features in synthetic versus authentic data.
http://w3id.org/mlsea/pwc/scientificWork/Air%20Traffic%20Management%20for%20Collaborative%20Routing%20of%20Unmanned%20Aerial%20Vehicles%20via%20Potential%20Fields                                                                                  Air Traffic Management for Collaborative Routing of Unmanned Aerial Vehicles via Potential Fields                                                                                  Aerial cargo transport is anticipated to play a pivotal role in the distribution of goods within urban environments. The shift is propelled by the surge in e-commerce, the imperative to deliver essential supplies to isolated areas, and the growing demand for expedited and more accessible deliveries. Our research introduces a quantifiable standard for defining routing restrictions for Unmanned Aircraft System Traffic Management (UTM) using the concept of repulsive potential fields. Furthermore, we propose a scalable infrastructure that facilitates collaborative routing of cargo Unmanned Aerial Vehicles (UAVs) by independent shareholders. The practicality of the infrastructure is validated through a functional prototype implemented at a national scale.
http://w3id.org/mlsea/pwc/scientificWork/Airline%20delays%2C%20congestion%20internalization%20and%20non-price%20spillover%20effects%20of%20low%20cost%20carrier%20entry                                                                                  Airline delays, congestion internalization and non-price spillover effects of low cost carrier entry                                                                                  This paper develops an econometric model of flight delays to investigate the influence of competition and dominance on the incentives of carriers to maintain on-time performance. We consider both the route and the airport levels to inspect the local and global effects of competition, with a unifying framework to test the hypotheses of 1. airport congestion internalization and 2. the market competition-quality relationship in a single econometric model. In particular, we examine the impacts of the entry of low cost carriers (LCC) on the flight delays of incumbent full service carriers in the Brazilian airline industry. The main results indicate a highly significant effect of airport congestion self-internalization in parallel with route-level quality competition. Additionally, the potential competition caused by LCC presence provokes a global effect that suggests the existence of non-price spillovers of the LCC entry to non-entered routes.
http://w3id.org/mlsea/pwc/scientificWork/Algebraic%20Complexity%20and%20Neurovariety%20of%20Linear%20Convolutional%20Networks                                                                                  Algebraic Complexity and Neurovariety of Linear Convolutional Networks                                                                                  In this paper, we study linear convolutional networks with one-dimensional filters and arbitrary strides. The neuromanifold of such a network is a semialgebraic set, represented by a space of polynomials admitting specific factorizations. Introducing a recursive algorithm, we generate polynomial equations whose common zero locus corresponds to the Zariski closure of the corresponding neuromanifold. Furthermore, we explore the algebraic complexity of training these networks employing tools from metric algebraic geometry. Our findings reveal that the number of all complex critical points in the optimization of such a network is equal to the generic Euclidean distance degree of a Segre variety. Notably, this count significantly surpasses the number of critical points encountered in the training of a fully connected linear network with the same number of parameters.
http://w3id.org/mlsea/pwc/scientificWork/Algebraic%20identifiability%20of%20partial%20differential%20equation%20models                                                                                  Algebraic identifiability of partial differential equation models                                                                                  Differential equation models are crucial to scientific processes. The values of model parameters are important for analyzing the behaviour of solutions. A parameter is called globally identifiable if its value can be uniquely determined from the input and output functions. To determine if a parameter estimation problem is well-posed for a given model, one must check if the model parameters are globally identifiable. This problem has been intensively studied for ordinary differential equation models, with theory and several efficient algorithms and software packages developed. A comprehensive theory of algebraic identifiability for PDEs has hitherto not been developed due to the complexity of initial and boundary conditions. Here, we provide theory and algorithms, based on differential algebra, for testing identifiability of polynomial PDE models. We showcase this approach on PDE models arising in the sciences.
http://w3id.org/mlsea/pwc/scientificWork/Algorithmic%20Arbitrariness%20in%20Content%20Moderation                                                                                  Algorithmic Arbitrariness in Content Moderation                                                                                  Machine learning (ML) is widely used to moderate online content. Despite its scalability relative to human moderation, the use of ML introduces unique challenges to content moderation. One such challenge is predictive multiplicity: multiple competing models for content classification may perform equally well on average, yet assign conflicting predictions to the same content. This multiplicity can result from seemingly innocuous choices during model development, such as random seed selection for parameter initialization. We experimentally demonstrate how content moderation tools can arbitrarily classify samples as toxic, leading to arbitrary restrictions on speech. We discuss these findings in terms of human rights set out by the International Covenant on Civil and Political Rights (ICCPR), namely freedom of expression, non-discrimination, and procedural justice. We analyze (i) the extent of predictive multiplicity among state-of-the-art LLMs used for detecting toxic content; (ii) the disparate impact of this arbitrariness across social groups; and (iii) how model multiplicity compares to unambiguous human classifications. Our findings indicate that the up-scaled algorithmic moderation risks legitimizing an algorithmic leviathan, where an algorithm disproportionately manages human rights. To mitigate such risks, our study underscores the need to identify and increase the transparency of arbitrariness in content moderation applications. Since algorithmic content moderation is being fueled by pressing social concerns, such as disinformation and hate speech, our discussion on harms raises concerns relevant to policy debates. Our findings also contribute to content moderation and intermediary liability laws being discussed and passed in many countries, such as the Digital Services Act in the European Union, the Online Safety Act in the United Kingdom, and the Fake News Bill in Brazil.
http://w3id.org/mlsea/pwc/scientificWork/Algorithmic%20Ways%20of%20Seeing%3A%20Using%20Object%20Detection%20to%20Facilitate%20Art%20Exploration                                                                                  Algorithmic Ways of Seeing: Using Object Detection to Facilitate Art Exploration                                                                                  This Research through Design paper explores how object detection may be applied to a large digital art museum collection to facilitate new ways of encountering and experiencing art. We present the design and evaluation of an interactive application called SMKExplore, which allows users to explore a museum's digital collection of paintings by browsing through objects detected in the images, as a novel form of open-ended exploration. We provide three contributions. First, we show how an object detection pipeline can be integrated into a design process for visual exploration. Second, we present the design and development of an app that enables exploration of an art museum's collection. Third, we offer reflections on future possibilities for museums and HCI researchers to incorporate object detection techniques into the digitalization of museums.
http://w3id.org/mlsea/pwc/scientificWork/Algorithmic%20syntactic%20causal%20identification                                                                                  Algorithmic syntactic causal identification                                                                                  Causal identification in causal Bayes nets (CBNs) is an important tool in causal inference allowing the derivation of interventional distributions from observational distributions where this is possible in principle. However, most existing formulations of causal identification using techniques such as d-separation and do-calculus are expressed within the mathematical language of classical probability theory on CBNs. However, there are many causal settings where probability theory and hence current causal identification techniques are inapplicable such as relational databases, dataflow programs such as hardware description languages, distributed systems and most modern machine learning algorithms. We show that this restriction can be lifted by replacing the use of classical probability theory with the alternative axiomatic foundation of symmetric monoidal categories. In this alternative axiomatization, we show how an unambiguous and clean distinction can be drawn between the general syntax of causal models and any specific semantic implementation of that causal model. This allows a purely syntactic algorithmic description of general causal identification by a translation of recent formulations of the general ID algorithm through fixing. Our description is given entirely in terms of the non-parametric ADMG structure specifying a causal model and the algebraic signature of the corresponding monoidal category, to which a sequence of manipulations is then applied so as to arrive at a modified monoidal category in which the desired, purely syntactic interventional causal model, is obtained. We use this idea to derive purely syntactic analogues of classical back-door and front-door causal adjustment, and illustrate an application to a more complex causal model.
http://w3id.org/mlsea/pwc/scientificWork/Alice%20Benchmarks%3A%20Connecting%20Real%20World%20Re-Identification%20with%20the%20Synthetic                                                                                  Alice Benchmarks: Connecting Real World Re-Identification with the Synthetic                                                                                  For object re-identification (re-ID), learning from synthetic data has become a promising strategy to cheaply acquire large-scale annotated datasets and effective models, with few privacy concerns. Many interesting research problems arise from this strategy, e.g., how to reduce the domain gap between synthetic source and real-world target. To facilitate developing more new approaches in learning from synthetic data, we introduce the Alice benchmarks, large-scale datasets providing benchmarks as well as evaluation protocols to the research community. Within the Alice benchmarks, two object re-ID tasks are offered: person and vehicle re-ID. We collected and annotated two challenging real-world target datasets: AlicePerson and AliceVehicle, captured under various illuminations, image resolutions, etc. As an important feature of our real target, the clusterability of its training set is not manually guaranteed to make it closer to a real domain adaptation test scenario. Correspondingly, we reuse existing PersonX and VehicleX as synthetic source domains. The primary goal is to train models from synthetic data that can work effectively in the real world. In this paper, we detail the settings of Alice benchmarks, provide an analysis of existing commonly-used domain adaptation methods, and discuss some interesting future directions. An online server has been set up for the community to evaluate methods conveniently and fairly. Datasets and the online server details are available at https://sites.google.com/view/alice-benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/Aligners%3A%20Decoupling%20LLMs%20and%20Alignment                                                                                  Aligners: Decoupling LLMs and Alignment                                                                                  Large Language Models (LLMs) need to be aligned with human expectations to ensure their safety and utility in most applications. Alignment is challenging, costly, and needs to be repeated for every LLM and alignment criterion. We propose to decouple LLMs and alignment by training aligner models that can be used to align any LLM for a given criteria on an as-needed basis, thus also reducing the potential negative impacts of alignment on performance. Our recipe for training the aligner models solely relies on synthetic data generated with a (prompted) LLM and can be easily adjusted for a variety of alignment criteria. We illustrate our method by training an 'ethical' aligner and verify its efficacy empirically.
http://w3id.org/mlsea/pwc/scientificWork/Aligning%20GPTRec%20with%20Beyond-Accuracy%20Goals%20with%20Reinforcement%20Learning                                                                                  Aligning GPTRec with Beyond-Accuracy Goals with Reinforcement Learning                                                                                  Adaptations of Transformer models, such as BERT4Rec and SASRec, achieve state-of-the-art performance in the sequential recommendation task according to accuracy-based metrics, such as NDCG. These models treat items as tokens and then utilise a score-and-rank approach (Top-K strategy), where the model first computes item scores and then ranks them according to this score. While this approach works well for accuracy-based metrics, it is hard to use it for optimising more complex beyond-accuracy metrics such as diversity. Recently, the GPTRec model, which uses a different Next-K strategy, has been proposed as an alternative to the Top-K models. In contrast with traditional Top-K recommendations, Next-K generates recommendations item-by-item and, therefore, can account for complex item-to-item interdependencies important for the beyond-accuracy measures. However, the original GPTRec paper focused only on accuracy in experiments and needed to address how to optimise the model for complex beyond-accuracy metrics. Indeed, training GPTRec for beyond-accuracy goals is challenging because the interaction training data available for training recommender systems typically needs to be aligned with beyond-accuracy recommendation goals. To solve the misalignment problem, we train GPTRec using a 2-stage approach: in the first stage, we use a teacher-student approach to train GPTRec, mimicking the behaviour of traditional Top-K models; in the second stage, we use Reinforcement Learning to align the model for beyond-accuracy goals. In particular, we experiment with increasing recommendation diversity and reducing popularity bias. Our experiments on two datasets show that in 3 out of 4 cases, GPTRec's Next-K generation approach offers a better tradeoff between accuracy and secondary metrics than classic greedy re-ranking techniques.
http://w3id.org/mlsea/pwc/scientificWork/Aligning%20Large%20Language%20Models%20for%20Controllable%20Recommendations                                                                                  Aligning Large Language Models for Controllable Recommendations                                                                                  Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems - systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy, often neglecting the ability to follow instructions. To address this gap, we initially introduce a collection of supervised learning tasks, augmented with labels derived from a conventional recommender model, aimed at explicitly improving LLMs' proficiency in adhering to recommendation-specific instructions. Subsequently, we develop a reinforcement learning-based alignment procedure to further strengthen LLMs' aptitude in responding to users' intentions and mitigating formatting errors. Through extensive experiments on two real-world datasets, our method markedly advances the capability of LLMs to comply with instructions within recommender systems, while sustaining a high level of accuracy performance.
http://w3id.org/mlsea/pwc/scientificWork/Aligning%20Large%20Language%20Models%20for%20Enhancing%20Psychiatric%20Interviews%20through%20Symptom%20Delineation%20and%20Summarization                                                                                  Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization                                                                                  Recent advancements in Large Language Models (LLMs) have accelerated their usage in various domains. Given the fact that psychiatric interviews are goal-oriented and structured dialogues between the professional interviewer and the interviewee, it is one of the most underexplored areas where LLMs can contribute substantial value. Here, we explore the use of LLMs for enhancing psychiatric interviews, by analyzing counseling data from North Korean defectors with traumatic events and mental health issues. Specifically, we investigate whether LLMs can (1) delineate the part of the conversation that suggests psychiatric symptoms and name the symptoms, and (2) summarize stressors and symptoms, based on the interview dialogue transcript. Here, the transcript data was labeled by mental health experts for training and evaluation of LLMs. Our experimental results show that appropriately prompted LLMs can achieve high performance on both the symptom delineation task and the summarization task. This research contributes to the nascent field of applying LLMs to psychiatric interview and demonstrates their potential effectiveness in aiding mental health practitioners.
http://w3id.org/mlsea/pwc/scientificWork/All%20Thresholds%20Barred%3A%20Direct%20Estimation%20of%20Call%20Density%20in%20Bioacoustic%20Data                                                                                  All Thresholds Barred: Direct Estimation of Call Density in Bioacoustic Data                                                                                  Passive acoustic monitoring (PAM) studies generate thousands of hours of audio, which may be used to monitor specific animal populations, conduct broad biodiversity surveys, detect threats such as poachers, and more. Machine learning classifiers for species identification are increasingly being used to process the vast amount of audio generated by bioacoustic surveys, expediting analysis and increasing the utility of PAM as a management tool. In common practice, a threshold is applied to classifier output scores, and scores above the threshold are aggregated into a detection count. The choice of threshold produces biased counts of vocalizations, which are subject to false positive/negative rates that may vary across subsets of the dataset. In this work, we advocate for directly estimating call density: The proportion of detection windows containing the target vocalization, regardless of classifier score. Our approach targets a desirable ecological estimator and provides a more rigorous grounding for identifying the core problems caused by distribution shifts -- when the defining characteristics of the data distribution change -- and designing strategies to mitigate them. We propose a validation scheme for estimating call density in a body of data and obtain, through Bayesian reasoning, probability distributions of confidence scores for both the positive and negative classes. We use these distributions to predict site-level densities, which may be subject to distribution shifts. We test our proposed methods on a real-world study of Hawaiian birds and provide simulation results leveraging existing fully annotated datasets, demonstrating robustness to variations in call density and classifier model quality.
http://w3id.org/mlsea/pwc/scientificWork/All%20in%20How%20You%20Ask%20for%20It%3A%20Simple%20Black-Box%20Method%20for%20Jailbreak%20Attacks                                                                                  All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks                                                                                  Large Language Models (LLMs), such as ChatGPT, encounter `jailbreak' challenges, wherein safeguards are circumvented to generate ethically harmful prompts. This study introduces a straightforward black-box method for efficiently crafting jailbreak prompts, addressing the significant complexity and computational costs associated with conventional methods. Our technique iteratively transforms harmful prompts into benign expressions directly utilizing the target LLM, predicated on the hypothesis that LLMs can autonomously generate expressions that evade safeguards. Through experiments conducted with ChatGPT (GPT-3.5 and GPT-4) and Gemini-Pro, our method consistently achieved an attack success rate exceeding 80% within an average of five iterations for forbidden questions and proved robust against model updates. The jailbreak prompts generated were not only naturally-worded and succinct but also challenging to defend against. These findings suggest that the creation of effective jailbreak prompts is less complex than previously believed, underscoring the heightened risk posed by black-box jailbreak attacks.
http://w3id.org/mlsea/pwc/scientificWork/All%20in%20One%20and%20One%20for%20All%3A%20A%20Simple%20yet%20Effective%20Method%20towards%20Cross-domain%20Graph%20Pretraining                                                                                  All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining                                                                                  Large Language Models (LLMs) have revolutionized the fields of computer vision (CV) and natural language processing (NLP). One of the most notable advancements of LLMs is that a single model is trained on vast and diverse datasets spanning multiple domains -- a paradigm we term `All in One'. This methodology empowers LLMs with super generalization capabilities, facilitating an encompassing comprehension of varied data distributions. Leveraging these capabilities, a single LLM demonstrates remarkable versatility across a variety of domains -- a paradigm we term `One for All'. However, applying this idea to the graph field remains a formidable challenge, with cross-domain pretraining often resulting in negative transfer. This issue is particularly important in few-shot learning scenarios, where the paucity of training data necessitates the incorporation of external knowledge sources. In response to this challenge, we propose a novel approach called Graph COordinators for PrEtraining (GCOPE), that harnesses the underlying commonalities across diverse graph datasets to enhance few-shot learning. Our novel methodology involves a unification framework that amalgamates disparate graph datasets during the pretraining phase to distill and transfer meaningful knowledge to target tasks. Extensive experiments across multiple graph datasets demonstrate the superior efficacy of our approach. By successfully leveraging the synergistic potential of multiple graph datasets for pretraining, our work stands as a pioneering contribution to the realm of graph foundational model.
http://w3id.org/mlsea/pwc/scientificWork/All%20the%20Feels%3A%20A%20dexterous%20hand%20with%20large-area%20tactile%20sensing                                                                                  All the Feels: A dexterous hand with large-area tactile sensing                                                                                  High cost and lack of reliability has precluded the widespread adoption of dexterous hands in robotics. Furthermore, the lack of a viable tactile sensor capable of sensing over the entire area of the hand impedes the rich, low-level feedback that would improve learning of dexterous manipulation skills. This paper introduces an inexpensive, modular, robust, and scalable platform -- the DManus -- aimed at resolving these challenges while satisfying the large-scale data collection capabilities demanded by deep robot learning paradigms. Studies on human manipulation point to the criticality of low-level tactile feedback in performing everyday dexterous tasks. The DManus comes with ReSkin sensing on the entire surface of the palm as well as the fingertips. We demonstrate effectiveness of the fully integrated system in a tactile aware task -- bin picking and sorting. Code, documentation, design files, detailed assembly instructions, trained models, task videos, and all supplementary materials required to recreate the setup can be found on https://sites.google.com/view/roboticsbenchmarks/platforms/dmanus.
http://w3id.org/mlsea/pwc/scientificWork/All-in-one%20simulation-based%20inference                                                                                  All-in-one simulation-based inference                                                                                  Amortized Bayesian inference trains neural networks to solve stochastic inference problems using model simulations, thereby making it possible to rapidly perform Bayesian inference for any newly observed data. However, current simulation-based amortized inference methods are simulation-hungry and inflexible: They require the specification of a fixed parametric prior, simulator, and inference tasks ahead of time. Here, we present a new amortized inference method -- the Simformer -- which overcomes these limitations. By training a probabilistic diffusion model with transformer architectures, the Simformer outperforms current state-of-the-art amortized inference approaches on benchmark tasks and is substantially more flexible: It can be applied to models with function-valued parameters, it can handle inference scenarios with missing or unstructured data, and it can sample arbitrary conditionals of the joint distribution of parameters and data, including both posterior and likelihood. We showcase the performance and flexibility of the Simformer on simulators from ecology, epidemiology, and neuroscience, and demonstrate that it opens up new possibilities and application domains for amortized Bayesian inference on simulation-based models.
http://w3id.org/mlsea/pwc/scientificWork/Allowing%20humans%20to%20interactively%20guide%20machines%20where%20to%20look%20does%20not%20always%20improve%20human-AI%20team%27s%20classification%20accuracy                                                                                  Allowing humans to interactively guide machines where to look does not always improve human-AI team's classification accuracy                                                                                  Via thousands of papers in Explainable AI (XAI), attention maps cite{vaswani2017attention} and feature attribution maps cite{bansal2020sam} have been established as a common means for finding how important each input feature is to an AI's decisions. It is an interesting, unexplored question whether allowing users to edit the feature importance at test time would improve a human-AI team's accuracy on downstream tasks. In this paper, we address this question by leveraging CHM-Corr, a state-of-the-art, ante-hoc explainable classifier cite{taesiri2022visual} that first predicts patch-wise correspondences between the input and training-set images, and then base on them to make classification decisions. We build CHM-Corr++, an interactive interface for CHM-Corr, enabling users to edit the feature attribution map provided by CHM-Corr and observe updated model decisions. Via CHM-Corr++, users can gain insights into if, when, and how the model changes its outputs, improving their understanding beyond static explanations. However, our user study with 18 users who performed 1,400 decisions finds no statistical significance that our interactive approach improves user accuracy on CUB-200 bird image classification over static explanations. This challenges the hypothesis that interactivity can boost human-AI team accuracy~ cite{sokol2020one,sun2022exploring,shen2024towards,singh2024rethinking,mindlin2024beyond,lakkaraju2022rethinking,cheng2019explaining,liu2021understanding} and raises needs for future research. We open-source CHM-Corr++, an interactive tool for editing image classifier attention (see an interactive demo href{http://137.184.82.109:7080/}{here}). % , and it lays the groundwork for future research to enable effective human-AI interaction in computer vision. We release code and data on href{https://github.com/anguyen8/chm-corr-interactive}{github}.
http://w3id.org/mlsea/pwc/scientificWork/Ambient%20Diffusion%20Posterior%20Sampling%3A%20Solving%20Inverse%20Problems%20with%20Diffusion%20Models%20trained%20on%20Corrupted%20Data                                                                                  Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models trained on Corrupted Data                                                                                  We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data. Our method, Ambient Diffusion Posterior Sampling (A-DPS), leverages a generative model pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling conditioned on measurements from a potentially different forward process (e.g. image blurring). We test the efficacy of our approach on standard natural image datasets (CelebA, FFHQ, and AFHQ) and we show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance. We further extend the Ambient Diffusion framework to train MRI models with access only to Fourier subsampled multi-coil MRI measurements at various acceleration factors (R=2, 4, 6, 8). We again observe that models trained on highly subsampled data are better priors for solving inverse problems in the high acceleration regime than models trained on fully sampled data. We open-source our code and the trained Ambient Diffusion MRI models: https://github.com/utcsilab/ambient-diffusion-mri .
http://w3id.org/mlsea/pwc/scientificWork/Ambiguity%20Function%20Shaping%20in%20FMCW%20Automotive%20Radar                                                                                  Ambiguity Function Shaping in FMCW Automotive Radar                                                                                  Frequency-modulated continuous wave (FMCW) radar with inter-chirp coding produces high side-lobes in the Doppler and range dimensions of the radar's ambiguity function. The high side-lobes may cause miss-detection due to masking between targets that are at similar range and have large received power difference, as is often the case in automotive scenarios. In this paper, we develop a novel code optimization method that attenuates the side-lobes of the radar's ambiguity function. In particular, we introduce a framework for designing radar transmit sequences by shaping the radar Ambiguity Function (AF) to a desired structure. The proposed approach suppresses the average amplitude of the AF of the transmitted signal in regions of interest by efficiently tackling a longstanding optimization problem. The optimization criterion is quartic in nature with respect to the radar transmit code. A cyclic iterative algorithm is introduced that recasts the quartic problem as a unimodular quadratic problem (UQP) which can be tackled using power-method-like iterations (PMLI). Our numerical results demonstrate the effectiveness of the proposed algorithm in designing sequences with desired AF which is of great interest to the future generations of automotive radar sensors.
http://w3id.org/mlsea/pwc/scientificWork/Ambiguity%20in%20the%20use%20of%20SIR%20models%20to%20fit%20epidemic%20incidence%20data                                                                                  Ambiguity in the use of SIR models to fit epidemic incidence data                                                                                  When fitting a multi-parameter model to a data set, computer algorithms may suggest that a range of parameters provide equally reasonable fits, making the parameter estimation difficult. Here, we prove this fact for an SIR model. We say a set of parameter values is a good fit to outbreak data if the solution has the data's three most significant characteristics: the standard deviation, the mean time, and the total number of cases. In our model, in addition to the 'basic reproduction number' $R_0$, three other parameters need to be estimated to fit a solution to outbreak data. We will show that those parameters can be chosen so that each gives a linear transformation of a solution's incidence data. As a result, we show that for every choice of $R_0>1$, there is a good fit for each outbreak. We also illustrate our results by providing the least square best fits of the New York City and London data sets of the Omicron variant of COVID-19. Furthermore, we show how versions of the SIR model with $N$ compartments have far more good fits- - indeed a high dimensional set of good fits -- for each target -- showing that more complicated models may have an even greater problem in overparametrizing outbreak characteristics.
http://w3id.org/mlsea/pwc/scientificWork/AmpleGCG%3A%20Learning%20a%20Universal%20and%20Transferable%20Generative%20Model%20of%20Adversarial%20Suffixes%20for%20Jailbreaking%20Both%20Open%20and%20Closed%20LLMs                                                                                  AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs                                                                                  As large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~ citep{zou2023universal} proposes a discrete token optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps. Moreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100 % attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. More interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99 % ASR on the latest GPT-3.5. To summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. In addition, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend.
http://w3id.org/mlsea/pwc/scientificWork/An%20Adaptive%20Dimension%20Reduction%20Estimation%20Method%20for%20High-dimensional%20Bayesian%20Optimization                                                                                  An Adaptive Dimension Reduction Estimation Method for High-dimensional Bayesian Optimization                                                                                  Bayesian optimization (BO) has shown impressive results in a variety of applications within low-to-moderate dimensional Euclidean spaces. However, extending BO to high-dimensional settings remains a significant challenge. We address this challenge by proposing a two-step optimization framework. Initially, we identify the effective dimension reduction (EDR) subspace for the objective function using the minimum average variance estimation (MAVE) method. Subsequently, we construct a Gaussian process model within this EDR subspace and optimize it using the expected improvement criterion. Our algorithm offers the flexibility to operate these steps either concurrently or in sequence. In the sequential approach, we meticulously balance the exploration-exploitation trade-off by distributing the sampling budget between subspace estimation and function optimization, and the convergence rate of our algorithm in high-dimensional contexts has been established. Numerical experiments validate the efficacy of our method in challenging scenarios.
http://w3id.org/mlsea/pwc/scientificWork/An%20Algorithmic%20Framework%20for%20Constructing%20Multiple%20Decision%20Trees%20by%20Evaluating%20Their%20Combination%20Performance%20Throughout%20the%20Construction%20Process                                                                                  An Algorithmic Framework for Constructing Multiple Decision Trees by Evaluating Their Combination Performance Throughout the Construction Process                                                                                  Predictions using a combination of decision trees are known to be effective in machine learning. Typical ideas for constructing a combination of decision trees for prediction are bagging and boosting. Bagging independently constructs decision trees without evaluating their combination performance and averages them afterward. Boosting constructs decision trees sequentially, only evaluating a combination performance of a new decision tree and the fixed past decision trees at each step. Therefore, neither method directly constructs nor evaluates a combination of decision trees for the final prediction. When the final prediction is based on a combination of decision trees, it is natural to evaluate the appropriateness of the combination when constructing them. In this study, we propose a new algorithmic framework that constructs decision trees simultaneously and evaluates their combination performance throughout the construction process. Our framework repeats two procedures. In the first procedure, we construct new candidates of combinations of decision trees to find a proper combination of decision trees. In the second procedure, we evaluate each combination performance of decision trees under some criteria and select a better combination. To confirm the performance of the proposed framework, we perform experiments on synthetic and benchmark data.
http://w3id.org/mlsea/pwc/scientificWork/An%20Analysis%20of%20Letter%20Dynamics%20in%20the%20English%20Alphabet                                                                                  An Analysis of Letter Dynamics in the English Alphabet                                                                                  The frequency with which the letters of the English alphabet appear in writings has been applied to the field of cryptography, the development of keyboard mechanics, and the study of linguistics. We expanded on the statistical analysis of the English alphabet by examining the average frequency which each letter appears in different categories of writings. We evaluated news articles, novels, plays, scientific publications and calculated the frequency of each letter of the alphabet, the information density of each letter, and the overall letter distribution. Furthermore, we developed a metric known as distance, d that can be used to algorithmically recognize different categories of writings. The results of our study can be applied to information transmission, large data curation, and linguistics.
http://w3id.org/mlsea/pwc/scientificWork/An%20Analysis%20of%20Switchback%20Designs%20in%20Reinforcement%20Learning                                                                                  An Analysis of Switchback Designs in Reinforcement Learning                                                                                  This paper offers a detailed investigation of switchback designs in A/B testing, which alternate between baseline and new policies over time. Our aim is to thoroughly evaluate the effects of these designs on the accuracy of their resulting average treatment effect (ATE) estimators. We propose a novel 'weak signal analysis' framework, which substantially simplifies the calculations of the mean squared errors (MSEs) of these ATEs in Markov decision process environments. Our findings suggest that (i) when the majority of reward errors are positively correlated, the switchback design is more efficient than the alternating-day design which switches policies in a daily basis. Additionally, increasing the frequency of policy switches tends to reduce the MSE of the ATE estimator. (ii) When the errors are uncorrelated, however, all these designs become asymptotically equivalent. (iii) In cases where the majority of errors are negative correlated, the alternating-day design becomes the optimal choice. These insights are crucial, offering guidelines for practitioners on designing experiments in A/B testing. Our analysis accommodates a variety of policy value estimators, including model-based estimators, least squares temporal difference learning estimators, and double reinforcement learning estimators, thereby offering a comprehensive understanding of optimal design strategies for policy evaluation in reinforcement learning.
http://w3id.org/mlsea/pwc/scientificWork/An%20Analytic%20Solution%20to%20Covariance%20Propagation%20in%20Neural%20Networks                                                                                  An Analytic Solution to Covariance Propagation in Neural Networks                                                                                  Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems. However, this often involves costly or inaccurate sampling methods and approximations. This paper presents a sample-free moment propagation technique that propagates mean vectors and covariance matrices across a network to accurately characterize the input-output distributions of neural networks. A key enabler of our technique is an analytic solution for the covariance of random variables passed through nonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide applicability and merits of the proposed technique are shown in experiments analyzing the input-output distributions of trained neural networks and training Bayesian neural networks.
http://w3id.org/mlsea/pwc/scientificWork/An%20Artificial%20Intelligence%20%28AI%29%20workflow%20for%20catalyst%20design%20and%20optimization                                                                                  An Artificial Intelligence (AI) workflow for catalyst design and optimization                                                                                  In the pursuit of novel catalyst development to address pressing environmental concerns and energy demand, conventional design and optimization methods often fall short due to the complexity and vastness of the catalyst parameter space. The advent of Machine Learning (ML) has ushered in a new era in the field of catalyst optimization, offering potential solutions to the shortcomings of traditional techniques. However, existing methods fail to effectively harness the wealth of information contained within the burgeoning body of scientific literature on catalyst synthesis. To address this gap, this study proposes an innovative Artificial Intelligence (AI) workflow that integrates Large Language Models (LLMs), Bayesian optimization, and an active learning loop to expedite and enhance catalyst optimization. Our methodology combines advanced language understanding with robust optimization strategies, effectively translating knowledge extracted from diverse literature into actionable parameters for practical experimentation and optimization. In this article, we demonstrate the application of this AI workflow in the optimization of catalyst synthesis for ammonia production. The results underscore the workflow's ability to streamline the catalyst development process, offering a swift, resource-efficient, and high-precision alternative to conventional methods.
http://w3id.org/mlsea/pwc/scientificWork/An%20Assessment%20on%20Comprehending%20Mental%20Health%20through%20Large%20Language%20Models                                                                                  An Assessment on Comprehending Mental Health through Large Language Models                                                                                  Mental health challenges pose considerable global burdens on individuals and communities. Recent data indicates that more than 20% of adults may encounter at least one mental disorder in their lifetime. On the one hand, the advancements in large language models have facilitated diverse applications, yet a significant research gap persists in understanding and enhancing the potential of large language models within the domain of mental health. On the other hand, across various applications, an outstanding question involves the capacity of large language models to comprehend expressions of human mental health conditions in natural language. This study presents an initial evaluation of large language models in addressing this gap. Due to this, we compare the performance of Llama-2 and ChatGPT with classical Machine as well as Deep learning models. Our results on the DAIC-WOZ dataset show that transformer-based models, like BERT or XLNet, outperform the large language models.
http://w3id.org/mlsea/pwc/scientificWork/An%20Autoencoder-Based%20Constellation%20Design%20for%20AirComp%20in%20Wireless%20Federated%20Learning                                                                                  An Autoencoder-Based Constellation Design for AirComp in Wireless Federated Learning                                                                                  Wireless federated learning (FL) relies on efficient uplink communications to aggregate model updates across distributed edge devices. Over-the-air computation (a.k.a. AirComp) has emerged as a promising approach for addressing the scalability challenge of FL over wireless links with limited communication resources. Unlike conventional methods, AirComp allows multiple edge devices to transmit uplink signals simultaneously, enabling the parameter server to directly decode the average global model. However, existing AirComp solutions are intrinsically analog, while modern wireless systems predominantly adopt digital modulations. Consequently, careful constellation designs are necessary to accurately decode the sum model updates without ambiguity. In this paper, we propose an end-to-end communication system supporting AirComp with digital modulation, aiming to overcome the challenges associated with accurate decoding of the sum signal with constellation designs. We leverage autoencoder network structures and explore the joint optimization of transmitter and receiver components. Our approach fills an important gap in the context of accurately decoding the sum signal in digital modulation-based AirComp, which can advance the deployment of FL in contemporary wireless systems.
http://w3id.org/mlsea/pwc/scientificWork/An%20Automated%20End-to-End%20Open-Source%20Software%20for%20High-Quality%20Text-to-Speech%20Dataset%20Generation                                                                                  An Automated End-to-End Open-Source Software for High-Quality Text-to-Speech Dataset Generation                                                                                  Data availability is crucial for advancing artificial intelligence applications, including voice-based technologies. As content creation, particularly in social media, experiences increasing demand, translation and text-to-speech (TTS) technologies have become essential tools. Notably, the performance of these TTS technologies is highly dependent on the quality of the training data, emphasizing the mutual dependence of data availability and technological progress. This paper introduces an end-to-end tool to generate high-quality datasets for text-to-speech (TTS) models to address this critical need for high-quality data. The contributions of this work are manifold and include: the integration of language-specific phoneme distribution into sample selection, automation of the recording process, automated and human-in-the-loop quality assurance of recordings, and processing of recordings to meet specified formats. The proposed application aims to streamline the dataset creation process for TTS models through these features, thereby facilitating advancements in voice-based technologies.
http://w3id.org/mlsea/pwc/scientificWork/An%20Autonomous%20Large%20Language%20Model%20Agent%20for%20Chemical%20Literature%20Data%20Mining                                                                                  An Autonomous Large Language Model Agent for Chemical Literature Data Mining                                                                                  Chemical synthesis, which is crucial for advancing material synthesis and drug discovery, impacts various sectors including environmental science and healthcare. The rise of technology in chemistry has generated extensive chemical data, challenging researchers to discern patterns and refine synthesis processes. Artificial intelligence (AI) helps by analyzing data to optimize synthesis and increase yields. However, AI faces challenges in processing literature data due to the unstructured format and diverse writing style of chemical literature. To overcome these difficulties, we introduce an end-to-end AI agent framework capable of high-fidelity extraction from extensive chemical literature. This AI agent employs large language models (LLMs) for prompt generation and iterative optimization. It functions as a chemistry assistant, automating data collection and analysis, thereby saving manpower and enhancing performance. Our framework's efficacy is evaluated using accuracy, recall, and F1 score of reaction condition data, and we compared our method with human experts in terms of content correctness and time efficiency. The proposed approach marks a significant advancement in automating chemical literature extraction and demonstrates the potential for AI to revolutionize data management and utilization in chemistry.
http://w3id.org/mlsea/pwc/scientificWork/An%20Effective%20Automated%20Speaking%20Assessment%20Approach%20to%20Mitigating%20Data%20Scarcity%20and%20Imbalanced%20Distribution                                                                                  An Effective Automated Speaking Assessment Approach to Mitigating Data Scarcity and Imbalanced Distribution                                                                                  Automated speaking assessment (ASA) typically involves automatic speech recognition (ASR) and hand-crafted feature extraction from the ASR transcript of a learner's speech. Recently, self-supervised learning (SSL) has shown stellar performance compared to traditional methods. However, SSL-based ASA systems are faced with at least three data-related challenges: limited annotated data, uneven distribution of learner proficiency levels and non-uniform score intervals between different CEFR proficiency levels. To address these challenges, we explore the use of two novel modeling strategies: metric-based classification and loss reweighting, leveraging distinct SSL-based embedding features. Extensive experimental results on the ICNALE benchmark dataset suggest that our approach can outperform existing strong baselines by a sizable margin, achieving a significant improvement of more than 10% in CEFR prediction accuracy.
http://w3id.org/mlsea/pwc/scientificWork/An%20Efficient%20Difference-of-Convex%20Solver%20for%20Privacy%20Funnel                                                                                  An Efficient Difference-of-Convex Solver for Privacy Funnel                                                                                  We propose an efficient solver for the privacy funnel (PF) method, leveraging its difference-of-convex (DC) structure. The proposed DC separation results in a closed-form update equation, which allows straightforward application to both known and unknown distribution settings. For known distribution case, we prove the convergence (local stationary points) of the proposed non-greedy solver, and empirically show that it outperforms the state-of-the-art approaches in characterizing the privacy-utility trade-off. The insights of our DC approach apply to unknown distribution settings where labeled empirical samples are available instead. Leveraging the insights, our alternating minimization solver satisfies the fundamental Markov relation of PF in contrast to previous variational inference-based solvers. Empirically, we evaluate the proposed solver with MNIST and Fashion-MNIST datasets. Our results show that under a comparable reconstruction quality, an adversary suffers from higher prediction error from clustering our compressed codes than that with the compared methods. Most importantly, our solver is independent to private information in inference phase contrary to the baselines.
http://w3id.org/mlsea/pwc/scientificWork/An%20Efficient%20Knowledge%20Transfer%20Strategy%20for%20Spiking%20Neural%20Networks%20from%20Static%20to%20Event%20Domain                                                                                  An Efficient Knowledge Transfer Strategy for Spiking Neural Networks from Static to Event Domain                                                                                  Spiking neural networks (SNNs) are rich in spatio-temporal dynamics and are suitable for processing event-based neuromorphic data. However, event-based datasets are usually less annotated than static datasets. This small data scale makes SNNs prone to overfitting and limits their performance. In order to improve the generalization ability of SNNs on event-based datasets, we use static images to assist SNN training on event data. In this paper, we first discuss the domain mismatch problem encountered when directly transferring networks trained on static datasets to event data. We argue that the inconsistency of feature distributions becomes a major factor hindering the effective transfer of knowledge from static images to event data. To address this problem, we propose solutions in terms of two aspects: feature distribution and training strategy. Firstly, we propose a knowledge transfer loss, which consists of domain alignment loss and spatio-temporal regularization. The domain alignment loss learns domain-invariant spatial features by reducing the marginal distribution distance between the static image and the event data. Spatio-temporal regularization provides dynamically learnable coefficients for domain alignment loss by using the output features of the event data at each time step as a regularization term. In addition, we propose a sliding training strategy, which gradually replaces static image inputs probabilistically with event data, resulting in a smoother and more stable training for the network. We validate our method on neuromorphic datasets, including N-Caltech101, CEP-DVS, and N-Omniglot. The experimental results show that our proposed method achieves better performance on all datasets compared to the current state-of-the-art methods. Code is available at https://github.com/Brain-Cog-Lab/Transfer-for-DVS.
http://w3id.org/mlsea/pwc/scientificWork/An%20Efficient%20Learning-based%20Solver%20Comparable%20to%20Metaheuristics%20for%20the%20Capacitated%20Arc%20Routing%20Problem                                                                                  An Efficient Learning-based Solver Comparable to Metaheuristics for the Capacitated Arc Routing Problem                                                                                  Recently, neural networks (NN) have made great strides in combinatorial optimization. However, they face challenges when solving the capacitated arc routing problem (CARP) which is to find the minimum-cost tour covering all required edges on a graph, while within capacity constraints. In tackling CARP, NN-based approaches tend to lag behind advanced metaheuristics, since they lack directed arc modeling and efficient learning methods tailored for complex CARP. In this paper, we introduce an NN-based solver to significantly narrow the gap with advanced metaheuristics while exhibiting superior efficiency. First, we propose the direction-aware attention model (DaAM) to incorporate directionality into the embedding process, facilitating more effective one-stage decision-making. Second, we design a supervised reinforcement learning scheme that involves supervised pre-training to establish a robust initial policy for subsequent reinforcement fine-tuning. It proves particularly valuable for solving CARP that has a higher complexity than the node routing problems (NRPs). Finally, a path optimization method is proposed to adjust the depot return positions within the path generated by DaAM. Experiments illustrate that our approach surpasses heuristics and achieves decision quality comparable to state-of-the-art metaheuristics for the first time while maintaining superior efficiency.
http://w3id.org/mlsea/pwc/scientificWork/An%20Efficient%20Rate%20Splitting%20Precoding%20Approach%20in%20Multi-User%20MISO%20FDD%20Systems                                                                                  An Efficient Rate Splitting Precoding Approach in Multi-User MISO FDD Systems                                                                                  In this work, we develop an efficient precoding strategy for a multi-user multiple-input-single output (MU MISO) system operating in frequency-division-duplex (FDD) mode, where rate splitting multiple access (RSMA) is implemented. To this end, we consider one-layer RS and show its significant impact on the system performance, specifically in the case where the channel state information (CSI) is incomplete at the transmitter. Based on a lower bound on the achievable rate that takes into account the CSI errors, we establish an augmented weighted average mean squared error (AWAMSE) algorithm for the RS setup denoted by AWAMSE-RS, where even the updates for the common and the private precoders are computed via analytical expressions, hence circumventing the need for interior-point methods. Simulation results validate the efficiency of our approach in terms of computational time and its competitiveness in terms of the achievable system throughput compared to state-of-the-art methods and non-RS setups.
http://w3id.org/mlsea/pwc/scientificWork/An%20Elementary%20Predictor%20Obtaining%20%242%20sqrt%7BT%7D%24%20Distance%20to%20Calibration                                                                                  An Elementary Predictor Obtaining $2 sqrt{T}$ Distance to Calibration                                                                                  Blasiok et al. [2023] proposed distance to calibration as a natural measure of calibration error that unlike expected calibration error (ECE) is continuous. Recently, Qiao and Zheng [2024] gave a non-constructive argument establishing the existence of an online predictor that can obtain $O( sqrt{T})$ distance to calibration in the adversarial setting, which is known to be impossible for ECE. They leave as an open problem finding an explicit, efficient algorithm. We resolve this problem and give an extremely simple, efficient, deterministic algorithm that obtains distance to calibration error at most $2 sqrt{T}$.
http://w3id.org/mlsea/pwc/scientificWork/An%20Embarrassingly%20Simple%20Defense%20Against%20Backdoor%20Attacks%20On%20SSL                                                                                  An Embarrassingly Simple Defense Against Backdoor Attacks On SSL                                                                                  Self Supervised Learning (SSL) has emerged as a powerful paradigm to tackle data landscapes with absence of human supervision. The ability to learn meaningful tasks without the use of labeled data makes SSL a popular method to manage large chunks of data in the absence of labels. However, recent work indicates SSL to be vulnerable to backdoor attacks, wherein models can be controlled, possibly maliciously, to suit an adversary's motives. Li et. al (2022) introduce a novel frequency-based backdoor attack: CTRL. They show that CTRL can be used to efficiently and stealthily gain control over a victim's model trained using SSL. In this work, we devise two defense strategies against frequency-based attacks in SSL: One applicable before model training and the second to be applied during model inference. Our first contribution utilizes the invariance property of the downstream task to defend against backdoor attacks in a generalizable fashion. We observe the ASR (Attack Success Rate) to reduce by over 60% across experiments. Our Inference-time defense relies on evasiveness of the attack and uses the luminance channel to defend against attacks. Using object classification as the downstream task for SSL, we demonstrate successful defense strategies that do not require re-training of the model. Code is available at https://github.com/Aryan-Satpathy/Backdoor.
http://w3id.org/mlsea/pwc/scientificWork/An%20Empirical%20Evaluation%20of%20Neural%20and%20Neuro-symbolic%20Approaches%20to%20Real-time%20Multimodal%20Complex%20Event%20Detection                                                                                  An Empirical Evaluation of Neural and Neuro-symbolic Approaches to Real-time Multimodal Complex Event Detection                                                                                  Robots and autonomous systems require an understanding of complex events (CEs) from sensor data to interact with their environments and humans effectively. Traditional end-to-end neural architectures, despite processing sensor data efficiently, struggle with long-duration events due to limited context sizes and reasoning capabilities. Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, promise improved performance with less data. This study addresses the gap in understanding these approaches' effectiveness in complex event detection (CED), especially in temporal reasoning. We investigate neural and neuro-symbolic architectures' performance in a multimodal CED task, analyzing IMU and acoustic data streams to recognize CE patterns. Our methodology includes (i) end-to-end neural architectures for direct CE detection from sensor embeddings, (ii) two-stage concept-based neural models mapping sensor embeddings to atomic events (AEs) before CE detection, and (iii) a neuro-symbolic approach using a symbolic finite-state machine for CE detection from AEs. Empirically, the neuro-symbolic architecture significantly surpasses purely neural models, demonstrating superior performance in CE recognition, even with extensive training data and ample temporal context for neural approaches.
http://w3id.org/mlsea/pwc/scientificWork/An%20Empirical%20Study%20of%20Speech%20Language%20Models%20for%20Prompt-Conditioned%20Speech%20Synthesis                                                                                  An Empirical Study of Speech Language Models for Prompt-Conditioned Speech Synthesis                                                                                  Speech language models (LMs) are promising for high-quality speech synthesis through in-context learning. A typical speech LM takes discrete semantic units as content and a short utterance as prompt, and synthesizes speech which preserves the content's semantics but mimics the prompt's style. However, there is no systematic understanding on how the synthesized audio is controlled by the prompt and content. In this work, we conduct an empirical study of the widely used autoregressive (AR) and non-autoregressive (NAR) speech LMs and provide insights into the prompt design and content semantic units. Our analysis reveals that heterogeneous and nonstationary prompts hurt the audio quality in contrast to the previous finding that longer prompts always lead to better synthesis. Moreover, we find that the speaker style of the synthesized audio is also affected by the content in addition to the prompt. We further show that semantic units carry rich acoustic information such as pitch, tempo, volume and speech emphasis, which might be leaked from the content to the synthesized audio.
http://w3id.org/mlsea/pwc/scientificWork/An%20Entropy-based%20Text%20Watermarking%20Detection%20Method                                                                                  An Entropy-based Text Watermarking Detection Method                                                                                  Currently, text watermarking algorithms for large language models (LLMs) can embed hidden features to texts generated by LLMs to facilitate subsequent detection, thus alleviating the problem of misuse of LLMs. Although the current text watermarking algorithms perform well in most high-entropy scenarios, its performance in low-entropy scenarios still needs to be improved. In this work, we proposed that the influence of token entropy should be fully considered in the watermark detection process, that is, the weight of each token during watermark detection should be adjusted according to its entropy, rather than setting the weights of all tokens to the same value as in previous methods. Specifically, we proposed an Entropy-based Watermark Detection (EWD) that gives higher-entropy tokens higher influence weights during watermark detection, so as to better reflect the degree of watermarking. Furthermore, the proposed detection process is training-free and fully automated. In the experiment, we found that our method can achieve better detection performance in low-entropy scenarios, and our method is also general and can be applied to texts with different entropy distributions. Our code and data will be available online.
http://w3id.org/mlsea/pwc/scientificWork/An%20Evaluation%20of%20Large%20Language%20Models%20in%20Bioinformatics%20Research                                                                                  An Evaluation of Large Language Models in Bioinformatics Research                                                                                  Large language models (LLMs) such as ChatGPT have gained considerable interest across diverse research communities. Their notable ability for text completion and generation has inaugurated a novel paradigm for language-interfaced problem solving. However, the potential and efficacy of these models in bioinformatics remain incompletely explored. In this work, we study the performance LLMs on a wide spectrum of crucial bioinformatics tasks. These tasks include the identification of potential coding regions, extraction of named entities for genes and proteins, detection of antimicrobial and anti-cancer peptides, molecular optimization, and resolution of educational bioinformatics problems. Our findings indicate that, given appropriate prompts, LLMs like GPT variants can successfully handle most of these tasks. In addition, we provide a thorough analysis of their limitations in the context of complicated bioinformatics tasks. In conclusion, we believe that this work can provide new perspectives and motivate future research in the field of LLMs applications, AI for Science and bioinformatics.
http://w3id.org/mlsea/pwc/scientificWork/An%20Execution-time-certified%20QP%20Algorithm%20for%20%24%20ell_1%24%20penalty-based%20Soft-constrained%20MPC                                                                                  An Execution-time-certified QP Algorithm for $ ell_1$ penalty-based Soft-constrained MPC                                                                                  Providing an execution time certificate and handling possible infeasibility in closed-loop are two pressing requirements of Model Predictive Control (MPC). To simultaneously meet these two requirements, this paper uses an $ ell_1$ penalty-based soft-constrained MPC formulation and innovatively transforms the resulting non-smooth QP into a box-constrained QP, which is solved by our previously proposed direct and execution-time certified algorithm with only dimension-dependent (data-independent), simple-calculated and exact number of iterations (Wu and Braatz (2023)). This approach not only overcomes the limitation of our previously proposed algorithm (Wu and Braatz (2023)), only applicable to input-constrained MPC, but also enjoys exact recovery feature (exactly recover the same solution when the original problem is feasible) of $ ell_1$ penalty-based soft-constrained MPC formulation without suffering numerical difficulty of the resulting non-smoothness. Other various real-time QP applications, not limited to MPC, would also benefit from our QP algorithm with execution-time certificate and global feasibility.
http://w3id.org/mlsea/pwc/scientificWork/An%20Experimental%20Comparison%20Of%20Multi-view%20Self-supervised%20Methods%20For%20Music%20Tagging                                                                                  An Experimental Comparison Of Multi-view Self-supervised Methods For Music Tagging                                                                                  Self-supervised learning has emerged as a powerful way to pre-train generalizable machine learning models on large amounts of unlabeled data. It is particularly compelling in the music domain, where obtaining labeled data is time-consuming, error-prone, and ambiguous. During the self-supervised process, models are trained on pretext tasks, with the primary objective of acquiring robust and informative features that can later be fine-tuned for specific downstream tasks. The choice of the pretext task is critical as it guides the model to shape the feature space with meaningful constraints for information encoding. In the context of music, most works have relied on contrastive learning or masking techniques. In this study, we expand the scope of pretext tasks applied to music by investigating and comparing the performance of new self-supervised methods for music tagging. We open-source a simple ResNet model trained on a diverse catalog of millions of tracks. Our results demonstrate that, although most of these pre-training methods result in similar downstream results, contrastive learning consistently results in better downstream performance compared to other self-supervised pre-training methods. This holds true in a limited-data downstream context.
http://w3id.org/mlsea/pwc/scientificWork/An%20Experimental%20Design%20Framework%20for%20Label-Efficient%20Supervised%20Finetuning%20of%20Large%20Language%20Models                                                                                  An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models                                                                                  Supervised finetuning (SFT) on instruction datasets has played a crucial role in achieving the remarkable zero-shot generalization capabilities observed in modern large language models (LLMs). However, the annotation efforts required to produce high quality responses for instructions are becoming prohibitively expensive, especially as the number of tasks spanned by instruction datasets continues to increase. Active learning is effective in identifying useful subsets of samples to annotate from an unlabeled pool, but its high computational cost remains a barrier to its widespread applicability in the context of LLMs. To mitigate the annotation cost of SFT and circumvent the computational bottlenecks of active learning, we propose using experimental design. Experimental design techniques select the most informative samples to label, and typically maximize some notion of uncertainty and/or diversity. In our work, we implement a framework that evaluates several existing and novel experimental design techniques and find that these methods consistently yield significant gains in label efficiency with little computational overhead. On generative tasks, our methods achieve the same generalization performance with only $50 %$ of annotation cost required by random sampling.
http://w3id.org/mlsea/pwc/scientificWork/An%20Expert%20System%20to%20Diagnose%20Pneumonia%20Using%20Fuzzy%20Logic                                                                                  An Expert System to Diagnose Pneumonia Using Fuzzy Logic                                                                                  Introduction: Pneumonia is the most common and widespread killing disease of respiratory system which is difficult to diagnose due to identical clinical signs of respiratory system. Aim: In this research, to diagnose this, a structure of a fuzzy expert system has been oﬀered. This is done in order to help general physicians and the patients make decision and also diﬀerentiate among chronic bronchitis, tuberculosis, asthma, embolism, lung cancer. Methods: This system has been created using fuzzy expert system and it has been created in 4 stages: defnition of knowledge system, design of knowledge system, implementation of system, system testing using prototype life cycle methodology. Results: The system has 97 percent sensitivity, 85 percent specifcity, 93 percent accuracy to diagnose the disease. Conclusion: Framework of the knowledge of specialist physicians using fuzzy model and its rules can help diagnose the disease correctly.
http://w3id.org/mlsea/pwc/scientificWork/An%20FPGA-Based%20Accelerator%20Enabling%20Efficient%20Support%20for%20CNNs%20with%20Arbitrary%20Kernel%20Sizes                                                                                  An FPGA-Based Accelerator Enabling Efficient Support for CNNs with Arbitrary Kernel Sizes                                                                                  Convolutional neural networks (CNNs) with large kernels, drawing inspiration from the key operations of vision transformers (ViTs), have demonstrated impressive performance in various vision-based applications. To address the issue of computational efficiency degradation in existing designs for supporting large-kernel convolutions, an FPGA-based inference accelerator is proposed for the efficient deployment of CNNs with arbitrary kernel sizes. Firstly, a Z-flow method is presented to optimize the computing data flow by maximizing data reuse opportunity. Besides, the proposed design, incorporating the kernel-segmentation (Kseg) scheme, enables extended support for large-kernel convolutions, significantly reducing the storage requirements for overlapped data. Moreover, based on the analysis of typical block structures in emerging CNNs, vertical-fused (VF) and horizontal-fused (HF) methods are developed to optimize CNN deployments from both computation and transmission perspectives. The proposed hardware accelerator, evaluated on Intel Arria 10 FPGA, achieves up to 3.91 times better DSP efficiency than prior art on the same network. Particularly, it demonstrates efficient support for large-kernel CNNs, achieving throughputs of 169.68 GOPS and 244.55 GOPS for RepLKNet-31 and PyConvResNet-50, respectively, both of which are implemented on hardware for the first time.
http://w3id.org/mlsea/pwc/scientificWork/An%20Interactive%20Agent%20Foundation%20Model                                                                                  An Interactive Agent Foundation Model                                                                                  The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications. We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks. Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework. We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare. Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area. The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effective multimodal and multi-task learning. Our approach provides a promising avenue for developing generalist, action-taking, multimodal systems.
http://w3id.org/mlsea/pwc/scientificWork/An%20Interpretable%20Client%20Decision%20Tree%20Aggregation%20process%20for%20Federated%20Learning                                                                                  An Interpretable Client Decision Tree Aggregation process for Federated Learning                                                                                  Trustworthy Artificial Intelligence solutions are essential in today's data-driven applications, prioritizing principles such as robustness, safety, transparency, explainability, and privacy among others. This has led to the emergence of Federated Learning as a solution for privacy and distributed machine learning. While decision trees, as self-explanatory models, are ideal for collaborative model training across multiple devices in resource-constrained environments such as federated learning environments for injecting interpretability in these models. Decision tree structure makes the aggregation in a federated learning environment not trivial. They require techniques that can merge their decision paths without introducing bias or overfitting while keeping the aggregated decision trees robust and generalizable. In this paper, we propose an Interpretable Client Decision Tree Aggregation process for Federated Learning scenarios that keeps the interpretability and the precision of the base decision trees used for the aggregation. This model is based on aggregating multiple decision paths of the decision trees and can be used on different decision tree types, such as ID3 and CART. We carry out the experiments within four datasets, and the analysis shows that the tree built with the model improves the local models, and outperforms the state-of-the-art.
http://w3id.org/mlsea/pwc/scientificWork/An%20Intra-BRNN%20and%20GB-RVQ%20Based%20END-TO-END%20Neural%20Audio%20Codec                                                                                  An Intra-BRNN and GB-RVQ Based END-TO-END Neural Audio Codec                                                                                  Recently, neural networks have proven to be effective in performing speech coding task at low bitrates. However, under-utilization of intra-frame correlations and the error of quantizer specifically degrade the reconstructed audio quality. To improve the coding quality, we present an end-to-end neural speech codec, namely CBRC (Convolutional and Bidirectional Recurrent neural Codec). An interleaved structure using 1D-CNN and Intra-BRNN is designed to exploit the intra-frame correlations more efficiently. Furthermore, Group-wise and Beam-search Residual Vector Quantizer (GB-RVQ) is used to reduce the quantization noise. CBRC encodes audio every 20ms with no additional latency, which is suitable for real-time communication. Experimental results demonstrate the superiority of the proposed codec when comparing CBRC at 3kbps with Opus at 12kbps.
http://w3id.org/mlsea/pwc/scientificWork/An%20LLM%20Maturity%20Model%20for%20Reliable%20and%20Transparent%20Text-to-Query                                                                                  An LLM Maturity Model for Reliable and Transparent Text-to-Query                                                                                  Recognizing the imperative to address the reliability and transparency issues of Large Language Models (LLM), this work proposes an LLM maturity model tailored for text-to-query applications. This maturity model seeks to fill the existing void in evaluating LLMs in such applications by incorporating dimensions beyond mere correctness or accuracy. Moreover, this work introduces a real-world use case from the law enforcement domain and showcases QueryIQ, an LLM-powered, domain-specific text-to-query assistant to expedite user workflows and reveal hidden relationship in data.
http://w3id.org/mlsea/pwc/scientificWork/An%20Ordering%20of%20Divergences%20for%20Variational%20Inference%20with%20Factorized%20Gaussian%20Approximations                                                                                  An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations                                                                                  Given an intractable distribution $p$, the problem of variational inference (VI) is to compute the best approximation $q$ from some more tractable family $ mathcal{Q}$. Most commonly the approximation is found by minimizing a Kullback-Leibler (KL) divergence. However, there exist other valid choices of divergences, and when $ mathcal{Q}$ does not contain~$p$, each divergence champions a different solution. We analyze how the choice of divergence affects the outcome of VI when a Gaussian with a dense covariance matrix is approximated by a Gaussian with a diagonal covariance matrix. In this setting we show that different divergences can be textit{ordered} by the amount that their variational approximations misestimate various measures of uncertainty, such as the variance, precision, and entropy. We also derive an impossibility theorem showing that no two of these measures can be simultaneously matched by a factorized approximation; hence, the choice of divergence informs which measure, if any, is correctly estimated. Our analysis covers the KL divergence, the R 'enyi divergences, and a score-based divergence that compares $ nabla log p$ and $ nabla log q$. We empirically evaluate whether these orderings hold when VI is used to approximate non-Gaussian distributions.
http://w3id.org/mlsea/pwc/scientificWork/An%20Over%20Complete%20Deep%20Learning%20Method%20for%20Inverse%20Problems                                                                                  An Over Complete Deep Learning Method for Inverse Problems                                                                                  Obtaining meaningful solutions for inverse problems has been a major challenge with many applications in science and engineering. Recent machine learning techniques based on proximal and diffusion-based methods have shown promising results. However, as we show in this work, they can also face challenges when applied to some exemplary problems. We show that similar to previous works on over-complete dictionaries, it is possible to overcome these shortcomings by embedding the solution into higher dimensions. The novelty of the work proposed is that we jointly design and learn the embedding and the regularizer for the embedding vector. We demonstrate the merit of this approach on several exemplary and common inverse problems.
http://w3id.org/mlsea/pwc/scientificWork/An%20Ultralightweight%20Hybrid%20CNN%20Based%20on%20Redundancy%20Removal%20for%20Hyperspectral%20Image%20Classification                                                                                  An Ultralightweight Hybrid CNN Based on Redundancy Removal for Hyperspectral Image Classification                                                                                  Convolutional neural network (CNN)-based hyper- spectral image (HSI) classification models often exhibit high volume and complexity. This not only poses challenges in deploying them on mobile and embedded devices due to storage and power constraints, but also introduces a dilemma between the growing demand for labeled samples and the high cost associated with manual labeling. To address these challenges, we propose an ultralightweight hybrid CNN based on redundancy removal (ULite-R2HCN), specifically designed for HSI classifica- tion in scenarios with limited samples. To reduce computational costs and enhance feature extraction effectiveness, we focus on optimizing the widely used depthwise convolution (DW-Conv) and pointwise convolution (PW-Conv) in the lightweight HSI classification model. For DW-Conv, we design a spatial convo- lution with redundancy removal (R2Spatial-Conv). This involves the design of multiscale 3-D convolution kernels with specific structures instead of 2-D convolution kernels, aiming to reduce redundant convolution kernels and extract multiscale spatial features. Simultaneously, for PW-Conv, we design a spectral convolution with redundancy removal (R2Spectral-Conv). This utilizes a “copy-splicing-grouping” structure to extract spectral features within arbitrary range intervals, effectively reducing redundant spectral extractions and capturing long-range spec- tral relationships. Numerous experiments have shown that the proposed ULite-R2HCN achieves higher classification accuracy with an ultralight volume for a few training samples. In addition, sufficient ablation experiments also verified the advanced perfor- mance of the designed R2Spatial-Conv and R2Spectral-Conv.
http://w3id.org/mlsea/pwc/scientificWork/An%20Upload-Efficient%20Scheme%20for%20Transferring%20Knowledge%20From%20a%20Server-Side%20Pre-trained%20Generator%20to%20Clients%20in%20Heterogeneous%20Federated%20Learning                                                                                  An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side Pre-trained Generator to Clients in Heterogeneous Federated Learning                                                                                  Heterogeneous Federated Learning (HtFL) enables collaborative learning on multiple clients with different model architectures while preserving privacy. Despite recent research progress, knowledge sharing in HtFL is still difficult due to data and model heterogeneity. To tackle this issue, we leverage the knowledge stored in pre-trained generators and propose a new upload-efficient knowledge transfer scheme called Federated Knowledge-Transfer Loop (FedKTL). Our FedKTL can produce client-task-related prototypical image-vector pairs via the generator's inference on the server. With these pairs, each client can transfer pre-existing knowledge from the generator to its local model through an additional supervised local task. We conduct extensive experiments on four datasets under two types of data heterogeneity with 14 kinds of models including CNNs and ViTs. Results show that our upload-efficient FedKTL surpasses seven state-of-the-art methods by up to 7.31% in accuracy. Moreover, our knowledge transfer scheme is applicable in scenarios with only one edge client. Code: https://github.com/TsingZ0/FedKTL
http://w3id.org/mlsea/pwc/scientificWork/An%20advanced%201D%20physics-based%20model%20for%20PEM%20hydrogen%20fuel%20cells%20with%20enhanced%20overvoltage%20prediction                                                                                  An advanced 1D physics-based model for PEM hydrogen fuel cells with enhanced overvoltage prediction                                                                                  A one-dimensional, dynamic, two-phase, isothermal and finite-difference model of proton exchange membrane fuel cell (PEMFC) systems has been developed. It is distinct from most existing models which are either fast but imprecise, such as lumped-parameter models, or detailed but computationally intensive, such as computational fluid dynamics models. This model, partially validated using experimental polarisation curves, provides a comprehensive description of cell internal states while maintaining a low computational burden. Additionally, a new physical quantity, named the limit liquid water saturation coefficient ($s_{lim}$), is introduced in the overvoltage calculation equation. This quantity replaces the limit current density coefficient ($i_{lim}$) and establishes a connection between the voltage drop at high current densities, the amount of liquid water present in the catalyst layers of the cell, and the operating conditions. At high current densities, a significant amount of liquid water is generated, which limits the accessibility of reactants to certain triple point zones within the catalyst layers by covering them. This, in turn, increases overpotential. It has also been observed that $s_{lim}$ is influenced, at minimum, by the gas pressure imposed by the operator.
http://w3id.org/mlsea/pwc/scientificWork/An%20agent-based%20modelling%20framework%20to%20study%20growth%20mechanisms%20in%20EGFR-L858R%20mutant%20alveolar%20type%20II%20cells                                                                                  An agent-based modelling framework to study growth mechanisms in EGFR-L858R mutant alveolar type II cells                                                                                  Mutations in the epidermal growth factor receptor (EGFR) are common in non-small cell lung cancer (NSCLC), particularly in never-smoker patients. However, these mutations are not always carcinogenic, and have recently been reported in histologically normal lung tissue from patients with and without lung cancer. To investigate the outcome of EGFR mutation in healthy lung stem cells, we grew murine alveolar type-II organoids monoclonally in a 3D Matrigel. Our experiments showed that the textit{EGFR-L858R} mutation induced a change in organoid structure: mutated organoids displayed more `budding', in comparison to non-mutant controls, which were nearly spherical. We perform on-lattice computational simulations, which suggest that this can be explained by the concentration of division amongst a small number of cells on the surface of the organoid, which may arise from several possible biological mechanisms. These results suggest that the L858R mutation produces structures which expand quickly from surface protrusions. We are currently unable to distinguish the cell-based mechanisms that lead to this spatial heterogeneity in growth, but suggest a number of future experiments which could be used to do so. We suggest that the likelihood of L858R-fuelled tumorigenesis is affected not just by random fluctuations in cell fitness, but by whether the mutation arises in a spatial environment that allows mutant cells to reproduce without being forced to encounter each other. These data may have implications for cancer prevention strategies and for understanding NSCLC progression.
http://w3id.org/mlsea/pwc/scientificWork/An%20empirical%20model%20of%20fleet%20modernization%3A%20on%20the%20relationship%20between%20market%20concentration%20and%20innovation%20adoption%20in%20the%20Brazilian%20airline%20industry                                                                                  An empirical model of fleet modernization: on the relationship between market concentration and innovation adoption in the Brazilian airline industry                                                                                  The modernization of an airline's fleet can reduce its operating costs, improve the perceived quality of service offered to passengers, and mitigate emissions. The present paper investigates the market incentives that airlines have to adopt technological innovation from manufacturers by acquiring new generation aircraft. We develop an econometric model of fleet modernization in the Brazilian commercial aviation over two decades. We examine the hypothesis of an inverted-U relationship between market concentration and fleet modernization and find evidence that both the extremes of competition and concentration may inhibit innovation adoption by carriers. We find limited evidence associating either hubbing activity or low-cost carriers with the more intense introduction of new types of aircraft models and variants in the industry. Finally, our results suggest that energy cost rises may provoke boosts in fleet modernization in the long term, with carriers possibly targeting more eco-efficient operations up to two years after an upsurge in fuel price.
http://w3id.org/mlsea/pwc/scientificWork/An%20enhanced%20Teaching-Learning-Based%20Optimization%20%28TLBO%29%20with%20Grey%20Wolf%20Optimizer%20%28GWO%29%20for%20text%20feature%20selection%20and%20clustering                                                                                  An enhanced Teaching-Learning-Based Optimization (TLBO) with Grey Wolf Optimizer (GWO) for text feature selection and clustering                                                                                  Text document clustering can play a vital role in organizing and handling the everincreasing number of text documents. Uninformative and redundant features included in large text documents reduce the effectiveness of the clustering algorithm. Feature selection (FS) is a well-known technique for removing these features. Since FS can be formulated as an optimization problem, various meta-heuristic algorithms have been employed to solve it. Teaching-Learning-Based Optimization (TLBO) is a novel meta-heuristic algorithm that benefits from the low number of parameters and fast convergence. A hybrid method can simultaneously benefit from the advantages of TLBO and tackle the possible entrapment in the local optimum. By proposing a hybrid of TLBO, Grey Wolf Optimizer (GWO), and Genetic Algorithm (GA) operators, this paper suggests a filter-based FS algorithm (TLBO-GWO). Six benchmark datasets are selected, and TLBO-GWO is compared with three recently proposed FS algorithms with similar approaches, the main TLBO and GWO. The comparison is conducted based on clustering evaluation measures, convergence behavior, and dimension reduction, and is validated using statistical tests. The results reveal that TLBO-GWO can significantly enhance the effectiveness of the text clustering technique (K-means).
http://w3id.org/mlsea/pwc/scientificWork/An%20evaluation%20framework%20for%20synthetic%20data%20generation%20models                                                                                  An evaluation framework for synthetic data generation models                                                                                  Nowadays, the use of synthetic data has gained popularity as a cost-efficient strategy for enhancing data augmentation for improving machine learning models performance as well as addressing concerns related to sensitive data privacy. Therefore, the necessity of ensuring quality of generated synthetic data, in terms of accurate representation of real data, consists of primary importance. In this work, we present a new framework for evaluating synthetic data generation models' ability for developing high-quality synthetic data. The proposed approach is able to provide strong statistical and theoretical information about the evaluation framework and the compared models' ranking. Two use case scenarios demonstrate the applicability of the proposed framework for evaluating the ability of synthetic data generation models to generated high quality data. The implementation code can be found in https://github.com/novelcore/synthetic_data_evaluation_framework.
http://w3id.org/mlsea/pwc/scientificWork/An%20image-computable%20model%20of%20speeded%20decision-making                                                                                  An image-computable model of speeded decision-making                                                                                  Evidence accumulation models (EAMs) are the dominant framework for modeling response time (RT) data from speeded decision-making tasks. While providing a good quantitative description of RT data in terms of abstract perceptual representations, EAMs do not explain how the visual system extracts these representations in the first place. To address this limitation, we introduce the visual accumulator model (VAM), in which convolutional neural network models of visual processing and traditional EAMs are jointly fitted to trial-level RTs and raw (pixel-space) visual stimuli from individual subjects. Models fitted to large-scale cognitive training data from a stylized flanker task captured individual differences in congruency effects, RTs, and accuracy. We find evidence that the selection of task-relevant information occurs through the orthogonalization of relevant and irrelevant representations, demonstrating how our framework can be used to relate visual representations to behavioral outputs. Together, our work provides a probabilistic framework for both constraining neural network models of vision with behavioral data and studying how the visual system extracts representations that guide decisions.
http://w3id.org/mlsea/pwc/scientificWork/An%20improved%20tabular%20data%20generator%20with%20VAE-GMM%20integration                                                                                  An improved tabular data generator with VAE-GMM integration                                                                                  The rising use of machine learning in various fields requires robust methods to create synthetic tabular data. Data should preserve key characteristics while addressing data scarcity challenges. Current approaches based on Generative Adversarial Networks, such as the state-of-the-art CTGAN model, struggle with the complex structures inherent in tabular data. These data often contain both continuous and discrete features with non-Gaussian distributions. Therefore, we propose a novel Variational Autoencoder (VAE)-based model that addresses these limitations. Inspired by the TVAE model, our approach incorporates a Bayesian Gaussian Mixture model (BGM) within the VAE architecture. This avoids the limitations imposed by assuming a strictly Gaussian latent space, allowing for a more accurate representation of the underlying data distribution during data generation. Furthermore, our model offers enhanced flexibility by allowing the use of various differentiable distributions for individual features, making it possible to handle both continuous and discrete data types. We thoroughly validate our model on three real-world datasets with mixed data types, including two medically relevant ones, based on their resemblance and utility. This evaluation demonstrates significant outperformance against CTGAN and TVAE, establishing its potential as a valuable tool for generating synthetic tabular data in various domains, particularly in healthcare.
http://w3id.org/mlsea/pwc/scientificWork/An%20inclusive%20review%20on%20deep%20learning%20techniques%20and%20their%20scope%20in%20handwriting%20recognition                                                                                  An inclusive review on deep learning techniques and their scope in handwriting recognition                                                                                  Deep learning expresses a category of machine learning algorithms that have the capability to combine raw inputs into intermediate features layers. These deep learning algorithms have demonstrated great results in different fields. Deep learning has particularly witnessed for a great achievement of human level performance across a number of domains in computer vision and pattern recognition. For the achievement of state-of-the-art performances in diverse domains, the deep learning used different architectures and these architectures used activation functions to perform various computations between hidden and output layers of any architecture. This paper presents a survey on the existing studies of deep learning in handwriting recognition field. Even though the recent progress indicates that the deep learning methods has provided valuable means for speeding up or proving accurate results in handwriting recognition, but following from the extensive literature survey, the present study finds that the deep learning has yet to revolutionize more and has to resolve many of the most pressing challenges in this field, but promising advances have been made on the prior state of the art. Additionally, an inadequate availability of labelled data to train presents problems in this domain. Nevertheless, the present handwriting recognition survey foresees deep learning enabling changes at both bench and bedside with the potential to transform several domains as image processing, speech recognition, computer vision, machine translation, robotics and control, medical imaging, medical information processing, bio-informatics, natural language processing, cyber security, and many others.
http://w3id.org/mlsea/pwc/scientificWork/An%20innovative%20in%20silico%20model%20of%20the%20oral%20mucosa%20reveals%20the%20impact%20of%20extracellular%20spaces%20on%20chemical%20permeation%20through%20epithelium                                                                                  An innovative in silico model of the oral mucosa reveals the impact of extracellular spaces on chemical permeation through epithelium                                                                                  In pharmaceutical therapeutic design or toxicology, accurately predicting the permeation of chemicals through human epithelial tissues is crucial, where permeation is significantly influenced by the tissue's cellular architecture. Current mathematical models for multi-layered epithelium such as the oral mucosa only use simplistic 'bricks and mortar' geometries and therefore do not account for the complex cellular architecture of these tissues at the microscale level, such as the extensive plasma membrane convolutions that define the extracellular spaces between cells. Chemicals often permeate tissues via this paracellular route, meaning that permeation is underestimated. To address this, measurements of human buccal mucosal tissue were conducted to ascertain the width and tortuosity of extracellular spaces across the epithelium. Using mechanistic mathematical modelling, we show that the convoluted geometry of extracellular spaces significantly impacts chemical permeation and that this can be approximated, provided that extracellular tortuosity is accounted for. We next developed an advanced physically-relevant in silico model of oral mucosal chemical permeation using partial differential equations, fitted to chemical permeation in vitro assays on tissue-engineered human oral mucosa. Tissue geometries were measured and captured in silico, and permeation examined and predicted for chemicals with different physicochemical properties. The effect of altering the extracellular space to mimic permeation enhancers was also assessed by perturbing the in silico model. This novel in vitro-in silico approach has the potential to expedite pharmaceutical innovation for testing oromucosal chemical permeation, providing a more accurate, physiologically-relevant model which can reduce animal testing with early screening based on chemical properties.
http://w3id.org/mlsea/pwc/scientificWork/An%20introduction%20to%20graphical%20tensor%20notation%20for%20mechanistic%20interpretability                                                                                  An introduction to graphical tensor notation for mechanistic interpretability                                                                                  Graphical tensor notation is a simple way of denoting linear operations on tensors, originating from physics. Modern deep learning consists almost entirely of operations on or between tensors, so easily understanding tensor operations is quite important for understanding these systems. This is especially true when attempting to reverse-engineer the algorithms learned by a neural network in order to understand its behavior: a field known as mechanistic interpretability. It's often easy to get confused about which operations are happening between tensors and lose sight of the overall structure, but graphical tensor notation makes it easier to parse things at a glance and see interesting equivalences. The first half of this document introduces the notation and applies it to some decompositions (SVD, CP, Tucker, and tensor network decompositions), while the second half applies it to some existing some foundational approaches for mechanistically understanding language models, loosely following ``A Mathematical Framework for Transformer Circuits'', then constructing an example ``induction head'' circuit in graphical tensor notation.
http://w3id.org/mlsea/pwc/scientificWork/An%20ontology%20alignment%20method%20with%20user%20intervention%20using%20compact%20differential%20evolution%20with%20adaptive%20parameter%20control                                                                                  An ontology alignment method with user intervention using compact differential evolution with adaptive parameter control                                                                                  User interaction is one of the most effective ways to improve the ontology alignment quality. However, this approach faces the challenge of how users can participate effectively in the matching process. To solve this challenge. In this paper, an interactive ontology alignment approach using compact differential evolution algorithm with adaptive parameter control (IOACDE) is proposed. In this method, the ontology alignment process is modeled as an interactive optimization problem and users are allowed to intervene in matching in two ways. One is that the mapping suggestions generated by IOACDE as a complete candidate alignment is evaluated by user during optimization process. The other is that the user ameliorates the alignment results by evaluating single mapping after the automatic matching process. To demonstrate the effectiveness of the proposed algorithm, the neural embedding model and K nearest neighbor (KNN) is employed to simulate user for the ontologies of the real world. The experimental results show that the proposed interactive approach can improve the alignment quality compared to the non-interactive. Compared with the state-of-the-art methods from OAEI, the results show that the proposed algorithm has a better performance under the same error rate.
http://w3id.org/mlsea/pwc/scientificWork/An%20open%20dataset%20for%20oracle%20bone%20script%20recognition%20and%20decipherment                                                                                  An open dataset for oracle bone script recognition and decipherment                                                                                  Oracle Bone Script (OBS), one of the earliest known forms of ancient Chinese writing, holds invaluable insights into the humanities and geography of the Shang Dynasty, dating back 3,000 years. The immense historical and cultural significance of these writings cannot be overstated. However, the passage of time has obscured much of their meaning, presenting a significant challenge in deciphering these ancient texts. With the advent of Artificial Intelligence (AI), employing AI to assist in interpreting OBS has become a feasible option. Yet, progress in this area has been hindered by a lack of high-quality datasets. To address this issue, this paper details the creation of the HUST-OBS dataset. This dataset encompasses 77,064 images of 1,588 individual deciphered scripts and 62,989 images of 9,411 undeciphered characters, with a total of 140,053 images, compiled from diverse sources. Additionally, all images and labels have been reviewed and corrected by experts in oracle bone studies. The hope is that this dataset could inspire and assist future research in deciphering those unknown OBS.
http://w3id.org/mlsea/pwc/scientificWork/An%C3%A1lise%20das%20estrat%C3%A9gias%20de%20planejamento%20de%20tempos%20de%20voo%20pelas%20companhias%20a%C3%A9reas                                                                                  Análise das estratégias de planejamento de tempos de voo pelas companhias aéreas                                                                                  This study explores the approaches used by airlines in setting flight times. It highlights the need to balance operational and strategic factors, such as optimizing the use of resources - including aircraft, crew, and fuel - and managing the risks related to delays and congestion. The work details a national analysis focused on domestic flights, investigating the factors that influence companies to adjust scheduled flight times and the impact of this practice on punctuality. The results indicate that decisions about flight time are influenced by both operational and strategic aspects, being affected by competition and the sector's policies on punctuality and slot allocation. Furthermore, it was found that adding extra time is an effective strategy for reducing delays, although it may conceal system deficiencies.
http://w3id.org/mlsea/pwc/scientificWork/Analyizing%20the%20Conjunction%20Fallacy%20as%20a%20Fact                                                                                  Analyizing the Conjunction Fallacy as a Fact                                                                                  Since the seminal paper by Tversky and Kahneman, the conjunction fallacy has been the subject of multiple debates and become a fundamental challenge for cognitive theories in decision-making. In this article, we take a rather uncommon perspective on this phenomenon. Instead of trying to explain the nature or causes of the conjunction fallacy (intensional definition), we analyze its range of factual possibilities (extensional definition). We show that the majority of research on the conjunction fallacy, according to our sample of experiments reviewed which covers literature between 1983 and 2016, has focused on a narrow part of the a priori factual possibilities, implying that explanations of the conjunction fallacy are fundamentally biased by the short scope of possibilities explored. The latter is a rather curious aspect of the research evolution in the conjunction fallacy considering that the very nature of it is motivated by extensional considerations.
http://w3id.org/mlsea/pwc/scientificWork/Analysing%20The%20Impact%20of%20Sequence%20Composition%20on%20Language%20Model%20Pre-Training                                                                                  Analysing The Impact of Sequence Composition on Language Model Pre-Training                                                                                  Most language model pre-training frameworks concatenate multiple documents into fixed-length sequences and use causal masking to compute the likelihood of each token given its context; this strategy is widely adopted due to its simplicity and efficiency. However, to this day, the influence of the pre-training sequence composition strategy on the generalisation properties of the model remains under-explored. In this work, we find that applying causal masking can lead to the inclusion of distracting information from previous documents during pre-training, which negatively impacts the performance of the models on language modelling and downstream tasks. In intra-document causal masking, the likelihood of each token is only conditioned on the previous tokens in the same document, eliminating potential distracting information from previous documents and significantly improving performance. Furthermore, we find that concatenating related documents can reduce some potential distractions during pre-training, and our proposed efficient retrieval-based sequence construction method, BM25Chunk, can improve in-context learning (+11.6 %), knowledge memorisation (+9.8 %), and context utilisation (+7.2 %) abilities of language models without sacrificing efficiency.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20and%20Approximate%20Inference%20of%20Large%20Random%20Kronecker%20Graphs                                                                                  Analysis and Approximate Inference of Large Random Kronecker Graphs                                                                                  Random graph models are playing an increasingly important role in various fields ranging from social networks, telecommunication systems, to physiologic and biological networks. Within this landscape, the random Kronecker graph model, emerges as a prominent framework for scrutinizing intricate real-world networks. In this paper, we investigate large random Kronecker graphs, i.e., the number of graph vertices $N$ is large. Built upon recent advances in random matrix theory (RMT) and high-dimensional statistics, we prove that the adjacency of a large random Kronecker graph can be decomposed, in a spectral norm sense, into two parts: a small-rank (of rank $O( log N)$) signal matrix that is linear in the graph parameters and a zero-mean random noise matrix. Based on this result, we propose a ``denoise-and-solve'' approach to infer the key graph parameters, with significantly reduced computational complexity. Experiments on both graph inference and classification are presented to evaluate the our proposed method. In both tasks, the proposed approach yields comparable or advantageous performance, than widely-used graph inference (e.g., KronFit) and graph neural net baselines, at a time cost that scales linearly as the graph size $N$.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20and%20Mortality%20Prediction%20using%20Multiclass%20Classification%20for%20Older%20Adults%20with%20Type%202%20Diabetes                                                                                  Analysis and Mortality Prediction using Multiclass Classification for Older Adults with Type 2 Diabetes                                                                                  Designing proper treatment plans to manage diabetes requires health practitioners to pay heed to the individuals remaining life along with the comorbidities affecting them. Older adults with Type 2 Diabetes Mellitus (T2DM) are prone to experience premature death or even hypoglycaemia. The structured dataset utilized has 68 potential mortality predictors for 275,190 diabetic U.S. military Veterans aged 65 years or older. A new target variable is invented by combining the two original target variables. Outliers are handled by discretizing the continuous variables. Categorical variables have been dummy encoded. Class balancing is achieved by random under-sampling. A benchmark regression model is built using Multinomial Logistic Regression with LASSO. Chi-Squared and Information Gain are the filter-based feature selection techniques utilized. Classifiers such as Multinomial Logistic Regression, Random Forest, Extreme Gradient Boosting (XGBoost), and One-vs-Rest classifier are employed to build various models. Contrary to expectations, all the models have constantly underperformed. XGBoost has given the highest accuracy of 53.03 percent with Chi-Squared feature selection. All the models have consistently shown an acceptable performance for Class 3 (remaining life is more than 10 years), significantly low for Class 1 (remaining life is up to 5 years), and the worst for Class 2 (remaining life is more than 5 but up to 10 years). Features analysis has deduced that almost all input variables are associated with multiple target classes. The high dimensionality of the input data after dummy encoding seems to have confused the models, leading to misclassifications. The approach taken in this study is ineffective in producing a high-performing predictive model but lays a foundation as this problem has never been viewed from a multiclass classification perspective.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20Distributed%20Optimization%20Algorithms%20on%20a%20Real%20Processing-In-Memory%20System                                                                                  Analysis of Distributed Optimization Algorithms on a Real Processing-In-Memory System                                                                                  Machine Learning (ML) training on large-scale datasets is a very expensive and time-consuming workload. Processor-centric architectures (e.g., CPU, GPU) commonly used for modern ML training workloads are limited by the data movement bottleneck, i.e., due to repeatedly accessing the training dataset. As a result, processor-centric systems suffer from performance degradation and high energy consumption. Processing-In-Memory (PIM) is a promising solution to alleviate the data movement bottleneck by placing the computation mechanisms inside or near memory. Our goal is to understand the capabilities and characteristics of popular distributed optimization algorithms on real-world PIM architectures to accelerate data-intensive ML training workloads. To this end, we 1) implement several representative centralized distributed optimization algorithms on UPMEM's real-world general-purpose PIM system, 2) rigorously evaluate these algorithms for ML training on large-scale datasets in terms of performance, accuracy, and scalability, 3) compare to conventional CPU and GPU baselines, and 4) discuss implications for future PIM hardware and the need to shift to an algorithm-hardware codesign perspective to accommodate decentralized distributed optimization algorithms. Our results demonstrate three major findings: 1) Modern general-purpose PIM architectures can be a viable alternative to state-of-the-art CPUs and GPUs for many memory-bound ML training workloads, when operations and datatypes are natively supported by PIM hardware, 2) the importance of carefully choosing the optimization algorithm that best fit PIM, and 3) contrary to popular belief, contemporary PIM architectures do not scale approximately linearly with the number of nodes for many data-intensive ML training workloads. To facilitate future research, we aim to open-source our complete codebase.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20Evolutionary%20Diversity%20Optimisation%20for%20the%20Maximum%20Matching%20Problem                                                                                  Analysis of Evolutionary Diversity Optimisation for the Maximum Matching Problem                                                                                  This paper explores the enhancement of solution diversity in evolutionary algorithms (EAs) for the maximum matching problem, concentrating on complete bipartite graphs and paths. We adopt binary string encoding for matchings and use Hamming distance to measure diversity, aiming for its maximization. Our study centers on the $( mu+1)$-EA and $2P-EA_D$, which are applied to optimize diversity. We provide a rigorous theoretical and empirical analysis of these algorithms. For complete bipartite graphs, our runtime analysis shows that, with a reasonably small $ mu$, the $( mu+1)$-EA achieves maximal diversity with an expected runtime of $O( mu^2 m^4 log(m))$ for the small gap case (where the population size $ mu$ is less than the difference in the sizes of the bipartite partitions) and $O( mu^2 m^2 log(m))$ otherwise. For paths, we establish an upper runtime bound of $O( mu^3 m^3)$. The $2P-EA_D$ displays stronger performance, with bounds of $O( mu^2 m^2 log(m))$ for the small gap case, $O( mu^2 n^2 log(n))$ otherwise, and $O( mu^3 m^2)$ for paths. Here, $n$ represents the total number of vertices and $m$ the number of edges. Our empirical studies, which examine the scaling behavior with respect to $m$ and $ mu$, complement these theoretical insights and suggest potential for further refinement of the runtime bounds.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20Neural%20Video%20Compression%20Networks%20for%20360-Degree%20Video%20Coding                                                                                  Analysis of Neural Video Compression Networks for 360-Degree Video Coding                                                                                  With the increasing efforts of bringing high-quality virtual reality technologies into the market, efficient 360-degree video compression gains in importance. As such, the state-of-the-art H.266/VVC video coding standard integrates dedicated tools for 360-degree video, and considerable efforts have been put into designing 360-degree projection formats with improved compression efficiency. For the fast-evolving field of neural video compression networks (NVCs), the effects of different 360-degree projection formats on the overall compression performance have not yet been investigated. It is thus unclear, whether a resampling from the conventional equirectangular projection (ERP) to other projection formats yields similar gains for NVCs as for hybrid video codecs, and which formats perform best. In this paper, we analyze several generations of NVCs and an extensive set of 360-degree projection formats with respect to their compression performance for 360-degree video. Based on our analysis, we find that projection format resampling yields significant improvements in compression performance also for NVCs. The adjusted cubemap projection (ACP) and equatorial cylindrical projection (ECP) show to perform best and achieve rate savings of more than 55% compared to ERP based on WS-PSNR for the most recent NVC. Remarkably, the observed rate savings are higher than for H.266/VVC, emphasizing the importance of projection format resampling for NVCs.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20Privacy%20Leakage%20in%20Federated%20Large%20Language%20Models                                                                                  Analysis of Privacy Leakage in Federated Large Language Models                                                                                  With the rapid adoption of Federated Learning (FL) as the training and tuning protocol for applications utilizing Large Language Models (LLMs), recent research highlights the need for significant modifications to FL to accommodate the large-scale of LLMs. While substantial adjustments to the protocol have been introduced as a response, comprehensive privacy analysis for the adapted FL protocol is currently lacking. To address this gap, our work delves into an extensive examination of the privacy analysis of FL when used for training LLMs, both from theoretical and practical perspectives. In particular, we design two active membership inference attacks with guaranteed theoretical success rates to assess the privacy leakages of various adapted FL configurations. Our theoretical findings are translated into practical attacks, revealing substantial privacy vulnerabilities in popular LLMs, including BERT, RoBERTa, DistilBERT, and OpenAI's GPTs, across multiple real-world language datasets. Additionally, we conduct thorough experiments to evaluate the privacy leakage of these models when data is protected by state-of-the-art differential privacy (DP) mechanisms.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20Systems%27%20Performance%20in%20Natural%20Language%20Processing%20Competitions                                                                                  Analysis of Systems' Performance in Natural Language Processing Competitions                                                                                  Collaborative competitions have gained popularity in the scientific and technological fields. These competitions involve defining tasks, selecting evaluation scores, and devising result verification methods. In the standard scenario, participants receive a training set and are expected to provide a solution for a held-out dataset kept by organizers. An essential challenge for organizers arises when comparing algorithms' performance, assessing multiple participants, and ranking them. Statistical tools are often used for this purpose; however, traditional statistical methods often fail to capture decisive differences between systems' performance. This manuscript describes an evaluation methodology for statistically analyzing competition results and competition. The methodology is designed to be universally applicable; however, it is illustrated using eight natural language competitions as case studies involving classification and regression problems. The proposed methodology offers several advantages, including off-the-shell comparisons with correction mechanisms and the inclusion of confidence intervals. Furthermore, we introduce metrics that allow organizers to assess the difficulty of competitions. Our analysis shows the potential usefulness of our methodology for effectively evaluating competition results.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20a%20Spatially%20Correlated%20Vehicular%20Network%20Assisted%20by%20Cox-distributed%20Vehicle%20Relays                                                                                  Analysis of a Spatially Correlated Vehicular Network Assisted by Cox-distributed Vehicle Relays                                                                                  In vehicle-to-all (V2X) communications, roadside units (RSUs) play an essential role in connecting various network devices. In some cases, users may not be well-served by RSUs due to congestion, attenuation, or interference. In these cases, vehicular relays associated with RSUs can be used to serve those users. This paper uses stochastic geometry to model and analyze a spatially correlated heterogeneous vehicular network where both RSUs and vehicular relays serve network users such as pedestrians or other vehicles. We present an analytical model where the spatial correlation between roads, RSUs, relays, and users is systematically modeled via Cox point processes. Assuming users are associated with either RSUs or relays, we derive the association probability and the coverage probability of the typical user. Then, we derive the user throughput by considering interactions of links unique to the proposed network. This paper gives practical insights into designing spatially correlated vehicular networks assisted by vehicle relays. For instance, we express the network performance such as the user association, SIR coverage probability, and the network throughput as the functions of network key geometric variables. In practice, this helps one to optimize the network so as to achieve ultra reliability or maximum user throughput of a spatially correlated vehicular networks by varying key aspects such as the relay density or the bandwidth for relays.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20an%20aggregate%20loss%20model%20in%20a%20Markov%20renewal%20regime                                                                                  Analysis of an aggregate loss model in a Markov renewal regime                                                                                  In this article we consider an aggregate loss model with dependent losses. The losses occurrence process is governed by a two-state Markovian arrival process (MAP2), a Markov renewal process process that allows for (1) correlated inter-losses times, (2) non-exponentially distributed inter-losses times and, (3) overdisperse losses counts. Some quantities of interest to measure persistence in the loss occurrence process are obtained. Given a real operational risk database, the aggregate loss model is estimated by fitting separately the inter-losses times and severities. The MAP2 is estimated via direct maximization of the likelihood function, and severities are modeled by the heavy-tailed, double-Pareto Lognormal distribution. In comparison with the fit provided by the Poisson process, the results point out that taking into account the dependence and overdispersion in the inter-losses times distribution leads to higher capital charges.
http://w3id.org/mlsea/pwc/scientificWork/Analysis%20of%20the%20Two-Step%20Heterogeneous%20Transfer%20Learning%20for%20Laryngeal%20Blood%20Vessel%20Classification%3A%20Issue%20and%20Improvement                                                                                  Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal Blood Vessel Classification: Issue and Improvement                                                                                  Accurate classification of laryngeal vascular as benign or malignant is crucial for early detection of laryngeal cancer. However, organizations with limited access to laryngeal vascular images face challenges due to the lack of large and homogeneous public datasets for effective learning. Distinguished from the most familiar works, which directly transfer the ImageNet pre-trained models to the target domain for fine-tuning, this work pioneers exploring two-step heterogeneous transfer learning (THTL) for laryngeal lesion classification with nine deep-learning models, utilizing the diabetic retinopathy color fundus images, semantically non-identical yet vascular images, as the intermediate domain. Attention visualization technique, Layer Class Activate Map (LayerCAM), reveals a novel finding that yet the intermediate and the target domain both reflect vascular structure to a certain extent, the prevalent radial vascular pattern in the intermediate domain prevents learning the features of twisted and tangled vessels that distinguish the malignant class in the target domain, summarizes a vital rule for laryngeal lesion classification using THTL. To address this, we introduce an enhanced fine-tuning strategy in THTL called Step-Wise Fine-Tuning (SWFT) and apply it to the ResNet models. SWFT progressively refines model performance by accumulating fine-tuning layers from back to front, guided by the visualization results of LayerCAM. Comparison with the original THTL approach shows significant improvements. For ResNet18, the accuracy and malignant recall increases by 26.1% and 79.8%, respectively, while for ResNet50, these indicators improve by 20.4% and 62.2%, respectively.
http://w3id.org/mlsea/pwc/scientificWork/Analytical%20results%20for%20uncertainty%20propagation%20through%20trained%20machine%20learning%20regression%20models                                                                                  Analytical results for uncertainty propagation through trained machine learning regression models                                                                                  Machine learning (ML) models are increasingly being used in metrology applications. However, for ML models to be credible in a metrology context they should be accompanied by principled uncertainty quantification. This paper addresses the challenge of uncertainty propagation through trained/fixed machine learning (ML) regression models. Analytical expressions for the mean and variance of the model output are obtained/presented for certain input data distributions and for a variety of ML models. Our results cover several popular ML models including linear regression, penalised linear regression, kernel ridge regression, Gaussian Processes (GPs), support vector machines (SVMs) and relevance vector machines (RVMs). We present numerical experiments in which we validate our methods and compare them with a Monte Carlo approach from a computational efficiency point of view. We also illustrate our methods in the context of a metrology application, namely modelling the state-of-health of lithium-ion cells based upon Electrical Impedance Spectroscopy (EIS) data
http://w3id.org/mlsea/pwc/scientificWork/Analytical%20valuation%20of%20vulnerable%20derivative%20claims%20with%20bilateral%20cash%20flows%20under%20credit%2C%20funding%20and%20wrong-way%20risk                                                                                  Analytical valuation of vulnerable derivative claims with bilateral cash flows under credit, funding and wrong-way risk                                                                                  We study the problem of valuing and hedging a vulnerable derivative claim with bilateral cash flows between two counterparties in the presence of asymmetric funding costs, defaults and wrong way risk (WWR). We characterize the pre-default claim value as the solution to a non-linear Cauchy problem. We show an explicit stochastic representation of the solution exists under a funding policy which linearises the Cauchy PDE. We apply this framework to the valuation of a vulnerable equity forward and show it can be represented as a portfolio of European options. Despite the complexity of the model, we prove the forward's value admits an analytical formula involving only elementary functions and Gaussian integrals. Based on this explicit formula, numerical analysis demonstrates WWR has a significant impact even under benign assumptions: with a parameter configuration less punitive than that representative of Archegos AM default, we find WWR can shift values for vulnerable forwards by 100bps of notional, while peak exposures increase by 25% of notional. This framework is the first to apply to contracts with bilateral cash flows in the presence of credit, funding and WWR, resulting in a non-linear valuation formula which admits a closed-form solution under a suitable funding policy.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Currency%20Fluctuations%3A%20A%20Comparative%20Study%20of%20GARCH%2C%20EWMA%2C%20and%20IV%20Models%20for%20GBP%2FUSD%20and%20EUR%2FGBP%20Pairs                                                                                  Analyzing Currency Fluctuations: A Comparative Study of GARCH, EWMA, and IV Models for GBP/USD and EUR/GBP Pairs                                                                                  In this study, we examine the fluctuation in the value of the Great Britain Pound (GBP). We focus particularly on its relationship with the United States Dollar (USD) and the Euro (EUR) currency pairs. Utilizing data from June 15, 2018, to June 15, 2023, we apply various mathematical models to assess their effectiveness in predicting the 20-day variation in the pairs' daily returns. Our analysis involves the implementation of Exponentially Weighted Moving Average (EWMA), Generalized Autoregressive Conditional Heteroskedasticity (GARCH) models, and Implied Volatility (IV) models. To evaluate their performance, we compare the accuracy of their predictions using Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) metrics. We delve into the intricacies of GARCH models, examining their statistical characteristics when applied to the provided dataset. Our findings suggest the existence of asymmetric returns in the EUR/GBP pair, while such evidence is inconclusive for the GBP/USD pair. Additionally, we observe that GARCH-type models better fit the data when assuming residuals follow a standard t-distribution rather than a standard normal distribution. Furthermore, we investigate the efficacy of different forecasting techniques within GARCH-type models. Comparing rolling window forecasts to expanding window forecasts, we find no definitive superiority in either approach across the tested scenarios. Our experiments reveal that for the GBP/USD pair, the most accurate volatility forecasts stem from the utilization of GARCH models employing a rolling window methodology. Conversely, for the EUR/GBP pair, optimal forecasts are derived from GARCH models and Ordinary Least Squares (OLS) models incorporating the annualized implied volatility of the exchange rate as an independent variable.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Emissions%20and%20Energy%20Efficiency%20at%20Unsignalized%20Real-world%20Intersections%20Under%20Mixed%20Traffic%20Control                                                                                  Analyzing Emissions and Energy Efficiency at Unsignalized Real-world Intersections Under Mixed Traffic Control                                                                                  Greenhouse gas emissions have dramatically risen since the early 1900s with U.S. transportation generating 28% of U.S. emissions. As such, there is interest in reducing transportation-related emissions. Specifically, sustainability research has sprouted around signalized intersections as intersections allow different streams of traffic to cross and change directions. Recent research has developed mixed traffic control eco-driving strategies at signalized intersections to decrease emissions. However, the inherent structure of a signalized intersection generates increased emissions by creating frequent acceleration/deceleration events, excessive idling from traffic congestion, and stop-and-go waves. Thus, we believe unsignalized intersections hold potential for further sustainability improvements. In this work, we provide an emissions analysis on unsignalized intersections with complex, real-world topologies and traffic demands where mixed traffic control strategies are employed by robot vehicles (RVs) to reduce wait times and congestion. We find with at least 10% RV penetration rate, RVs generate less fuel consumption, CO2 emissions, and NOx emissions than signalized intersections by up to 27%, 27% and 28%, respectively. With at least 30% RVs, CO and HC emissions are reduced by up to 42% and 43%, respectively. Additionally, RVs can reduce network-wide emissions despite only employing their strategies at intersections.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Fairness%20in%20Deepfake%20Detection%20With%20Massively%20Annotated%20Databases                                                                                  Analyzing Fairness in Deepfake Detection With Massively Annotated Databases                                                                                  In recent years, image and video manipulations with Deepfake have become a severe concern for security and society. Many detection models and datasets have been proposed to detect Deepfake data reliably. However, there is an increased concern that these models and training databases might be biased and, thus, cause Deepfake detectors to fail. In this work, we investigate factors causing biased detection in public Deepfake datasets by (a) creating large-scale demographic and non-demographic attribute annotations with 47 different attributes for five popular Deepfake datasets and (b) comprehensively analysing attributes resulting in AI-bias of three state-of-the-art Deepfake detection backbone models on these datasets. The analysis shows how various attributes influence a large variety of distinctive attributes (from over 65M labels) on the detection performance which includes demographic (age, gender, ethnicity) and non-demographic (hair, skin, accessories, etc.) attributes. The results examined datasets show limited diversity and, more importantly, show that the utilised Deepfake detection backbone models are strongly affected by investigated attributes making them not fair across attributes. The Deepfake detection backbone methods trained on such imbalanced/biased datasets result in incorrect detection results leading to generalisability, fairness, and security issues. Our findings and annotated datasets will guide future research to evaluate and mitigate bias in Deepfake detection techniques. The annotated datasets and the corresponding code are publicly available.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Regional%20Organization%20of%20the%20Human%20Hippocampus%20in%203D-PLI%20Using%20Contrastive%20Learning%20and%20Geometric%20Unfolding                                                                                  Analyzing Regional Organization of the Human Hippocampus in 3D-PLI Using Contrastive Learning and Geometric Unfolding                                                                                  Understanding the cortical organization of the human brain requires interpretable descriptors for distinct structural and functional imaging data. 3D polarized light imaging (3D-PLI) is an imaging modality for visualizing fiber architecture in postmortem brains with high resolution that also captures the presence of cell bodies, for example, to identify hippocampal subfields. The rich texture in 3D-PLI images, however, makes this modality particularly difficult to analyze and best practices for characterizing architectonic patterns still need to be established. In this work, we demonstrate a novel method to analyze the regional organization of the human hippocampus in 3D-PLI by combining recent advances in unfolding methods with deep texture features obtained using a self-supervised contrastive learning approach. We identify clusters in the representations that correspond well with classical descriptions of hippocampal subfields, lending validity to the developed methodology.
http://w3id.org/mlsea/pwc/scientificWork/Analyzing%20Sharpness-aware%20Minimization%20under%20Overparameterization                                                                                  Analyzing Sharpness-aware Minimization under Overparameterization                                                                                  Training an overparameterized neural network can yield minimizers of different generalization capabilities despite the same level of training loss. With evidence that suggests a correlation between sharpness of minima and their generalization errors, increasing efforts have been made to develop an optimization method to explicitly find flat minima as more generalizable solutions. However, this sharpness-aware minimization (SAM) strategy has not been studied much yet as to whether and how it is affected by overparameterization. In this work, we analyze SAM under overparameterization of varying degrees and present both empirical and theoretical results that indicate a critical influence of overparameterization on SAM. Specifically, we conduct extensive numerical experiments across various domains, and show that there exists a consistent trend that SAM continues to benefit from increasing overparameterization. We also discover compelling cases where the effect of overparameterization is more pronounced or even diminished along with a series of ablation studies. On the theoretical side, we use standard techniques in optimization and prove that SAM can achieve a linear rate of convergence under overparameterization in a stochastic setting. We also show that overparameterization can improve generalization of SAM based on an analysis of two-layer networks, and further, that the linearly stable minima found by SAM have more uniform Hessian moments compared to SGD.
http://w3id.org/mlsea/pwc/scientificWork/Anatomical%20Conditioning%20for%20Contrastive%20Unpaired%20Image-to-Image%20Translation%20of%20Optical%20Coherence%20Tomography%20Images                                                                                  Anatomical Conditioning for Contrastive Unpaired Image-to-Image Translation of Optical Coherence Tomography Images                                                                                  For a unified analysis of medical images from different modalities, data harmonization using image-to-image (I2I) translation is desired. We study this problem employing an optical coherence tomography (OCT) data set of Spectralis-OCT and Home-OCT images. I2I translation is challenging because the images are unpaired, and a bijective mapping does not exist due to the information discrepancy between both domains. This problem has been addressed by the Contrastive Learning for Unpaired I2I Translation (CUT) approach, but it reduces semantic consistency. To restore the semantic consistency, we support the style decoder using an additional segmentation decoder. Our approach increases the similarity between the style-translated images and the target distribution. Importantly, we improve the segmentation of biomarkers in Home-OCT images in an unsupervised domain adaptation scenario. Our data harmonization approach provides potential for the monitoring of diseases, e.g., age related macular disease, using different OCT devices.
http://w3id.org/mlsea/pwc/scientificWork/Anchor-free%20Clustering%20based%20on%20Anchor%20Graph%20Factorization                                                                                  Anchor-free Clustering based on Anchor Graph Factorization                                                                                  Anchor-based methods are a pivotal approach in handling clustering of large-scale data. However, these methods typically entail two distinct stages: selecting anchor points and constructing an anchor graph. This bifurcation, along with the initialization of anchor points, significantly influences the overall performance of the algorithm. To mitigate these issues, we introduce a novel method termed Anchor-free Clustering based on Anchor Graph Factorization (AFCAGF). AFCAGF innovates in learning the anchor graph, requiring only the computation of pairwise distances between samples. This process, achievable through straightforward optimization, circumvents the necessity for explicit selection of anchor points. More concretely, our approach enhances the Fuzzy k-means clustering algorithm (FKM), introducing a new manifold learning technique that obviates the need for initializing cluster centers. Additionally, we evolve the concept of the membership matrix between cluster centers and samples in FKM into an anchor graph encompassing multiple anchor points and samples. Employing Non-negative Matrix Factorization (NMF) on this anchor graph allows for the direct derivation of cluster labels, thereby eliminating the requirement for further post-processing steps. To solve the method proposed, we implement an alternating optimization algorithm that ensures convergence. Empirical evaluations on various real-world datasets underscore the superior efficacy of our algorithm compared to traditional approaches.
http://w3id.org/mlsea/pwc/scientificWork/AnimateLCM%3A%20Accelerating%20the%20Animation%20of%20Personalized%20Diffusion%20Models%20and%20Adapters%20with%20Decoupled%20Consistency%20Learning                                                                                  AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning                                                                                  Video diffusion models has been gaining increasing attention for its ability to produce videos that are both coherent and of high fidelity. However, the iterative denoising process makes it computationally intensive and time-consuming, thus limiting its applications. Inspired by the Consistency Model (CM) that distills pretrained image diffusion models to accelerate the sampling with minimal steps and its successful extension Latent Consistency Model (LCM) on conditional image generation, we propose AnimateLCM, allowing for high-fidelity video generation within minimal steps. Instead of directly conducting consistency learning on the raw video dataset, we propose a decoupled consistency learning strategy that decouples the distillation of image generation priors and motion generation priors, which improves the training efficiency and enhance the generation visual quality. Additionally, to enable the combination of plug-and-play adapters in stable diffusion community to achieve various functions (e.g., ControlNet for controllable generation). we propose an efficient strategy to adapt existing adapters to our distilled text-conditioned video consistency model or train adapters from scratch without harming the sampling speed. We validate the proposed strategy in image-conditioned video generation and layout-conditioned video generation, all achieving top-performing results. Experimental results validate the effectiveness of our proposed method. Code and weights will be made public. More details are available at https://github.com/G-U-N/AnimateLCM.
http://w3id.org/mlsea/pwc/scientificWork/Annolid%3A%20Annotate%2C%20Segment%2C%20and%20Track%20Anything%20You%20Need                                                                                  Annolid: Annotate, Segment, and Track Anything You Need                                                                                  Annolid is a deep learning-based software package designed for the segmentation, labeling, and tracking of research targets within video files, focusing primarily on animal behavior analysis. Based on state-of-the-art instance segmentation methods, Annolid now harnesses the Cutie video object segmentation model to achieve resilient, markerless tracking of multiple animals from single annotated frames, even in environments in which they may be partially or entirely concealed by environmental features or by one another. Our integration of Segment Anything and Grounding-DINO strategies additionally enables the automatic masking and segmentation of recognizable animals and objects by text command, removing the need for manual annotation. Annolid's comprehensive approach to object segmentation flexibly accommodates a broad spectrum of behavior analysis applications, enabling the classification of diverse behavioral states such as freezing, digging, pup huddling, and social interactions in addition to the tracking of animals and their body parts.
http://w3id.org/mlsea/pwc/scientificWork/Anomaly%20Detection%20by%20Adapting%20a%20pre-trained%20Vision%20Language%20Model                                                                                  Anomaly Detection by Adapting a pre-trained Vision Language Model                                                                                  Recently, large vision and language models have shown their success when adapting them to many downstream tasks. In this paper, we present a unified framework named CLIP-ADA for Anomaly Detection by Adapting a pre-trained CLIP model. To this end, we make two important improvements: 1) To acquire unified anomaly detection across industrial images of multiple categories, we introduce the learnable prompt and propose to associate it with abnormal patterns through self-supervised learning. 2) To fully exploit the representation power of CLIP, we introduce an anomaly region refinement strategy to refine the localization quality. During testing, the anomalies are localized by directly calculating the similarity between the representation of the learnable prompt and the image. Comprehensive experiments demonstrate the superiority of our framework, e.g., we achieve the state-of-the-art 97.5/55.6 and 89.3/33.1 on MVTec-AD and VisA for anomaly detection and localization. In addition, the proposed method also achieves encouraging performance with marginal training data, which is more challenging.
http://w3id.org/mlsea/pwc/scientificWork/Ansible%20Lightspeed%3A%20A%20Code%20Generation%20Service%20for%20IT%20Automation                                                                                  Ansible Lightspeed: A Code Generation Service for IT Automation                                                                                  The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for IT automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Red Hat Ansible Lightspeed with IBM Watson Code Assistant, further referred to as Ansible Lightspeed, is an LLM-based service designed explicitly for natural language to Ansible code generation. In this paper, we describe the design and implementation of the Ansible Lightspeed service and analyze feedback from thousands of real users. We examine diverse performance indicators, classified according to both immediate and extended utilization patterns along with user sentiments. The analysis shows that the user acceptance rate of Ansible Lightspeed suggestions is higher than comparable tools that are more general and not specific to a programming language. This remains true even after we use much more stringent criteria for what is considered an accepted model suggestion, discarding suggestions which were heavily edited after being accepted. The relatively high acceptance rate results in higher-than-expected user retention and generally positive user feedback. This paper provides insights on how a comparatively small, dedicated model performs on a domain-specific language and more importantly, how it is received by users.
http://w3id.org/mlsea/pwc/scientificWork/Ant%20Colony%20Sampling%20with%20GFlowNets%20for%20Combinatorial%20Optimization                                                                                  Ant Colony Sampling with GFlowNets for Combinatorial Optimization                                                                                  This paper introduces the Generative Flow Ant Colony Sampler (GFACS), a novel neural-guided meta-heuristic algorithm for combinatorial optimization. GFACS integrates generative flow networks (GFlowNets) with the ant colony optimization (ACO) methodology. GFlowNets, a generative model that learns a constructive policy in combinatorial spaces, enhance ACO by providing an informed prior distribution of decision variables conditioned on input graph instances. Furthermore, we introduce a novel combination of training tricks, including search-guided local exploration, energy normalization, and energy shaping to improve GFACS. Our experimental results demonstrate that GFACS outperforms baseline ACO algorithms in seven CO tasks and is competitive with problem-specific heuristics for vehicle routing problems. The source code is available at url{https://github.com/ai4co/gfacs}.
http://w3id.org/mlsea/pwc/scientificWork/Any-Precision%20LLM%3A%20Low-Cost%20Deployment%20of%20Multiple%2C%20Different-Sized%20LLMs                                                                                  Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs                                                                                  Recently, considerable efforts have been directed towards compressing Large Language Models (LLMs), which showcase groundbreaking capabilities across diverse applications but entail significant deployment costs due to their large sizes. Meanwhile, much less attention has been given to mitigating the costs associated with deploying multiple LLMs of varying sizes despite its practical significance. Thus, this paper introduces emph{any-precision LLM}, extending the concept of any-precision DNN to LLMs. Addressing challenges in any-precision LLM, we propose a lightweight method for any-precision quantization of LLMs, leveraging a post-training quantization framework, and develop a specialized software engine for its efficient serving. As a result, our solution significantly reduces the high costs of deploying multiple, different-sized LLMs by overlaying LLMs quantized to varying bit-widths, such as 3, 4, ..., $n$ bits, into a memory footprint comparable to a single $n$-bit LLM. All the supported LLMs with varying bit-widths demonstrate state-of-the-art model quality and inference throughput, proving itself to be a compelling option for deployment of multiple, different-sized LLMs. The source code will be publicly available soon.
http://w3id.org/mlsea/pwc/scientificWork/Anytime%20Neural%20Architecture%20Search%20on%20Tabular%20Data                                                                                  Anytime Neural Architecture Search on Tabular Data                                                                                  The increasing demand for tabular data analysis calls for transitioning from manual architecture design to Neural Architecture Search (NAS). This transition demands an efficient and responsive anytime NAS approach that is capable of returning current optimal architectures within any given time budget while progressively enhancing architecture quality with increased budget allocation. However, the area of research on Anytime NAS for tabular data remains unexplored. To this end, we introduce ATLAS, the first anytime NAS approach tailored for tabular data. ATLAS introduces a novel two-phase filtering-and-refinement optimization scheme with joint optimization, combining the strengths of both paradigms of training-free and training-based architecture evaluation. Specifically, in the filtering phase, ATLAS employs a new zero-cost proxy specifically designed for tabular data to efficiently estimate the performance of candidate architectures, thereby obtaining a set of promising architectures. Subsequently, in the refinement phase, ATLAS leverages a fixed-budget search algorithm to schedule the training of the promising candidates, so as to accurately identify the optimal architecture. To jointly optimize the two phases for anytime NAS, we also devise a budget-aware coordinator that delivers high NAS performance within constraints. Experimental evaluations demonstrate that our ATLAS can obtain a good-performing architecture within any predefined time budget and return better architectures as and when a new time budget is made available. Overall, it reduces the search time on tabular data by up to 82.75x compared to existing NAS approaches.
http://w3id.org/mlsea/pwc/scientificWork/Application%20analysis%20of%20ai%20technology%20combined%20with%20spiral%20CT%20scanning%20in%20early%20lung%20cancer%20screening                                                                                  Application analysis of ai technology combined with spiral CT scanning in early lung cancer screening                                                                                  At present, the incidence and fatality rate of lung cancer in China rank first among all malignant tumors. Despite the continuous development and improvement of China's medical level, the overall 5-year survival rate of lung cancer patients is still lower than 20% and is staged. A number of studies have confirmed that early diagnosis and treatment of early stage lung cancer is of great significance to improve the prognosis of patients. In recent years, artificial intelligence technology has gradually begun to be applied in oncology. ai is used in cancer screening, clinical diagnosis, radiation therapy (image acquisition, at-risk organ segmentation, image calibration and delivery) and other aspects of rapid development. However, whether medical ai can be socialized depends on the public's attitude and acceptance to a certain extent. However, at present, there are few studies on the diagnosis of early lung cancer by AI technology combined with SCT scanning. In view of this, this study applied the combined method in early lung cancer screening, aiming to find a safe and efficient screening mode and provide a reference for clinical diagnosis and treatment.
http://w3id.org/mlsea/pwc/scientificWork/Application%20of%20Deep%20Learning%20in%20Blind%20Motion%20Deblurring%3A%20Current%20Status%20and%20Future%20Prospects                                                                                  Application of Deep Learning in Blind Motion Deblurring: Current Status and Future Prospects                                                                                  Motion deblurring is one of the fundamental problems of computer vision and has received continuous attention. The variability in blur, both within and across images, imposes limitations on non-blind deblurring techniques that rely on estimating the blur kernel. As a response, blind motion deblurring has emerged, aiming to restore clear and detailed images without prior knowledge of the blur type, fueled by the advancements in deep learning methodologies. Despite strides in this field, a comprehensive synthesis of recent progress in deep learning-based blind motion deblurring is notably absent. This paper fills that gap by providing an exhaustive overview of the role of deep learning in blind motion deblurring, encompassing datasets, evaluation metrics, and methods developed over the last six years. Specifically, we first introduce the types of motion blur and the fundamental principles of deblurring. Next, we outline the shortcomings of traditional non-blind deblurring algorithms, emphasizing the advantages of employing deep learning techniques for deblurring tasks. Following this, we categorize and summarize existing blind motion deblurring methods based on different backbone networks, including convolutional neural networks, generative adversarial networks, recurrent neural networks, and Transformer networks. Subsequently, we elaborate not only on the fundamental principles of these different categories but also provide a comprehensive summary and comparison of their advantages and limitations. Qualitative and quantitative experimental results conducted on four widely used datasets further compare the performance of SOTA methods. Finally, an analysis of present challenges and future pathways. All collected models, benchmark datasets, source code links, and codes for evaluation have been made publicly available at https://github.com/VisionVerse/Blind-Motion-Deblurring-Survey
http://w3id.org/mlsea/pwc/scientificWork/Application-Driven%20Learning%3A%20A%20Closed-Loop%20Prediction%20and%20Optimization%20Approach%20Applied%20to%20Dynamic%20Reserves%20and%20Demand%20Forecasting                                                                                  Application-Driven Learning: A Closed-Loop Prediction and Optimization Approach Applied to Dynamic Reserves and Demand Forecasting                                                                                  Forecasting and decision-making are generally modeled as two sequential steps with no feedback, following an open-loop approach. In this paper, we present application-driven learning, a new closed-loop framework in which the processes of forecasting and decision-making are merged and co-optimized through a bilevel optimization problem. We present our methodology in a general format and prove that the solution converges to the best estimator in terms of the expected cost of the selected application. Then, we propose two solution methods: an exact method based on the KKT conditions of the second-level problem and a scalable heuristic approach suitable for decomposition methods. The proposed methodology is applied to the relevant problem of defining dynamic reserve requirements and conditional load forecasts, offering an alternative approach to current ad hoc procedures implemented in industry practices. We benchmark our methodology with the standard sequential least-squares forecast and dispatch planning process. We apply the proposed methodology to an illustrative system and to a wide range of instances, from dozens of buses to large-scale realistic systems with thousands of buses. Our results show that the proposed methodology is scalable and yields consistently better performance than the standard open-loop approach.
http://w3id.org/mlsea/pwc/scientificWork/Applications%20of%20the%20multi-sigmoidal%20deterministic%20and%20stochastic%20logistic%20models%20for%20plant%20dynamics                                                                                  Applications of the multi-sigmoidal deterministic and stochastic logistic models for plant dynamics                                                                                  We consider a generalization of the classical logistic growth model introducing more than one inflection point. The growth, called multi-sigmoidal, is firstly analyzed from a deterministic point of view in order to obtain the main properties of the curve, such as the limit behavior, the inflection points and the threshold-crossing-time through a fixed boundary. We also present an application in population dynamics of plants based on real data. Then, we define two different birth-death processes, one with linear birth and death rates and the other with quadratic rates, and we analyze their main features. The conditions under which the processes have a mean of multi-sigmoidal logistic type and the first-passage-time problem are also discussed. Finally, with the aim of obtaining a more manageable stochastic description of the growth, we perform a scaling procedure leading to a lognormal diffusion process with mean of multi-sigmoidal logistic type. We finally conduct a detailed probabilistic analysis of this process
http://w3id.org/mlsea/pwc/scientificWork/Applying%20Large%20Language%20Models%20API%20to%20Issue%20Classification%20Problem                                                                                  Applying Large Language Models API to Issue Classification Problem                                                                                  Effective prioritization of issue reports is crucial in software engineering to optimize resource allocation and address critical problems promptly. However, the manual classification of issue reports for prioritization is laborious and lacks scalability. Alternatively, many open source software (OSS) projects employ automated processes for this task, albeit relying on substantial datasets for adequate training. This research seeks to devise an automated approach that ensures reliability in issue prioritization, even when trained on smaller datasets. Our proposed methodology harnesses the power of Generative Pre-trained Transformers (GPT), recognizing their potential to efficiently handle this task. By leveraging the capabilities of such models, we aim to develop a robust system for prioritizing issue reports accurately, mitigating the necessity for extensive training data while maintaining reliability. In our research, we have developed a reliable GPT-based approach to accurately label and prioritize issue reports with a reduced training dataset. By reducing reliance on massive data requirements and focusing on few-shot fine-tuning, our methodology offers a more accessible and efficient solution for issue prioritization in software engineering. Our model predicted issue types in individual projects up to 93.2% in precision, 95% in recall, and 89.3% in F1-score.
http://w3id.org/mlsea/pwc/scientificWork/Apprentices%20to%20Research%20Assistants%3A%20Advancing%20Research%20with%20Large%20Language%20Models                                                                                  Apprentices to Research Assistants: Advancing Research with Large Language Models                                                                                  Large Language Models (LLMs) have emerged as powerful tools in various research domains. This article examines their potential through a literature review and firsthand experimentation. While LLMs offer benefits like cost-effectiveness and efficiency, challenges such as prompt tuning, biases, and subjectivity must be addressed. The study presents insights from experiments utilizing LLMs for qualitative analysis, highlighting successes and limitations. Additionally, it discusses strategies for mitigating challenges, such as prompt optimization techniques and leveraging human expertise. This study aligns with the 'LLMs as Research Tools' workshop's focus on integrating LLMs into HCI data work critically and ethically. By addressing both opportunities and challenges, our work contributes to the ongoing dialogue on their responsible application in research.
http://w3id.org/mlsea/pwc/scientificWork/Approaching%20Human-Level%20Forecasting%20with%20Language%20Models                                                                                  Approaching Human-Level Forecasting with Language Models                                                                                  Forecasting future events is important for policy and decision making. In this work, we study whether language models (LMs) can forecast at the level of competitive human forecasters. Towards this goal, we develop a retrieval-augmented LM system designed to automatically search for relevant information, generate forecasts, and aggregate predictions. To facilitate our study, we collect a large dataset of questions from competitive forecasting platforms. Under a test set published after the knowledge cut-offs of our LMs, we evaluate the end-to-end performance of our system against the aggregates of human forecasts. On average, the system nears the crowd aggregate of competitive forecasters, and in some settings surpasses it. Our work suggests that using LMs to forecast the future could provide accurate predictions at scale and help to inform institutional decision making.
http://w3id.org/mlsea/pwc/scientificWork/Approaching%20Rate-Distortion%20Limits%20in%20Neural%20Compression%20with%20Lattice%20Transform%20Coding                                                                                  Approaching Rate-Distortion Limits in Neural Compression with Lattice Transform Coding                                                                                  Neural compression has brought tremendous progress in designing lossy compressors with good rate-distortion (RD) performance at low complexity. Thus far, neural compression design involves transforming the source to a latent vector, which is then rounded to integers and entropy coded. While this approach has been shown to be optimal in a one-shot sense on certain sources, we show that it is highly sub-optimal on i.i.d. sequences, and in fact always recovers scalar quantization of the original source sequence. We demonstrate that the sub-optimality is due to the choice of quantization scheme in the latent space, and not the transform design. By employing lattice quantization instead of scalar quantization in the latent space, we demonstrate that Lattice Transform Coding (LTC) is able to recover optimal vector quantization at various dimensions and approach the asymptotically-achievable rate-distortion function at reasonable complexity. On general vector sources, LTC improves upon standard neural compressors in one-shot coding performance. LTC also enables neural compressors that perform block coding on i.i.d. vector sources, which yields coding gain over optimal one-shot coding.
http://w3id.org/mlsea/pwc/scientificWork/ApproxDARTS%3A%20Differentiable%20Neural%20Architecture%20Search%20with%20Approximate%20Multipliers                                                                                  ApproxDARTS: Differentiable Neural Architecture Search with Approximate Multipliers                                                                                  Integrating the principles of approximate computing into the design of hardware-aware deep neural networks (DNN) has led to DNNs implementations showing good output quality and highly optimized hardware parameters such as low latency or inference energy. In this work, we present ApproxDARTS, a neural architecture search (NAS) method enabling the popular differentiable neural architecture search method called DARTS to exploit approximate multipliers and thus reduce the power consumption of generated neural networks. We showed on the CIFAR-10 data set that the ApproxDARTS is able to perform a complete architecture search within less than $10$ GPU hours and produce competitive convolutional neural networks (CNN) containing approximate multipliers in convolutional layers. For example, ApproxDARTS created a CNN showing an energy consumption reduction of (a) $53.84 %$ in the arithmetic operations of the inference phase compared to the CNN utilizing the native $32$-bit floating-point multipliers and (b) $5.97 %$ compared to the CNN utilizing the exact $8$-bit fixed-point multipliers, in both cases with a negligible accuracy drop. Moreover, the ApproxDARTS is $2.3 times$ faster than a similar but evolutionary algorithm-based method called EvoApproxNAS.
http://w3id.org/mlsea/pwc/scientificWork/Approximate%20Gradient%20Coding%20for%20Privacy-Flexible%20Federated%20Learning%20with%20Non-IID%20Data                                                                                  Approximate Gradient Coding for Privacy-Flexible Federated Learning with Non-IID Data                                                                                  This work focuses on the challenges of non-IID data and stragglers/dropouts in federated learning. We introduce and explore a privacy-flexible paradigm that models parts of the clients' local data as non-private, offering a more versatile and business-oriented perspective on privacy. Within this framework, we propose a data-driven strategy for mitigating the effects of label heterogeneity and client straggling on federated learning. Our solution combines both offline data sharing and approximate gradient coding techniques. Through numerical simulations using the MNIST dataset, we demonstrate that our approach enables achieving a deliberate trade-off between privacy and utility, leading to improved model convergence and accuracy while using an adaptable portion of non-private data.
http://w3id.org/mlsea/pwc/scientificWork/Approximating%20Families%20of%20Sharp%20Solutions%20to%20Fisher%27s%20Equation%20with%20Physics-Informed%20Neural%20Networks                                                                                  Approximating Families of Sharp Solutions to Fisher's Equation with Physics-Informed Neural Networks                                                                                  This paper employs physics-informed neural networks (PINNs) to solve Fisher's equation, a fundamental representation of a reaction-diffusion system with both simplicity and significance. The focus lies specifically in investigating Fisher's equation under conditions of large reaction rate coefficients, wherein solutions manifest as traveling waves, posing a challenge for numerical methods due to the occurring steepness of the wave front. To address optimization challenges associated with the standard PINN approach, a residual weighting scheme is introduced. This scheme is designed to enhance the tracking of propagating wave fronts by considering the reaction term in the reaction-diffusion equation. Furthermore, a specific network architecture is studied which is tailored for solutions in the form of traveling waves. Lastly, the capacity of PINNs to approximate an entire family of solutions is assessed by incorporating the reaction rate coefficient as an additional input to the network architecture. This modification enables the approximation of the solution across a broad and continuous range of reaction rate coefficients, thus solving a class of reaction-diffusion systems using a single PINN instance.
http://w3id.org/mlsea/pwc/scientificWork/Approximating%20Numerical%20Fluxes%20Using%20Fourier%20Neural%20Operators%20for%20Hyperbolic%20Conservation%20Laws                                                                                  Approximating Numerical Fluxes Using Fourier Neural Operators for Hyperbolic Conservation Laws                                                                                  Traditionally, classical numerical schemes have been employed to solve partial differential equations (PDEs) using computational methods. Recently, neural network-based methods have emerged. Despite these advancements, neural network-based methods, such as physics-informed neural networks (PINNs) and neural operators, exhibit deficiencies in robustness and generalization. To address these issues, numerous studies have integrated classical numerical frameworks with machine learning techniques, incorporating neural networks into parts of traditional numerical methods. In this study, we focus on hyperbolic conservation laws by replacing traditional numerical fluxes with neural operators. To this end, we developed loss functions inspired by established numerical schemes related to conservation laws and approximated numerical fluxes using Fourier neural operators (FNOs). Our experiments demonstrated that our approach combines the strengths of both traditional numerical schemes and FNOs, outperforming standard FNO methods in several respects. For instance, we demonstrate that our method is robust, has resolution invariance, and is feasible as a data-driven method. In particular, our method can make continuous predictions over time and exhibits superior generalization capabilities with out-of-distribution (OOD) samples, which are challenges that existing neural operator methods encounter.
http://w3id.org/mlsea/pwc/scientificWork/Approximation%20of%20RKHS%20Functionals%20by%20Neural%20Networks                                                                                  Approximation of RKHS Functionals by Neural Networks                                                                                  Motivated by the abundance of functional data such as time series and images, there has been a growing interest in integrating such data into neural networks and learning maps from function spaces to R (i.e., functionals). In this paper, we study the approximation of functionals on reproducing kernel Hilbert spaces (RKHS's) using neural networks. We establish the universality of the approximation of functionals on the RKHS's. Specifically, we derive explicit error bounds for those induced by inverse multiquadric, Gaussian, and Sobolev kernels. Moreover, we apply our findings to functional regression, proving that neural networks can accurately approximate the regression maps in generalized functional linear models. Existing works on functional learning require integration-type basis function expansions with a set of pre-specified basis functions. By leveraging the interpolating orthogonal projections in RKHS's, our proposed network is much simpler in that we use point evaluations to replace basis function expansions.
http://w3id.org/mlsea/pwc/scientificWork/Aquarium%3A%20A%20Comprehensive%20Framework%20for%20Exploring%20Predator-Prey%20Dynamics%20through%20Multi-Agent%20Reinforcement%20Learning%20Algorithms                                                                                  Aquarium: A Comprehensive Framework for Exploring Predator-Prey Dynamics through Multi-Agent Reinforcement Learning Algorithms                                                                                  Recent advances in Multi-Agent Reinforcement Learning have prompted the modeling of intricate interactions between agents in simulated environments. In particular, the predator-prey dynamics have captured substantial interest and various simulations been tailored to unique requirements. To prevent further time-intensive developments, we introduce Aquarium, a comprehensive Multi-Agent Reinforcement Learning environment for predator-prey interaction, enabling the study of emergent behavior. Aquarium is open source and offers a seamless integration of the PettingZoo framework, allowing a quick start with proven algorithm implementations. It features physics-based agent movement on a two-dimensional, edge-wrapping plane. The agent-environment interaction (observations, actions, rewards) and the environment settings (agent speed, prey reproduction, predator starvation, and others) are fully customizable. Besides a resource-efficient visualization, Aquarium supports to record video files, providing a visual comprehension of agent behavior. To demonstrate the environment's capabilities, we conduct preliminary studies which use PPO to train multiple prey agents to evade a predator. In accordance to the literature, we find Individual Learning to result in worse performance than Parameter Sharing, which significantly improves coordination and sample-efficiency.
http://w3id.org/mlsea/pwc/scientificWork/AraCovTexFinder%3A%20Leveraging%20the%20transformer-based%20language%20model%20for%20Arabic%20COVID-19%20text%20identification                                                                                  AraCovTexFinder: Leveraging the transformer-based language model for Arabic COVID-19 text identification                                                                                  In light of the pandemic, the identification and processing of COVID-19-related text have emerged as critical research areas within the field of Natural Language Processing (NLP). With a growing reliance on online portals and social media for information exchange and interaction, a surge in online textual content, comprising disinformation, misinformation, fake news, and rumors has led to the phenomenon of an infodemic on the World Wide Web. Arabic, spoken by over 420 million people worldwide, stands as a significant low-resource language, lacking efficient tools or applications for the detection of COVID-19-related text. Additionally, the identification of COVID-19 text is an essential prerequisite task for detecting fake and toxic content associated with COVID-19. This gap hampers crucial COVID information retrieval and processing necessary for policymakers and health authorities. Addressing this issue, this paper introduces an intelligent Arabic COVID-19 text identification system named ‘AraCovTexFinder,’ leveraging a fine-tuned fusion-based transformer model. Recognizing the challenges posed by a scarcity of related text corpora, substantial morphological variations in the language, and a deficiency of well-tuned hyperparameters, the proposed system aims to mitigate these hurdles. To support the proposed method, two corpora are developed: an Arabic embedding corpus (AraEC) and an Arabic COVID-19 text identification corpus (AraCoV). The study evaluates the performance of six transformer-based language models (mBERT, XML-RoBERTa, mDeBERTa-V3, mDistilBERT, BERT-Arabic, and AraBERT), 12 deep learning models (combining Word2Vec, GloVe, and FastText embedding with CNN, LSTM, VDCNN, and BiLSTM), and the newly introduced model AraCovTexFinder. Through extensive evaluation, AraCovTexFinder achieves a high accuracy of 98.89 ± 0.001%, outperforming other baseline models, including transformer-based language and deep learning models. This research highlights the importance of specialized tools in low-resource languages to combat the infodemic relating to COVID-19, which can assist policymakers and health authorities in making informed decisions.
http://w3id.org/mlsea/pwc/scientificWork/Arabic%20Text%20Sentiment%20Analysis%3A%20Reinforcing%20Human-Performed%20Surveys%20with%20Wider%20Topic%20Analysis                                                                                  Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with Wider Topic Analysis                                                                                  Sentiment analysis (SA) has been, and is still, a thriving research area. However, the task of Arabic sentiment analysis (ASA) is still underrepresented in the body of research. This study offers the first in-depth and in-breadth analysis of existing ASA studies of textual content and identifies their common themes, domains of application, methods, approaches, technologies and algorithms used. The in-depth study manually analyses 133 ASA papers published in the English language between 2002 and 2020 from four academic databases (SAGE, IEEE, Springer, WILEY) and from Google Scholar. The in-breadth study uses modern, automatic machine learning techniques, such as topic modelling and temporal analysis, on Open Access resources, to reinforce themes and trends identified by the prior study, on 2297 ASA publications between 2010-2020. The main findings show the different approaches used for ASA: machine learning, lexicon-based and hybrid approaches. Other findings include ASA 'winning' algorithms (SVM, NB, hybrid methods). Deep learning methods, such as LSTM can provide higher accuracy, but for ASA sometimes the corpora are not large enough to support them. Additionally, whilst there are some ASA corpora and lexicons, more are required. Specifically, Arabic tweets corpora and datasets are currently only moderately sized. Moreover, Arabic lexicons that have high coverage contain only Modern Standard Arabic (MSA) words, and those with Arabic dialects are quite small. Thus, new corpora need to be created. On the other hand, ASA tools are stringently lacking. There is a need to develop ASA tools that can be used in industry, as well as in academia, for Arabic text SA. Hence, our study offers insights into the challenges associated with ASA research and provides suggestions for ways to move the field forward such as lack of Dialectical Arabic resource, Arabic tweets, corpora and data sets for SA.
http://w3id.org/mlsea/pwc/scientificWork/Arbitrary%20Discrete%20Fourier%20Analysis%20and%20Its%20Application%20in%20Replayed%20Speech%20Detection                                                                                  Arbitrary Discrete Fourier Analysis and Its Application in Replayed Speech Detection                                                                                  In this paper, a group of finite sequences and its variants were proposed to use in conducting signal analysis; we called the developed signal analysis methods arbitrary discrete Fourier analysis (ADFA), Mel-scale discrete Fourier analysis (MDFA) and constant Q analysis (CQA). The effectiveness of three signal analysis methods were then validated by testing their performance on a replayed speech detection benchmark (i.e., the ASVspoof 2019 Physical Access) along with a state-of-the-art model. Comparable performance to the best reported systems were shown by the experimental results with three signal analysis methods. Furthermore, the CQA method shown its efficiency with less computation time in compared to the convention method constant Q transform (CQT), which is commonly used in spoofed and fake speech detection and music processing.
http://w3id.org/mlsea/pwc/scientificWork/Arbitrary%20Scale%20Super-Resolution%20Assisted%20Lunar%20Crater%20Detection%20in%20Satellite%20Images                                                                                  Arbitrary Scale Super-Resolution Assisted Lunar Crater Detection in Satellite Images                                                                                  Craters are one of the most studied planetary features used for different scientific analyses, such as estimation of surface age and surface processes. Satellite images utilized for crater detection often have low resolution (LR) due to hardware constraints and transmission time. Super-resolution (SR) is a practical and cost-effective solution; however, most SR approaches work on fixed integer scale factors, i.e., a single model can generate images of a specific resolution. In practical applications, SR on multiple scales provides various levels of detail, but training for each scale is resource-intensive. Therefore, this paper proposes a system for crater detection assisted with an arbitrary scale super-resolution approach (i.e., a single model can be used for multiple scale factors) for the lunar surface. Our work is composed of two subsystems. The first sub-system employs an arbitrary scale SR approach to generate super-resolved images of multiple resolutions. Subsequently, the second sub-system passes super-resolved images of multiple resolutions to a deep learning-based crater detection framework for identifying craters on the lunar surface. Employed arbitrary scale SR approach is based on a combination of convolution and transformer modules. For the crater detection sub-system, we utilize the Mask-RCNN framework. Using SR images of multiple resolutions, the proposed system detects 13.47% more craters from the ground truth than the craters detected using only the LR images. Further, in complex crater settings, specifically in overlapping and degraded craters, 11.84% and 15.01% more craters are detected as compared to the crater detection networks using only the LR images. The proposed system also leads to better localization performance, 3.19% IoU increment compared to the LR images
http://w3id.org/mlsea/pwc/scientificWork/Architectural%20Strategies%20for%20the%20optimization%20of%20Physics-Informed%20Neural%20Networks                                                                                  Architectural Strategies for the optimization of Physics-Informed Neural Networks                                                                                  Physics-informed neural networks (PINNs) offer a promising avenue for tackling both forward and inverse problems in partial differential equations (PDEs) by incorporating deep learning with fundamental physics principles. Despite their remarkable empirical success, PINNs have garnered a reputation for their notorious training challenges across a spectrum of PDEs. In this work, we delve into the intricacies of PINN optimization from a neural architecture perspective. Leveraging the Neural Tangent Kernel (NTK), our study reveals that Gaussian activations surpass several alternate activations when it comes to effectively training PINNs. Building on insights from numerical linear algebra, we introduce a preconditioned neural architecture, showcasing how such tailored architectures enhance the optimization process. Our theoretical findings are substantiated through rigorous validation against established PDEs within the scientific literature.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Human%20Conversations%20Special%3F%20A%20Large%20Language%20Model%20Perspective                                                                                  Are Human Conversations Special? A Large Language Model Perspective                                                                                  This study analyzes changes in the attention mechanisms of large language models (LLMs) when used to understand natural conversations between humans (human-human). We analyze three use cases of LLMs: interactions over web content, code, and mathematical texts. By analyzing attention distance, dispersion, and interdependency across these domains, we highlight the unique challenges posed by conversational data. Notably, conversations require nuanced handling of long-term contextual relationships and exhibit higher complexity through their attention patterns. Our findings reveal that while language models exhibit domain-specific attention behaviors, there is a significant gap in their ability to specialize in human conversations. Through detailed attention entropy analysis and t-SNE visualizations, we demonstrate the need for models trained with a diverse array of high-quality conversational data to enhance understanding and generation of human-like dialogue. This research highlights the importance of domain specialization in language models and suggests pathways for future advancement in modeling human conversational nuances.
http://w3id.org/mlsea/pwc/scientificWork/Are%20LLM-based%20Evaluators%20Confusing%20NLG%20Quality%20Criteria%3F                                                                                  Are LLM-based Evaluators Confusing NLG Quality Criteria?                                                                                  Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and vague expression in existing NLG quality criteria themselves. So we summarize a clear hierarchical classification system for 11 common aspects with corresponding different criteria from previous studies involved. Inspired by behavioral testing, we elaborately design 18 types of aspect-targeted perturbation attacks for fine-grained analysis of the evaluation behaviors of different LLMs. We also conduct human annotations beyond the guidance of the classification system to validate the impact of the perturbations. Our experimental results reveal confusion issues inherent in LLMs, as well as other noteworthy phenomena, and necessitate further research and improvements for LLM-based evaluation.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Language%20Models%20More%20Like%20Libraries%20or%20Like%20Librarians%3F%20Bibliotechnism%2C%20the%20Novel%20Reference%20Problem%2C%20and%20the%20Attitudes%20of%20LLMs                                                                                  Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs                                                                                  Are LLMs cultural technologies like photocopiers or printing presses, which transmit information but cannot create new content? A challenge for this idea, which we call bibliotechnism, is that LLMs often generate entirely novel text. We begin (Part I) with a sustained defense of bibliotechnism against this challenge showing how even entirely novel text may be meaningful only in a derivative sense, and arguing that, in particular, much novel text generated by LLMs is only derivatively meaningful. But we argue (Part II) that bibliotechnism faces a different, novel challenge, stemming from examples in which LLMs generate 'novel reference', using novel names to refer to novel entities. Such examples could be smoothly explained if LLMs were not cultural technologies but possessed a limited form of agency (beliefs, desires, and intentions). According to interpretationism in the philosophy of mind, a system has beliefs, desires and intentions if and only if its behavior is well explained by the hypothesis that it has such states. So, according to interpretationism, cases of novel reference provide evidence that LLMs have beliefs, desires, and intentions. Given that interpretationism is a live hypothesis about the nature of these states, we suggest that cases of novel reference provide evidence that LLMs do have beliefs, desires, and intentions.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Large%20Language%20Models%20Table-based%20Fact-Checkers%3F                                                                                  Are Large Language Models Table-based Fact-Checkers?                                                                                  Table-based Fact Verification (TFV) aims to extract the entailment relation between statements and structured tables. Existing TFV methods based on small-scaled models suffer from insufficient labeled data and weak zero-shot ability. Recently, the appearance of Large Language Models (LLMs) has gained lots of attraction in research fields. They have shown powerful zero-shot and in-context learning abilities on several NLP tasks, but their potential on TFV is still unknown. In this work, we implement a preliminary study about whether LLMs are table-based fact-checkers. In detail, we design diverse prompts to explore how the in-context learning can help LLMs in TFV, i.e., zero-shot and few-shot TFV capability. Besides, we carefully design and construct TFV instructions to study the performance gain brought by the instruction tuning of LLMs. Experimental results demonstrate that LLMs can achieve acceptable results on zero-shot and few-shot TFV with prompt engineering, while instruction-tuning can stimulate the TFV capability significantly. We also make some valuable findings about the format of zero-shot prompts and the number of in-context examples. Finally, we analyze some possible directions to promote the accuracy of TFV via LLMs, which is beneficial to further research of table reasoning.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Latent%20Vulnerabilities%20Hidden%20Gems%20for%20Software%20Vulnerability%20Prediction%3F%20An%20Empirical%20Study                                                                                  Are Latent Vulnerabilities Hidden Gems for Software Vulnerability Prediction? An Empirical Study                                                                                  Collecting relevant and high-quality data is integral to the development of effective Software Vulnerability (SV) prediction models. Most of the current SV datasets rely on SV-fixing commits to extract vulnerable functions and lines. However, none of these datasets have considered latent SVs existing between the introduction and fix of the collected SVs. There is also little known about the usefulness of these latent SVs for SV prediction. To bridge these gaps, we conduct a large-scale study on the latent vulnerable functions in two commonly used SV datasets and their utilization for function-level and line-level SV predictions. Leveraging the state-of-the-art SZZ algorithm, we identify more than 100k latent vulnerable functions in the studied datasets. We find that these latent functions can increase the number of SVs by 4x on average and correct up to 5k mislabeled functions, yet they have a noise level of around 6%. Despite the noise, we show that the state-of-the-art SV prediction model can significantly benefit from such latent SVs. The improvements are up to 24.5% in the performance (F1-Score) of function-level SV predictions and up to 67% in the effectiveness of localizing vulnerable lines. Overall, our study presents the first promising step toward the use of latent SVs to improve the quality of SV datasets and enhance the performance of SV prediction tasks.
http://w3id.org/mlsea/pwc/scientificWork/Are%20Synthetic%20Data%20Useful%20for%20Egocentric%20Hand-Object%20Interaction%20Detection%3F                                                                                  Are Synthetic Data Useful for Egocentric Hand-Object Interaction Detection?                                                                                  In this study, we investigate the effectiveness of synthetic data in enhancing egocentric hand-object interaction detection. Via extensive experiments and comparative analyses on three egocentric datasets, VISOR, EgoHOS, and ENIGMA-51, our findings reveal how to exploit synthetic data for the HOI detection task when real labeled data are scarce or unavailable. Specifically, by leveraging only 10% of real labeled data, we achieve improvements in Overall AP compared to baselines trained exclusively on real data of: +5.67% on EPIC-KITCHENS VISOR, +8.24% on EgoHOS, and +11.69% on ENIGMA-51. Our analysis is supported by a novel data generation pipeline and the newly introduced HOI-Synth benchmark which augments existing datasets with synthetic images of hand-object interactions automatically labeled with hand-object contact states, bounding boxes, and pixel-wise segmentation masks. We publicly release the generated data, code, and data generation tools to support future research at the following link: https://iplab.dmi.unict.it/HOI-Synth/.
http://w3id.org/mlsea/pwc/scientificWork/Are%20we%20making%20much%20progress%3F%20Revisiting%20chemical%20reaction%20yield%20prediction%20from%20an%20imbalanced%20regression%20perspective                                                                                  Are we making much progress? Revisiting chemical reaction yield prediction from an imbalanced regression perspective                                                                                  The yield of a chemical reaction quantifies the percentage of the target product formed in relation to the reactants consumed during the chemical reaction. Accurate yield prediction can guide chemists toward selecting high-yield reactions during synthesis planning, offering valuable insights before dedicating time and resources to wet lab experiments. While recent advancements in yield prediction have led to overall performance improvement across the entire yield range, an open challenge remains in enhancing predictions for high-yield reactions, which are of greater concern to chemists. In this paper, we argue that the performance gap in high-yield predictions results from the imbalanced distribution of real-world data skewed towards low-yield reactions, often due to unreacted starting materials and inherent ambiguities in the reaction processes. Despite this data imbalance, existing yield prediction methods continue to treat different yield ranges equally, assuming a balanced training distribution. Through extensive experiments on three real-world yield prediction datasets, we emphasize the urgent need to reframe reaction yield prediction as an imbalanced regression problem. Finally, we demonstrate that incorporating simple cost-sensitive re-weighting methods can significantly enhance the performance of yield prediction models on underrepresented high-yield regions.
http://w3id.org/mlsea/pwc/scientificWork/Argument-Aware%20Approach%20To%20Event%20Linking                                                                                  Argument-Aware Approach To Event Linking                                                                                  Event linking connects event mentions in text with relevant nodes in a knowledge base (KB). Prior research in event linking has mainly borrowed methods from entity linking, overlooking the distinct features of events. Compared to the extensively explored entity linking task, events have more complex structures and can be more effectively distinguished by examining their associated arguments. Moreover, the information-rich nature of events leads to the scarcity of event KBs. This emphasizes the need for event linking models to identify and classify event mentions not in the KB as ``out-of-KB,'' an area that has received limited attention. In this work, we tackle these challenges by introducing an argument-aware approach. First, we improve event linking models by augmenting input text with tagged event argument information, facilitating the recognition of key information about event mentions. Subsequently, to help the model handle ``out-of-KB'' scenarios, we synthesize out-of-KB training examples from in-KB instances through controlled manipulation of event arguments. Our experiment across two test datasets showed significant enhancements in both in-KB and out-of-KB scenarios, with a notable 22% improvement in out-of-KB evaluations.
http://w3id.org/mlsea/pwc/scientificWork/Array%20Geometry-Robust%20Attention-Based%20Neural%20Beamformer%20for%20Moving%20Speakers                                                                                  Array Geometry-Robust Attention-Based Neural Beamformer for Moving Speakers                                                                                  Recently, a mask-based beamformer with attention-based spatial covariance matrix aggregator (ASA) was proposed, which was demonstrated to track moving sources accurately. However, the deep neural network model used in this algorithm is limited to a specific channel configuration, requiring a different model in case a different channel permutation, channel count, or microphone array geometry is considered. Addressing this limitation, in this paper, we investigate three approaches to improve the robustness of the ASA-based tracking method against such variations: incorporating random channel configurations during the training process, employing the transform-average-concatenate (TAC) method to process multi-channel input features (allowing for any channel count and enabling permutation invariance), and utilizing input features that are robust against variations of the channel configuration. Our experiments, conducted using the CHiME-3 and DEMAND datasets, demonstrate improved robustness against mismatches in channel permutations, channel counts, and microphone array geometries compared to the conventional ASA-based tracking method without compromising performance in matched conditions, suggesting that the mask-based beamformer with ASA integrating the proposed approaches has the potential to track moving sources for arbitrary microphone arrays.
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Bee%20Colony%20optimization%20of%20Deep%20Convolutional%20Neural%20Networks%20in%20the%20context%20of%20Biomedical%20Imaging                                                                                  Artificial Bee Colony optimization of Deep Convolutional Neural Networks in the context of Biomedical Imaging                                                                                  Most efforts in Computer Vision focus on natural images or artwork, which differ significantly both in size and contents from the kind of data biomedical image processing deals with. Thus, Transfer Learning models often prove themselves suboptimal for these tasks, even after manual finetuning. The development of architectures from scratch is oftentimes unfeasible due to the vastness of the hyperparameter space and a shortage of time, computational resources and Deep Learning experts in most biomedical research laboratories. An alternative to manually defining the models is the use of Neuroevolution, which employs metaheuristic techniques to optimize Deep Learning architectures. However, many algorithms proposed in the neuroevolutive literature are either too unreliable or limited to a small, predefined region of the hyperparameter space. To overcome these shortcomings, we propose the Chimera Algorithm, a novel, hybrid neuroevolutive algorithm that integrates the Artificial Bee Colony Algorithm with Evolutionary Computation tools to generate models from scratch, as well as to refine a given previous architecture to better fit the task at hand. The Chimera Algorithm has been validated with two datasets of natural and medical images, producing models that surpassed the performance of those coming from Transfer Learning.
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Intelligence%20and%20the%20Spatial%20Documentation%20of%20Languages                                                                                  Artificial Intelligence and the Spatial Documentation of Languages                                                                                  The advancement in technology has made interdisciplinary research more accessible. Particularly the breakthrough in Artificial Intelligence AI has given huge advantages to researchers working in interdisciplinary and multidisciplinary fields. This study investigates the ability of AI models, particularly GPT4 and GPT Data Analyst in creating language maps for language documentation. The study Integrates documentary linguistics linguistic geography and AI by showcasing how AI models facilitate the spatial documentation of languages through the creation of language maps with minimal cartographic expertise. The study is conducted using a CSV file and a GeoJSON file both obtained from HDX and from the researchers fieldwork. The study data is then applied in realtime conversations with the AI models in order to generate the language distribution maps. The study highlights the two AI models capabilities in generating highquality static and interactive web maps and streamlining the mapmaking process, despite facing challenges like inconsistencies and difficulties in adding legends. The findings suggest a promising future for AI in generating language maps and enhancing the work of documentary linguists as they collect their data in the field pointing towards the need for further development to fully harness AI potential in this field.
http://w3id.org/mlsea/pwc/scientificWork/Artificial%20Neural%20Microcircuits%20as%20Building%20Blocks%3A%20Concept%20and%20Challenges                                                                                  Artificial Neural Microcircuits as Building Blocks: Concept and Challenges                                                                                  Artificial Neural Networks (ANNs) are one of the most widely employed forms of bio-inspired computation. However the current trend is for ANNs to be structurally homogeneous. Furthermore, this structural homogeneity requires the application of complex training and learning tools that produce application specific ANNs, susceptible to pitfalls such as overfitting. In this paper, an new approach is explored, inspired by the role played in biology by Neural Microcircuits, the so called ``fundamental processing elements'' of organic nervous systems. How large neural networks, particularly Spiking Neural Networks (SNNs) can be assembled using Artificial Neural Microcircuits (ANMs), intended as off-the-shelf components, is articulated; the results of initial work to produce a catalogue of such Microcircuits though the use of Novelty Search is shown; followed by efforts to expand upon this initial work, including a discussion of challenges uncovered during these efforts and explorations of methods by which they might be overcome.
http://w3id.org/mlsea/pwc/scientificWork/As%20Good%20As%20A%20Coin%20Toss%3A%20Human%20detection%20of%20AI-generated%20images%2C%20videos%2C%20audio%2C%20and%20audiovisual%20stimuli                                                                                  As Good As A Coin Toss: Human detection of AI-generated images, videos, audio, and audiovisual stimuli                                                                                  As synthetic media becomes progressively more realistic and barriers to using it continue to lower, the technology has been increasingly utilized for malicious purposes, from financial fraud to nonconsensual pornography. Today, the principal defense against being misled by synthetic media relies on the ability of the human observer to visually and auditorily discern between real and fake. However, it remains unclear just how vulnerable people actually are to deceptive synthetic media in the course of their day to day lives. We conducted a perceptual study with 1276 participants to assess how accurate people were at distinguishing synthetic images, audio only, video only, and audiovisual stimuli from authentic. To reflect the circumstances under which people would likely encounter synthetic media in the wild, testing conditions and stimuli emulated a typical online platform, while all synthetic media used in the survey was sourced from publicly accessible generative AI technology. We find that overall, participants struggled to meaningfully discern between synthetic and authentic content. We also find that detection performance worsens when the stimuli contains synthetic content as compared to authentic content, images featuring human faces as compared to non face objects, a single modality as compared to multimodal stimuli, mixed authenticity as compared to being fully synthetic for audiovisual stimuli, and features foreign languages as compared to languages the observer is fluent in. Finally, we also find that prior knowledge of synthetic media does not meaningfully impact their detection performance. Collectively, these results indicate that people are highly susceptible to being tricked by synthetic media in their daily lives and that human perceptual detection capabilities can no longer be relied upon as an effective counterdefense.
http://w3id.org/mlsea/pwc/scientificWork/Asking%20the%20Right%20Question%20at%20the%20Right%20Time%3A%20Human%20and%20Model%20Uncertainty%20Guidance%20to%20Ask%20Clarification%20Questions                                                                                  Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions                                                                                  Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping dialogue systems with the ability to assess their own uncertainty and exploit in interaction.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Economic%20Viability%3A%20A%20Comparative%20Analysis%20of%20Total%20Cost%20of%20Ownership%20for%20Domain-Adapted%20Large%20Language%20Models%20versus%20State-of-the-art%20Counterparts%20in%20Chip%20Design%20Coding%20Assistance                                                                                  Assessing Economic Viability: A Comparative Analysis of Total Cost of Ownership for Domain-Adapted Large Language Models versus State-of-the-art Counterparts in Chip Design Coding Assistance                                                                                  This paper presents a comparative analysis of total cost of ownership (TCO) and performance between domain-adapted large language models (LLM) and state-of-the-art (SoTA) LLMs , with a particular emphasis on tasks related to coding assistance for chip design. We examine the TCO and performance metrics of a domain-adaptive LLM, ChipNeMo, against two leading LLMs, Claude 3 Opus and ChatGPT-4 Turbo, to assess their efficacy in chip design coding generation. Through a detailed evaluation of the accuracy of the model, training methodologies, and operational expenditures, this study aims to provide stakeholders with critical information to select the most economically viable and performance-efficient solutions for their specific needs. Our results underscore the benefits of employing domain-adapted models, such as ChipNeMo, that demonstrate improved performance at significantly reduced costs compared to their general-purpose counterparts. In particular, we reveal the potential of domain-adapted LLMs to decrease TCO by approximately 90%-95%, with the cost advantages becoming increasingly evident as the deployment scale expands. With expansion of deployment, the cost benefits of ChipNeMo become more pronounced, making domain-adaptive LLMs an attractive option for organizations with substantial coding needs supported by LLMs
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Engraftment%20Following%20Fecal%20Microbiota%20Transplant                                                                                  Assessing Engraftment Following Fecal Microbiota Transplant                                                                                  Fecal Microbiota Transplant (FMT) is an FDA approved treatment for recurrent Clostridium difficile infections, and is being explored for other clinical applications, from alleviating digestive and neurological disorders, to priming the microbiome for cancer treatment, and restoring microbiomes impacted by cancer treatment. Quantifying the extent of engraftment following an FMT is important in determining if a recipient didn't respond because the engrafted microbiome didn't produce the desired outcomes (a successful FMT, but negative treatment outcome), or the microbiome didn't engraft (an unsuccessful FMT and negative treatment outcome). The lack of a consistent methodology for quantifying FMT engraftment extent hinders the assessment of FMT success and its relation to clinical outcomes, and presents challenges for comparing FMT results and protocols across studies. Here we review 46 studies of FMT in humans and model organisms and group their approaches for assessing the extent to which an FMT engrafts into three criteria: 1) Chimeric Asymmetric Community Coalescence investigates microbiome shifts following FMT engraftment. 2) Donated Microbiome Indicator Features tracks donated microbiome features as a signal of engraftment with methods such as differential abundance testing based on the current sample collection, or tracking changes in feature abundances that have been previously identified. 3) Temporal Stability examines how resistant post-FMT recipient's microbiomes are to reverting back to their baseline microbiome. Investigated together, these criteria provide a clear assessment of microbiome engraftment. We discuss the pros and cons of each of these criteria, providing illustrative examples of their application. We also introduce key terminology and recommendations on how FMT studies can be analyzed for rigorous engraftment extent assessment.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Patient%20Eligibility%20for%20Inspire%20Therapy%20through%20Machine%20Learning%20and%20Deep%20Learning%20Models                                                                                  Assessing Patient Eligibility for Inspire Therapy through Machine Learning and Deep Learning Models                                                                                  Inspire therapy is an FDA-approved internal neurostimulation treatment for obstructive sleep apnea. However, not all patients respond to this therapy, posing a challenge even for experienced otolaryngologists to determine candidacy. This paper makes the first attempt to leverage both machine learning and deep learning techniques in discerning patient responsiveness to Inspire therapy using medical data and videos captured through Drug-Induced Sleep Endoscopy (DISE), an essential procedure for Inspire therapy. To achieve this, we gathered and annotated three datasets from 127 patients. Two of these datasets comprise endoscopic videos focused on the Base of the Tongue and Velopharynx. The third dataset composes the patient's clinical information. By utilizing these datasets, we benchmarked and compared the performance of six deep learning models and five classical machine learning algorithms. The results demonstrate the potential of employing machine learning and deep learning techniques to determine a patient's eligibility for Inspire therapy, paving the way for future advancements in this field.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20Visually-Continuous%20Corruption%20Robustness%20of%20Neural%20Networks%20Relative%20to%20Human%20Performance                                                                                  Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance                                                                                  While Neural Networks (NNs) have surpassed human accuracy in image classification on ImageNet, they often lack robustness against image corruption, i.e., corruption robustness. Yet such robustness is seemingly effortless for human perception. In this paper, we propose visually-continuous corruption robustness (VCR) -- an extension of corruption robustness to allow assessing it over the wide and continuous range of changes that correspond to the human perceptive quality (i.e., from the original image to the full distortion of all perceived visual information), along with two novel human-aware metrics for NN evaluation. To compare VCR of NNs with human perception, we conducted extensive experiments on 14 commonly used image corruptions with 7,718 human participants and state-of-the-art robust NN models with different training objectives (e.g., standard, adversarial, corruption robustness), different architectures (e.g., convolution NNs, vision transformers), and different amounts of training data augmentation. Our study showed that: 1) assessing robustness against continuous corruption can reveal insufficient robustness undetected by existing benchmarks; as a result, 2) the gap between NN and human robustness is larger than previously known; and finally, 3) some image corruptions have a similar impact on human perception, offering opportunities for more cost-effective robustness assessments. Our validation set with 14 image corruptions, human robustness data, and the evaluation code is provided as a toolbox and a benchmark.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20the%20Extrapolation%20Capability%20of%20Template-Free%20Retrosynthesis%20Models                                                                                  Assessing the Extrapolation Capability of Template-Free Retrosynthesis Models                                                                                  Despite the acknowledged capability of template-free models in exploring unseen reaction spaces compared to template-based models for retrosynthesis prediction, their ability to venture beyond established boundaries remains relatively uncharted. In this study, we empirically assess the extrapolation capability of state-of-the-art template-free models by meticulously assembling an extensive set of out-of-distribution (OOD) reactions. Our findings demonstrate that while template-free models exhibit potential in predicting precursors with novel synthesis rules, their top-10 exact-match accuracy in OOD reactions is strikingly modest (< 1%). Furthermore, despite the capability of generating novel reactions, our investigation highlights a recurring issue where more than half of the novel reactions predicted by template-free models are chemically implausible. Consequently, we advocate for the future development of template-free models that integrate considerations of chemical feasibility when navigating unexplored regions of reaction space.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20the%20Performance%20of%20Deep%20Learning%20for%20Automated%20Gleason%20Grading%20in%20Prostate%20Cancer                                                                                  Assessing the Performance of Deep Learning for Automated Gleason Grading in Prostate Cancer                                                                                  Prostate cancer is a dominant health concern calling for advanced diagnostic tools. Utilizing digital pathology and artificial intelligence, this study explores the potential of 11 deep neural network architectures for automated Gleason grading in prostate carcinoma focusing on comparing traditional and recent architectures. A standardized image classification pipeline, based on the AUCMEDI framework, facilitated robust evaluation using an in-house dataset consisting of 34,264 annotated tissue tiles. The results indicated varying sensitivity across architectures, with ConvNeXt demonstrating the strongest performance. Notably, newer architectures achieved superior performance, even though with challenges in differentiating closely related Gleason grades. The ConvNeXt model was capable of learning a balance between complexity and generalizability. Overall, this study lays the groundwork for enhanced Gleason grading systems, potentially improving diagnostic efficiency for prostate cancer.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20the%20importance%20of%20long-range%20correlations%20for%20deep-learning-based%20sleep%20staging                                                                                  Assessing the importance of long-range correlations for deep-learning-based sleep staging                                                                                  This study aims to elucidate the significance of long-range correlations for deep-learning-based sleep staging. It is centered around S4Sleep(TS), a recently proposed model for automated sleep staging. This model utilizes electroencephalography (EEG) as raw time series input and relies on structured state space sequence (S4) models as essential model component. Although the model already surpasses state-of-the-art methods for a moderate number of 15 input epochs, recent literature results suggest potential benefits from incorporating very long correlations spanning hundreds of input epochs. In this submission, we explore the possibility of achieving further enhancements by systematically scaling up the model's input size, anticipating potential improvements in prediction accuracy. In contrast to findings in literature, our results demonstrate that augmenting the input size does not yield a significant enhancement in the performance of S4Sleep(TS). These findings, coupled with the distinctive ability of S4 models to capture long-range dependencies in time series data, cast doubt on the diagnostic relevance of very long-range interactions for sleep staging.
http://w3id.org/mlsea/pwc/scientificWork/Assessing%20the%20similarity%20of%20real%20matrices%20with%20arbitrary%20shape                                                                                  Assessing the similarity of real matrices with arbitrary shape                                                                                  Assessing the similarity of matrices is valuable for analyzing the extent to which data sets exhibit common features in tasks such as data clustering, dimensionality reduction, pattern recognition, group comparison, and graph analysis. Methods proposed for comparing vectors, such as cosine similarity, can be readily generalized to matrices. However, this approach usually neglects the inherent two-dimensional structure of matrices. Here, we propose singular angle similarity (SAS), a measure for evaluating the structural similarity between two arbitrary, real matrices of the same shape based on singular value decomposition. After introducing the measure, we compare SAS with standard measures for matrix comparison and show that only SAS captures the two-dimensional structure of matrices. Further, we characterize the behavior of SAS in the presence of noise and as a function of matrix dimensionality. Finally, we apply SAS to two use cases: square non-symmetric matrices of probabilistic network connectivity, and non-square matrices representing neural brain activity. For synthetic data of network connectivity, SAS matches intuitive expectations and allows for a robust assessment of similarities and differences. For experimental data of brain activity, SAS captures differences in the structure of high-dimensional responses to different stimuli. We conclude that SAS is a suitable measure for quantifying the shared structure of matrices with arbitrary shape.
http://w3id.org/mlsea/pwc/scientificWork/Asset%20management%2C%20condition%20monitoring%20and%20Digital%20Twins%3A%20damage%20detection%20and%20virtual%20inspection%20on%20a%20reinforced%20concrete%20bridge                                                                                  Asset management, condition monitoring and Digital Twins: damage detection and virtual inspection on a reinforced concrete bridge                                                                                  In April 2021 Stava bridge, a main bridge on E6 in Norway, was abruptly closed for traffic. A structural defect had seriously compromised the bridge structural integrity. The Norwegian Public Roads Administration (NPRA) closed it, made a temporary solution and reopened with severe traffic restrictions. The incident was alerted through what constitutes the bridge Digital Twin processing data from Internet of Things sensors. The solution was crucial in online and offline diagnostics, the case demonstrating the value of technologies to tackle emerging dangerous situations as well as acting preventively. A critical and rapidly developing damage was detected in time to stop the development, but not in time to avoid the incident altogether. The paper puts risk in a broader perspective for an organization responsible for highway infrastructure. It positions online monitoring and Digital Twins in the context of Risk- and Condition-Based Maintenance. The situation that arose at Stava bridge, and how it was detected, analyzed, and diagnosed during virtual inspection, is described. The case demonstrates how combining physics-based methods with Machine Learning can facilitate damage detection and diagnostics. A summary of lessons learnt, both from technical and organizational perspectives, as well as plans of future work, is presented.
http://w3id.org/mlsea/pwc/scientificWork/Asymptotic%20Analysis%20of%20Synchronous%20Signal%20Processing                                                                                  Asymptotic Analysis of Synchronous Signal Processing                                                                                  This paper extends various theoretical results from stationary data processing to cyclostationary (CS) processes under a unified framework. We first derive their asymptotic eigenbasis, which provides a link between their Fourier and Karhunen-Lo `eve (KL) expansions, through a unitary transformation dictated by the cyclic spectrum. By exploiting this connection and the optimalities offered by the KL representation, we study the asymptotic performance of smoothing, filtering and prediction of CS processes, without the need for deriving explicit implementations. We obtain minimum mean squared error expressions that depend on the cyclic spectrum and include classical limits based on the power spectral density as particular cases. We conclude this work by applying the results to a practical scenario, in order to quantify the achievable gains of synchronous signal processing.
http://w3id.org/mlsea/pwc/scientificWork/Asyn2F%3A%20An%20Asynchronous%20Federated%20Learning%20Framework%20with%20Bidirectional%20Model%20Aggregation                                                                                  Asyn2F: An Asynchronous Federated Learning Framework with Bidirectional Model Aggregation                                                                                  In federated learning, the models can be trained synchronously or asynchronously. Many research works have focused on developing an aggregation method for the server to aggregate multiple local models into the global model with improved performance. They ignore the heterogeneity of the training workers, which causes the delay in the training of the local models, leading to the obsolete information issue. In this paper, we design and develop Asyn2F, an Asynchronous Federated learning Framework with bidirectional model aggregation. By bidirectional model aggregation, Asyn2F, on one hand, allows the server to asynchronously aggregate multiple local models and results in a new global model. On the other hand, it allows the training workers to aggregate the new version of the global model into the local model, which is being trained even in the middle of a training epoch. We develop Asyn2F considering the practical implementation requirements such as using cloud services for model storage and message queuing protocols for communications. Extensive experiments with different datasets show that the models trained by Asyn2F achieve higher performance compared to the state-of-the-art techniques. The experiments also demonstrate the effectiveness, practicality, and scalability of Asyn2F, making it ready for deployment in real scenarios.
http://w3id.org/mlsea/pwc/scientificWork/Asynchronous%20Parallel%20Reinforcement%20Learning%20for%20Optimizing%20Propulsive%20Performance%20in%20Fin%20Ray%20Control                                                                                  Asynchronous Parallel Reinforcement Learning for Optimizing Propulsive Performance in Fin Ray Control                                                                                  Fish fin rays constitute a sophisticated control system for ray-finned fish, facilitating versatile locomotion within complex fluid environments. Despite extensive research on the kinematics and hydrodynamics of fish locomotion, the intricate control strategies in fin-ray actuation remain largely unexplored. While deep reinforcement learning (DRL) has demonstrated potential in managing complex nonlinear dynamics; its trial-and-error nature limits its application to problems involving computationally demanding environmental interactions. This study introduces a cutting-edge off-policy DRL algorithm, interacting with a fluid-structure interaction (FSI) environment to acquire intricate fin-ray control strategies tailored for various propulsive performance objectives. To enhance training efficiency and enable scalable parallelism, an innovative asynchronous parallel training (APT) strategy is proposed, which fully decouples FSI environment interactions and policy/value network optimization. The results demonstrated the success of the proposed method in discovering optimal complex policies for fin-ray actuation control, resulting in a superior propulsive performance compared to the optimal sinusoidal actuation function identified through a parametric grid search. The merit and effectiveness of the APT approach are also showcased through comprehensive comparison with conventional DRL training strategies in numerical experiments of controlling nonlinear dynamics.
http://w3id.org/mlsea/pwc/scientificWork/Attacking%20Transformers%20with%20Feature%20Diversity%20Adversarial%20Perturbation                                                                                  Attacking Transformers with Feature Diversity Adversarial Perturbation                                                                                  Understanding the mechanisms behind Vision Transformer (ViT), particularly its vulnerability to adversarial perturba tions, is crucial for addressing challenges in its real-world applications. Existing ViT adversarial attackers rely on la bels to calculate the gradient for perturbation, and exhibit low transferability to other structures and tasks. In this paper, we present a label-free white-box attack approach for ViT-based models that exhibits strong transferability to various black box models, including most ViT variants, CNNs, and MLPs, even for models developed for other modalities. Our inspira tion comes from the feature collapse phenomenon in ViTs, where the critical attention mechanism overly depends on the low-frequency component of features, causing the features in middle-to-end layers to become increasingly similar and eventually collapse. We propose the feature diversity attacker to naturally accelerate this process and achieve remarkable performance and transferability.
http://w3id.org/mlsea/pwc/scientificWork/Attacks%2C%20Defenses%20and%20Evaluations%20for%20LLM%20Conversation%20Safety%3A%20A%20Survey                                                                                  Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey                                                                                  Large Language Models (LLMs) are now commonplace in conversation applications. However, their risks of misuse for generating harmful responses have raised serious societal concerns and spurred recent research on LLM conversation safety. Therefore, in this survey, we provide a comprehensive overview of recent studies, covering three critical aspects of LLM conversation safety: attacks, defenses, and evaluations. Our goal is to provide a structured summary that enhances understanding of LLM conversation safety and encourages further investigation into this important subject. For easy reference, we have categorized all the studies mentioned in this survey according to our taxonomy, available at: https://github.com/niconi19/LLM-conversation-safety.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20Graph%20for%20Multi-Robot%20Social%20Navigation%20with%20Deep%20Reinforcement%20Learning                                                                                  Attention Graph for Multi-Robot Social Navigation with Deep Reinforcement Learning                                                                                  Learning robot navigation strategies among pedestrian is crucial for domain based applications. Combining perception, planning and prediction allows us to model the interactions between robots and pedestrians, resulting in impressive outcomes especially with recent approaches based on deep reinforcement learning (RL). However, these works do not consider multi-robot scenarios. In this paper, we present MultiSoc, a new method for learning multi-agent socially aware navigation strategies using RL. Inspired by recent works on multi-agent deep RL, our method leverages graph-based representation of agent interactions, combining the positions and fields of view of entities (pedestrians and agents). Each agent uses a model based on two Graph Neural Network combined with attention mechanisms. First an edge-selector produces a sparse graph, then a crowd coordinator applies node attention to produce a graph representing the influence of each entity on the others. This is incorporated into a model-free RL framework to learn multi-agent policies. We evaluate our approach on simulation and provide a series of experiments in a set of various conditions (number of agents / pedestrians). Empirical results show that our method learns faster than social navigation deep RL mono-agent techniques, and enables efficient multi-agent implicit coordination in challenging crowd navigation with multiple heterogeneous humans. Furthermore, by incorporating customizable meta-parameters, we can adjust the neighborhood density to take into account in our navigation strategy.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20Is%20Not%20the%20Only%20Choice%3A%20Counterfactual%20Reasoning%20for%20Path-Based%20Explainable%20Recommendation                                                                                  Attention Is Not the Only Choice: Counterfactual Reasoning for Path-Based Explainable Recommendation                                                                                  Compared with only pursuing recommendation accuracy, the explainability of a recommendation model has drawn more attention in recent years. Many graph-based recommendations resort to informative paths with the attention mechanism for the explanation. Unfortunately, these attention weights are intentionally designed for model accuracy but not explainability. Recently, some researchers have started to question attention-based explainability because the attention weights are unstable for different reproductions, and they may not always align with human intuition. Inspired by the counterfactual reasoning from causality learning theory, we propose a novel explainable framework targeting path-based recommendations, wherein the explainable weights of paths are learned to replace attention weights. Specifically, we design two counterfactual reasoning algorithms from both path representation and path topological structure perspectives. Moreover, unlike traditional case studies, we also propose a package of explainability evaluation solutions with both qualitative and quantitative methods. We conduct extensive experiments on three real-world datasets, the results of which further demonstrate the effectiveness and reliability of our method.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20Meets%20Post-hoc%20Interpretability%3A%20A%20Mathematical%20Perspective                                                                                  Attention Meets Post-hoc Interpretability: A Mathematical Perspective                                                                                  Attention-based architectures, in particular transformers, are at the heart of a technological revolution. Interestingly, in addition to helping obtain state-of-the-art results on a wide range of applications, the attention mechanism intrinsically provides meaningful insights on the internal behavior of the model. Can these insights be used as explanations? Debate rages on. In this paper, we mathematically study a simple attention-based architecture and pinpoint the differences between post-hoc and attention-based explanations. We show that they provide quite different results, and that, despite their limitations, post-hoc methods are capable of capturing more useful insights than merely examining the attention weights.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20Modules%20Improve%20Modern%20Image-Level%20Anomaly%20Detection%3A%20A%20DifferNet%20Case%20Study                                                                                  Attention Modules Improve Modern Image-Level Anomaly Detection: A DifferNet Case Study                                                                                  Within (semi-)automated visual inspection, learning-based approaches for assessing visual defects, including deep neural networks, enable the processing of otherwise small defect patterns in pixel size on high-resolution imagery. The emergence of these often rarely occurring defect patterns explains the general need for labeled data corpora. To not only alleviate this issue but to furthermore advance the current state of the art in unsupervised visual inspection, this contribution proposes a DifferNet-based solution enhanced with attention modules utilizing SENet and CBAM as backbone - AttentDifferNet - to improve the detection and classification capabilities on three different visual inspection and anomaly detection datasets: MVTec AD, InsPLAD-fault, and Semiconductor Wafer. In comparison to the current state of the art, it is shown that AttentDifferNet achieves improved results, which are, in turn, highlighted throughout our quantitative as well as qualitative evaluation, indicated by a general improvement in AUC of 94.34 vs. 92.46, 96.67 vs. 94.69, and 90.20 vs. 88.74%. As our variants to AttentDifferNet show great prospects in the context of currently investigated approaches, a baseline is formulated, emphasizing the importance of attention for anomaly detection.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20as%20Robust%20Representation%20for%20Time%20Series%20Forecasting                                                                                  Attention as Robust Representation for Time Series Forecasting                                                                                  Time series forecasting is essential for many practical applications, with the adoption of transformer-based models on the rise due to their impressive performance in NLP and CV. Transformers' key feature, the attention mechanism, dynamically fusing embeddings to enhance data representation, often relegating attention weights to a byproduct role. Yet, time series data, characterized by noise and non-stationarity, poses significant forecasting challenges. Our approach elevates attention weights as the primary representation for time series, capitalizing on the temporal relationships among data points to improve forecasting accuracy. Our study shows that an attention map, structured using global landmarks and local windows, acts as a robust kernel representation for data points, withstanding noise and shifts in distribution. Our method outperforms state-of-the-art models, reducing mean squared error (MSE) in multivariate time series forecasting by a notable 3.6% without altering the core neural network architecture. It serves as a versatile component that can readily replace recent patching based embedding schemes in transformer-based models, boosting their performance.
http://w3id.org/mlsea/pwc/scientificWork/Attention%20based%20End%20to%20end%20network%20for%20Offline%20Writer%20Identification%20on%20Word%20level%20data                                                                                  Attention based End to end network for Offline Writer Identification on Word level data                                                                                  Writer identification due to its widespread application in various fields has gained popularity over the years. In scenarios where optimum handwriting samples are available, whether they be in the form of a single line, a sentence, or an entire page, writer identification algorithms have demonstrated noteworthy levels of accuracy. However, in scenarios where only a limited number of handwritten samples are available, particularly in the form of word images, there is a significant scope for improvement. In this paper, we propose a writer identification system based on an attention-driven Convolutional Neural Network (CNN). The system is trained utilizing image segments, known as fragments, extracted from word images, employing a pyramid-based strategy. This methodology enables the system to capture a comprehensive representation of the data, encompassing both fine-grained details and coarse features across various levels of abstraction. These extracted fragments serve as the training data for the convolutional network, enabling it to learn a more robust representation compared to traditional convolution-based networks trained on word images. Additionally, the paper explores the integration of an attention mechanism to enhance the representational power of the learned features. The efficacy of the proposed algorithm is evaluated on three benchmark databases, demonstrating its proficiency in writer identification tasks, particularly in scenarios with limited access to handwriting data.
http://w3id.org/mlsea/pwc/scientificWork/Attention-Enhanced%20Deep%20Learning%20for%20Device-Free%20Through-the-Wall%20Presence%20Detection%20Using%20Indoor%20WiFi%20Systems                                                                                  Attention-Enhanced Deep Learning for Device-Free Through-the-Wall Presence Detection Using Indoor WiFi Systems                                                                                  Accurate detection of human presence in indoor environments is important for various applications, such as energy management and security. In this paper, we propose a novel system for human presence detection using the channel state information (CSI) of WiFi signals. Our system named attention-enhanced deep learning for presence detection (ALPD) employs an attention mechanism to automatically select informative subcarriers from the CSI data and a bidirectional long short-term memory (LSTM) network to capture temporal dependencies in CSI. Additionally, we utilize a static feature to improve the accuracy of human presence detection in static states. We evaluate the proposed ALPD system by deploying a pair of WiFi access points (APs) for collecting CSI dataset, which is further compared with several benchmarks. The results demonstrate that our ALPD system outperforms the benchmarks in terms of accuracy, especially in the presence of interference. Moreover, bidirectional transmission data is beneficial to training improving stability and accuracy, as well as reducing the costs of data collection for training. To elaborate a little further, we have also evaluated the potential of ALPD for detecting more challenging human activities in multi-rooms. Overall, our proposed ALPD system shows promising results for human presence detection using WiFi CSI signals.
http://w3id.org/mlsea/pwc/scientificWork/Attention-Refined%20Unrolling%20for%20Sparse%20Sequential%20micro-Doppler%20Reconstruction                                                                                  Attention-Refined Unrolling for Sparse Sequential micro-Doppler Reconstruction                                                                                  The reconstruction of micro-Doppler signatures of human movements is a key enabler for fine-grained activity recognition wireless sensing. In Joint Communication and Sensing (JCS) systems, unlike in dedicated radar sensing systems, a suitable trade-off between sensing accuracy and communication overhead has to be attained. It follows that the micro-Doppler has to be reconstructed from incomplete windows of channel estimates obtained from communication packets. Existing approaches exploit compressed sensing, but produce very poor reconstructions when only a few channel measurements are available, which is often the case with real communication patterns. In addition, the large number of iterations they need to converge hinders their use in real-time systems. In this work, we propose and validate STAR, a neural network that reconstructs micro-Doppler sequences of human movement even from highly incomplete channel measurements. STAR is based upon a new architectural design that combines a single unrolled iterative hard-thresholding layer with an attention mechanism, used at its output. This results in an interpretable and lightweight architecture that reaps the benefits of both model-based and data driven solutions. STAR is evaluated on a public JCS dataset of 60 GHz channel measurements of human activity traces. Experimental results show that it substantially outperforms state-of-the-art techniques in terms of the reconstructed micro-Doppler quality. Remarkably, STAR enables human activity recognition with satisfactory accuracy even with 90% of missing channel measurements, for which existing techniques fail.
http://w3id.org/mlsea/pwc/scientificWork/Attentive%20Fusion%3A%20A%20Transformer-based%20Approach%20to%20Multimodal%20Hate%20Speech%20Detection                                                                                  Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech Detection                                                                                  With the recent surge and exponential growth of social media usage, scrutinizing social media content for the presence of any hateful content is of utmost importance. Researchers have been diligently working since the past decade on distinguishing between content that promotes hatred and content that does not. Traditionally, the main focus has been on analyzing textual content. However, recent research attempts have also commenced into the identification of audio-based content. Nevertheless, studies have shown that relying solely on audio or text-based content may be ineffective, as recent upsurge indicates that individuals often employ sarcasm in their speech and writing. To overcome these challenges, we present an approach to identify whether a speech promotes hate or not utilizing both audio and textual representations. Our methodology is based on the Transformer framework that incorporates both audio and text sampling, accompanied by our very own layer called 'Attentive Fusion'. The results of our study surpassed previous state-of-the-art techniques, achieving an impressive macro F1 score of 0.927 on the Test Set.
http://w3id.org/mlsea/pwc/scientificWork/Attraction%20Via%20Prices%20and%20Information                                                                                  Attraction Via Prices and Information                                                                                  We study the ramifications of increased commitment power for information provision in an oligopolistic market with search frictions. Although prices are posted and, therefore, guide search, if firms cannot commit to information provision policies, there is no active search at equilibrium so consumers visit (and purchase from) at most one firm. If firms can guide search by both their prices and information policies, there exists a unique symmetric equilibrium exhibiting price dispersion and active search. Nevertheless, when the market is thin, consumers prefer the former case, which features intense price competition. Firms always prefer the latter.
http://w3id.org/mlsea/pwc/scientificWork/Audio%20Simulation%20for%20Sound%20Source%20Localization%20in%20Virtual%20Evironment                                                                                  Audio Simulation for Sound Source Localization in Virtual Evironment                                                                                  Non-line-of-sight localization in signal-deprived environments is a challenging yet pertinent problem. Acoustic methods in such predominantly indoor scenarios encounter difficulty due to the reverberant nature. In this study, we aim to locate sound sources to specific locations within a virtual environment by leveraging physically grounded sound propagation simulations and machine learning methods. This process attempts to overcome the issue of data insufficiency to localize sound sources to their location of occurrence especially in post-event localization. We achieve 0.786+/- 0.0136 F1-score using an audio transformer spectrogram approach.
http://w3id.org/mlsea/pwc/scientificWork/Audio-Visual%20Segmentation%20via%20Unlabeled%20Frame%20Exploitation                                                                                  Audio-Visual Segmentation via Unlabeled Frame Exploitation                                                                                  Audio-visual segmentation (AVS) aims to segment the sounding objects in video frames. Although great progress has been witnessed, we experimentally reveal that current methods reach marginal performance gain within the use of the unlabeled frames, leading to the underutilization issue. To fully explore the potential of the unlabeled frames for AVS, we explicitly divide them into two categories based on their temporal characteristics, i.e., neighboring frame (NF) and distant frame (DF). NFs, temporally adjacent to the labeled frame, often contain rich motion information that assists in the accurate localization of sounding objects. Contrary to NFs, DFs have long temporal distances from the labeled frame, which share semantic-similar objects with appearance variations. Considering their unique characteristics, we propose a versatile framework that effectively leverages them to tackle AVS. Specifically, for NFs, we exploit the motion cues as the dynamic guidance to improve the objectness localization. Besides, we exploit the semantic cues in DFs by treating them as valid augmentations to the labeled frames, which are then used to enrich data diversity in a self-training manner. Extensive experimental results demonstrate the versatility and superiority of our method, unleashing the power of the abundant unlabeled frames.
http://w3id.org/mlsea/pwc/scientificWork/Audio-Visual%20Speech%20Enhancement%20in%20Noisy%20Environments%20via%20Emotion-Based%20Contextual%20Cues                                                                                  Audio-Visual Speech Enhancement in Noisy Environments via Emotion-Based Contextual Cues                                                                                  In real-world environments, background noise significantly degrades the intelligibility and clarity of human speech. Audio-visual speech enhancement (AVSE) attempts to restore speech quality, but existing methods often fall short, particularly in dynamic noise conditions. This study investigates the inclusion of emotion as a novel contextual cue within AVSE, hypothesizing that incorporating emotional understanding can improve speech enhancement performance. We propose a novel emotion-aware AVSE system that leverages both auditory and visual information. It extracts emotional features from the facial landmarks of the speaker and fuses them with corresponding audio and visual modalities. This enriched data serves as input to a deep UNet-based encoder-decoder network, specifically designed to orchestrate the fusion of multimodal information enhanced with emotion. The network iteratively refines the enhanced speech representation through an encoder-decoder architecture, guided by perceptually-inspired loss functions for joint learning and optimization. We train and evaluate the model on the CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) dataset, a rich repository of audio-visual recordings with annotated emotions. Our comprehensive evaluation demonstrates the effectiveness of emotion as a contextual cue for AVSE. By integrating emotional features, the proposed system achieves significant improvements in both objective and subjective assessments of speech quality and intelligibility, especially in challenging noise environments. Compared to baseline AVSE and audio-only speech enhancement systems, our approach exhibits a noticeable increase in PESQ and STOI, indicating higher perceptual quality and intelligibility. Large-scale listening tests corroborate these findings, suggesting improved human understanding of enhanced speech.
http://w3id.org/mlsea/pwc/scientificWork/AudioChatLlama%3A%20Towards%20General-Purpose%20Speech%20Abilities%20for%20LLMs                                                                                  AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs                                                                                  In this work, we extend the instruction-tuned Llama-2 model with end-to-end general-purpose speech processing and reasoning abilities while maintaining the wide range of original LLM capabilities, without using any carefully curated paired data. The resulting end-to-end model, named AudioChatLlama, can utilize audio prompts as a replacement for text and sustain a conversation. Such a model also has extended cross-modal capabilities such as being able to perform spoken question answering (QA), speech translation, and audio summarization amongst many other closed and open-domain tasks. This is unlike prior approaches in speech, in which LLMs are extended to handle audio for a limited number of pre-designated tasks. On both synthesized and recorded speech QA test sets, evaluations show that our end-to-end approach is on par with or outperforms cascaded systems (speech recognizer + LLM) in terms of modeling the response to a prompt. Furthermore, unlike cascades, our approach can interchange text and audio modalities and intrinsically utilize prior context in a conversation to provide better results.
http://w3id.org/mlsea/pwc/scientificWork/Audiosockets%3A%20A%20Python%20socket%20package%20for%20Real-Time%20Audio%20Processing                                                                                  Audiosockets: A Python socket package for Real-Time Audio Processing                                                                                  There are many packages in Python which allow one to perform real-time processing on audio data. Unfortunately, due to the synchronous nature of the language, there lacks a framework which allows for distributed parallel processing of the data without requiring a large programming overhead and in which the data acquisition is not blocked by subsequent processing operations. This work improves on packages used for audio data collection with a light-weight backend and a simple interface that allows for distributed processing through a socket-based structure. This is intended for real-time audio machine learning and data processing in Python with a quick deployment of multiple parallel operations on the same data, allowing users to spend less time debugging and more time developing.
http://w3id.org/mlsea/pwc/scientificWork/Augmentations%20vs%20Algorithms%3A%20What%20Works%20in%20Self-Supervised%20Learning                                                                                  Augmentations vs Algorithms: What Works in Self-Supervised Learning                                                                                  We study the relative effects of data augmentations, pretraining algorithms, and model architectures in Self-Supervised Learning (SSL). While the recent literature in this space leaves the impression that the pretraining algorithm is of critical importance to performance, understanding its effect is complicated by the difficulty in making objective and direct comparisons between methods. We propose a new framework which unifies many seemingly disparate SSL methods into a single shared template. Using this framework, we identify aspects in which methods differ and observe that in addition to changing the pretraining algorithm, many works also use new data augmentations or more powerful model architectures. We compare several popular SSL methods using our framework and find that many algorithmic additions, such as prediction networks or new losses, have a minor impact on downstream task performance (often less than $1 %$), while enhanced augmentation techniques offer more significant performance improvements ($2-4 %$). Our findings challenge the premise that SSL is being driven primarily by algorithmic improvements, and suggest instead a bitter lesson for SSL: that augmentation diversity and data / model scale are more critical contributors to recent advances in self-supervised learning.
http://w3id.org/mlsea/pwc/scientificWork/Augmenting%20emotion%20features%20in%20irony%20detection%20with%20Large%20language%20modeling                                                                                  Augmenting emotion features in irony detection with Large language modeling                                                                                  This study introduces a novel method for irony detection, applying Large Language Models (LLMs) with prompt-based learning to facilitate emotion-centric text augmentation. Traditional irony detection techniques typically fall short due to their reliance on static linguistic features and predefined knowledge bases, often overlooking the nuanced emotional dimensions integral to irony. In contrast, our methodology augments the detection process by integrating subtle emotional cues, augmented through LLMs, into three benchmark pre-trained NLP models - BERT, T5, and GPT-2 - which are widely recognized as foundational in irony detection. We assessed our method using the SemEval-2018 Task 3 dataset and observed substantial enhancements in irony detection capabilities.
http://w3id.org/mlsea/pwc/scientificWork/Authors%27%20Values%20and%20Attitudes%20Towards%20AI-bridged%20Scalable%20Personalization%20of%20Creative%20Language%20Arts                                                                                  Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts                                                                                  Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author's vision to the audience's context and taste at scale. However, it is unclear what the authors' values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors' concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors' values.
http://w3id.org/mlsea/pwc/scientificWork/Autism%20Detection%20in%20Speech%20-%20A%20Survey                                                                                  Autism Detection in Speech - A Survey                                                                                  There has been a range of studies of how autism is displayed in voice, speech, and language. We analyse studies from the biomedical, as well as the psychological domain, but also from the NLP domain in order to find linguistic, prosodic and acoustic cues that could indicate autism. Our survey looks at all three domains. We define autism and which comorbidities might influence the correct detection of the disorder. We especially look at observations such as verbal and semantic fluency, prosodic features, but also disfluencies and speaking rate. We also show word-based approaches and describe machine learning and transformer-based approaches both on the audio data as well as the transcripts. Lastly, we conclude, while there already is a lot of research, female patients seem to be severely under-researched. Also, most NLP research focuses on traditional machine learning methods instead of transformers which could be beneficial in this context. Additionally, we were unable to find research combining both features from audio and transcripts.
http://w3id.org/mlsea/pwc/scientificWork/Auto-configuring%20Exploration-Exploitation%20Tradeoff%20in%20Evolutionary%20Computation%20via%20Deep%20Reinforcement%20Learning                                                                                  Auto-configuring Exploration-Exploitation Tradeoff in Evolutionary Computation via Deep Reinforcement Learning                                                                                  Evolutionary computation (EC) algorithms, renowned as powerful black-box optimizers, leverage a group of individuals to cooperatively search for the optimum. The exploration-exploitation tradeoff (EET) plays a crucial role in EC, which, however, has traditionally been governed by manually designed rules. In this paper, we propose a deep reinforcement learning-based framework that autonomously configures and adapts the EET throughout the EC search process. The framework allows different individuals of the population to selectively attend to the global and local exemplars based on the current search state, maximizing the cooperative search outcome. Our proposed framework is characterized by its simplicity, effectiveness, and generalizability, with the potential to enhance numerous existing EC algorithms. To validate its capabilities, we apply our framework to several representative EC algorithms and conduct extensive experiments on the augmented CEC2021 benchmark. The results demonstrate significant improvements in the performance of the backbone algorithms, as well as favorable generalization across diverse problem classes, dimensions, and population sizes. Additionally, we provide an in-depth analysis of the EET issue by interpreting the learned behaviors of EC.
http://w3id.org/mlsea/pwc/scientificWork/AutoDev%3A%20Automated%20AI-Driven%20Development                                                                                  AutoDev: Automated AI-Driven Development                                                                                  The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot. However, existing solutions are not leveraging all the potential capabilities available in an IDE such as building, testing, executing code, git operations, etc. Therefore, they are constrained by their limited capabilities, primarily focusing on suggesting code snippets and file manipulation within a chat-based interface. To fill this gap, we present AutoDev, a fully automated AI-driven software development framework, designed for autonomous planning and execution of intricate software engineering tasks. AutoDev enables users to define complex software engineering objectives, which are assigned to AutoDev's autonomous AI Agents to achieve. These AI agents can perform diverse operations on a codebase, including file editing, retrieval, build processes, execution, testing, and git operations. They also have access to files, compiler output, build and testing logs, static analysis tools, and more. This enables the AI Agents to execute tasks in a fully automated manner with a comprehensive understanding of the contextual information required. Furthermore, AutoDev establishes a secure development environment by confining all operations within Docker containers. This framework incorporates guardrails to ensure user privacy and file security, allowing users to define specific permitted or restricted commands and operations within AutoDev. In our evaluation, we tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.
http://w3id.org/mlsea/pwc/scientificWork/AutoGuide%3A%20Automated%20Generation%20and%20Selection%20of%20State-Aware%20Guidelines%20for%20Large%20Language%20Model%20Agents                                                                                  AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents                                                                                  The primary limitation of large language models (LLMs) is their restricted understanding of the world. This poses significant difficulties for LLM-based agents, particularly in domains where pre-trained LLMs lack sufficient knowledge. In this paper, we introduce a novel framework, called AutoGuide, that bridges the knowledge gap in pre-trained LLMs by leveraging implicit knowledge in offline experiences. Specifically, AutoGuide effectively extracts knowledge embedded in offline data by extracting a set of state-aware guidelines. Importantly, each state-aware guideline is expressed in concise natural language and follows a conditional structure, clearly describing the state where it is applicable. As such, the resulting guidelines enable a principled way to provide helpful knowledge pertinent to an agent's current decision-making process. We show that our approach outperforms competitive LLM-based baselines by a large margin in sequential decision-making benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/AutoRD%3A%20An%20Automatic%20and%20End-to-End%20System%20for%20Rare%20Disease%20Knowledge%20Graph%20Construction%20Based%20on%20Ontologies-enhanced%20Large%20Language%20Models                                                                                  AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models                                                                                  Objectives: Our objective is to create an end-to-end system called AutoRD, which automates extracting information from clinical text about rare diseases. We have conducted various tests to evaluate the performance of AutoRD and highlighted its strengths and limitations in this paper. Materials and Methods: Our system, AutoRD, is a software pipeline involving data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implement this using large language models and medical knowledge graphs developed from open-source medical ontologies. We quantitatively evaluate our system on entity extraction, relation extraction, and the performance of knowledge graph construction. Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement compared to the base LLM. In detail, AutoRD achieves an overall entity extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%, symptom_and_sign: 46.1%, anaphor: 67.5%) and an overall relation extraction F1 score of 38.6% (produces: 34.7%, increases_risk_of: 12.4%, is_a: 37.4%, is_acronym: 44.1%, is_synonym: 16.3%, anaphora: 57.5%). Our qualitative experiment also demonstrates that the performance in constructing the knowledge graph is commendable. Discussion: AutoRD demonstrates the potential of LLM applications in rare disease detection. This improvement is attributed to several design, including the integration of ontologies-enhanced LLMs. Conclusion: AutoRD is an automated end-to-end system for extracting rare disease information from text to build knowledge graphs. It uses ontologies-enhanced LLMs for a robust medical knowledge base. The superior performance of AutoRD is validated by experimental evaluations, demonstrating the potential of LLMs in healthcare.
http://w3id.org/mlsea/pwc/scientificWork/AutoRT%3A%20Embodied%20Foundation%20Models%20for%20Large%20Scale%20Orchestration%20of%20Robotic%20Agents                                                                                  AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents                                                                                  Foundation models that incorporate language, vision, and more recently actions have revolutionized the ability to harness internet scale data to reason about useful tasks. However, one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world. In this paper, we propose AutoRT, a system that leverages existing foundation models to scale up the deployment of operational robots in completely unseen scenarios with minimal human supervision. AutoRT leverages vision-language models (VLMs) for scene understanding and grounding, and further uses large language models (LLMs) for proposing diverse and novel instructions to be performed by a fleet of robots. Guiding data collection by tapping into the knowledge of foundation models enables AutoRT to effectively reason about autonomy tradeoffs and safety while significantly scaling up data collection for robot learning. We demonstrate AutoRT proposing instructions to over 20 robots across multiple buildings and collecting 77k real robot episodes via both teleoperation and autonomous robot policies. We experimentally show that such 'in-the-wild' data collected by AutoRT is significantly more diverse, and that AutoRT's use of LLMs allows for instruction following data collection robots that can align to human preferences.
http://w3id.org/mlsea/pwc/scientificWork/Autoencoder-based%20General%20Purpose%20Representation%20Learning%20for%20Customer%20Embedding                                                                                  Autoencoder-based General Purpose Representation Learning for Customer Embedding                                                                                  In recent years, exploiting the domain-specific underlying structure of data and its generative factors for representation learning has shown success in various use-case agnostic applications. However, the diversity and complexity of tabular data have made it challenging to represent these structures in a latent space through multi-dimensional vectors. We design an autoencoder-based framework for building general purpose embeddings, we assess the performance of different autoencoder architectures, and show simpler models outperform complex ones in embedding highly complex tabular data. We apply our framework to produce plug-and-play, rich, and anonymized embeddings representing AWS customers for usage in any model, saving up to 45% of development time, and observe significant improvements in downstream models. Moreover, we propose a significant improvement to the calculation of reconstruction loss for multi-layer contractive autoencoders (CAE) by calculating the Jacobian of the entire encoder leading to a 15% improvement in reconstruction quality when compared to a stacked CAE.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Completion%20of%20Statements%20and%20Proofs%20in%20Synthetic%20Geometry%3A%20an%20Approach%20based%20on%20Constraint%20Solving                                                                                  Automated Completion of Statements and Proofs in Synthetic Geometry: an Approach based on Constraint Solving                                                                                  Conjecturing and theorem proving are activities at the center of mathematical practice and are difficult to separate. In this paper, we propose a framework for completing incomplete conjectures and incomplete proofs. The framework can turn a conjecture with missing assumptions and with an under-specified goal into a proper theorem. Also, the proposed framework can help in completing a proof sketch into a human-readable and machine-checkable proof. Our approach is focused on synthetic geometry, and uses coherent logic and constraint solving. The proposed approach is uniform for all three kinds of tasks, flexible and, to our knowledge, unique such approach.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Data%20Curation%20for%20Robust%20Language%20Model%20Fine-Tuning                                                                                  Automated Data Curation for Robust Language Model Fine-Tuning                                                                                  Large Language Models have become the de facto approach to sequence-to-sequence text generation tasks, but for specialized tasks/domains, a pretrained LLM lacks specific capabilities to produce accurate or well-formatted responses. Supervised fine-tuning specializes a LLM by training it on dataset of example prompts with target responses, but real-world data tends to be noisy. While many fine-tuning algorithms exist, here we consider a emph{data-centric AI} perspective on LLM fine-tuning, studying how to emph{systematically} curate the training dataset to improve the LLM produced via emph{any} fine-tuning algorithm. We introduce an automated data curation pipeline CLEAR (Confidence-based LLM Evaluation And Rectification) for instruction tuning datasets, that can be used with any LLM and fine-tuning procedure. CLEAR estimates which training data is low-quality and either filters or corrects it. Automatically identifying which data to filter or correct is done via LLM-derived confidence estimates, to ensure only confident modifications to the dataset. Unlike existing data curation techniques, CLEAR is a comprehensive framework that can improve a dataset (and trained model outputs) without additional fine-tuning computations. We don't assume access to a stronger LLM than the model being fine-tuned (e.g. relying on GPT-4 when fine-tuning GPT-3.5), to see whether CLEAR can meaningfully improve the capabilities of any LLM. Experiments reveal that CLEAR consistently improves the performance of fine-tuned models across many datasets and models (like GPT-3.5 and Llama2).
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Detection%20of%20Welding%20Defects%20without%20Segmentation                                                                                  Automated Detection of Welding Defects without Segmentation                                                                                  Abstract Substantial research has been performed on automated detection and classification of welding defects in continuous welds using X-ray imaging. Typically, the detection follows a pattern recognition schema (segmentation, feature extraction and classification). In computer vision community, however, many object detection and classification problems, like face and human detection, have been recently solved - without segmentation- using sliding-windows and novel features like local binary patterns extracted from saliency maps. For this reason, we propose in this paper the use of sliding-windows with the mentioned features to perform automatically the automated detection of welding defects. In the experiments, we analyzed 5000 detection windows (24x24 pixels) and 572 intensity features from 10 representative X-ray images. Cross validation yielded a detection performance of 94% using a support vector machine classifier with only 14 selected features. The method was implemented and tested on real X-ray images showing high effectiveness. We believe that the proposed approach opens new possibilities in the field of automated detection of welding defects
http://w3id.org/mlsea/pwc/scientificWork/Automated%20Prediction%20of%20Breast%20Cancer%20Response%20to%20Neoadjuvant%20Chemotherapy%20from%20DWI%20Data                                                                                  Automated Prediction of Breast Cancer Response to Neoadjuvant Chemotherapy from DWI Data                                                                                  Effective surgical planning for breast cancer hinges on accurately predicting pathological complete response (pCR) to neoadjuvant chemotherapy (NAC). Diffusion-weighted MRI (DWI) and machine learning offer a non-invasive approach for early pCR assessment. However, most machine-learning models require manual tumor segmentation, a cumbersome and error-prone task. We propose a deep learning model employing 'Size-Adaptive Lesion Weighting' for automatic DWI tumor segmentation to enhance pCR prediction accuracy. Despite histopathological changes during NAC complicating DWI image segmentation, our model demonstrates robust performance. Utilizing the BMMR2 challenge dataset, it matches human experts in pCR prediction pre-NAC with an area under the curve (AUC) of 0.76 vs. 0.796, and surpasses standard automated methods mid-NAC, with an AUC of 0.729 vs. 0.654 and 0.576. Our approach represents a significant advancement in automating breast cancer treatment planning, enabling more reliable pCR predictions without manual segmentation.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20data%20processing%20and%20feature%20engineering%20for%20deep%20learning%20and%20big%20data%20applications%3A%20a%20survey                                                                                  Automated data processing and feature engineering for deep learning and big data applications: a survey                                                                                  Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for Big Data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing--e.g., data cleaning, labeling, missing data imputation, and categorical data encoding--as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering--specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.
http://w3id.org/mlsea/pwc/scientificWork/Automated%20detection%20of%20motion%20artifacts%20in%20brain%20MR%20images%20using%20deep%20learning%20and%20explainable%20artificial%20intelligence                                                                                  Automated detection of motion artifacts in brain MR images using deep learning and explainable artificial intelligence                                                                                  Quality assessment, including inspecting the images for artifacts, is a critical step during MRI data acquisition to ensure data quality and downstream analysis or interpretation success. This study demonstrates a deep learning model to detect rigid motion in T1-weighted brain images. We leveraged a 2D CNN for three-class classification and tested it on publicly available retrospective and prospective datasets. Grad-CAM heatmaps enabled the identification of failure modes and provided an interpretation of the model's results. The model achieved average precision and recall metrics of 85% and 80% on six motion-simulated retrospective datasets. Additionally, the model's classifications on the prospective dataset showed a strong inverse correlation (-0.84) compared to average edge strength, an image quality metric indicative of motion. This model is part of the ArtifactID tool, aimed at inline automatic detection of Gibbs ringing, wrap-around, and motion artifacts. This tool automates part of the time-consuming QA process and augments expertise on-site, particularly relevant in low-resource settings where local MR knowledge is scarce.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Alignment%20of%20Discourse%20Relations%20of%20Different%20Discourse%20Annotation%20Frameworks                                                                                  Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks                                                                                  Existing discourse corpora are annotated based on different frameworks, which show significant dissimilarities in definitions of arguments and relations and structural constraints. Despite surface differences, these frameworks share basic understandings of discourse relations. The relationship between these frameworks has been an open research question, especially the correlation between relation inventories utilized in different frameworks. Better understanding of this question is helpful for integrating discourse theories and enabling interoperability of discourse corpora annotated under different frameworks. However, studies that explore correlations between discourse relation inventories are hindered by different criteria of discourse segmentation, and expert knowledge and manual examination are typically needed. Some semi-automatic methods have been proposed, but they rely on corpora annotated in multiple frameworks in parallel. In this paper, we introduce a fully automatic approach to address the challenges. Specifically, we extend the label-anchored contrastive learning method introduced by Zhang et al. (2022b) to learn label embeddings during a classification task. These embeddings are then utilized to map discourse relations from different frameworks. We show experimental results on RST-DT (Carlson et al., 2001) and PDTB 3.0 (Prasad et al., 2018).
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Construction%20of%20a%20Large-Scale%20Corpus%20for%20Geoparsing%20Using%20Wikipedia%20Hyperlinks                                                                                  Automatic Construction of a Large-Scale Corpus for Geoparsing Using Wikipedia Hyperlinks                                                                                  Geoparsing is the task of estimating the latitude and longitude (coordinates) of location expressions in texts. Geoparsing must deal with the ambiguity of the expressions that indicate multiple locations with the same notation. For evaluating geoparsing systems, several corpora have been proposed in previous work. However, these corpora are small-scale and suffer from the coverage of location expressions on general domains. In this paper, we propose Wikipedia Hyperlink-based Location Linking (WHLL), a novel method to construct a large-scale corpus for geoparsing from Wikipedia articles. WHLL leverages hyperlinks in Wikipedia to annotate multiple location expressions with coordinates. With this method, we constructed the WHLL corpus, a new large-scale corpus for geoparsing. The WHLL corpus consists of 1.3M articles, each containing about 7.8 unique location expressions. 45.6% of location expressions are ambiguous and refer to more than one location with the same notation. In each article, location expressions of the article title and those hyperlinks to other articles are assigned with coordinates. By utilizing hyperlinks, we can accurately assign location expressions with coordinates even with ambiguous location expressions in the texts. Experimental results show that there remains room for improvement by disambiguating location expressions.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Generation%20and%20Evaluation%20of%20Reading%20Comprehension%20Test%20Items%20with%20Large%20Language%20Models                                                                                  Automatic Generation and Evaluation of Reading Comprehension Test Items with Large Language Models                                                                                  Reading comprehension tests are used in a variety of applications, reaching from education to assessing the comprehensibility of simplified texts. However, creating such tests manually and ensuring their quality is difficult and time-consuming. In this paper, we explore how large language models (LLMs) can be used to generate and evaluate multiple-choice reading comprehension items. To this end, we compiled a dataset of German reading comprehension items and developed a new protocol for human and automatic evaluation, including a metric we call text informativity, which is based on guessability and answerability. We then used this protocol and the dataset to evaluate the quality of items generated by Llama 2 and GPT-4. Our results suggest that both models are capable of generating items of acceptable quality in a zero-shot setting, but GPT-4 clearly outperforms Llama 2. We also show that LLMs can be used for automatic evaluation by eliciting item reponses from them. In this scenario, evaluation results with GPT-4 were the most similar to human annotators. Overall, zero-shot generation with LLMs is a promising approach for generating and evaluating reading comprehension test items, in particular for languages without large amounts of available data.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Recognition%20of%20Learning%20Resource%20Category%20in%20a%20Digital%20Library                                                                                  Automatic Recognition of Learning Resource Category in a Digital Library                                                                                  Digital libraries often face the challenge of processing a large volume of diverse document types. The manual collection and tagging of metadata can be a time-consuming and error-prone task. To address this, we aim to develop an automatic metadata extractor for digital libraries. In this work, we introduce the Heterogeneous Learning Resources (HLR) dataset designed for document image classification. The approach involves decomposing individual learning resources into constituent document images (sheets). These images are then processed through an OCR tool to extract textual representation. State-of-the-art classifiers are employed to classify both the document image and its textual content. Subsequently, the labels of the constituent document images are utilized to predict the label of the overall document.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Speech%20Recognition%20using%20Advanced%20Deep%20Learning%20Approaches%3A%20A%20survey                                                                                  Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey                                                                                  Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and reinforcement learning (RL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and RL optimizes decision-making in dynamic environments, reducing computation costs. This survey offers a comprehensive review of DTL, FL, and RL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges. Additionally, transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence. The paper starts by presenting the background of DTL, FL, RL, and Transformers and then adopts a well-designed taxonomy to outline the state-of-the-art approaches. Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework. Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20Tuning%20of%20Denoising%20Algorithms%20Parameters%20Without%20Ground%20Truth                                                                                  Automatic Tuning of Denoising Algorithms Parameters Without Ground Truth                                                                                  Denoising is omnipresent in image processing. It is usually addressed with algorithms relying on a set of hyperparameters that control the quality of the recovered image. Manual tuning of those parameters can be a daunting task, which calls for the development of automatic tuning methods. Given a denoising algorithm, the best set of parameters is the one that minimizes the error between denoised and ground-truth images. Clearly, this ideal approach is unrealistic, as the ground-truth images are unknown in practice. In this work, we propose unsupervised cost functions -- i.e., that only require the noisy image -- that allow us to reach this ideal gold standard performance. Specifically, the proposed approach makes it possible to obtain an average PSNR output within less than 1% of the best achievable PSNR.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20UAV-based%20Airport%20Pavement%20Inspection%20Using%20Mixed%20Real%20and%20Virtual%20Scenarios                                                                                  Automatic UAV-based Airport Pavement Inspection Using Mixed Real and Virtual Scenarios                                                                                  Runway and taxiway pavements are exposed to high stress during their projected lifetime, which inevitably leads to a decrease in their condition over time. To make sure airport pavement condition ensure uninterrupted and resilient operations, it is of utmost importance to monitor their condition and conduct regular inspections. UAV-based inspection is recently gaining importance due to its wide range monitoring capabilities and reduced cost. In this work, we propose a vision-based approach to automatically identify pavement distress using images captured by UAVs. The proposed method is based on Deep Learning (DL) to segment defects in the image. The DL architecture leverages the low computational capacities of embedded systems in UAVs by using an optimised implementation of EfficientNet feature extraction and Feature Pyramid Network segmentation. To deal with the lack of annotated data for training we have developed a synthetic dataset generation methodology to extend available distress datasets. We demonstrate that the use of a mixed dataset composed of synthetic and real training images yields better results when testing the training models in real application scenarios.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20design%20optimization%20of%20preference-based%20subjective%20evaluation%20with%20online%20learning%20in%20crowdsourcing%20environment                                                                                  Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment                                                                                  A preference-based subjective evaluation is a key method for evaluating generative media reliably. However, its huge combinations of pairs prohibit it from being applied to large-scale evaluation using crowdsourcing. To address this issue, we propose an automatic optimization method for preference-based subjective evaluation in terms of pair combination selections and allocation of evaluation volumes with online learning in a crowdsourcing environment. We use a preference-based online learning method based on a sorting algorithm to identify the total order of evaluation targets with minimum sample volumes. Our online learning algorithm supports parallel and asynchronous execution under fixed-budget conditions required for crowdsourcing. Our experiment on preference-based subjective evaluation of synthetic speech shows that our method successfully optimizes the test by reducing pair combinations from 351 to 83 and allocating optimal evaluation volumes for each pair ranging from 30 to 663 without compromising evaluation accuracies and wasting budget allocations.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20detection%20of%20relevant%20information%2C%20predictions%20and%20forecasts%20in%20financial%20news%20through%20topic%20modelling%20with%20Latent%20Dirichlet%20Allocation                                                                                  Automatic detection of relevant information, predictions and forecasts in financial news through topic modelling with Latent Dirichlet Allocation                                                                                  Financial news items are unstructured sources of information that can be mined to extract knowledge for market screening applications. Manual extraction of relevant information from the continuous stream of finance-related news is cumbersome and beyond the skills of many investors, who, at most, can follow a few sources and authors. Accordingly, we focus on the analysis of financial news to identify relevant text and, within that text, forecasts and predictions. We propose a novel Natural Language Processing (NLP) system to assist investors in the detection of relevant financial events in unstructured textual sources by considering both relevance and temporality at the discursive level. Firstly, we segment the text to group together closely related text. Secondly, we apply co-reference resolution to discover internal dependencies within segments. Finally, we perform relevant topic modelling with Latent Dirichlet Allocation (LDA) to separate relevant from less relevant text and then analyse the relevant text using a Machine Learning-oriented temporal approach to identify predictions and speculative statements. We created an experimental data set composed of 2,158 financial news items that were manually labelled by NLP researchers to evaluate our solution. The ROUGE-L values for the identification of relevant text and predictions/forecasts were 0.662 and 0.982, respectively. To our knowledge, this is the first work to jointly consider relevance and temporality at the discursive level. It contributes to the transfer of human associative discourse capabilities to expert systems through the combination of multi-paragraph topic segmentation and co-reference resolution to separate author expression patterns, topic modelling with LDA to detect relevant text, and discursive temporality analysis to identify forecasts and predictions within this text.
http://w3id.org/mlsea/pwc/scientificWork/Automatic%20driving%20lane%20change%20safety%20prediction%20model%20based%20on%20LSTM                                                                                  Automatic driving lane change safety prediction model based on LSTM                                                                                  Autonomous driving technology can improve traffic safety and reduce traffic accidents. In addition, it improves traffic flow, reduces congestion, saves energy and increases travel efficiency. In the relatively mature automatic driving technology, the automatic driving function is divided into several modules: perception, decision-making, planning and control, and a reasonable division of labor can improve the stability of the system. Therefore, autonomous vehicles need to have the ability to predict the trajectory of surrounding vehicles in order to make reasonable decision planning and safety measures to improve driving safety. By using deep learning method, a safety-sensitive deep learning model based on short term memory (LSTM) network is proposed. This model can alleviate the shortcomings of current automatic driving trajectory planning, and the output trajectory not only ensures high accuracy but also improves safety. The cell state simulation algorithm simulates the trackability of the trajectory generated by this model. The research results show that compared with the traditional model-based method, the trajectory prediction method based on LSTM network has obvious advantages in predicting the trajectory in the long time domain. The intention recognition module considering interactive information has higher prediction and accuracy, and the algorithm results show that the trajectory is very smooth based on the premise of safe prediction and efficient lane change. And autonomous vehicles can efficiently and safely complete lane changes.
http://w3id.org/mlsea/pwc/scientificWork/Automating%20Psychological%20Hypothesis%20Generation%20with%20AI%3A%20Large%20Language%20Models%20Meet%20Causal%20Graph                                                                                  Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph                                                                                  Leveraging the synergy between causal knowledge graphs and a large language model (LLM), our study introduces a groundbreaking approach for computational hypothesis generation in psychology. We analyzed 43,312 psychology articles using a LLM to extract causal relation pairs. This analysis produced a specialized causal graph for psychology. Applying link prediction algorithms, we generated 130 potential psychological hypotheses focusing on `well-being', then compared them against research ideas conceived by doctoral scholars and those produced solely by the LLM. Interestingly, our combined approach of a LLM and causal graphs mirrored the expert-level insights in terms of novelty, clearly surpassing the LLM-only hypotheses (t(59) = 3.34, p=0.007 and t(59) = 4.32, p<0.001, respectively). This alignment was further corroborated using deep semantic analysis. Our results show that combining LLM with machine learning techniques such as causal knowledge graphs can revolutionize automated discovery in psychology, extracting novel insights from the extensive literature. This work stands at the crossroads of psychology and artificial intelligence, championing a new enriched paradigm for data-driven hypothesis generation in psychological research.
http://w3id.org/mlsea/pwc/scientificWork/Automating%20the%20Information%20Extraction%20from%20Semi-Structured%20Interview%20Transcripts                                                                                  Automating the Information Extraction from Semi-Structured Interview Transcripts                                                                                  This paper explores the development and application of an automated system designed to extract information from semi-structured interview transcripts. Given the labor-intensive nature of traditional qualitative analysis methods, such as coding, there exists a significant demand for tools that can facilitate the analysis process. Our research investigates various topic modeling techniques and concludes that the best model for analyzing interview texts is a combination of BERT embeddings and HDBSCAN clustering. We present a user-friendly software prototype that enables researchers, including those without programming skills, to efficiently process and visualize the thematic structure of interview data. This tool not only facilitates the initial stages of qualitative analysis but also offers insights into the interconnectedness of topics revealed, thereby enhancing the depth of qualitative analysis.
http://w3id.org/mlsea/pwc/scientificWork/Automation%20of%20Triangle%20Ruler-and-Compass%20Constructions%20Using%20Constraint%20Solvers                                                                                  Automation of Triangle Ruler-and-Compass Constructions Using Constraint Solvers                                                                                  In this paper, we present an approach to automated solving of triangle ruler-and-compass construction problems using finite-domain constraint solvers. The constraint model is described in the MiniZinc modeling language, and is based on the automated planning. The main benefit of using general constraint solvers for such purpose, instead of developing dedicated tools, is that we can rely on the efficient search that is already implemented within the solver, enabling us to focus on geometric aspects of the problem. We may also use the solver's built-in optimization capabilities to search for the shortest possible constructions. We evaluate our approach on 74 solvable problems from the Wernick's list, and compare it to the dedicated triangle construction solver ArgoTriCS. The results show that our approach is comparable to dedicated tools, while it requires much less effort to implement. Also, our model often finds shorter constructions, thanks to the optimization capabilities offered by the constraint solvers.
http://w3id.org/mlsea/pwc/scientificWork/Autonomous%20Emergency%20Braking%20With%20Driver-In-The-Loop%3A%20Torque%20Vectoring%20for%20Active%20Learning                                                                                  Autonomous Emergency Braking With Driver-In-The-Loop: Torque Vectoring for Active Learning                                                                                  Autonomous Emergency Braking (AEB) potentially brings significant improvements in automotive safety due to its ability to autonomously prevent collisions in situations where the driver may not be able to do so. Driven by the poor performance of the state of the art in recent testing, this work provides an online solution to identify critical parameters such as the current and maximum friction coefficients. The method introduced here, namely Torque Vectoring for Active Learning (TVAL), can perform state and parameter estimation whilst following the driver's input. Importantly with less power requirements than normal driving. Our method is designed with a crucial focus on ensuring minimal disruption to the driver, allowing them to maintain full control of the vehicle. Additionally, we exploit a rain/light sensor to drive the observer resampling to maintain estimation certainty across prolonged operation. Then a scheme to modulate TVAL is introduced that considers powertrain efficiency, safety, and availability in an online fashion. Using a high-fidelity vehicle model and drive cycle we demonstrate the functionality of TVAL controller across changing road surfaces where we successfully identify the road surface whenever possible.
http://w3id.org/mlsea/pwc/scientificWork/Autonomous%20vehicle%20decision%20and%20control%20through%20reinforcement%20learning%20with%20traffic%20flow%20randomization                                                                                  Autonomous vehicle decision and control through reinforcement learning with traffic flow randomization                                                                                  Most of the current studies on autonomous vehicle decision-making and control tasks based on reinforcement learning are conducted in simulated environments. The training and testing of these studies are carried out under rule-based microscopic traffic flow, with little consideration of migrating them to real or near-real environments to test their performance. It may lead to a degradation in performance when the trained model is tested in more realistic traffic scenes. In this study, we propose a method to randomize the driving style and behavior of surrounding vehicles by randomizing certain parameters of the car-following model and the lane-changing model of rule-based microscopic traffic flow in SUMO. We trained policies with deep reinforcement learning algorithms under the domain randomized rule-based microscopic traffic flow in freeway and merging scenes, and then tested them separately in rule-based microscopic traffic flow and high-fidelity microscopic traffic flow. Results indicate that the policy trained under domain randomization traffic flow has significantly better success rate and calculative reward compared to the models trained under other microscopic traffic flows.
http://w3id.org/mlsea/pwc/scientificWork/Auxiliary%20Label%20Embedding%20for%20Multi-label%20Learning%20with%20Missing%20Labels                                                                                  Auxiliary Label Embedding for Multi-label Learning with Missing Labels                                                                                  Label correlation has been exploited for multi-label learning in different ways. Existing approaches presume that label correlation information is available as a prior, but for multi-label datasets having incomplete labels, the assumption is violated. In this paper, we propose an approach for multi-label classification when label details are incomplete by learning auxiliary label matrix from the observed labels, and generating an embedding from learnt label correlations preserving the correlation structure in model coefficients. The approach recovers missing labels and simultaneously guides the construction of model coefficients from the learnt label correlations. Empirical results on multi-label datasets from diverse domains such as image & music substantiate the correlation embedding approach for missing label scenario. The proposed approach performs favorably over four popular multi-label learning techniques using five multi-label evaluation metrics.
http://w3id.org/mlsea/pwc/scientificWork/Auxiliary%20Tasks%20Enhanced%20Dual-affinity%20Learning%20for%20Weakly%20Supervised%20Semantic%20Segmentation                                                                                  Auxiliary Tasks Enhanced Dual-affinity Learning for Weakly Supervised Semantic Segmentation                                                                                  Most existing weakly supervised semantic segmentation (WSSS) methods rely on Class Activation Mapping (CAM) to extract coarse class-specific localization maps using image-level labels. Prior works have commonly used an off-line heuristic thresholding process that combines the CAM maps with off-the-shelf saliency maps produced by a general pre-trained saliency model to produce more accurate pseudo-segmentation labels. We propose AuxSegNet+, a weakly supervised auxiliary learning framework to explore the rich information from these saliency maps and the significant inter-task correlation between saliency detection and semantic segmentation. In the proposed AuxSegNet+, saliency detection and multi-label image classification are used as auxiliary tasks to improve the primary task of semantic segmentation with only image-level ground-truth labels. We also propose a cross-task affinity learning mechanism to learn pixel-level affinities from the saliency and segmentation feature maps. In particular, we propose a cross-task dual-affinity learning module to learn both pairwise and unary affinities, which are used to enhance the task-specific features and predictions by aggregating both query-dependent and query-independent global context for both saliency detection and semantic segmentation. The learned cross-task pairwise affinity can also be used to refine and propagate CAM maps to provide better pseudo labels for both tasks. Iterative improvement of segmentation performance is enabled by cross-task affinity learning and pseudo-label updating. Extensive experiments demonstrate the effectiveness of the proposed approach with new state-of-the-art WSSS results on the challenging PASCAL VOC and MS COCO benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/Averaging%20Rate%20Scheduler%20for%20Decentralized%20Learning%20on%20Heterogeneous%20Data                                                                                  Averaging Rate Scheduler for Decentralized Learning on Heterogeneous Data                                                                                  State-of-the-art decentralized learning algorithms typically require the data distribution to be Independent and Identically Distributed (IID). However, in practical scenarios, the data distribution across the agents can have significant heterogeneity. In this work, we propose averaging rate scheduling as a simple yet effective way to reduce the impact of heterogeneity in decentralized learning. Our experiments illustrate the superiority of the proposed method (~3% improvement in test accuracy) compared to the conventional approach of employing a constant averaging rate.
http://w3id.org/mlsea/pwc/scientificWork/Ax-to-Grind%20Urdu%3A%20Benchmark%20Dataset%20for%20Urdu%20Fake%20News%20Detection                                                                                  Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection                                                                                  Misinformation can seriously impact society, affecting anything from public opinion to institutional confidence and the political horizon of a state. Fake News (FN) proliferation on online websites and Online Social Networks (OSNs) has increased profusely. Various fact-checking websites include news in English and barely provide information about FN in regional languages. Thus the Urdu FN purveyors cannot be discerned using factchecking portals. SOTA approaches for Fake News Detection (FND) count upon appropriately labelled and large datasets. FND in regional and resource-constrained languages lags due to the lack of limited-sized datasets and legitimate lexical resources. The previous datasets for Urdu FND are limited-sized, domain-restricted, publicly unavailable and not manually verified where the news is translated from English into Urdu. In this paper, we curate and contribute the first largest publicly available dataset for Urdu FND, Ax-to-Grind Urdu, to bridge the identified gaps and limitations of existing Urdu datasets in the literature. It constitutes 10,083 fake and real news on fifteen domains collected from leading and authentic Urdu newspapers and news channel websites in Pakistan and India. FN for the Ax-to-Grind dataset is collected from websites and crowdsourcing. The dataset contains news items in Urdu from the year 2017 to the year 2023. Expert journalists annotated the dataset. We benchmark the dataset with an ensemble model of mBERT,XLNet, and XLM RoBERTa. The selected models are originally trained on multilingual large corpora. The results of the proposed model are based on performance metrics, F1-score, accuracy, precision, recall and MCC value.
http://w3id.org/mlsea/pwc/scientificWork/Axiomatic%20Characterizations%20of%20Draft%20Rules                                                                                  Axiomatic Characterizations of Draft Rules                                                                                  Drafts are sequential allocation procedures for distributing heterogeneous and indivisible objects among agents subject to some priority order (e.g., allocating players' contract rights to teams in professional sports leagues). Agents report ordinal preferences over objects and bundles are partially ordered by pairwise comparison. We provide a simple characterization of draft rules: they are the only allocation rules which are respectful of a priority (RP), envy-free up to one object (EF1), non-wasteful (NW) and resource monotonic (RM). RP and EF1 are crucial for competitive balance in sports leagues. We also prove three related impossibility theorems showing that the competitive-balance axioms RP and EF1 are generally incompatible with strategy-proofness. However, draft rules satisfy maxmin strategy-proofness. If agents may declare some objects unacceptable, then draft rules are characterized by RP, EF1, NW, and RM, in conjunction with individual rationality and truncation invariance. In a model with variable populations, draft rules are characterized by EF1, EFF, and RM, together with (population) consistency, top-object consistency, and neutrality.
http://w3id.org/mlsea/pwc/scientificWork/Aya%20Dataset%3A%20An%20Open-Access%20Collection%20for%20Multilingual%20Instruction%20Tuning                                                                                  Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning                                                                                  Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent achievements in the space of natural language processing (NLP) can be attributed to the finetuning of pre-trained models on a diverse set of tasks that enables a large language model (LLM) to respond to instructions. Instruction fine-tuning (IFT) requires specifically constructed and annotated datasets. However, existing datasets are almost all in the English language. In this work, our primary goal is to bridge the language gap by building a human-curated instruction-following dataset spanning 65 languages. We worked with fluent speakers of languages from around the world to collect natural instances of instructions and completions. Furthermore, we create the most extensive multilingual collection to date, comprising 513 million instances through templating and translating existing datasets across 114 languages. In total, we contribute four key resources: we develop and open-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection, and the Aya Evaluation Suite. The Aya initiative also serves as a valuable case study in participatory research, involving collaborators from 119 countries. We see this as a valuable framework for future research collaborations that aim to bridge gaps in resources.
http://w3id.org/mlsea/pwc/scientificWork/BAGS%3A%20Blur%20Agnostic%20Gaussian%20Splatting%20through%20Multi-Scale%20Kernel%20Modeling                                                                                  BAGS: Blur Agnostic Gaussian Splatting through Multi-Scale Kernel Modeling                                                                                  Recent efforts in using 3D Gaussians for scene reconstruction and novel view synthesis can achieve impressive results on curated benchmarks; however, images captured in real life are often blurry. In this work, we analyze the robustness of Gaussian-Splatting-based methods against various image blur, such as motion blur, defocus blur, downscaling blur, etc. Under these degradations, Gaussian-Splatting-based methods tend to overfit and produce worse results than Neural-Radiance-Field-based methods. To address this issue, we propose Blur Agnostic Gaussian Splatting (BAGS). BAGS introduces additional 2D modeling capacities such that a 3D-consistent and high quality scene can be reconstructed despite image-wise blur. Specifically, we model blur by estimating per-pixel convolution kernels from a Blur Proposal Network (BPN). BPN is designed to consider spatial, color, and depth variations of the scene to maximize modeling capacity. Additionally, BPN also proposes a quality-assessing mask, which indicates regions where blur occur. Finally, we introduce a coarse-to-fine kernel optimization scheme; this optimization scheme is fast and avoids sub-optimal solutions due to a sparse point cloud initialization, which often occurs when we apply Structure-from-Motion on blurry images. We demonstrate that BAGS achieves photorealistic renderings under various challenging blur conditions and imaging geometry, while significantly improving upon existing approaches.
http://w3id.org/mlsea/pwc/scientificWork/BASES%3A%20Large-scale%20Web%20Search%20User%20Simulation%20with%20Large%20Language%20Model%20based%20Agents                                                                                  BASES: Large-scale Web Search User Simulation with Large Language Model based Agents                                                                                  Due to the excellent capacities of large language models (LLMs), it becomes feasible to develop LLM-based agents for reliable user simulation. Considering the scarcity and limit (e.g., privacy issues) of real user data, in this paper, we conduct large-scale user simulation for web search, to improve the analysis and modeling of user search behavior. Specially, we propose BASES, a novel user simulation framework with LLM-based agents, designed to facilitate comprehensive simulations of web search user behaviors. Our simulation framework can generate unique user profiles at scale, which subsequently leads to diverse search behaviors. To demonstrate the effectiveness of BASES, we conduct evaluation experiments based on two human benchmarks in both Chinese and English, demonstrating that BASES can effectively simulate large-scale human-like search behaviors. To further accommodate the research on web search, we develop WARRIORS, a new large-scale dataset encompassing web search user behaviors, including both Chinese and English versions, which can greatly bolster research in the field of information retrieval. Our code and data will be publicly released soon.
http://w3id.org/mlsea/pwc/scientificWork/BAT%3A%20Learning%20to%20Reason%20about%20Spatial%20Sounds%20with%20Large%20Language%20Models                                                                                  BAT: Learning to Reason about Spatial Sounds with Large Language Models                                                                                  Spatial sound reasoning is a fundamental human skill, enabling us to navigate and interpret our surroundings based on sound. In this paper we present BAT, which combines the spatial sound perception ability of a binaural acoustic scene analysis model with the natural language reasoning capabilities of a large language model (LLM) to replicate this innate ability. To address the lack of existing datasets of in-the-wild spatial sounds, we synthesized a binaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed SpatialSoundQA, a spatial sound-based question-answering dataset, offering a range of QA tasks that train BAT in various aspects of spatial sound perception and reasoning. The acoustic front end encoder of BAT is a novel spatial audio encoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by itself achieves strong performance across sound event detection, spatial localization, and distance estimation. By integrating Spatial-AST with LLaMA-2 7B model, BAT transcends standard Sound Event Localization and Detection (SELD) tasks, enabling the model to reason about the relationships between the sounds in its environment. Our experiments demonstrate BAT's superior performance on both spatial sound perception and reasoning, showcasing the immense potential of LLMs in navigating and interpreting complex spatial audio environments.
http://w3id.org/mlsea/pwc/scientificWork/BAdam%3A%20A%20Memory%20Efficient%20Full%20Parameter%20Training%20Method%20for%20Large%20Language%20Models                                                                                  BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models                                                                                  This work presents BAdam, an optimizer that leverages the block coordinate optimization framework with Adam as the inner solver. BAdam offers a memory efficient approach to the full parameter finetuning of large language models and reduces running time of the backward process thanks to the chain rule property. Experimentally, we apply BAdam to instruction-tune the Llama 2-7B model on the Alpaca-GPT4 dataset using a single RTX3090-24GB GPU. The results indicate that BAdam exhibits superior convergence behavior in comparison to LoRA and LOMO. Furthermore, our downstream performance evaluation of the instruction-tuned models using the MT-bench shows that BAdam modestly surpasses LoRA and more substantially outperforms LOMO. Finally, we compare BAdam with Adam on a medium-sized task, i.e., finetuning RoBERTa-large on the SuperGLUE benchmark. The results demonstrate that BAdam is capable of narrowing the performance gap with Adam. Our code is available at https://github.com/Ledzy/BAdam.
http://w3id.org/mlsea/pwc/scientificWork/BBE-LSWCM%3A%20A%20Bootstrapped%20Ensemble%20of%20Long%20and%20Short%20Window%20Clickstream%20Models                                                                                  BBE-LSWCM: A Bootstrapped Ensemble of Long and Short Window Clickstream Models                                                                                  We consider the problem of developing a clickstream modeling framework for real-time customer event prediction problems in SaaS products like QBO. We develop a low-latency, cost-effective, and robust ensemble architecture (BBE-LSWCM), which combines both aggregated user behavior data from a longer historical window (e.g., over the last few weeks) as well as user activities over a short window in recent-past (e.g., in the current session). As compared to other baseline approaches, we demonstrate the superior performance of the proposed method for two important real-time event prediction problems: subscription cancellation and intended task detection for QBO subscribers. Finally, we present details of the live deployment and results from online experiments in QBO.
http://w3id.org/mlsea/pwc/scientificWork/BD-MSA%3A%20Body%20decouple%20VHR%20Remote%20Sensing%20Image%20Change%20Detection%20method%20guided%20by%20multi-scale%20feature%20information%20aggregation                                                                                  BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation                                                                                  The purpose of remote sensing image change detection (RSCD) is to detect differences between bi-temporal images taken at the same place. Deep learning has been extensively used to RSCD tasks, yielding significant results in terms of result recognition. However, due to the shooting angle of the satellite, the impacts of thin clouds, and certain lighting conditions, the problem of fuzzy edges in the change region in some remote sensing photographs cannot be properly handled using current RSCD algorithms. To solve this issue, we proposed a Body Decouple Multi-Scale by fearure Aggregation change detection (BD-MSA), a novel model that collects both global and local feature map information in the channel and space dimensions of the feature map during the training and prediction phases. This approach allows us to successfully extract the change region's boundary information while also divorcing the change region's main body from its boundary. Numerous studies have shown that the assessment metrics and evaluation effects of the model described in this paper on the publicly available datasets DSIFN-CD, S2Looking and WHU-CD are the best when compared to other models.
http://w3id.org/mlsea/pwc/scientificWork/BEBLID%3A%20Boosted%20efficient%20binary%20local%20image%20descriptor                                                                                  BEBLID: Boosted efficient binary local image descriptor                                                                                  Efficient matching of local image features is a fundamental task in many computer vision applications. However, the real-time performance of top matching algorithms is compromised in computationally limited devices, such as mobile phones or drones, due to the simplicity of their hardware and their finite energy supply. In this paper we introduce BEBLID, an efficient learned binary image descriptor. It improves our previous real-valued descriptor, BELID, making it both more efficient for matching and more accurate. To this end we use AdaBoost with an improved weak-learner training scheme that produces better local descriptions. Further, we binarize our descriptor by forcing all weak-learners to have the same weight in the strong learner combination and train it in an unbalanced data set to address the asymmetries arising in matching and retrieval tasks. In our experiments BEBLID achieves an accuracy close to SIFT and better computational efficiency than ORB, the fastest algorithm in the literature.
http://w3id.org/mlsea/pwc/scientificWork/BELHD%3A%20Improving%20Biomedical%20Entity%20Linking%20with%20Homonoym%20Disambiguation                                                                                  BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation                                                                                  Biomedical entity linking (BEL) is the task of grounding entity mentions to a knowledge base (KB). A popular approach to the task are name-based methods, i.e. those identifying the most appropriate name in the KB for a given mention, either via dense retrieval or autoregressive modeling. However, as these methods directly return KB names, they cannot cope with homonyms, i.e. different KB entities sharing the exact same name. This significantly affects their performance, especially for KBs where homonyms account for a large amount of entity mentions (e.g. UMLS and NCBI Gene). We therefore present BELHD (Biomedical Entity Linking with Homonym Disambiguation), a new name-based method that copes with this challenge. Specifically, BELHD builds upon the BioSyn (Sung et al.,2020) model introducing two crucial extensions. First, it performs a preprocessing of the KB in which it expands homonyms with an automatically chosen disambiguating string, thus enforcing unique linking decisions. Second, we introduce candidate sharing, a novel strategy to select candidates for contrastive learning that enhances the overall training signal. Experiments with 10 corpora and five entity types show that BELHD improves upon state-of-the-art approaches, achieving the best results in 6 out 10 corpora with an average improvement of 4.55pp recall@1. Furthermore, the KB preprocessing is orthogonal to the core prediction model and thus can also improve other methods, which we exemplify for GenBioEL (Yuan et al, 2022), a generative name-based BEL approach. Code is available at: link added upon publication.
http://w3id.org/mlsea/pwc/scientificWork/BERT-LSH%3A%20Reducing%20Absolute%20Compute%20For%20Attention                                                                                  BERT-LSH: Reducing Absolute Compute For Attention                                                                                  This study introduces a novel BERT-LSH model that incorporates Locality Sensitive Hashing (LSH) to approximate the attention mechanism in the BERT architecture. We examine the computational efficiency and performance of this model compared to a standard baseline BERT model. Our findings reveal that BERT-LSH significantly reduces computational demand for the self-attention layer while unexpectedly outperforming the baseline model in pretraining and fine-tuning tasks. These results suggest that the LSH-based attention mechanism not only offers computational advantages but also may enhance the model's ability to generalize from its training data. For more information, visit our GitHub repository: https://github.com/leo4life2/algoml-final
http://w3id.org/mlsea/pwc/scientificWork/BERT4FCA%3A%20A%20Method%20for%20Bipartite%20Link%20Prediction%20using%20Formal%20Concept%20Analysis%20and%20BERT                                                                                  BERT4FCA: A Method for Bipartite Link Prediction using Formal Concept Analysis and BERT                                                                                  We propose BERT4FCA, a novel method for link prediction in bipartite networks, using formal concept analysis (FCA) and BERT. Link prediction in bipartite networks is an important task that can solve various practical problems like friend recommendation in social networks and co-authorship prediction in author-paper networks. Recent research has found that in bipartite networks, maximal bi-cliques provide important information for link prediction, and they can be extracted by FCA. Some FCA-based bipartite link prediction methods have achieved good performance. However, we figured out that their performance could be further improved because these methods did not fully capture the rich information of the extracted maximal bi-cliques. To address this limitation, we propose an approach using BERT, which can learn more information from the maximal bi-cliques extracted by FCA and use them to make link prediction. We conduct experiments on three real-world bipartite networks and demonstrate that our method outperforms previous FCA-based methods, and some classic methods such as matrix-factorization and node2vec.
http://w3id.org/mlsea/pwc/scientificWork/BET%3A%20Explaining%20Deep%20Reinforcement%20Learning%20through%20The%20Error-Prone%20Decisions                                                                                  BET: Explaining Deep Reinforcement Learning through The Error-Prone Decisions                                                                                  Despite the impressive capabilities of Deep Reinforcement Learning (DRL) agents in many challenging scenarios, their black-box decision-making process significantly limits their deployment in safety-sensitive domains. Several previous self-interpretable works focus on revealing the critical states of the agent's decision. However, they cannot pinpoint the error-prone states. To address this issue, we propose a novel self-interpretable structure, named Backbone Extract Tree (BET), to better explain the agent's behavior by identify the error-prone states. At a high level, BET hypothesizes that states in which the agent consistently executes uniform decisions exhibit a reduced propensity for errors. To effectively model this phenomenon, BET expresses these states within neighborhoods, each defined by a curated set of representative states. Therefore, states positioned at a greater distance from these representative benchmarks are more prone to error. We evaluate BET in various popular RL environments and show its superiority over existing self-interpretable models in terms of explanation fidelity. Furthermore, we demonstrate a use case for providing explanations for the agents in StarCraft II, a sophisticated multi-agent cooperative game. To the best of our knowledge, we are the first to explain such a complex scenarios using a fully transparent structure.
http://w3id.org/mlsea/pwc/scientificWork/BEVUDA%3A%20Multi-geometric%20Space%20Alignments%20for%20Domain%20Adaptive%20BEV%203D%20Object%20Detection                                                                                  BEVUDA: Multi-geometric Space Alignments for Domain Adaptive BEV 3D Object Detection                                                                                  Vision-centric bird-eye-view (BEV) perception has shown promising potential in autonomous driving. Recent works mainly focus on improving efficiency or accuracy but neglect the challenges when facing environment changing, resulting in severe degradation of transfer performance. For BEV perception, we figure out the significant domain gaps existing in typical real-world cross-domain scenarios and comprehensively solve the Domain Adaption (DA) problem for multi-view 3D object detection. Since BEV perception approaches are complicated and contain several components, the domain shift accumulation on multiple geometric spaces (i.e., 2D, 3D Voxel, BEV) makes BEV DA even challenging. In this paper, we propose a Multi-space Alignment Teacher-Student (MATS) framework to ease the domain shift accumulation, which consists of a Depth-Aware Teacher (DAT) and a Geometric-space Aligned Student (GAS) model. DAT tactfully combines target lidar and reliable depth prediction to construct depth-aware information, extracting target domain-specific knowledge in Voxel and BEV feature spaces. It then transfers the sufficient domain knowledge of multiple spaces to the student model. In order to jointly alleviate the domain shift, GAS projects multi-geometric space features to a shared geometric embedding space and decreases data distribution distance between two domains. To verify the effectiveness of our method, we conduct BEV 3D object detection experiments on three cross-domain scenarios and achieve state-of-the-art performance.
http://w3id.org/mlsea/pwc/scientificWork/BSDP%3A%20Brain-inspired%20Streaming%20Dual-level%20Perturbations%20for%20Online%20Open%20World%20Object%20Detection                                                                                  BSDP: Brain-inspired Streaming Dual-level Perturbations for Online Open World Object Detection                                                                                  Humans can easily distinguish the known and unknown categories and can recognize the unknown object by learning it once instead of repeating it many times without forgetting the learned object. Hence, we aim to make deep learning models simulate the way people learn. We refer to such a learning manner as OnLine Open World Object Detection(OLOWOD). Existing OWOD approaches pay more attention to the identification of unknown categories, while the incremental learning part is also very important. Besides, some neuroscience research shows that specific noises allow the brain to form new connections and neural pathways which may improve learning speed and efficiency. In this paper, we take the dual-level information of old samples as perturbations on new samples to make the model good at learning new knowledge without forgetting the old knowledge. Therefore, we propose a simple plug-and-play method, called Brain-inspired Streaming Dual-level Perturbations(BSDP), to solve the OLOWOD problem. Specifically, (1) we first calculate the prototypes of previous categories and use the distance between samples and the prototypes as the sample selecting strategy to choose old samples for replay; (2) then take the prototypes as the streaming feature-level perturbations of new samples, so as to improve the plasticity of the model through revisiting the old knowledge; (3) and also use the distribution of the features of the old category samples to generate adversarial data in the form of streams as the data-level perturbations to enhance the robustness of the model to new categories. We empirically evaluate BSDP on PASCAL VOC and MS-COCO, and the excellent results demonstrate the promising performance of our proposed method and learning manner.
http://w3id.org/mlsea/pwc/scientificWork/BVR%20Gym%3A%20A%20Reinforcement%20Learning%20Environment%20for%20Beyond-Visual-Range%20Air%20Combat                                                                                  BVR Gym: A Reinforcement Learning Environment for Beyond-Visual-Range Air Combat                                                                                  Creating new air combat tactics and discovering novel maneuvers can require numerous hours of expert pilots' time. Additionally, for each different combat scenario, the same strategies may not work since small changes in equipment performance may drastically change the air combat outcome. For this reason, we created a reinforcement learning environment to help investigate potential air combat tactics in the field of beyond-visual-range (BVR) air combat: the BVR Gym. This type of air combat is important since long-range missiles are often the first weapon to be used in aerial combat. Some existing environments provide high-fidelity simulations but are either not open source or are not adapted to the BVR air combat domain. Other environments are open source but use less accurate simulation models. Our work provides a high-fidelity environment based on the open-source flight dynamics simulator JSBSim and is adapted to the BVR air combat domain. This article describes the building blocks of the environment and some use cases.
http://w3id.org/mlsea/pwc/scientificWork/BaSAL%3A%20Size-Balanced%20Warm%20Start%20Active%20Learning%20for%20LiDAR%20Semantic%20Segmentation                                                                                  BaSAL: Size-Balanced Warm Start Active Learning for LiDAR Semantic Segmentation                                                                                  Active learning strives to reduce the need for costly data annotation, by repeatedly querying an annotator to label the most informative samples from a pool of unlabeled data, and then training a model from these samples. We identify two problems with existing active learning methods for LiDAR semantic segmentation. First, they overlook the severe class imbalance inherent in LiDAR semantic segmentation datasets. Second, to bootstrap the active learning loop when there is no labeled data available, they train their initial model from randomly selected data samples, leading to low performance. This situation is referred to as the cold start problem. To address these problems we propose BaSAL, a size-balanced warm start active learning model, based on the observation that each object class has a characteristic size. By sampling object clusters according to their size, we can thus create a size-balanced dataset that is also more class-balanced. Furthermore, in contrast to existing information measures like entropy or CoreSet, size-based sampling does not require a pretrained model, thus addressing the cold start problem effectively. Results show that we are able to improve the performance of the initial model by a large margin. Combining warm start and size-balanced sampling with established information measures, our approach achieves comparable performance to training on the entire SemanticKITTI dataset, despite using only 5% of the annotations, outperforming existing active learning methods. We also match the existing state-of-the-art in active learning on nuScenes. Our code is available at: https://github.com/Tony-WJR/BaSAL.
http://w3id.org/mlsea/pwc/scientificWork/Backdoor%20Attacks%20on%20Dense%20Passage%20Retrievers%20for%20Disseminating%20Misinformation                                                                                  Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation                                                                                  Dense retrievers and retrieval-augmented language models have been widely used in various NLP applications. Despite being designed to deliver reliable and secure outcomes, the vulnerability of retrievers to potential attacks remains unclear, raising concerns about their security. In this paper, we introduce a novel scenario where the attackers aim to covertly disseminate targeted misinformation, such as hate speech or advertisement, through a retrieval system. To achieve this, we propose a perilous backdoor attack triggered by grammar errors in dense passage retrieval. Our approach ensures that attacked models can function normally for standard queries but are manipulated to return passages specified by the attacker when users unintentionally make grammatical mistakes in their queries. Extensive experiments demonstrate the effectiveness and stealthiness of our proposed attack method. When a user query is error-free, our model consistently retrieves accurate information while effectively filtering out misinformation from the top-k results. However, when a query contains grammar errors, our system shows a significantly higher success rate in fetching the targeted content.
http://w3id.org/mlsea/pwc/scientificWork/Bacterial%20Communications%20and%20Computing%20in%20Internet%20of%20Everything%20%28IoE%29                                                                                  Bacterial Communications and Computing in Internet of Everything (IoE)                                                                                  Concurrent with advancements in molecular communication (MC), bacterial communication is emerging as a key area of interest. Given the frequent use of bacteria in various MC models, it is essential to have a thorough grasp of their intrinsic communication, signaling, and engineering techniques. Although it is crucial to have a strong understanding of the communication background, the inherent biological variability of bacteria may introduce complexity. Thus, an in-depth understanding of bacteria and their communication is a must for improving and extending the models in which they are utilized. Furthermore, the emerging and evolving domain of bacterial computing provides an exciting opportunity for advancing applications in areas such as environmental monitoring and biological computing networks. By integrating the communication and sensing capabilities, bacterial computing offers a promising framework for enhancing the adaptability and responsiveness of bacteria. This paper provides a comprehensive review of bacterial communication and computing, illustrating their application and the link with the concept of the Internet of Everything (IoE). Through the analysis of these biological systems, we reach a deeper insight on how the small-scale interactions may contribute to the major concept of universal interconnectedness; thus, we make the knowledge to flow and communication stronger between different fields. The discussion include the identification of the different bacterial mechanisms that could revolutionize the traditional communication systems. Thus, this paper offers valuable insights into previously unaddressed aspects of bacterial behavior, suggesting novel avenues for future research and aiming to advance understanding and application of bacterial sensing, communication and computing in MC models.
http://w3id.org/mlsea/pwc/scientificWork/Balanced%20Truncation%20of%20Linear%20Systems%20with%20Quadratic%20Outputs%20in%20Limited%20Time%20and%20Frequency%20Intervals                                                                                  Balanced Truncation of Linear Systems with Quadratic Outputs in Limited Time and Frequency Intervals                                                                                  Model order reduction involves constructing a reduced-order approximation of a high-order model while retaining its essential characteristics. This reduced-order model serves as a substitute for the original one in various applications such as simulation, analysis, and design. Often, there's a need to maintain high accuracy within a specific time or frequency interval, while errors beyond this limit can be tolerated. This paper addresses time-limited and frequency-limited model order reduction scenarios for linear systems with quadratic outputs, by generalizing the recently introduced structure-preserving balanced truncation algorithm. To that end, limited interval system Gramians are defined, and the corresponding generalized Lyapunov equations governing their computation are derived. Additionally, low-rank solutions for these equations are investigated. Next, balanced truncation algorithms are proposed for time-limited and frequency-limited scenarios, each utilizing its corresponding limited-interval system Gramians. The proposed algorithms ensure accurate results within specified time and frequency intervals while preserving the quadratic-output structure. Two benchmark numerical examples are presented to demonstrate the effectiveness of the algorithms, showcasing their ability to achieve superior accuracy within the desired time or frequency interval.
http://w3id.org/mlsea/pwc/scientificWork/Balancing%20Act%3A%20Distribution-Guided%20Debiasing%20in%20Diffusion%20Models                                                                                  Balancing Act: Distribution-Guided Debiasing in Diffusion Models                                                                                  Diffusion Models (DMs) have emerged as powerful generative models with unprecedented image generation capability. These models are widely used for data augmentation and creative applications. However, DMs reflect the biases present in the training datasets. This is especially concerning in the context of faces, where the DM prefers one demographic subgroup vs others (eg. female vs male). In this work, we present a method for debiasing DMs without relying on additional data or model retraining. Specifically, we propose Distribution Guidance, which enforces the generated images to follow the prescribed attribute distribution. To realize this, we build on the key insight that the latent features of denoising UNet hold rich demographic semantics, and the same can be leveraged to guide debiased generation. We train Attribute Distribution Predictor (ADP) - a small mlp that maps the latent features to the distribution of attributes. ADP is trained with pseudo labels generated from existing attribute classifiers. The proposed Distribution Guidance with ADP enables us to do fair generation. Our method reduces bias across single/multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models. Further, we present a downstream task of training a fair attribute classifier by rebalancing the training set with our generated data.
http://w3id.org/mlsea/pwc/scientificWork/Balancing%20Exploration%20and%20Exploitation%20in%20LLM%20using%20Soft%20RLLF%20for%20Enhanced%20Negation%20Understanding                                                                                  Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding                                                                                  Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models. Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial. To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs. Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities. We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach. Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluating its impact on negation understanding. Our experimental results exhibit the effectiveness of balancing exploration and exploitation with RLLF in improving LLMs' negation capabilities. This has implications for the development of more accurate, reliable, and logically consistent language models in high-stakes domains.
http://w3id.org/mlsea/pwc/scientificWork/Balancing%20Progress%20and%20Responsibility%3A%20A%20Synthesis%20of%20Sustainability%20Trade-Offs%20of%20AI-Based%20Systems                                                                                  Balancing Progress and Responsibility: A Synthesis of Sustainability Trade-Offs of AI-Based Systems                                                                                  Recent advances in artificial intelligence (AI) capabilities have increased the eagerness of companies to integrate AI into software systems. While AI can be used to have a positive impact on several dimensions of sustainability, this is often overshadowed by its potential negative influence. While many studies have explored sustainability factors in isolation, there is insufficient holistic coverage of potential sustainability benefits or costs that practitioners need to consider during decision-making for AI adoption. We therefore aim to synthesize trade-offs related to sustainability in the context of integrating AI into software systems. We want to make the sustainability benefits and costs of integrating AI more transparent and accessible for practitioners. The study was conducted in collaboration with a Dutch financial organization. We first performed a rapid review that led to the inclusion of 151 research papers. Afterward, we conducted six semi-structured interviews to enrich the data with industry perspectives. The combined results showcase the potential sustainability benefits and costs of integrating AI. The labels synthesized from the review regarding potential sustainability benefits were clustered into 16 themes, with 'energy management' being the most frequently mentioned one. 11 themes were identified in the interviews, with the top mentioned theme being 'employee wellbeing'. Regarding sustainability costs, the review discovered seven themes, with 'deployment issues' being the most popular one, followed by 'ethics & society'. 'Environmental issues' was the top theme from the interviews. Our results provide valuable insights to organizations and practitioners for understanding the potential sustainability implications of adopting AI.
http://w3id.org/mlsea/pwc/scientificWork/Band-Attention%20Modulated%20RetNet%20for%20Face%20Forgery%20Detection                                                                                  Band-Attention Modulated RetNet for Face Forgery Detection                                                                                  The transformer networks are extensively utilized in face forgery detection due to their scalability across large datasets.Despite their success, transformers face challenges in balancing the capture of global context, which is crucial for unveiling forgery clues, with computational complexity.To mitigate this issue, we introduce Band-Attention modulated RetNet (BAR-Net), a lightweight network designed to efficiently process extensive visual contexts while avoiding catastrophic forgetting.Our approach empowers the target token to perceive global information by assigning differential attention levels to tokens at varying distances. We implement self-attention along both spatial axes, thereby maintaining spatial priors and easing the computational burden.Moreover, we present the adaptive frequency Band-Attention Modulation mechanism, which treats the entire Discrete Cosine Transform spectrogram as a series of frequency bands with learnable weights.Together, BAR-Net achieves favorable performance on several face forgery datasets, outperforming current state-of-the-art methods.
http://w3id.org/mlsea/pwc/scientificWork/BanglaNum%20--%20A%20Public%20Dataset%20for%20Bengali%20Digit%20Recognition%20from%20Speech                                                                                  BanglaNum -- A Public Dataset for Bengali Digit Recognition from Speech                                                                                  Automatic speech recognition (ASR) converts the human voice into readily understandable and categorized text or words. Although Bengali is one of the most widely spoken languages in the world, there have been very few studies on Bengali ASR, particularly on Bangladeshi-accented Bengali. In this study, audio recordings of spoken digits (0-9) from university students were used to create a Bengali speech digits dataset that may be employed to train artificial neural networks for voice-based digital input systems. This paper also compares the Bengali digit recognition accuracy of several Convolutional Neural Networks (CNNs) using spectrograms and shows that a test accuracy of 98.23% is achievable using parameter-efficient models such as SqueezeNet on our dataset.
http://w3id.org/mlsea/pwc/scientificWork/Batch%20Universal%20Prediction                                                                                  Batch Universal Prediction                                                                                  Large language models (LLMs) have recently gained much popularity due to their surprising ability at generating human-like English sentences. LLMs are essentially predictors, estimating the probability of a sequence of words given the past. Therefore, it is natural to evaluate their performance from a universal prediction perspective. In order to do that fairly, we introduce the notion of batch regret as a modification of the classical average regret, and we study its asymptotical value for add-constant predictors, in the case of memoryless sources and first-order Markov sources.
http://w3id.org/mlsea/pwc/scientificWork/Batch-ICL%3A%20Effective%2C%20Efficient%2C%20and%20Order-Agnostic%20In-Context%20Learning                                                                                  Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning                                                                                  In this paper, by treating in-context learning (ICL) as a meta-optimization process, we explain why LLMs are sensitive to the order of ICL examples. This understanding leads us to the development of Batch-ICL, an effective, efficient, and order-agnostic inference algorithm for ICL. Differing from the standard N-shot learning approach, Batch-ICL employs $N$ separate 1-shot forward computations and aggregates the resulting meta-gradients. These aggregated meta-gradients are then applied to the forward computation of a zero-shot query to generate the final prediction. This batch processing approach renders the LLM agnostic to the order of ICL examples. Through extensive experiments and analysis, we demonstrate that Batch-ICL consistently outperforms most permutations of ICL examples. In some cases, it even exceeds the performance of the best order for standard ICL, all while reducing the computational resources required. Furthermore, we develop a novel variant of Batch-ICL featuring multiple 'epochs' of meta-optimization. This variant implicitly explores permutations of ICL examples, further enhancing ICL performance.
http://w3id.org/mlsea/pwc/scientificWork/Bayes-Optimal%20Fair%20Classification%20with%20Linear%20Disparity%20Constraints%20via%20Pre-%2C%20In-%2C%20and%20Post-processing                                                                                  Bayes-Optimal Fair Classification with Linear Disparity Constraints via Pre-, In-, and Post-processing                                                                                  Machine learning algorithms may have disparate impacts on protected groups. To address this, we develop methods for Bayes-optimal fair classification, aiming to minimize classification error subject to given group fairness constraints. We introduce the notion of emph{linear disparity measures}, which are linear functions of a probabilistic classifier; and emph{bilinear disparity measures}, which are also linear in the group-wise regression functions. We show that several popular disparity measures -- the deviations from demographic parity, equality of opportunity, and predictive equality -- are bilinear. We find the form of Bayes-optimal fair classifiers under a single linear disparity measure, by uncovering a connection with the Neyman-Pearson lemma. For bilinear disparity measures, Bayes-optimal fair classifiers become group-wise thresholding rules. Our approach can also handle multiple fairness constraints (such as equalized odds), and the common scenario when the protected attribute cannot be used at the prediction phase. Leveraging our theoretical results, we design methods that learn fair Bayes-optimal classifiers under bilinear disparity constraints. Our methods cover three popular approaches to fairness-aware classification, via pre-processing (Fair Up- and Down-Sampling), in-processing (Fair Cost-Sensitive Classification) and post-processing (a Fair Plug-In Rule). Our methods control disparity directly while achieving near-optimal fairness-accuracy tradeoffs. We show empirically that our methods compare favorably to existing algorithms.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Active%20Learning%20for%20Censored%20Regression                                                                                  Bayesian Active Learning for Censored Regression                                                                                  Bayesian active learning is based on information theoretical approaches that focus on maximising the information that new observations provide to the model parameters. This is commonly done by maximising the Bayesian Active Learning by Disagreement (BALD) acquisitions function. However, we highlight that it is challenging to estimate BALD when the new data points are subject to censorship, where only clipped values of the targets are observed. To address this, we derive the entropy and the mutual information for censored distributions and derive the BALD objective for active learning in censored regression ($ mathcal{C}$-BALD). We propose a novel modelling approach to estimate the $ mathcal{C}$-BALD objective and use it for active learning in the censored setting. Across a wide range of datasets and models, we demonstrate that $ mathcal{C}$-BALD outperforms other Bayesian active learning methods in censored regression.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Causal%20Inference%20with%20Gaussian%20Process%20Networks                                                                                  Bayesian Causal Inference with Gaussian Process Networks                                                                                  Causal discovery and inference from observational data is an essential problem in statistics posing both modeling and computational challenges. These are typically addressed by imposing strict assumptions on the joint distribution such as linearity. We consider the problem of the Bayesian estimation of the effects of hypothetical interventions in the Gaussian Process Network (GPN) model, a flexible causal framework which allows describing the causal relationships nonparametrically. We detail how to perform causal inference on GPNs by simulating the effect of an intervention across the whole network and propagating the effect of the intervention on downstream variables. We further derive a simpler computational approximation by estimating the intervention distribution as a function of local variables only, modeling the conditional distributions via additive Gaussian processes. We extend both frameworks beyond the case of a known causal graph, incorporating uncertainty about the causal structure via Markov chain Monte Carlo methods. Simulation studies show that our approach is able to identify the effects of hypothetical interventions with non-Gaussian, non-linear observational data and accurately reflect the posterior uncertainty of the causal estimates. Finally we compare the results of our GPN-based causal inference approach to existing methods on a dataset of $A.~thaliana$ gene expressions.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Federated%20Inference%20for%20regression%20models%20with%20heterogeneous%20multi-center%20populations                                                                                  Bayesian Federated Inference for regression models with heterogeneous multi-center populations                                                                                  To estimate accurately the parameters of a regression model, the sample size must be large enough relative to the number of possible predictors for the model. In practice, sufficient data is often lacking, which can lead to overfitting of the model and, as a consequence, unreliable predictions of the outcome of new patients. Pooling data from different data sets collected in different (medical) centers would alleviate this problem, but is often not feasible due to privacy regulation or logistic problems. An alternative route would be to analyze the local data in the centers separately and combine the statistical inference results with the Bayesian Federated Inference (BFI) methodology. The aim of this approach is to compute from the inference results in separate centers what would have been found if the statistical analysis was performed on the combined data. We explain the methodology under homogeneity and heterogeneity across the populations in the separate centers, and give real life examples for better understanding. Excellent performance of the proposed methodology is shown. An R-package to do all the calculations has been developed and is illustrated in this paper. The mathematical details are given in the Appendix.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Multi-Task%20Transfer%20Learning%20for%20Soft%20Prompt%20Tuning                                                                                  Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning                                                                                  Prompt tuning, in which prompts are optimized to adapt large-scale pre-trained language models to downstream tasks instead of fine-tuning the full model parameters, has been shown to be particularly effective when the prompts are trained in a multi-task transfer learning setting. These methods generally involve individually training prompts for each source task and then aggregating them to provide the initialization of the prompt for the target task. However, this approach critically ignores the fact that some of the source tasks could be negatively or positively interfering with each other. We argue that when we extract knowledge from source tasks via training source prompts, we need to consider this correlation among source tasks for better transfer to target tasks. To this end, we propose a Bayesian approach where we work with the posterior distribution of prompts across source tasks. We obtain representative source prompts corresponding to the samples from the posterior utilizing Stein Variational Gradient Descent, which are then aggregated to constitute the initial target prompt. We show extensive experimental results on the standard benchmark NLP tasks, where our Bayesian multi-task transfer learning approach outperforms the state-of-the-art methods in many settings. Furthermore, our approach requires no auxiliary models other than the prompt itself, achieving a high degree of parameter efficiency.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20NeRF%3A%20Quantifying%20Uncertainty%20with%20Volume%20Density%20in%20Neural%20Radiance%20Fields                                                                                  Bayesian NeRF: Quantifying Uncertainty with Volume Density in Neural Radiance Fields                                                                                  We present the Bayesian Neural Radiance Field (NeRF), which explicitly quantifies uncertainty in geometric volume structures without the need for additional networks, making it adept for challenging observations and uncontrolled images. NeRF diverges from traditional geometric methods by offering an enriched scene representation, rendering color and density in 3D space from various viewpoints. However, NeRF encounters limitations in relaxing uncertainties by using geometric structure information, leading to inaccuracies in interpretation under insufficient real-world observations. Recent research efforts aimed at addressing this issue have primarily relied on empirical methods or auxiliary networks. To fundamentally address this issue, we propose a series of formulational extensions to NeRF. By introducing generalized approximations and defining density-related uncertainty, our method seamlessly extends to manage uncertainty not only for RGB but also for depth, without the need for additional networks or empirical assumptions. In experiments we show that our method significantly enhances performance on RGB and depth images in the comprehensive dataset, demonstrating the reliability of the Bayesian NeRF approach to quantifying uncertainty based on the geometric structure.
http://w3id.org/mlsea/pwc/scientificWork/Bayesian%20Off-Policy%20Evaluation%20and%20Learning%20for%20Large%20Action%20Spaces                                                                                  Bayesian Off-Policy Evaluation and Learning for Large Action Spaces                                                                                  In interactive systems, actions are often correlated, presenting an opportunity for more sample-efficient off-policy evaluation (OPE) and learning (OPL) in large action spaces. We introduce a unified Bayesian framework to capture these correlations through structured and informative priors. In this framework, we propose sDM, a generic Bayesian approach designed for OPE and OPL, grounded in both algorithmic and theoretical foundations. Notably, sDM leverages action correlations without compromising computational efficiency. Moreover, inspired by online Bayesian bandits, we introduce Bayesian metrics that assess the average performance of algorithms across multiple problem instances, deviating from the conventional worst-case assessments. We analyze sDM in OPE and OPL, highlighting the benefits of leveraging action correlations. Empirical evidence showcases the strong performance of sDM.
http://w3id.org/mlsea/pwc/scientificWork/Beacon%2C%20a%20lightweight%20deep%20reinforcement%20learning%20benchmark%20library%20for%20flow%20control                                                                                  Beacon, a lightweight deep reinforcement learning benchmark library for flow control                                                                                  Recently, the increasing use of deep reinforcement learning for flow control problems has led to a new area of research, focused on the coupling and the adaptation of the existing algorithms to the control of numerical fluid dynamics environments. Although still in its infancy, the field has seen multiple successes in a short time span, and its fast development pace can certainly be partly imparted to the open-source effort that drives the expansion of the community. Yet, this emerging domain still misses a common ground to (i) ensure the reproducibility of the results, and (ii) offer a proper ad-hoc benchmarking basis. To this end, we propose Beacon, an open-source benchmark library composed of seven lightweight 1D and 2D flow control problems with various characteristics, action and observation space characteristics, and CPU requirements. In this contribution, the seven considered problems are described, and reference control solutions are provided. The sources for the following work are available at https://github.com/jviquerat/beacon.
http://w3id.org/mlsea/pwc/scientificWork/Bearing%20damage%20detection%20with%20orthogonal%20and%20non-negative%20low-rank%20feature%20extraction                                                                                  Bearing damage detection with orthogonal and non-negative low-rank feature extraction                                                                                  Local damage of bearings can be detected as a weak cyclic and impulsive component in a highly noisy measured signal. A key problem is how to extract the signal of interest (SOI) from the raw signal, i.e., how to identify and design an optimal filter. To tackle this problem, we propose to use stochastic sampled orthogonal non-negative matrix factorization for extracting frequency-based features from a spectrogram of the measured signal. The proposed algorithm finds a selective filter that is tailored to the frequency band of the SOI. We show that our approach outperforms the other state-of-the-art selectors that were previously used in condition monitoring. The efficiency of the proposed method is illustrated using both a simulation study and the following real signals: (a) vibration signal from a test rig in the laboratory and (b) acoustic signal from a belt conveyor.
http://w3id.org/mlsea/pwc/scientificWork/Behavior%20Alignment%3A%20A%20New%20Perspective%20of%20Evaluating%20LLM-based%20Conversational%20Recommendation%20Systems                                                                                  Behavior Alignment: A New Perspective of Evaluating LLM-based Conversational Recommendation Systems                                                                                  Large Language Models (LLMs) have demonstrated great potential in Conversational Recommender Systems (CRS). However, the application of LLMs to CRS has exposed a notable discrepancy in behavior between LLM-based CRS and human recommenders: LLMs often appear inflexible and passive, frequently rushing to complete the recommendation task without sufficient inquiry.This behavior discrepancy can lead to decreased accuracy in recommendations and lower user satisfaction. Despite its importance, existing studies in CRS lack a study about how to measure such behavior discrepancy. To fill this gap, we propose Behavior Alignment, a new evaluation metric to measure how well the recommendation strategies made by a LLM-based CRS are consistent with human recommenders'. Our experiment results show that the new metric is better aligned with human preferences and can better differentiate how systems perform than existing evaluation metrics. As Behavior Alignment requires explicit and costly human annotations on the recommendation strategies, we also propose a classification-based method to implicitly measure the Behavior Alignment based on the responses. The evaluation results confirm the robustness of the method.
http://w3id.org/mlsea/pwc/scientificWork/Behind%20the%20Myth%20of%20Exploration%20in%20Policy%20Gradients                                                                                  Behind the Myth of Exploration in Policy Gradients                                                                                  Policy-gradient algorithms are effective reinforcement learning methods for solving control problems with continuous state and action spaces. To compute near-optimal policies, it is essential in practice to include exploration terms in the learning objective. Although the effectiveness of these terms is usually justified by an intrinsic need to explore environments, we propose a novel analysis and distinguish two different implications of these techniques. First, they make it possible to smooth the learning objective and to eliminate local optima while preserving the global maximum. Second, they modify the gradient estimates, increasing the probability that the stochastic parameter update eventually provides an optimal policy. In light of these effects, we discuss and illustrate empirically exploration strategies based on entropy bonuses, highlighting their limitations and opening avenues for future works in the design and analysis of such strategies.
http://w3id.org/mlsea/pwc/scientificWork/Belief%20Samples%20Are%20All%20You%20Need%20For%20Social%20Learning                                                                                  Belief Samples Are All You Need For Social Learning                                                                                  In this paper, we consider the problem of social learning, where a group of agents embedded in a social network are interested in learning an underlying state of the world. Agents have incomplete, noisy, and heterogeneous sources of information, providing them with recurring private observations of the underlying state of the world. Agents can share their learning experience with their peers by taking actions observable to them, with values from a finite feasible set of states. Actions can be interpreted as samples from the beliefs which agents may form and update on what the true state of the world is. Sharing samples, in place of full beliefs, is motivated by the limited communication, cognitive, and information-processing resources available to agents especially in large populations. Previous work (Salhab et al.) poses the question as to whether learning with probability one is still achievable if agents are only allowed to communicate samples from their beliefs. We provide a definite positive answer to this question, assuming a strongly connected network and a ``collective distinguishability'' assumption, which are both required for learning even in full-belief-sharing settings. In our proposed belief update mechanism, each agent's belief is a normalized weighted geometric interpolation between a fully Bayesian private belief -- aggregating information from the private source -- and an ensemble of empirical distributions of the samples shared by her neighbors over time. By carefully constructing asymptotic almost-sure lower/upper bounds on the frequency of shared samples matching the true state/or not, we rigorously prove the convergence of all the beliefs to the true state, with probability one.
http://w3id.org/mlsea/pwc/scientificWork/BenchCLAMP%3A%20A%20Benchmark%20for%20Evaluating%20Language%20Models%20on%20Syntactic%20and%20Semantic%20Parsing                                                                                  BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and Semantic Parsing                                                                                  Recent work has shown that generation from a prompted or fine-tuned language model can perform well at semantic parsing when the output is constrained to be a valid semantic representation. We introduce BenchCLAMP, a Benchmark to evaluate Constrained LAnguage Model Parsing, that includes context-free grammars for seven semantic parsing datasets and two syntactic parsing datasets with varied output meaning representations, as well as a constrained decoding interface to generate only valid outputs covered by these grammars. We provide low, medium, and high resource splits for each dataset, allowing accurate comparison of various language models under different data regimes. Our benchmark supports evaluation of language models using prompt-based learning as well as fine-tuning. We benchmark seven language models, including two GPT-3 variants available only through an API. Our experiments show that encoder-decoder pretrained language models can achieve similar performance or even surpass state-of-the-art methods for both syntactic and semantic parsing when the model output is constrained to be valid.Submission Number: 139
http://w3id.org/mlsea/pwc/scientificWork/BenchCLAMP%3A%20A%20Benchmark%20for%20Evaluating%20Language%20Models%20on%20Syntactic%20and%20Semantic%20Parsing                                                                                  BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and Semantic Parsing                                                                                  Recent work has shown that generation from a prompted or fine-tuned language model can perform well at semantic parsing when the output is constrained to be a valid semantic representation. We introduce BenchCLAMP, a Benchmark to evaluate Constrained LAnguage Model Parsing, that includes context-free grammars for seven semantic parsing datasets and two syntactic parsing datasets with varied output representations, as well as a constrained decoding interface to generate only valid outputs covered by these grammars. We provide low, medium, and high resource splits for each dataset, allowing accurate comparison of various language models under different data regimes. Our benchmark supports evaluation of language models using prompt-based learning as well as fine-tuning. We benchmark eight language models, including two GPT-3 variants available only through an API. Our experiments show that encoder-decoder pretrained language models can achieve similar performance or surpass state-of-the-art methods for syntactic and semantic parsing when the model output is constrained to be valid.
http://w3id.org/mlsea/pwc/scientificWork/Benchmark%20Analysis%20of%20Various%20Pre-trained%20Deep%20Learning%20Models%20on%20ASSIRA%20Cats%20and%20Dogs%20Dataset                                                                                  Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats and Dogs Dataset                                                                                  As the most basic application and implementation of deep learning, image classification has grown in popularity. Various datasets are provided by renowned data science communities for benchmarking machine learning algorithms and pre-trained models. The ASSIRA Cats & Dogs dataset is one of them and is being used in this research for its overall acceptance and benchmark standards. A comparison of various pre-trained models is demonstrated by using different types of optimizers and loss functions. Hyper-parameters are changed to gain the best result from a model. By applying this approach, we have got higher accuracy without major changes in the training model. To run the experiment, we used three different computer architectures: a laptop equipped with NVIDIA GeForce GTX 1070, a laptop equipped with NVIDIA GeForce RTX 3080Ti, and a desktop equipped with NVIDIA GeForce RTX 3090. The acquired results demonstrate supremacy in terms of accuracy over the previously done experiments on this dataset. From this experiment, the highest accuracy which is 99.65% is gained using the NASNet Large.
http://w3id.org/mlsea/pwc/scientificWork/Benchmark%20for%20CEC%202024%20Competition%20on%20Multiparty%20Multiobjective%20Optimization                                                                                  Benchmark for CEC 2024 Competition on Multiparty Multiobjective Optimization                                                                                  The competition focuses on Multiparty Multiobjective Optimization Problems (MPMOPs), where multiple decision makers have conflicting objectives, as seen in applications like UAV path planning. Despite their importance, MPMOPs remain understudied in comparison to conventional multiobjective optimization. The competition aims to address this gap by encouraging researchers to explore tailored modeling approaches. The test suite comprises two parts: problems with common Pareto optimal solutions and Biparty Multiobjective UAV Path Planning (BPMO-UAVPP) problems with unknown solutions. Optimization algorithms for the first part are evaluated using Multiparty Inverted Generational Distance (MPIGD), and the second part is evaluated using Multiparty Hypervolume (MPHV) metrics. The average algorithm ranking across all problems serves as a performance benchmark.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Implicit%20Neural%20Representation%20and%20Geometric%20Rendering%20in%20Real-Time%20RGB-D%20SLAM                                                                                  Benchmarking Implicit Neural Representation and Geometric Rendering in Real-Time RGB-D SLAM                                                                                  Implicit neural representation (INR), in combination with geometric rendering, has recently been employed in real-time dense RGB-D SLAM. Despite active research endeavors being made, there lacks a unified protocol for fair evaluation, impeding the evolution of this area. In this work, we establish, to our knowledge, the first open-source benchmark framework to evaluate the performance of a wide spectrum of commonly used INRs and rendering functions for mapping and localization. The goal of our benchmark is to 1) gain an intuition of how different INRs and rendering functions impact mapping and localization and 2) establish a unified evaluation protocol w.r.t. the design choices that may impact the mapping and localization. With the framework, we conduct a large suite of experiments, offering various insights in choosing the INRs and geometric rendering functions: for example, the dense feature grid outperforms other INRs (e.g. tri-plane and hash grid), even when geometric and color features are jointly encoded for memory efficiency. To extend the findings into the practical scenario, a hybrid encoding strategy is proposed to bring the best of the accuracy and completion from the grid-based and decomposition-based INRs. We further propose explicit hybrid encoding for high-fidelity dense grid mapping to comply with the RGB-D SLAM system that puts the premise on robustness and computation efficiency.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Knowledge%20Boundary%20for%20Large%20Language%20Model%3A%20A%20Different%20Perspective%20on%20Model%20Evaluation                                                                                  Benchmarking Knowledge Boundary for Large Language Model: A Different Perspective on Model Evaluation                                                                                  In recent years, substantial advancements have been made in the development of large language models, achieving remarkable performance across diverse tasks. To evaluate the knowledge ability of language models, previous studies have proposed lots of benchmarks based on question-answering pairs. We argue that it is not reliable and comprehensive to evaluate language models with a fixed question or limited paraphrases as the query, since language models are sensitive to prompt. Therefore, we introduce a novel concept named knowledge boundary to encompass both prompt-agnostic and prompt-sensitive knowledge within language models. Knowledge boundary avoids prompt sensitivity in language model evaluations, rendering them more dependable and robust. To explore the knowledge boundary for a given model, we propose projected gradient descent method with semantic constraints, a new algorithm designed to identify the optimal prompt for each piece of knowledge. Experiments demonstrate a superior performance of our algorithm in computing the knowledge boundary compared to existing methods. Furthermore, we evaluate the ability of multiple language models in several domains with knowledge boundary.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20LLM-based%20Machine%20Translation%20on%20Cultural%20Awareness                                                                                  Benchmarking LLM-based Machine Translation on Cultural Awareness                                                                                  Translating cultural-specific content is crucial for effective cross-cultural communication. However, many MT systems still struggle to translate sentences containing cultural-specific entities accurately and understandably. Recent advancements in in-context learning utilize lightweight prompts to guide large language models (LLMs) in machine translation tasks. Nevertheless, the effectiveness of this approach in enhancing machine translation with cultural awareness remains uncertain. To address this gap, we introduce a new data curation pipeline to construct a culturally relevant parallel corpus, enriched with annotations of cultural-specific items. Furthermore, we devise a novel evaluation metric to assess the understandability of translations in a reference-free manner by GPT-4. We evaluate a variety of neural machine translation (NMT) and LLM-based MT systems using our dataset. Additionally, we propose several prompting strategies for LLMs to incorporate external and internal cultural knowledge into the translation process. Our results demonstrate that eliciting explanations can significantly enhance the understandability of cultural-specific entities, especially those without well-known translations.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20LLMs%20via%20Uncertainty%20Quantification                                                                                  Benchmarking LLMs via Uncertainty Quantification                                                                                  The proliferation of open-source Large Language Models (LLMs) from various institutions has highlighted the urgent need for comprehensive evaluation methods. However, current evaluation platforms, such as the widely recognized HuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty, which is vital for thoroughly assessing LLMs. To bridge this gap, we introduce a new benchmarking approach for LLMs that integrates uncertainty quantification. Our examination involves eight LLMs (LLM series) spanning five representative natural language processing tasks. Additionally, we introduce an uncertainty-aware evaluation metric, UAcc, which takes into account both prediction accuracy and prediction uncertainty. Our findings reveal that: I) LLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs may display greater uncertainty compared to their smaller counterparts; and III) Instruction-finetuning tends to increase the uncertainty of LLMs. By taking uncertainty into account, our new UAcc metric can either amplify or diminish the relative improvement of one LLM over another and may even change the relative ranking of two LLMs. These results underscore the significance of incorporating uncertainty in the evaluation of LLMs.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Large%20Multimodal%20Models%20against%20Common%20Corruptions                                                                                  Benchmarking Large Multimodal Models against Common Corruptions                                                                                  This technical report aims to fill a deficiency in the assessment of large multimodal models (LMMs) by specifically examining the self-consistency of their outputs when subjected to common corruptions. We investigate the cross-modal interactions between text, image, and speech, encompassing four essential generation tasks: text-to-image, image-to-text, text-to-speech, and speech-to-text. We create a comprehensive benchmark, named MMCBench, that covers more than 100 popular LMMs (totally over 150 model checkpoints). A thorough evaluation under common corruptions is critical for practical deployment and facilitates a better understanding of the reliability of cutting-edge LMMs. The benchmarking code is available at https://github.com/sail-sg/MMCBench
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Micro-action%20Recognition%3A%20Dataset%2C%20Methods%2C%20and%20Applications                                                                                  Benchmarking Micro-action Recognition: Dataset, Methods, and Applications                                                                                  Micro-action is an imperceptible non-verbal behaviour characterised by low-intensity movement. It offers insights into the feelings and intentions of individuals and is important for human-oriented applications such as emotion recognition and psychological assessment. However, the identification, differentiation, and understanding of micro-actions pose challenges due to the imperceptible and inaccessible nature of these subtle human behaviors in everyday life. In this study, we innovatively collect a new micro-action dataset designated as Micro-action-52 (MA-52), and propose a benchmark named micro-action network (MANet) for micro-action recognition (MAR) task. Uniquely, MA-52 provides the whole-body perspective including gestures, upper- and lower-limb movements, attempting to reveal comprehensive micro-action cues. In detail, MA-52 contains 52 micro-action categories along with seven body part labels, and encompasses a full array of realistic and natural micro-actions, accounting for 205 participants and 22,422 video instances collated from the psychological interviews. Based on the proposed dataset, we assess MANet and other nine prevalent action recognition methods. MANet incorporates squeeze-and excitation (SE) and temporal shift module (TSM) into the ResNet architecture for modeling the spatiotemporal characteristics of micro-actions. Then a joint-embedding loss is designed for semantic matching between video and action labels; the loss is used to better distinguish between visually similar yet distinct micro-action categories. The extended application in emotion recognition has demonstrated one of the important values of our proposed dataset and method. In the future, further exploration of human behaviour, emotion, and psychological assessment will be conducted in depth. The dataset and source code are released at https://github.com/VUT-HFUT/Micro-Action.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Segmentation%20Models%20with%20Mask-Preserved%20Attribute%20Editing                                                                                  Benchmarking Segmentation Models with Mask-Preserved Attribute Editing                                                                                  When deploying segmentation models in practice, it is critical to evaluate their behaviors in varied and complex scenes. Different from the previous evaluation paradigms only in consideration of global attribute variations (e.g. adverse weather), we investigate both local and global attribute variations for robustness evaluation. To achieve this, we construct a mask-preserved attribute editing pipeline to edit visual attributes of real images with precise control of structural information. Therefore, the original segmentation labels can be reused for the edited images. Using our pipeline, we construct a benchmark covering both object and image attributes (e.g. color, material, pattern, style). We evaluate a broad variety of semantic segmentation models, spanning from conventional close-set models to recent open-vocabulary large models on their robustness to different types of variations. We find that both local and global attribute variations affect segmentation performances, and the sensitivity of models diverges across different variation types. We argue that local attributes have the same importance as global attributes, and should be considered in the robustness evaluation of segmentation models. Code: https://github.com/PRIS-CV/Pascal-EA.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Sensitivity%20of%20Continual%20Graph%20Learning%20for%20Skeleton-Based%20Action%20Recognition                                                                                  Benchmarking Sensitivity of Continual Graph Learning for Skeleton-Based Action Recognition                                                                                  Continual learning (CL) is the research field that aims to build machine learning models that can accumulate knowledge continuously over different tasks without retraining from scratch. Previous studies have shown that pre-training graph neural networks (GNN) may lead to negative transfer (Hu et al., 2020) after fine-tuning, a setting which is closely related to CL. Thus, we focus on studying GNN in the continual graph learning (CGL) setting. We propose the first continual graph learning benchmark for spatio-temporal graphs and use it to benchmark well-known CGL methods in this novel setting. The benchmark is based on the N-UCLA and NTU-RGB+D datasets for skeleton-based action recognition. Beyond benchmarking for standard performance metrics, we study the class and task-order sensitivity of CGL methods, i.e., the impact of learning order on each class/task's performance, and the architectural sensitivity of CGL methods with backbone GNN at various widths and depths. We reveal that task-order robust methods can still be class-order sensitive and observe results that contradict previous empirical observations on architectural sensitivity in CL.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Transferable%20Adversarial%20Attacks                                                                                  Benchmarking Transferable Adversarial Attacks                                                                                  The robustness of deep learning models against adversarial attacks remains a pivotal concern. This study presents, for the first time, an exhaustive review of the transferability aspect of adversarial attacks. It systematically categorizes and critically evaluates various methodologies developed to augment the transferability of adversarial attacks. This study encompasses a spectrum of techniques, including Generative Structure, Semantic Similarity, Gradient Editing, Target Modification, and Ensemble Approach. Concurrently, this paper introduces a benchmark framework textit{TAA-Bench}, integrating ten leading methodologies for adversarial attack transferability, thereby providing a standardized and systematic platform for comparative analysis across diverse model architectures. Through comprehensive scrutiny, we delineate the efficacy and constraints of each method, shedding light on their underlying operational principles and practical utility. This review endeavors to be a quintessential resource for both scholars and practitioners in the field, charting the complex terrain of adversarial transferability and setting a foundation for future explorations in this vital sector. The associated codebase is accessible at: https://github.com/KxPlaug/TAA-Bench
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20Zero-Shot%20Robustness%20of%20Multimodal%20Foundation%20Models%3A%20A%20Pilot%20Study                                                                                  Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study                                                                                  Pre-training image representations from the raw text about images enables zero-shot vision transfer to downstream tasks. Through pre-training on millions of samples collected from the internet, multimodal foundation models, such as CLIP, produce state-of-the-art zero-shot results that often reach competitiveness with fully supervised methods without the need for task-specific training. Besides the encouraging performance on classification accuracy, it is reported that these models close the robustness gap by matching the performance of supervised models trained on ImageNet under natural distribution shift. Because robustness is critical to real-world applications, especially safety-critical ones, in this paper, we present a comprehensive evaluation based on a large-scale robustness benchmark covering 7 natural, 3 synthetic distribution shifts, and 11 adversarial attacks. We use CLIP as a pilot study. We show that CLIP leads to a significant robustness drop compared to supervised ImageNet models on our benchmark, especially under synthetic distribution shift and adversarial attacks. Furthermore, data overlap analysis suggests that the observed robustness under natural distribution shifts could be attributed, at least in part, to data overlap. In summary, our evaluation shows a comprehensive evaluation of robustness is necessary; and there is a significant need to improve the robustness of zero-shot multimodal models.
http://w3id.org/mlsea/pwc/scientificWork/Benchmarking%20the%20Robustness%20of%20Image%20Watermarks                                                                                  Benchmarking the Robustness of Image Watermarks                                                                                  This paper investigates the weaknesses of image watermarking techniques. We present WAVES (Watermark Analysis Via Enhanced Stress-testing), a novel benchmark for assessing watermark robustness, overcoming the limitations of current evaluation methods.WAVES integrates detection and identification tasks, and establishes a standardized evaluation protocol comprised of a diverse range of stress tests. The attacks in WAVES range from traditional image distortions to advanced and novel variations of diffusive, and adversarial attacks. Our evaluation examines two pivotal dimensions: the degree of image quality degradation and the efficacy of watermark detection after attacks. We develop a series of Performance vs. Quality 2D plots, varying over several prominent image similarity metrics, which are then aggregated in a heuristically novel manner to paint an overall picture of watermark robustness and attack potency. Our comprehensive evaluation reveals previously undetected vulnerabilities of several modern watermarking algorithms. We envision WAVES as a toolkit for the future development of robust watermarking systems. The project is available at https://wavesbench.github.io/
http://w3id.org/mlsea/pwc/scientificWork/Best%20Practices%20for%20Text%20Annotation%20with%20Large%20Language%20Models                                                                                  Best Practices for Text Annotation with Large Language Models                                                                                  Large Language Models (LLMs) have ushered in a new era of text annotation, as their ease-of-use, high accuracy, and relatively low costs have meant that their use has exploded in recent months. However, the rapid growth of the field has meant that LLM-based annotation has become something of an academic Wild West: the lack of established practices and standards has led to concerns about the quality and validity of research. Researchers have warned that the ostensible simplicity of LLMs can be misleading, as they are prone to bias, misunderstandings, and unreliable results. Recognizing the transformative potential of LLMs, this paper proposes a comprehensive set of standards and best practices for their reliable, reproducible, and ethical use. These guidelines span critical areas such as model selection, prompt engineering, structured prompting, prompt stability analysis, rigorous model validation, and the consideration of ethical and legal implications. The paper emphasizes the need for a structured, directed, and formalized approach to using LLMs, aiming to ensure the integrity and robustness of text annotation practices, and advocates for a nuanced and critical engagement with LLMs in social scientific research.
http://w3id.org/mlsea/pwc/scientificWork/Better%20Schedules%20for%20Low%20Precision%20Training%20of%20Deep%20Neural%20Networks                                                                                  Better Schedules for Low Precision Training of Deep Neural Networks                                                                                  Low precision training can significantly reduce the computational overhead of training deep neural networks (DNNs). Though many such techniques exist, cyclic precision training (CPT), which dynamically adjusts precision throughout training according to a cyclic schedule, achieves particularly impressive improvements in training efficiency, while actually improving DNN performance. Existing CPT implementations take common learning rate schedules (e.g., cyclical cosine schedules) and use them for low precision training without adequate comparisons to alternative scheduling options. We define a diverse suite of CPT schedules and analyze their performance across a variety of DNN training regimes, some of which are unexplored in the low precision training literature (e.g., node classification with graph neural networks). From these experiments, we discover alternative CPT schedules that offer further improvements in training efficiency and model performance, as well as derive a set of best practices for choosing CPT schedules. Going further, we find that a correlation exists between model performance and training cost, and that changing the underlying CPT schedule can control the tradeoff between these two variables. To explain the direct correlation between model performance and training cost, we draw a connection between quantized training and critical learning periods, suggesting that aggressive quantization is a form of learning impairment that can permanently damage model performance.
http://w3id.org/mlsea/pwc/scientificWork/Better%20than%20classical%3F%20The%20subtle%20art%20of%20benchmarking%20quantum%20machine%20learning%20models                                                                                  Better than classical? The subtle art of benchmarking quantum machine learning models                                                                                  Benchmarking models via classical simulations is one of the main ways to judge ideas in quantum machine learning before noise-free hardware is available. However, the huge impact of the experimental design on the results, the small scales within reach today, as well as narratives influenced by the commercialisation of quantum technologies make it difficult to gain robust insights. To facilitate better decision-making we develop an open-source package based on the PennyLane software framework and use it to conduct a large-scale study that systematically tests 12 popular quantum machine learning models on 6 binary classification tasks used to create 160 individual datasets. We find that overall, out-of-the-box classical machine learning models outperform the quantum classifiers. Moreover, removing entanglement from a quantum model often results in as good or better performance, suggesting that 'quantumness' may not be the crucial ingredient for the small learning tasks considered here. Our benchmarks also unlock investigations beyond simplistic leaderboard comparisons, and we identify five important questions for quantum model design that follow from our results.
http://w3id.org/mlsea/pwc/scientificWork/Better-than-KL%20PAC-Bayes%20Bounds                                                                                  Better-than-KL PAC-Bayes Bounds                                                                                  Let $f( theta, X_1),$ $ dots,$ $ f( theta, X_n)$ be a sequence of random elements, where $f$ is a fixed scalar function, $X_1, dots, X_n$ are independent random variables (data), and $ theta$ is a random parameter distributed according to some data-dependent posterior distribution $P_n$. In this paper, we consider the problem of proving concentration inequalities to estimate the mean of the sequence. An example of such a problem is the estimation of the generalization error of some predictor trained by a stochastic algorithm, such as a neural network where $f$ is a loss function. Classically, this problem is approached through a PAC-Bayes analysis where, in addition to the posterior, we choose a prior distribution which captures our belief about the inductive bias of the learning problem. Then, the key quantity in PAC-Bayes concentration bounds is a divergence that captures the complexity of the learning problem where the de facto standard choice is the KL divergence. However, the tightness of this choice has rarely been questioned. In this paper, we challenge the tightness of the KL-divergence-based bounds by showing that it is possible to achieve a strictly tighter bound. In particular, we demonstrate new high-probability PAC-Bayes bounds with a novel and better-than-KL divergence that is inspired by Zhang et al. (2022). Our proof is inspired by recent advances in regret analysis of gambling algorithms, and its use to derive concentration inequalities. Our result is first-of-its-kind in that existing PAC-Bayes bounds with non-KL divergences are not known to be strictly better than KL. Thus, we believe our work marks the first step towards identifying optimal rates of PAC-Bayes bounds.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Accuracy%3A%20Evaluating%20the%20Reasoning%20Behavior%20of%20Large%20Language%20Models%20--%20A%20Survey                                                                                  Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey                                                                                  Large language models (LLMs) have recently shown impressive performance on tasks involving reasoning, leading to a lively debate on whether these models possess reasoning capabilities similar to humans. However, despite these successes, the depth of LLMs' reasoning abilities remains uncertain. This uncertainty partly stems from the predominant focus on task performance, measured through shallow accuracy metrics, rather than a thorough investigation of the models' reasoning behavior. This paper seeks to address this gap by providing a comprehensive review of studies that go beyond task accuracy, offering deeper insights into the models' reasoning processes. Furthermore, we survey prevalent methodologies to evaluate the reasoning behavior of LLMs, emphasizing current trends and efforts towards more nuanced reasoning analyses. Our review suggests that LLMs tend to rely on surface-level patterns and correlations in their training data, rather than on genuine reasoning abilities. Additionally, we identify the need for further research that delineates the key differences between human and LLM-based reasoning. Through this survey, we aim to shed light on the complex reasoning processes within LLMs.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Accuracy-Fairness%3A%20Stop%20evaluating%20bias%20mitigation%20methods%20solely%20on%20between-group%20metrics                                                                                  Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely on between-group metrics                                                                                  Artificial Intelligence (AI) finds widespread applications across various domains, sparking concerns about fairness in its deployment. While fairness in AI remains a central concern, the prevailing discourse often emphasizes outcome-based metrics without a nuanced consideration of the differential impacts within subgroups. Bias mitigation techniques do not only affect the ranking of pairs of instances across sensitive groups, but often also significantly affect the ranking of instances within these groups. Such changes are hard to explain and raise concerns regarding the validity of the intervention. Unfortunately, these effects largely remain under the radar in the accuracy-fairness evaluation framework that is usually applied. This paper challenges the prevailing metrics for assessing bias mitigation techniques, arguing that they do not take into account the changes within-groups and that the resulting prediction labels fall short of reflecting real-world scenarios. We propose a paradigm shift: initially, we should focus on generating the most precise ranking for each subgroup. Following this, individuals should be chosen from these rankings to meet both fairness standards and practical considerations.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Diagonal%20RIS%3A%20Key%20to%20Next-Generation%20Integrated%20Sensing%20and%20Communications%3F                                                                                  Beyond Diagonal RIS: Key to Next-Generation Integrated Sensing and Communications?                                                                                  Reconfigurable intelligent surface (RIS) have introduced unprecedented flexibility and adaptability toward smart wireless channels. Recent research on integrated sensing and communication (ISAC) systems has demonstrated that RIS platforms enable enhanced signal quality, coverage, and link capacity. In this paper, we explore the application of fully-connected beyond diagonal RIS (BD-RIS) to ISAC systems. BD-RIS introduces additional degrees of freedom by allowing non-zero off-diagonal elements for the scattering matrix, potentially enabling further functionalities and performance enhancements. In particular, we consider the joint design objective of maximizing the weighted sum of the signal-to-noise ratio (SNR) at the radar receiver and communication users by leveraging the extra degrees-of-freedom offered in the BD-RIS setting. These degrees-of-freedom are unleashed by formulating an alternating optimization process over known and auxiliary (latent) variables of such systems. Our numerical results reveal the advantages of deploying BD-RIS in the context of ISAC and the effectiveness of the proposed algorithm by improving the SNR values for both radar and communication users by several orders of magnitude.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Eviction%20Prediction%3A%20Leveraging%20Local%20Spatiotemporal%20Public%20Records%20to%20Inform%20Action                                                                                  Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public Records to Inform Action                                                                                  There has been considerable recent interest in scoring properties on the basis of eviction risk. The success of methods for eviction prediction is typically evaluated using different measures of predictive accuracy. However, the underlying goal of such prediction is to direct appropriate assistance to households that may be at greater risk so they remain stably housed. Thus, we must ask the question of how useful such predictions are in targeting outreach efforts - informing action. In this paper, we investigate this question using a novel dataset that matches information on properties, evictions, and owners. We perform an eviction prediction task to produce risk scores and then use these risk scores to plan targeted outreach policies. We show that the risk scores are, in fact, useful, enabling a theoretical team of caseworkers to reach more eviction-prone properties in the same amount of time, compared to outreach policies that are either neighborhood-based or focus on buildings with a recent history of evictions. We also discuss the importance of neighborhood and ownership features in both risk prediction and targeted outreach.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Hate%20Speech%3A%20NLP%27s%20Challenges%20and%20Opportunities%20in%20Uncovering%20Dehumanizing%20Language                                                                                  Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering Dehumanizing Language                                                                                  Dehumanization, characterized as a subtle yet harmful manifestation of hate speech, involves denying individuals of their human qualities and often results in violence against marginalized groups. Despite significant progress in Natural Language Processing across various domains, its application in detecting dehumanizing language is limited, largely due to the scarcity of publicly available annotated data for this domain. This paper evaluates the performance of cutting-edge NLP models, including GPT-4, GPT-3.5, and LLAMA-2, in identifying dehumanizing language. Our findings reveal that while these models demonstrate potential, achieving a 70 % accuracy rate in distinguishing dehumanizing language from broader hate speech, they also display biases. They are over-sensitive in classifying other forms of hate speech as dehumanization for a specific subset of target groups, while more frequently failing to identify clear cases of dehumanization for other target groups. Moreover, leveraging one of the best-performing models, we automatically annotated a larger dataset for training more accessible models. However, our findings indicate that these models currently do not meet the high-quality data generation threshold necessary for this task.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Image%20Super-Resolution%20for%20Image%20Recognition%20with%20Task-Driven%20Perceptual%20Loss                                                                                  Beyond Image Super-Resolution for Image Recognition with Task-Driven Perceptual Loss                                                                                  In real-world scenarios, image recognition tasks, such as semantic segmentation and object detection, often pose greater challenges due to the lack of information available within low-resolution (LR) content. Image super-resolution (SR) is one of the promising solutions for addressing the challenges. However, due to the ill-posed property of SR, it is challenging for typical SR methods to restore task-relevant high-frequency contents, which may dilute the advantage of utilizing the SR method. Therefore, in this paper, we propose Super-Resolution for Image Recognition (SR4IR) that effectively guides the generation of SR images beneficial to achieving satisfactory image recognition performance when processing LR images. The critical component of our SR4IR is the task-driven perceptual (TDP) loss that enables the SR network to acquire task-specific knowledge from a network tailored for a specific task. Moreover, we propose a cross-quality patch mix and an alternate training framework that significantly enhances the efficacy of the TDP loss by addressing potential problems when employing the TDP loss. Through extensive experiments, we demonstrate that our SR4IR achieves outstanding task performance by generating SR images useful for a specific image recognition task, including semantic segmentation, object detection, and image classification. The implementation code is available at https://github.com/JaehaKim97/SR4IR.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Imitation%3A%20Generating%20Human%20Mobility%20from%20Context-aware%20Reasoning%20with%20Large%20Language%20Models                                                                                  Beyond Imitation: Generating Human Mobility from Context-aware Reasoning with Large Language Models                                                                                  Human mobility behaviours are closely linked to various important societal problems such as traffic congestion, and epidemic control. However, collecting mobility data can be prohibitively expensive and involves serious privacy issues, posing a pressing need for high-quality generative mobility models. Previous efforts focus on learning the behaviour distribution from training samples, and generate new mobility data by sampling the learned distributions. They cannot effectively capture the coherent intentions that drive mobility behavior, leading to low sample efficiency and semantic-awareness. Inspired by the emergent reasoning ability in LLMs, we propose a radical perspective shift that reformulates mobility generation as a commonsense reasoning problem. In this paper, we design a novel Mobility Generation as Reasoning (MobiGeaR) framework that prompts LLM to recursively generate mobility behaviour. Specifically, we design a context-aware chain-of-thoughts prompting technique to align LLMs with context-aware mobility behaviour by few-shot in-context learning. Besides, MobiGeaR employ a divide-and-coordinate mechanism to exploit the synergistic effect between LLM reasoning and mechanistic gravity model. It leverages the step-by-step LLM reasoning to recursively generate a temporal template of activity intentions, which are then mapped to physical locations with a mechanistic gravity model. Experiments on two real-world datasets show MobiGeaR achieves state-of-the-art performance across all metrics, and substantially reduces the size of training samples at the same time. Besides, MobiGeaR also significantly improves the semantic-awareness of mobility generation by improving the intention accuracy by 62.23% and the generated mobility data is proven effective in boosting the performance of downstream applications. The implementation of our approach is available in the paper.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Inference%3A%20Performance%20Analysis%20of%20DNN%20Server%20Overheads%20for%20Computer%20Vision                                                                                  Beyond Inference: Performance Analysis of DNN Server Overheads for Computer Vision                                                                                  Deep neural network (DNN) inference has become an important part of many data-center workloads. This has prompted focused efforts to design ever-faster deep learning accelerators such as GPUs and TPUs. However, an end-to-end DNN-based vision application contains more than just DNN inference, including input decompression, resizing, sampling, normalization, and data transfer. In this paper, we perform a thorough evaluation of computer vision inference requests performed on a throughput-optimized serving system. We quantify the performance impact of server overheads such as data movement, preprocessing, and message brokers between two DNNs producing outputs at different rates. Our empirical analysis encompasses many computer vision tasks including image classification, segmentation, detection, depth-estimation, and more complex processing pipelines with multiple DNNs. Our results consistently demonstrate that end-to-end application performance can easily be dominated by data processing and data movement functions (up to 56% of end-to-end latency in a medium-sized image, and $ sim$ 80% impact on system throughput in a large image), even though these functions have been conventionally overlooked in deep learning system design. Our work identifies important performance bottlenecks in different application scenarios, achieves 2.25$ times$ better throughput compared to prior work, and paves the way for more holistic deep learning system design.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20MD17%3A%20the%20reactive%20xxMD%20dataset                                                                                  Beyond MD17: the reactive xxMD dataset                                                                                  System specific neural force fields (NFFs) have gained popularity in computational chemistry. One of the most popular datasets as a bencharmk to develop NFFs models is the MD17 dataset and its subsequent extension. These datasets comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampled from direct adiabatic dynamics. However, many chemical reactions involve significant molecular geometrical deformations, for example, bond breaking. Therefore, MD17 is inadequate to represent a chemical reaction. To address this limitation in MD17, we introduce a new dataset, called Extended Excited-state Molecular Dynamics (xxMD) dataset. The xxMD dataset involves geometries sampled from direct non-adiabatic dynamics, and the energies are computed at both multireference wavefunction theory and density functional theory. We show that the xxMD dataset involves diverse geometries which represent chemical reactions. Assessment of NFF models on xxMD dataset reveals significantly higher predictive errors than those reported for MD17 and its variants. This work underscores the challenges faced in crafting a generalizable NFF model with extrapolation capability.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Natural%20Language%3A%20LLMs%20Leveraging%20Alternative%20Formats%20for%20Enhanced%20Reasoning%20and%20Communication                                                                                  Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication                                                                                  Natural language (NL) has long been the predominant format for human cognition and communication, and by extension, has been similarly pivotal in the development and application of Large Language Models (LLMs). Yet, besides NL, LLMs have seen various non-NL formats during pre-training, such as code and logical expression. NL's status as the optimal format for LLMs, particularly in single-LLM reasoning and multi-agent communication, has not been thoroughly examined. In this work, we challenge the default use of NL by exploring the utility of non-NL formats in these contexts. We show that allowing LLMs to autonomously select the most suitable format before reasoning or communicating leads to a 3.3 to 5.7 % improvement in reasoning efficiency for different LLMs, and up to a 72.7 % reduction in token usage in multi-agent communication, all while maintaining communicative effectiveness. Our comprehensive analysis further reveals that LLMs can devise a format from limited task instructions and that the devised format is effectively transferable across different LLMs. Intriguingly, the structured communication format decided by LLMs exhibits notable parallels with established agent communication languages, suggesting a natural evolution towards efficient, structured communication in agent communication. Our code is released at url{https://github.com/thunlp/AutoForm}.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20RMSE%20and%20MAE%3A%20Introducing%20EAUC%20to%20unmask%20hidden%20bias%20and%20unfairness%20in%20dyadic%20regression%20models                                                                                  Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models                                                                                  Dyadic regression models, which predict real-valued outcomes for pairs of entities, are fundamental in many domains (e.g. predicting the rating of a user to a product in Recommender Systems) and promising and under exploration in many others (e.g. approximating the adequate dosage of a drug for a patient in personalized pharmacology). In this work, we demonstrate that non-uniformity in the observed value distributions of individual entities leads to severely biased predictions in state-of-the-art models, skewing predictions towards the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet equally important cases. We show that the usage of global error metrics like Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) is insufficient to capture this phenomenon, which we name eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as a new complementary metric that can quantify it in all studied models and datasets. We also prove the adequateness of EAUC by using naive de-biasing corrections to demonstrate that a lower model bias correlates with a lower EAUC and vice-versa. This work contributes a bias-aware evaluation of dyadic regression models to avoid potential unfairness and risks in critical real-world applications of such systems.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Random%20Inputs%3A%20A%20Novel%20ML-Based%20Hardware%20Fuzzing                                                                                  Beyond Random Inputs: A Novel ML-Based Hardware Fuzzing                                                                                  Modern computing systems heavily rely on hardware as the root of trust. However, their increasing complexity has given rise to security-critical vulnerabilities that cross-layer at-tacks can exploit. Traditional hardware vulnerability detection methods, such as random regression and formal verification, have limitations. Random regression, while scalable, is slow in exploring hardware, and formal verification techniques are often concerned with manual effort and state explosions. Hardware fuzzing has emerged as an effective approach to exploring and detecting security vulnerabilities in large-scale designs like modern processors. They outperform traditional methods regarding coverage, scalability, and efficiency. However, state-of-the-art fuzzers struggle to achieve comprehensive coverage of intricate hardware designs within a practical timeframe, often falling short of a 70% coverage threshold. We propose a novel ML-based hardware fuzzer, ChatFuzz, to address this challenge. Ourapproach leverages LLMs like ChatGPT to understand processor language, focusing on machine codes and generating assembly code sequences. RL is integrated to guide the input generation process by rewarding the inputs using code coverage metrics. We use the open-source RISCV-based RocketCore processor as our testbed. ChatFuzz achieves condition coverage rate of 75% in just 52 minutes compared to a state-of-the-art fuzzer, which requires a lengthy 30-hour window to reach a similar condition coverage. Furthermore, our fuzzer can attain 80% coverage when provided with a limited pool of 10 simulation instances/licenses within a 130-hour window. During this time, it conducted a total of 199K test cases, of which 6K produced discrepancies with the processor's golden model. Our analysis identified more than 10 unique mismatches, including two new bugs in the RocketCore and discrepancies from the RISC-V ISA Simulator.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Single-Model%20Views%20for%20Deep%20Learning%3A%20Optimization%20versus%20Generalizability%20of%20Stochastic%20Optimization%20Algorithms                                                                                  Beyond Single-Model Views for Deep Learning: Optimization versus Generalizability of Stochastic Optimization Algorithms                                                                                  Despite an extensive body of literature on deep learning optimization, our current understanding of what makes an optimization algorithm effective is fragmented. In particular, we do not understand well whether enhanced optimization translates to improved generalizability. Current research overlooks the inherent stochastic nature of stochastic gradient descent (SGD) and its variants, resulting in a lack of comprehensive benchmarking and insight into their statistical performance. This paper aims to address this gap by adopting a novel approach. Rather than solely evaluating the endpoint of individual optimization trajectories, we draw from an ensemble of trajectories to estimate the stationary distribution of stochastic optimizers. Our investigation encompasses a wide array of techniques, including SGD and its variants, flat-minima optimizers, and new algorithms we propose under the Basin Hopping framework. Through our evaluation, which encompasses synthetic functions with known minima and real-world problems in computer vision and natural language processing, we emphasize fair benchmarking under a statistical framework, comparing stationary distributions and establishing statistical significance. Our study uncovers several key findings regarding the relationship between training loss and hold-out accuracy, as well as the comparable performance of SGD, noise-enabled variants, and novel optimizers utilizing the BH framework. Notably, these algorithms demonstrate performance on par with flat-minima optimizers like SAM, albeit with half the gradient evaluations. We anticipate that our work will catalyze further exploration in deep learning optimization, encouraging a shift away from single-model approaches towards methodologies that acknowledge and leverage the stochastic nature of optimizers.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Sparse%20Rewards%3A%20Enhancing%20Reinforcement%20Learning%20with%20Language%20Model%20Critique%20in%20Text%20Generation                                                                                  Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation                                                                                  Reinforcement learning (RL) can align language models with non-differentiable reward signals, such as human preferences. However, a major challenge arises from the sparsity of these reward signals - typically, there is only a single reward for an entire output. This sparsity of rewards can lead to inefficient and unstable learning. To address this challenge, our paper introduces an novel framework that utilizes the critique capability of Large Language Models (LLMs) to produce intermediate-step rewards during RL training. Our method involves coupling a policy model with a critic language model, which is responsible for providing comprehensive feedback of each part of the output. This feedback is then translated into token or span-level rewards that can be used to guide the RL training process. We investigate this approach under two different settings: one where the policy model is smaller and is paired with a more powerful critic model, and another where a single language model fulfills both roles. We assess our approach on three text generation tasks: sentiment control, language model detoxification, and summarization. Experimental results show that incorporating artificial intrinsic rewards significantly improve both sample efficiency and the overall performance of the policy model, supported by both automatic and human evaluation.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Talking%20--%20Generating%20Holistic%203D%20Human%20Dyadic%20Motion%20for%20Communication                                                                                  Beyond Talking -- Generating Holistic 3D Human Dyadic Motion for Communication                                                                                  In this paper, we introduce an innovative task focused on human communication, aiming to generate 3D holistic human motions for both speakers and listeners. Central to our approach is the incorporation of factorization to decouple audio features and the combination of textual semantic information, thereby facilitating the creation of more realistic and coordinated movements. We separately train VQ-VAEs with respect to the holistic motions of both speaker and listener. We consider the real-time mutual influence between the speaker and the listener and propose a novel chain-like transformer-based auto-regressive model specifically designed to characterize real-world communication scenarios effectively which can generate the motions of both the speaker and the listener simultaneously. These designs ensure that the results we generate are both coordinated and diverse. Our approach demonstrates state-of-the-art performance on two benchmark datasets. Furthermore, we introduce the HoCo holistic communication dataset, which is a valuable resource for future research. Our HoCo dataset and code will be released for research purposes upon acceptance.
http://w3id.org/mlsea/pwc/scientificWork/Beyond%20Text%3A%20Frozen%20Large%20Language%20Models%20in%20Visual%20Signal%20Comprehension                                                                                  Beyond Text: Frozen Large Language Models in Visual Signal Comprehension                                                                                  In this work, we investigate the potential of a large language model (LLM) to directly comprehend visual signals without the necessity of fine-tuning on multi-modal datasets. The foundational concept of our method views an image as a linguistic entity, and translates it to a set of discrete words derived from the LLM's vocabulary. To achieve this, we present the Vision-to-Language Tokenizer, abbreviated as V2T Tokenizer, which transforms an image into a ``foreign language'' with the combined aid of an encoder-decoder, the LLM vocabulary, and a CLIP model. With this innovative image encoding, the LLM gains the ability not only for visual comprehension but also for image denoising and restoration in an auto-regressive fashion-crucially, without any fine-tuning. We undertake rigorous experiments to validate our method, encompassing understanding tasks like image recognition, image captioning, and visual question answering, as well as image denoising tasks like inpainting, outpainting, deblurring, and shift restoration. Code and models are available at https://github.com/zh460045050/V2L-Tokenizer.
http://w3id.org/mlsea/pwc/scientificWork/Bi-LORA%3A%20A%20Vision-Language%20Approach%20for%20Synthetic%20Image%20Detection                                                                                  Bi-LORA: A Vision-Language Approach for Synthetic Image Detection                                                                                  Advancements in deep image synthesis techniques, such as generative adversarial networks (GANs) and diffusion models (DMs), have ushered in an era of generating highly realistic images. While this technological progress has captured significant interest, it has also raised concerns about the potential difficulty in distinguishing real images from their synthetic counterparts. This paper takes inspiration from the potent convergence capabilities between vision and language, coupled with the zero-shot nature of vision-language models (VLMs). We introduce an innovative method called Bi-LORA that leverages VLMs, combined with low-rank adaptation (LORA) tuning techniques, to enhance the precision of synthetic image detection for unseen model-generated images. The pivotal conceptual shift in our methodology revolves around reframing binary classification as an image captioning task, leveraging the distinctive capabilities of cutting-edge VLM, notably bootstrapping language image pre-training (BLIP2). Rigorous and comprehensive experiments are conducted to validate the effectiveness of our proposed approach, particularly in detecting unseen diffusion-generated images from unknown diffusion-based generative models during training, showcasing robustness to noise, and demonstrating generalization capabilities to GANs. The obtained results showcase an impressive average accuracy of 93.41% in synthetic image detection on unseen generation models. The code and models associated with this research can be publicly accessed at https://github.com/Mamadou-Keita/VLM-DETECT.
http://w3id.org/mlsea/pwc/scientificWork/Bi-Level%20Control%20of%20Weaving%20Sections%20in%20Mixed%20Traffic%20Environments%20with%20Connected%20and%20Automated%20Vehicles                                                                                  Bi-Level Control of Weaving Sections in Mixed Traffic Environments with Connected and Automated Vehicles                                                                                  Connected and automated vehicles (CAVs) can be beneficial for improving the operation of highway bottlenecks such as weaving sections. This paper proposes a bi-level control approach based on an upper-level deep reinforcement learning controller and a lower-level model predictive controller to coordinate the lane-changings of a mixed fleet of CAVs and human-driven vehicles (HVs) in weaving sections. The upper level represents a roadside controller that collects vehicular information from the entire weaving section and determines the control weights used in the lower-level controller. The lower level is implemented within each CAV, which takes the control weights from the upper-level controller and generates the acceleration and steering angle for individual CAVs based on the local situation. The lower-level controller further incorporates an HV trajectory predictor, which is capable of handling the dynamic topology of vehicles in weaving scenarios with intensive mandatory lane changes. The case study inspired by a real weaving section in Basel, Switzerland, shows that our method consistently outperforms state-of-the-art benchmarks.
http://w3id.org/mlsea/pwc/scientificWork/BiTT%3A%20Bi-directional%20Texture%20Reconstruction%20of%20Interacting%20Two%20Hands%20from%20a%20Single%20Image                                                                                  BiTT: Bi-directional Texture Reconstruction of Interacting Two Hands from a Single Image                                                                                  Creating personalized hand avatars is important to offer a realistic experience to users on AR / VR platforms. While most prior studies focused on reconstructing 3D hand shapes, some recent work has tackled the reconstruction of hand textures on top of shapes. However, these methods are often limited to capturing pixels on the visible side of a hand, requiring diverse views of the hand in a video or multiple images as input. In this paper, we propose a novel method, BiTT(Bi-directional Texture reconstruction of Two hands), which is the first end-to-end trainable method for relightable, pose-free texture reconstruction of two interacting hands taking only a single RGB image, by three novel components: 1) bi-directional (left $ leftrightarrow$ right) texture reconstruction using the texture symmetry of left / right hands, 2) utilizing a texture parametric model for hand texture recovery, and 3) the overall coarse-to-fine stage pipeline for reconstructing personalized texture of two interacting hands. BiTT first estimates the scene light condition and albedo image from an input image, then reconstructs the texture of both hands through the texture parametric model and bi-directional texture reconstructor. In experiments using InterHand2.6M and RGB2Hands datasets, our method significantly outperforms state-of-the-art hand texture reconstruction methods quantitatively and qualitatively. The code is available at https://github.com/yunminjin2/BiTT
http://w3id.org/mlsea/pwc/scientificWork/BiVert%3A%20Bidirectional%20Vocabulary%20Evaluation%20using%20Relations%20for%20Machine%20Translation                                                                                  BiVert: Bidirectional Vocabulary Evaluation using Relations for Machine Translation                                                                                  Neural machine translation (NMT) has progressed rapidly in the past few years, promising improvements and quality translations for different languages. Evaluation of this task is crucial to determine the quality of the translation. Overall, insufficient emphasis is placed on the actual sense of the translation in traditional methods. We propose a bidirectional semantic-based evaluation method designed to assess the sense distance of the translation from the source text. This approach employs the comprehensive multilingual encyclopedic dictionary BabelNet. Through the calculation of the semantic distance between the source and its back translation of the output, our method introduces a quantifiable approach that empowers sentence comparison on the same linguistic level. Factual analysis shows a strong correlation between the average evaluation scores generated by our method and the human assessments across various machine translation systems for English-German language pair. Finally, our method proposes a new multilingual approach to rank MT systems without the need for parallel corpora.
http://w3id.org/mlsea/pwc/scientificWork/Bias-Augmented%20Consistency%20Training%20Reduces%20Biased%20Reasoning%20in%20Chain-of-Thought                                                                                  Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought                                                                                  While chain-of-thought prompting (CoT) has the potential to improve the explainability of language model reasoning, it can systematically misrepresent the factors influencing models' behavior--for example, rationalizing answers in line with a user's opinion without mentioning this bias. To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT), an unsupervised fine-tuning scheme that trains models to give consistent reasoning across prompts with and without biasing features. We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86% on held-out tasks. Moreover, this model generalizes to other forms of bias, reducing biased reasoning on held-out biases by an average of 37%. As BCT generalizes to held-out biases and does not require gold labels, this method may hold promise for reducing biased reasoning from as-of-yet unknown biases and on tasks where supervision for ground truth reasoning is unavailable.
http://w3id.org/mlsea/pwc/scientificWork/Bias-Conflict%20Sample%20Synthesis%20and%20Adversarial%20Removal%20Debias%20Strategy%20for%20Temporal%20Sentence%20Grounding%20in%20Video                                                                                  Bias-Conflict Sample Synthesis and Adversarial Removal Debias Strategy for Temporal Sentence Grounding in Video                                                                                  Temporal Sentence Grounding in Video (TSGV) is troubled by dataset bias issue, which is caused by the uneven temporal distribution of the target moments for samples with similar semantic components in input videos or query texts. Existing methods resort to utilizing prior knowledge about bias to artificially break this uneven distribution, which only removes a limited amount of significant language biases. In this work, we propose the bias-conflict sample synthesis and adversarial removal debias strategy (BSSARD), which dynamically generates bias-conflict samples by explicitly leveraging potentially spurious correlations between single-modality features and the temporal position of the target moments. Through adversarial training, its bias generators continuously introduce biases and generate bias-conflict samples to deceive its grounding model. Meanwhile, the grounding model continuously eliminates the introduced biases, which requires it to model multi-modality alignment information. BSSARD will cover most kinds of coupling relationships and disrupt language and visual biases simultaneously. Extensive experiments on Charades-CD and ActivityNet-CD demonstrate the promising debiasing capability of BSSARD. Source codes are available at https://github.com/qzhb/BSSARD.
http://w3id.org/mlsea/pwc/scientificWork/Big%20City%20Bias%3A%20Evaluating%20the%20Impact%20of%20Metropolitan%20Size%20on%20Computational%20Job%20Market%20Abilities%20of%20Language%20Models                                                                                  Big City Bias: Evaluating the Impact of Metropolitan Size on Computational Job Market Abilities of Language Models                                                                                  Large language models (LLMs) have emerged as a useful technology for job matching, for both candidates and employers. Job matching is often based on a particular geographic location, such as a city or region. However, LLMs have known biases, commonly derived from their training data. In this work, we aim to quantify the metropolitan size bias encoded within large language models, evaluating zero-shot salary, employer presence, and commute duration predictions in 384 of the United States' metropolitan regions. Across all benchmarks, we observe negative correlations between the metropolitan size and the performance of the LLMS, indicating that smaller regions are indeed underrepresented. More concretely, the smallest 10 metropolitan regions show upwards of 300% worse benchmark performance than the largest 10.
http://w3id.org/mlsea/pwc/scientificWork/BigGait%3A%20Learning%20Gait%20Representation%20You%20Want%20by%20Large%20Vision%20Models                                                                                  BigGait: Learning Gait Representation You Want by Large Vision Models                                                                                  Gait recognition stands as one of the most pivotal remote identification technologies and progressively expands across research and industry communities. However, existing gait recognition methods heavily rely on task-specific upstream driven by supervised learning to provide explicit gait representations like silhouette sequences, which inevitably introduce expensive annotation costs and potential error accumulation. Escaping from this trend, this work explores effective gait representations based on the all-purpose knowledge produced by task-agnostic Large Vision Models (LVMs) and proposes a simple yet efficient gait framework, termed BigGait. Specifically, the Gait Representation Extractor (GRE) within BigGait draws upon design principles from established gait representations, effectively transforming all-purpose knowledge into implicit gait representations without requiring third-party supervision signals. Experiments on CCPG, CAISA-B* and SUSTech1K indicate that BigGait significantly outperforms the previous methods in both within-domain and cross-domain tasks in most cases, and provides a more practical paradigm for learning the next-generation gait representation. Finally, we delve into prospective challenges and promising directions in LVMs-based gait recognition, aiming to inspire future work in this emerging topic. The source code is available at https://github.com/ShiqiYu/OpenGait.
http://w3id.org/mlsea/pwc/scientificWork/Bilateral%20Unsymmetrical%20Graph%20Contrastive%20Learning%20for%20Recommendation                                                                                  Bilateral Unsymmetrical Graph Contrastive Learning for Recommendation                                                                                  Recent methods utilize graph contrastive Learning within graph-structured user-item interaction data for collaborative filtering and have demonstrated their efficacy in recommendation tasks. However, they ignore that the difference relation density of nodes between the user- and item-side causes the adaptability of graphs on bilateral nodes to be different after multi-hop graph interaction calculation, which limits existing models to achieve ideal results. To solve this issue, we propose a novel framework for recommendation tasks called Bilateral Unsymmetrical Graph Contrastive Learning (BusGCL) that consider the bilateral unsymmetry on user-item node relation density for sliced user and item graph reasoning better with bilateral slicing contrastive training. Especially, taking into account the aggregation ability of hypergraph-based graph convolutional network (GCN) in digging implicit similarities is more suitable for user nodes, embeddings generated from three different modules: hypergraph-based GCN, GCN and perturbed GCN, are sliced into two subviews by the user- and item-side respectively, and selectively combined into subview pairs bilaterally based on the characteristics of inter-node relation structure. Furthermore, to align the distribution of user and item embeddings after aggregation, a dispersing loss is leveraged to adjust the mutual distance between all embeddings for maintaining learning ability. Comprehensive experiments on two public datasets have proved the superiority of BusGCL in comparison to various recommendation methods. Other models can simply utilize our bilateral slicing contrastive learning to enhance recommending performance without incurring extra expenses.
http://w3id.org/mlsea/pwc/scientificWork/Binding%20Touch%20to%20Everything%3A%20Learning%20Unified%20Multimodal%20Tactile%20Representations                                                                                  Binding Touch to Everything: Learning Unified Multimodal Tactile Representations                                                                                  The ability to associate touch with other modalities has huge implications for humans and computational systems. However, multimodal learning with touch remains challenging due to the expensive data collection process and non-standardized sensor outputs. We introduce UniTouch, a unified tactile model for vision-based touch sensors connected to multiple modalities, including vision, language, and sound. We achieve this by aligning our UniTouch embeddings to pretrained image embeddings already associated with a variety of other modalities. We further propose learnable sensor-specific tokens, allowing the model to learn from a set of heterogeneous tactile sensors, all at the same time. UniTouch is capable of conducting various touch sensing tasks in the zero-shot setting, from robot grasping prediction to touch image question answering. To the best of our knowledge, UniTouch is the first to demonstrate such capabilities. Project page: https://cfeng16.github.io/UniTouch/
http://w3id.org/mlsea/pwc/scientificWork/Binomial%20Self-compensation%20for%20Motion%20Error%20in%20Dynamic%203D%20Scanning                                                                                  Binomial Self-compensation for Motion Error in Dynamic 3D Scanning                                                                                  Phase shifting profilometry (PSP) is favored in high-precision 3D scanning due to its high accuracy, robustness, and pixel-wise property. However, a fundamental assumption of PSP that the object should remain static is violated in dynamic measurement, making PSP susceptible to object moving, resulting in ripple-like errors in the point clouds. We propose a pixel-wise and frame-wise loopable binomial self-compensation (BSC) algorithm to effectively and flexibly eliminate motion error in the four-step PSP. Our mathematical model demonstrates that by summing successive motion-affected phase frames weighted by binomial coefficients, motion error exponentially diminishes as the binomial order increases, accomplishing automatic error compensation through the motion-affected phase sequence, without the assistance of any intermediate variable. Extensive experiments show that our BSC outperforms the existing methods in reducing motion error, while achieving a depth map frame rate equal to the camera's acquisition rate (90 fps), enabling high-accuracy 3D reconstruction with a quasi-single-shot frame rate.
http://w3id.org/mlsea/pwc/scientificWork/BioDiffusion%3A%20A%20Versatile%20Diffusion%20Model%20for%20Biomedical%20Signal%20Synthesis                                                                                  BioDiffusion: A Versatile Diffusion Model for Biomedical Signal Synthesis                                                                                  Machine learning tasks involving biomedical signals frequently grapple with issues such as limited data availability, imbalanced datasets, labeling complexities, and the interference of measurement noise. These challenges often hinder the optimal training of machine learning algorithms. Addressing these concerns, we introduce BioDiffusion, a diffusion-based probabilistic model optimized for the synthesis of multivariate biomedical signals. BioDiffusion demonstrates excellence in producing high-fidelity, non-stationary, multivariate signals for a range of tasks including unconditional, label-conditional, and signal-conditional generation. Leveraging these synthesized signals offers a notable solution to the aforementioned challenges. Our research encompasses both qualitative and quantitative assessments of the synthesized data quality, underscoring its capacity to bolster accuracy in machine learning tasks tied to biomedical signals. Furthermore, when juxtaposed with current leading time-series generative models, empirical evidence suggests that BioDiffusion outperforms them in biomedical signal generation quality.
http://w3id.org/mlsea/pwc/scientificWork/BioDrone%3A%20A%20Bionic%20Drone-based%20Single%20Object%20Tracking%20Benchmark%20for%20Robust%20Vision                                                                                  BioDrone: A Bionic Drone-based Single Object Tracking Benchmark for Robust Vision                                                                                  Single object tracking (SOT) is a fundamental problem in computer vision, with a wide range of applications, including autonomous driving, augmented reality, and robot navigation. The robustness of SOT faces two main challenges: tiny target and fast motion. These challenges are especially manifested in videos captured by unmanned aerial vehicles (UAV), where the target is usually far away from the camera and often with significant motion relative to the camera. To evaluate the robustness of SOT methods, we propose BioDrone -- the first bionic drone-based visual benchmark for SOT. Unlike existing UAV datasets, BioDrone features videos captured from a flapping-wing UAV system with a major camera shake due to its aerodynamics. BioDrone hence highlights the tracking of tiny targets with drastic changes between consecutive frames, providing a new robust vision benchmark for SOT. To date, BioDrone offers the largest UAV-based SOT benchmark with high-quality fine-grained manual annotations and automatically generates frame-level labels, designed for robust vision analyses. Leveraging our proposed BioDrone, we conduct a systematic evaluation of existing SOT methods, comparing the performance of 20 representative models and studying novel means of optimizing a SOTA method (KeepTrack KeepTrack) for robust SOT. Our evaluation leads to new baselines and insights for robust SOT. Moving forward, we hope that BioDrone will not only serve as a high-quality benchmark for robust SOT, but also invite future research into robust computer vision. The database, toolkits, evaluation server, and baseline results are available at http://biodrone.aitestunion.com.
http://w3id.org/mlsea/pwc/scientificWork/BioFusionNet%3A%20Deep%20Learning-Based%20Survival%20Risk%20Stratification%20in%20ER%2B%20Breast%20Cancer%20Through%20Multifeature%20and%20Multimodal%20Data%20Fusion                                                                                  BioFusionNet: Deep Learning-Based Survival Risk Stratification in ER+ Breast Cancer Through Multifeature and Multimodal Data Fusion                                                                                  Breast cancer is a significant health concern affecting millions of women worldwide. Accurate survival risk stratification plays a crucial role in guiding personalised treatment decisions and improving patient outcomes. Here we present BioFusionNet, a deep learning framework that fuses image-derived features with genetic and clinical data to achieve a holistic patient profile and perform survival risk stratification of ER+ breast cancer patients. We employ multiple self-supervised feature extractors, namely DINO and MoCoV3, pretrained on histopathology patches to capture detailed histopathological image features. We then utilise a variational autoencoder (VAE) to fuse these features, and harness the latent space of the VAE to feed into a self-attention network, generating patient-level features. Next, we develop a co-dual-cross-attention mechanism to combine the histopathological features with genetic data, enabling the model to capture the interplay between them. Additionally, clinical data is incorporated using a feed-forward network (FFN), further enhancing predictive performance and achieving comprehensive multimodal feature integration. Furthermore, we introduce a weighted Cox loss function, specifically designed to handle imbalanced survival data, which is a common challenge in the field. The proposed model achieves a mean concordance index (C-index) of 0.77 and a time-dependent area under the curve (AUC) of 0.84, outperforming state-of-the-art methods. It predicts risk (high versus low) with prognostic significance for overall survival (OS) in univariate analysis (HR=2.99, 95% CI: 1.88--4.78, p<0.005), and maintains independent significance in multivariate analysis incorporating standard clinicopathological variables (HR=2.91, 95% CI: 1.80--4.68, p<0.005). The proposed method not only improves model performance but also addresses a critical gap in handling imbalanced data.
http://w3id.org/mlsea/pwc/scientificWork/BioMistral%3A%20A%20Collection%20of%20Open-Source%20Pretrained%20Large%20Language%20Models%20for%20Medical%20Domains                                                                                  BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains                                                                                  Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges. In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central. We conduct a comprehensive evaluation of BioMistral on a benchmark comprising 10 established medical question-answering (QA) tasks in English. We also explore lightweight models obtained through quantization and model merging approaches. Our results demonstrate BioMistral's superior performance compared to existing open-source medical models and its competitive edge against proprietary counterparts. Finally, to address the limited availability of data beyond English and to assess the multilingual generalization of medical LLMs, we automatically translated and evaluated this benchmark into 7 other languages. This marks the first large-scale multilingual evaluation of LLMs in the medical domain. Datasets, multilingual evaluation benchmarks, scripts, and all the models obtained during our experiments are freely released.
http://w3id.org/mlsea/pwc/scientificWork/BirdSet%3A%20A%20Multi-Task%20Benchmark%20for%20Classification%20in%20Computational%20Avian%20Bioacoustics                                                                                  BirdSet: A Multi-Task Benchmark for Classification in Computational Avian Bioacoustics                                                                                  Deep learning (DL) models have emerged as a powerful tool in avian bioacoustics to diagnose environmental health and biodiversity. However, inconsistencies in research pose notable challenges hindering progress. Reliable DL models need to analyze bird calls flexibly across various species and environments to fully harness the potential of bioacoustics in a cost-effective passive acoustic monitoring scenario. Data fragmentation and opacity across studies complicate a comprehensive evaluation of model performance. To overcome these challenges, we present the BirdSet benchmark, a unified framework consolidating research efforts with a holistic approach for the classification of bird vocalizations in computational avian bioacoustics. BirdSet aggregates open-source bird recordings into a curated dataset collection. This unified approach provides an in-depth understanding of model performance and identifies potential shortcomings across different tasks. By providing baseline results of current models, we aim to facilitate comparability and ease accessibility for newcomers. Additionally, we release an open-source package benchmark containing a comprehensive data pipeline that enables easy and fast model evaluation, available at https://github.com/DBD-research-group/BirdSet.
http://w3id.org/mlsea/pwc/scientificWork/Bispectrum%20Analysis%20of%20Noninvasive%20EEG%20Signals%20Discriminates%20Complex%20and%20Natural%20Grasp%20Types                                                                                  Bispectrum Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types                                                                                  The bispectrum stands out as a revolutionary tool in frequency domain analysis, leaping the usual power spectrum by capturing crucial phase information between frequency components. In our innovative study, we have utilized the bispectrum to analyze and decode complex grasping movements, gathering EEG data from five human subjects. We put this data through its paces with three classifiers, focusing on both magnitude and phase-related features. The results highlight the bispectrum's incredible ability to delve into neural activity and differentiate between various grasping motions with the Support Vector Machine (SVM) classifier emerging as a standout performer. In binary classification, it achieved a remarkable 97 % accuracy in identifying power grasp, and in the more complex multiclass tasks, it maintained an impressive 94.93 % accuracy. This finding not only underscores the bispectrum's analytical strength but also showcases the SVM's exceptional capability in classification, opening new doors in our understanding of movement and neural dynamics.
http://w3id.org/mlsea/pwc/scientificWork/Bit%20error%20probability%20and%20capacity%20bound%20of%20OFDM%20systems%20in%20deterministic%20doubly-selective%20channels                                                                                  Bit error probability and capacity bound of OFDM systems in deterministic doubly-selective channels                                                                                  Doubly-selective channels, such as those that occur when the transmitter and the receiver move relative to each other at high speeds, are a key scenario for fifth generation (5G) cellular systems, which are mostly based in the use of the orthogonal frequency-division multiplexing (OFDM) modulation. In this paper, we consider an OFDM system using quadrature amplitude modulation (QAM) symbols and we show that, when transmitting over deterministic doubly-selective channels, the inter-carrier interference (ICI) affecting a symbol can be well approximated by a complex-valued normal distribution. Based on this, we derive a lower bound for the link capacity using the Shannon-Hartley theorem. Finally, we provide an approximation of the bit error probability (BEP) using the well-known BEP expressions for Gray-coded QAM constellations over additive white Gaussian noise (AWGN) channels, and show numerical results that confirm that the proposed BEP expression approximates accurately the bit error ratio (BER) of the OFDM system for standardized channel models. The proposed closed-form analytical expressions for the capacity and the BEP do not only allow for discarding the need of computationally-costly Monte-Carlo system simulations, but also provide a theoretical framework to optimize the system parameters directly impacting on the achievable performance.
http://w3id.org/mlsea/pwc/scientificWork/BitDelta%3A%20Your%20Fine-Tune%20May%20Only%20Be%20Worth%20One%20Bit                                                                                  BitDelta: Your Fine-Tune May Only Be Worth One Bit                                                                                  Large Language Models (LLMs) are typically trained in two phases: pre-training on large internet-scale datasets, and fine-tuning for downstream tasks. Given the higher computational demand of pre-training, it's intuitive to assume that fine-tuning adds less new information to the model, and is thus more compressible. We explore this assumption by decomposing the weights of fine-tuned models into their pre-trained components and an additional delta. We introduce a simple method, BitDelta, which successfully quantizes this delta down to 1 bit without compromising performance. This interesting finding not only highlights the potential redundancy of information added during fine-tuning, but also has significant implications for the multi-tenant serving and multi-tenant storage of fine-tuned models. By enabling the use of a single high-precision base model accompanied by multiple 1-bit deltas, BitDelta dramatically reduces GPU memory requirements by more than 10x, which can also be translated to enhanced generation latency in multi-tenant settings. We validate BitDelta through experiments across Llama-2 and Mistral model families, and on models up to 70B parameters, showcasing minimal performance degradation over all tested settings.
http://w3id.org/mlsea/pwc/scientificWork/Black-Box%20%24k%24-to-%241%24-PCA%20Reductions%3A%20Theory%20and%20Applications                                                                                  Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications                                                                                  The $k$-principal component analysis ($k$-PCA) problem is a fundamental algorithmic primitive that is widely-used in data analysis and dimensionality reduction applications. In statistical settings, the goal of $k$-PCA is to identify a top eigenspace of the covariance matrix of a distribution, which we only have implicit access to via samples. Motivated by these implicit settings, we analyze black-box deflation methods as a framework for designing $k$-PCA algorithms, where we model access to the unknown target matrix via a black-box $1$-PCA oracle which returns an approximate top eigenvector, under two popular notions of approximation. Despite being arguably the most natural reduction-based approach to $k$-PCA algorithm design, such black-box methods, which recursively call a $1$-PCA oracle $k$ times, were previously poorly-understood. Our main contribution is significantly sharper bounds on the approximation parameter degradation of deflation methods for $k$-PCA. For a quadratic form notion of approximation we term ePCA (energy PCA), we show deflation methods suffer no parameter loss. For an alternative well-studied approximation notion we term cPCA (correlation PCA), we tightly characterize the parameter regimes where deflation methods are feasible. Moreover, we show that in all feasible regimes, $k$-cPCA deflation algorithms suffer no asymptotic parameter loss for any constant $k$. We apply our framework to obtain state-of-the-art $k$-PCA algorithms robust to dataset contamination, improving prior work both in sample complexity and approximation quality.
http://w3id.org/mlsea/pwc/scientificWork/Blackout%20Mitigation%20via%20Physics-guided%20RL                                                                                  Blackout Mitigation via Physics-guided RL                                                                                  This paper considers the sequential design of remedial control actions in response to system anomalies for the ultimate objective of preventing blackouts. A physics-guided reinforcement learning (RL) framework is designed to identify effective sequences of real-time remedial look-ahead decisions accounting for the long-term impact on the system's stability. The paper considers a space of control actions that involve both discrete-valued transmission line-switching decisions (line reconnections and removals) and continuous-valued generator adjustments. To identify an effective blackout mitigation policy, a physics-guided approach is designed that uses power-flow sensitivity factors associated with the power transmission network to guide the RL exploration during agent training. Comprehensive empirical evaluations using the open-source Grid2Op platform demonstrate the notable advantages of incorporating physical signals into RL decisions, establishing the gains of the proposed physics-guided approach compared to its black box counterparts. One important observation is that strategically~ emph{removing} transmission lines, in conjunction with multiple real-time generator adjustments, often renders effective long-term decisions that are likely to prevent or delay blackouts.
http://w3id.org/mlsea/pwc/scientificWork/BlendFilter%3A%20Advancing%20Retrieval-Augmented%20Large%20Language%20Models%20via%20Query%20Generation%20Blending%20and%20Knowledge%20Filtering                                                                                  BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering                                                                                  Retrieval-augmented Large Language Models (LLMs) offer substantial benefits in enhancing performance across knowledge-intensive scenarios. However, these methods often face challenges with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness. To address this issue, we introduce BlendFilter, a novel approach that elevates retrieval-augmented LLMs by integrating query generation blending with knowledge filtering. BlendFilter proposes the blending process through its query generation method, which integrates both external and internal knowledge augmentation with the original query, ensuring comprehensive information gathering. Additionally, our distinctive knowledge filtering module capitalizes on the intrinsic capabilities of the LLM, effectively eliminating extraneous data. We conduct extensive experiments on three open-domain question answering benchmarks, and the findings clearly indicate that our innovative BlendFilter surpasses state-of-the-art baselines significantly.
http://w3id.org/mlsea/pwc/scientificWork/BlendScape%3A%20Enabling%20Unified%20and%20Personalized%20Video-Conferencing%20Environments%20through%20Generative%20AI                                                                                  BlendScape: Enabling Unified and Personalized Video-Conferencing Environments through Generative AI                                                                                  Today's video-conferencing tools support a rich range of professional and social activities, but their generic, grid-based environments cannot be easily adapted to meet the varying needs of distributed collaborators. To enable end-user customization, we developed BlendScape, a system for meeting participants to compose video-conferencing environments tailored to their collaboration context by leveraging AI image generation techniques. BlendScape supports flexible representations of task spaces by blending users' physical or virtual backgrounds into unified environments and implements multimodal interaction techniques to steer the generation. Through an evaluation with 15 end-users, we investigated their customization preferences for work and social scenarios. Participants could rapidly express their design intentions with BlendScape and envisioned using the system to structure collaboration in future meetings, but experienced challenges with preventing distracting elements. We implement scenarios to demonstrate BlendScape's expressiveness in supporting distributed collaboration techniques from prior work and propose composition techniques to improve the quality of environments.
http://w3id.org/mlsea/pwc/scientificWork/BlendX%3A%20Complex%20Multi-Intent%20Detection%20with%20Blended%20Patterns                                                                                  BlendX: Complex Multi-Intent Detection with Blended Patterns                                                                                  Task-oriented dialogue (TOD) systems are commonly designed with the presumption that each utterance represents a single intent. However, this assumption may not accurately reflect real-world situations, where users frequently express multiple intents within a single utterance. While there is an emerging interest in multi-intent detection (MID), existing in-domain datasets such as MixATIS and MixSNIPS have limitations in their formulation. To address these issues, we present BlendX, a suite of refined datasets featuring more diverse patterns than their predecessors, elevating both its complexity and diversity. For dataset construction, we utilize both rule-based heuristics as well as a generative tool -- OpenAI's ChatGPT -- which is augmented with a similarity-driven strategy for utterance selection. To ensure the quality of the proposed datasets, we also introduce three novel metrics that assess the statistical properties of an utterance related to word count, conjunction use, and pronoun usage. Extensive experiments on BlendX reveal that state-of-the-art MID models struggle with the challenges posed by the new datasets, highlighting the need to reexamine the current state of the MID field. The dataset is available at https://github.com/HYU-NLP/BlendX.
http://w3id.org/mlsea/pwc/scientificWork/Blending%20Data-Driven%20Priors%20in%20Dynamic%20Games                                                                                  Blending Data-Driven Priors in Dynamic Games                                                                                  As intelligent robots like autonomous vehicles become increasingly deployed in the presence of people, the extent to which these systems should leverage model-based game-theoretic planners versus data-driven policies for safe, interaction-aware motion planning remains an open question. Existing dynamic game formulations assume all agents are task-driven and behave optimally. However, in reality, humans tend to deviate from the decisions prescribed by these models, and their behavior is better approximated under a noisy-rational paradigm. In this work, we investigate a principled methodology to blend a data-driven reference policy with an optimization-based game-theoretic policy. We formulate KLGame, a type of non-cooperative dynamic game with Kullback-Leibler (KL) regularization with respect to a general, stochastic, and possibly multi-modal reference policy. Our method incorporates, for each decision maker, a tunable parameter that permits modulation between task-driven and data-driven behaviors. We propose an efficient algorithm for computing multimodal approximate feedback Nash equilibrium strategies of KLGame in real time. Through a series of simulated and real-world autonomous driving scenarios, we demonstrate that KLGame policies can more effectively incorporate guidance from the reference policy and account for noisily-rational human behaviors versus non-regularized baselines.
http://w3id.org/mlsea/pwc/scientificWork/BlindDiff%3A%20Empowering%20Degradation%20Modelling%20in%20Diffusion%20Models%20for%20Blind%20Image%20Super-Resolution                                                                                  BlindDiff: Empowering Degradation Modelling in Diffusion Models for Blind Image Super-Resolution                                                                                  Diffusion models (DM) have achieved remarkable promise in image super-resolution (SR). However, most of them are tailored to solving non-blind inverse problems with fixed known degradation settings, limiting their adaptability to real-world applications that involve complex unknown degradations. In this work, we propose BlindDiff, a DM-based blind SR method to tackle the blind degradation settings in SISR. BlindDiff seamlessly integrates the MAP-based optimization into DMs, which constructs a joint distribution of the low-resolution (LR) observation, high-resolution (HR) data, and degradation kernels for the data and kernel priors, and solves the blind SR problem by unfolding MAP approach along with the reverse process. Unlike most DMs, BlindDiff firstly presents a modulated conditional transformer (MCFormer) that is pre-trained with noise and kernel constraints, further serving as a posterior sampler to provide both priors simultaneously. Then, we plug a simple yet effective kernel-aware gradient term between adjacent sampling iterations that guides the diffusion model to learn degradation consistency knowledge. This also enables to joint refine the degradation model as well as HR images by observing the previous denoised sample. With the MAP-based reverse diffusion process, we show that BlindDiff advocates alternate optimization for blur kernel estimation and HR image restoration in a mutual reinforcing manner. Experiments on both synthetic and real-world datasets show that BlindDiff achieves the state-of-the-art performance with significant model complexity reduction compared to recent DM-based methods. Code will be available at url{https://github.com/lifengcs/BlindDiff}
http://w3id.org/mlsea/pwc/scientificWork/BlockEcho%3A%20Retaining%20Long-Range%20Dependencies%20for%20Imputing%20Block-Wise%20Missing%20Data                                                                                  BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data                                                                                  Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method ``BlockEcho' for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within Generative Adversarial Networks (GAN) to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for GAN, comparing the generator's intermediate progress with pre-trained MF results to constrain high-order feature distributions. Subsequently, we evaluate BlockEcho on public datasets across three domains. Results demonstrate superior performance over both traditional and SOTA methods when imputing block-wise missing data, especially at higher missing rates. The advantage also holds for scattered missing data at high missing rates. We also contribute on the analyses in providing theoretical justification on the optimality and convergence of fusing MF and GAN for missing block data.
http://w3id.org/mlsea/pwc/scientificWork/BlockFusion%3A%20Expandable%203D%20Scene%20Generation%20using%20Latent%20Tri-plane%20Extrapolation                                                                                  BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation                                                                                  We present BlockFusion, a diffusion-based model that generates 3D scenes as unit blocks and seamlessly incorporates new blocks to extend the scene. BlockFusion is trained using datasets of 3D blocks that are randomly cropped from complete 3D scene meshes. Through per-block fitting, all training blocks are converted into the hybrid neural fields: with a tri-plane containing the geometry features, followed by a Multi-layer Perceptron (MLP) for decoding the signed distance values. A variational auto-encoder is employed to compress the tri-planes into the latent tri-plane space, on which the denoising diffusion process is performed. Diffusion applied to the latent representations allows for high-quality and diverse 3D scene generation. To expand a scene during generation, one needs only to append empty blocks to overlap with the current scene and extrapolate existing latent tri-planes to populate new blocks. The extrapolation is done by conditioning the generation process with the feature samples from the overlapping tri-planes during the denoising iterations. Latent tri-plane extrapolation produces semantically and geometrically meaningful transitions that harmoniously blend with the existing scene. A 2D layout conditioning mechanism is used to control the placement and arrangement of scene elements. Experimental results indicate that BlockFusion is capable of generating diverse, geometrically consistent and unbounded large 3D scenes with unprecedented high-quality shapes in both indoor and outdoor scenarios.
http://w3id.org/mlsea/pwc/scientificWork/Body-Area%20Capacitive%20or%20Electric%20Field%20Sensing%20for%20Human%20Activity%20Recognition%20and%20Human-Computer%20Interaction%3A%20A%20Comprehensive%20Survey                                                                                  Body-Area Capacitive or Electric Field Sensing for Human Activity Recognition and Human-Computer Interaction: A Comprehensive Survey                                                                                  Due to the fact that roughly sixty percent of the human body is essentially composed of water, the human body is inherently a conductive object, being able to, firstly, form an inherent electric field from the body to the surroundings and secondly, deform the distribution of an existing electric field near the body. Body-area capacitive sensing, also called body-area electric field sensing, is becoming a promising alternative for wearable devices to accomplish certain tasks in human activity recognition and human-computer interaction. Over the last decade, researchers have explored plentiful novel sensing systems backed by the body-area electric field. On the other hand, despite the pervasive exploration of the body-area electric field, a comprehensive survey does not exist for an enlightening guideline. Moreover, the various hardware implementations, applied algorithms, and targeted applications result in a challenging task to achieve a systematic overview of the subject. This paper aims to fill in the gap by comprehensively summarizing the existing works on body-area capacitive sensing so that researchers can have a better view of the current exploration status. To this end, we first sorted the explorations into three domains according to the involved body forms: body-part electric field, whole-body electric field, and body-to-body electric field, and enumerated the state-of-art works in the domains with a detailed survey of the backed sensing tricks and targeted applications. We then summarized the three types of sensing frontends in circuit design, which is the most critical part in body-area capacitive sensing, and analyzed the data processing pipeline categorized into three kinds of approaches. Finally, we described the challenges and outlooks of body-area electric sensing.
http://w3id.org/mlsea/pwc/scientificWork/BodyMAP%20--%20Jointly%20Predicting%20Body%20Mesh%20and%203D%20Applied%20Pressure%20Map%20for%20People%20in%20Bed                                                                                  BodyMAP -- Jointly Predicting Body Mesh and 3D Applied Pressure Map for People in Bed                                                                                  Accurately predicting the 3D human posture and the pressure exerted on the body for people resting in bed, visualized as a body mesh (3D pose & shape) with a 3D pressure map, holds significant promise for healthcare applications, particularly, in the prevention of pressure ulcers. Current methods focus on singular facets of the problem -- predicting only 2D/3D poses, generating 2D pressure images, predicting pressure only for certain body regions instead of the full body, or forming indirect approximations to the 3D pressure map. In contrast, we introduce BodyMAP, which jointly predicts the human body mesh and 3D applied pressure map across the entire human body. Our network leverages multiple visual modalities, incorporating both a depth image of a person in bed and its corresponding 2D pressure image acquired from a pressure-sensing mattress. The 3D pressure map is represented as a pressure value at each mesh vertex and thus allows for precise localization of high-pressure regions on the body. Additionally, we present BodyMAP-WS, a new formulation of pressure prediction in which we implicitly learn pressure in 3D by aligning sensed 2D pressure images with a differentiable 2D projection of the predicted 3D pressure maps. In evaluations with real-world human data, our method outperforms the current state-of-the-art technique by 25% on both body mesh and 3D applied pressure map prediction tasks for people in bed.
http://w3id.org/mlsea/pwc/scientificWork/BoolGebra%3A%20Attributed%20Graph-learning%20for%20Boolean%20Algebraic%20Manipulation                                                                                  BoolGebra: Attributed Graph-learning for Boolean Algebraic Manipulation                                                                                  Boolean algebraic manipulation is at the core of logic synthesis in Electronic Design Automation (EDA) design flow. Existing methods struggle to fully exploit optimization opportunities, and often suffer from an explosive search space and limited scalability efficiency. This work presents BoolGebra, a novel attributed graph-learning approach for Boolean algebraic manipulation that aims to improve fundamental logic synthesis. BoolGebra incorporates Graph Neural Networks (GNNs) and takes initial feature embeddings from both structural and functional information as inputs. A fully connected neural network is employed as the predictor for direct optimization result predictions, significantly reducing the search space and efficiently locating the optimization space. The experiments involve training the BoolGebra model w.r.t design-specific and cross-design inferences using the trained model, where BoolGebra demonstrates generalizability for cross-design inference and its potential to scale from small, simple training datasets to large, complex inference datasets. Finally, BoolGebra is integrated with existing synthesis tool ABC to perform end-to-end logic minimization evaluation w.r.t SOTA baselines.
http://w3id.org/mlsea/pwc/scientificWork/BoostDream%3A%20Efficient%20Refining%20for%20High-Quality%20Text-to-3D%20Generation%20from%20Multi-View%20Diffusion                                                                                  BoostDream: Efficient Refining for High-Quality Text-to-3D Generation from Multi-View Diffusion                                                                                  Witnessing the evolution of text-to-image diffusion models, significant strides have been made in text-to-3D generation. Currently, two primary paradigms dominate the field of text-to-3D: the feed-forward generation solutions, capable of swiftly producing 3D assets but often yielding coarse results, and the Score Distillation Sampling (SDS) based solutions, known for generating high-fidelity 3D assets albeit at a slower pace. The synergistic integration of these methods holds substantial promise for advancing 3D generation techniques. In this paper, we present BoostDream, a highly efficient plug-and-play 3D refining method designed to transform coarse 3D assets into high-quality. The BoostDream framework comprises three distinct processes: (1) We introduce 3D model distillation that fits differentiable representations from the 3D assets obtained through feed-forward generation. (2) A novel multi-view SDS loss is designed, which utilizes a multi-view aware 2D diffusion model to refine the 3D assets. (3) We propose to use prompt and multi-view consistent normal maps as guidance in refinement.Our extensive experiment is conducted on different differentiable 3D representations, revealing that BoostDream excels in generating high-quality 3D assets rapidly, overcoming the Janus problem compared to conventional SDS-based methods. This breakthrough signifies a substantial advancement in both the efficiency and quality of 3D generation processes.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Adversarial%20Training%20via%20Fisher-Rao%20Norm-based%20Regularization                                                                                  Boosting Adversarial Training via Fisher-Rao Norm-based Regularization                                                                                  Adversarial training is extensively utilized to improve the adversarial robustness of deep neural networks. Yet, mitigating the degradation of standard generalization performance in adversarial-trained models remains an open problem. This paper attempts to resolve this issue through the lens of model complexity. First, We leverage the Fisher-Rao norm, a geometrically invariant metric for model complexity, to establish the non-trivial bounds of the Cross-Entropy Loss-based Rademacher complexity for a ReLU-activated Multi-Layer Perceptron. Then we generalize a complexity-related variable, which is sensitive to the changes in model width and the trade-off factors in adversarial training. Moreover, intensive empirical evidence validates that this variable highly correlates with the generalization gap of Cross-Entropy loss between adversarial-trained and standard-trained models, especially during the initial and final phases of the training process. Building upon this observation, we propose a novel regularization framework, called Logit-Oriented Adversarial Training (LOAT), which can mitigate the trade-off between robustness and accuracy while imposing only a negligible increase in computational overhead. Our extensive experiments demonstrate that the proposed regularization strategy can boost the performance of the prevalent adversarial training algorithms, including PGD-AT, TRADES, TRADES (LSE), MART, and DM-AT, across various network architectures. Our code will be available at https://github.com/TrustAI/LOAT.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Disfluency%20Detection%20with%20Large%20Language%20Model%20as%20Disfluency%20Generator                                                                                  Boosting Disfluency Detection with Large Language Model as Disfluency Generator                                                                                  Current disfluency detection methods heavily rely on costly and scarce human-annotated data. To tackle this issue, some approaches employ heuristic or statistical features to generate disfluent sentences, partially improving detection performance. However, these sentences often deviate from real-life scenarios, constraining overall model enhancement. In this study, we propose a lightweight data augmentation approach for disfluency detection, utilizing the superior generative and semantic understanding capabilities of large language model (LLM) to generate disfluent sentences as augmentation data. We leverage LLM to generate diverse and more realistic sentences guided by specific prompts, without the need for fine-tuning the LLM. Subsequently, we apply an uncertainty-aware data filtering approach to improve the quality of the generated sentences, utilized in training a small detection model for improved performance. Experiments using enhanced data yielded state-of-the-art results. The results showed that using a small amount of LLM-generated enhanced data can significantly improve performance, thereby further enhancing cost-effectiveness.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Fairness%20and%20Robustness%20in%20Over-the-Air%20Federated%20Learning                                                                                  Boosting Fairness and Robustness in Over-the-Air Federated Learning                                                                                  Over-the-Air Computation is a beyond-5G communication strategy that has recently been shown to be useful for the decentralized training of machine learning models due to its efficiency. In this paper, we propose an Over-the-Air federated learning algorithm that aims to provide fairness and robustness through minmax optimization. By using the epigraph form of the problem at hand, we show that the proposed algorithm converges to the optimal solution of the minmax problem. Moreover, the proposed approach does not require reconstructing channel coefficients by complex encoding-decoding schemes as opposed to state-of-the-art approaches. This improves both efficiency and privacy.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Gradient%20Ascent%20for%20Continuous%20DR-submodular%20Maximization                                                                                  Boosting Gradient Ascent for Continuous DR-submodular Maximization                                                                                  Projected Gradient Ascent (PGA) is the most commonly used optimization scheme in machine learning and operations research areas. Nevertheless, numerous studies and examples have shown that the PGA methods may fail to achieve the tight approximation ratio for continuous DR-submodular maximization problems. To address this challenge, we present a boosting technique in this paper, which can efficiently improve the approximation guarantee of the standard PGA to emph{optimal} with only small modifications on the objective function. The fundamental idea of our boosting technique is to exploit non-oblivious search to derive a novel auxiliary function $F$, whose stationary points are excellent approximations to the global maximum of the original DR-submodular objective $f$. Specifically, when $f$ is monotone and $ gamma$-weakly DR-submodular, we propose an auxiliary function $F$ whose stationary points can provide a better $(1-e^{- gamma})$-approximation than the $( gamma^2/(1+ gamma^2))$-approximation guaranteed by the stationary points of $f$ itself. Similarly, for the non-monotone case, we devise another auxiliary function $F$ whose stationary points can achieve an optimal $ frac{1- min_{ boldsymbol{x} in mathcal{C}} | boldsymbol{x} |_{ infty}}{4}$-approximation guarantee where $ mathcal{C}$ is a convex constraint set. In contrast, the stationary points of the original non-monotone DR-submodular function can be arbitrarily bad~ citep{chen2023continuous}. Furthermore, we demonstrate the scalability of our boosting technique on four problems. In all of these four problems, our resulting variants of boosting PGA algorithm beat the previous standard PGA in several aspects such as approximation ratio and efficiency. Finally, we corroborate our theoretical findings with numerical experiments, which demonstrate the effectiveness of our boosting PGA methods.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Long-Delayed%20Reinforcement%20Learning%20with%20Auxiliary%20Short-Delayed%20Task                                                                                  Boosting Long-Delayed Reinforcement Learning with Auxiliary Short-Delayed Task                                                                                  Reinforcement learning is challenging in delayed scenarios, a common real-world situation where observations and interactions occur with delays. State-of-the-art (SOTA) state-augmentation techniques either suffer from the state-space explosion along with the delayed steps, or performance degeneration in stochastic environments. To address these challenges, our novel Auxiliary-Delayed Reinforcement Learning (AD-RL) leverages an auxiliary short-delayed task to accelerate the learning on a long-delayed task without compromising the performance in stochastic environments. Specifically, AD-RL learns the value function in the short-delayed task and then employs it with the bootstrapping and policy improvement techniques in the long-delayed task. We theoretically show that this can greatly reduce the sample complexity compared to directly learning on the original long-delayed task. On deterministic and stochastic benchmarks, our method remarkably outperforms the SOTAs in both sample efficiency and policy performance.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Order-Preserving%20and%20Transferability%20for%20Neural%20Architecture%20Search%3A%20a%20Joint%20Architecture%20Refined%20Search%20and%20Fine-tuning%20Approach                                                                                  Boosting Order-Preserving and Transferability for Neural Architecture Search: a Joint Architecture Refined Search and Fine-tuning Approach                                                                                  Supernet is a core component in many recent Neural Architecture Search (NAS) methods. It not only helps embody the search space but also provides a (relative) estimation of the final performance of candidate architectures. Thus, it is critical that the top architectures ranked by a supernet should be consistent with those ranked by true performance, which is known as the order-preserving ability. In this work, we analyze the order-preserving ability on the whole search space (global) and a sub-space of top architectures (local), and empirically show that the local order-preserving for current two-stage NAS methods still need to be improved. To rectify this, we propose a novel concept of Supernet Shifting, a refined search strategy combining architecture searching with supernet fine-tuning. Specifically, apart from evaluating, the training loss is also accumulated in searching and the supernet is updated every iteration. Since superior architectures are sampled more frequently in evolutionary searching, the supernet is encouraged to focus on top architectures, thus improving local order-preserving. Besides, a pre-trained supernet is often un-reusable for one-shot methods. We show that Supernet Shifting can fulfill transferring supernet to a new dataset. Specifically, the last classifier layer will be unset and trained through evolutionary searching. Comprehensive experiments show that our method has better order-preserving ability and can find a dominating architecture. Moreover, the pre-trained supernet can be easily transferred into a new dataset with no loss of performance.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Self-Supervision%20for%20Single-View%20Scene%20Completion%20via%20Knowledge%20Distillation                                                                                  Boosting Self-Supervision for Single-View Scene Completion via Knowledge Distillation                                                                                  Inferring scene geometry from images via Structure from Motion is a long-standing and fundamental problem in computer vision. While classical approaches and, more recently, depth map predictions only focus on the visible parts of a scene, the task of scene completion aims to reason about geometry even in occluded regions. With the popularity of neural radiance fields (NeRFs), implicit representations also became popular for scene completion by predicting so-called density fields. Unlike explicit approaches. e.g. voxel-based methods, density fields also allow for accurate depth prediction and novel-view synthesis via image-based rendering. In this work, we propose to fuse the scene reconstruction from multiple images and distill this knowledge into a more accurate single-view scene reconstruction. To this end, we propose Multi-View Behind the Scenes (MVBTS) to fuse density fields from multiple posed images, trained fully self-supervised only from image data. Using knowledge distillation, we use MVBTS to train a single-view scene completion network via direct supervision called KDBTS. It achieves state-of-the-art performance on occupancy prediction, especially in occluded regions.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20Visual%20Recognition%20for%20Autonomous%20Driving%20in%20Real-world%20Degradations%20with%20Deep%20Channel%20Prior                                                                                  Boosting Visual Recognition for Autonomous Driving in Real-world Degradations with Deep Channel Prior                                                                                  The environmental perception of autonomous vehicles in normal conditions have achieved considerable success in the past decade. However, various unfavourable conditions such as fog, low-light, and motion blur will degrade image quality and pose tremendous threats to the safety of autonomous driving. That is, when applied to degraded images, state-of-the-art visual models often suffer performance decline due to the feature content loss and artifact interference caused by statistical and structural properties disruption of captured images. To address this problem, this work proposes a novel Deep Channel Prior (DCP) for degraded visual recognition. Specifically, we observe that, in the deep representation space of pre-trained models, the channel correlations of degraded features with the same degradation type have uniform distribution even if they have different content and semantics, which can facilitate the mapping relationship learning between degraded and clear representations in high-sparsity feature space. Based on this, a novel plug-and-play Unsupervised Feature Enhancement Module (UFEM) is proposed to achieve unsupervised feature correction, where the multi-adversarial mechanism is introduced in the first stage of UFEM to achieve the latent content restoration and artifact removal in high-sparsity feature space. Then, the generated features are transferred to the second stage for global correlation modulation under the guidance of DCP to obtain high-quality and recognition-friendly features. Evaluations of three tasks and eight benchmark datasets demonstrate that our proposed method can comprehensively improve the performance of pre-trained models in real degradation conditions. The source code is available at https://github.com/liyuhang166/Deep_Channel_Prior
http://w3id.org/mlsea/pwc/scientificWork/Boosting%20of%20Thoughts%3A%20Trial-and-Error%20Problem%20Solving%20with%20Large%20Language%20Models                                                                                  Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models                                                                                  The reasoning performance of Large Language Models (LLMs) on a wide range of problems critically relies on chain-of-thought prompting, which involves providing a few chain of thought demonstrations as exemplars in prompts. Recent work, e.g., Tree of Thoughts, has pointed out the importance of exploration and self-evaluation in reasoning step selection for complex problem solving. In this paper, we present Boosting of Thoughts (BoT), an automated prompting framework for problem solving with LLMs by iteratively exploring and self-evaluating many trees of thoughts in order to acquire an ensemble of trial-and-error reasoning experiences, which will serve as a new form of prompting to solve the complex problem. Starting from a simple prompt without requiring examples, BoT iteratively explores and evaluates a large collection of reasoning steps, and more importantly, uses error analysis obtained from the LLM on them to explicitly revise prompting, which in turn enhances reasoning step generation, until a final answer is attained. Our experiments with GPT-4 and Llama2 across extensive complex mathematical problems demonstrate that BoT consistently achieves higher or comparable problem-solving rates than other advanced prompting approaches.
http://w3id.org/mlsea/pwc/scientificWork/Boosting%2C%20Voting%20Classifiers%20and%20Randomized%20Sample%20Compression%20Schemes                                                                                  Boosting, Voting Classifiers and Randomized Sample Compression Schemes                                                                                  In boosting, we aim to leverage multiple weak learners to produce a strong learner. At the center of this paradigm lies the concept of building the strong learner as a voting classifier, which outputs a weighted majority vote of the weak learners. While many successful boosting algorithms, such as the iconic AdaBoost, produce voting classifiers, their theoretical performance has long remained sub-optimal: the best known bounds on the number of training examples necessary for a voting classifier to obtain a given accuracy has so far always contained at least two logarithmic factors above what is known to be achievable by general weak-to-strong learners. In this work, we break this barrier by proposing a randomized boosting algorithm that outputs voting classifiers whose generalization error contains a single logarithmic dependency on the sample size. We obtain this result by building a general framework that extends sample compression methods to support randomized learning algorithms based on sub-sampling.
http://w3id.org/mlsea/pwc/scientificWork/Bootstrapping%20LLM-based%20Task-Oriented%20Dialogue%20Agents%20via%20Self-Talk                                                                                  Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk                                                                                  Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via 'self-talk' of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the generated conversational data that is fed back in LLM for training. Based on our automated and human evaluations of conversation quality, we demonstrate that such self-talk data improves results. In addition, we examine the various characteristics that showcase the quality of generated dialogues and how they can be connected to their potential utility as training data.
http://w3id.org/mlsea/openml/scientificWork/10                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1027                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1028                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1030                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1044                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1046                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1047                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1049                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1050                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1051                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1053                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1054                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1055                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1056                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1057                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1063                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1065                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1066                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1067                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1068                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1069                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1071                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1075                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1076                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/11                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/12                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/1245                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/13                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/14                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/15                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/150                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/151                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/155                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/16                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/18                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/20                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/22                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/23                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/23515                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/23516                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/24                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/26                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/273                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/28                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/285                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/287                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/29                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/293                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/299                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/3                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/30                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/300                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/301                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/307                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/31                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/311                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/312                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/315                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/32                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/329                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/333                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/334                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/335                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/336                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/337                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/34                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/346                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/35                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/350                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/351                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/37                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/374                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/375                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/376                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/377                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/378                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/379                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/38                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/380                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/381                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/382                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/39                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/4                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/40                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41214                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41440                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41514                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41515                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41982                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/41990                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42078                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42087                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42088                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42089                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42123                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42125                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42130                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42131                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42159                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42164                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42165                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42349                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42468                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42665                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42720                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42723                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42727                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42738                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42768                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42793                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42804                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42805                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42834                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42835                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42836                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42837                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42838                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42839                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42840                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42841                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42842                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42843                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42844                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42845                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42846                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42847                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42848                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42849                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42850                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42851                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42853                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42855                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42856                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42857                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42858                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42859                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42860                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42861                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42862                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42863                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42864                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42865                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42866                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42867                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42869                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42870                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42871                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42872                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42887                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42889                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42890                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42891                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42893                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42905                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42906                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42907                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42908                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42911                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/42912                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43069                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43855                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43874                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43943                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/43959                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44096                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44097                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44098                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44153                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44154                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44155                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44187                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44191                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44192                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44194                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44223                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/443                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/444                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44793                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44794                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44956                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44957                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44958                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44959                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44960                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44961                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44962                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44964                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44965                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44967                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44968                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44969                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44970                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44971                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44972                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44973                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44974                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44976                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44977                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44984                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44985                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44987                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44992                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44993                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/44994                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45081                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45083                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45084                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45085                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45086                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45087                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45088                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45089                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45090                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45091                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45092                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45093                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45094                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45095                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45096                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45097                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45098                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45099                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45100                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45101                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45106                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45109                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45110                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45111                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45112                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45113                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45114                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45115                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45116                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45117                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45118                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45119                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45120                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45121                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45122                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/45123                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/46                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/48                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/50                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/52                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/537                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/54                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/55                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/5587                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/56                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/561                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/564                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/5648                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/566                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/569                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/57                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/5889                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/59                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/6                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/61                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/659                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/660                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/661                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/663                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/664                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/665                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/666                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/670                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/671                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/672                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/673                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/674                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/675                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/676                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/678                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/679                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/680                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/682                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/683                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/684                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/685                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/686                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/687                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/688                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/689                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/690                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/691                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/692                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/693                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/694                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/695                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/697                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/698                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/699                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/7                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/702                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/703                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/704                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/705                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/706                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/707                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/709                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/710                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/712                                                                                                                                                                    
http://w3id.org/mlsea/openml/scientificWork/8                                                                                                                                                                    

1000 Rows. -- 2558 msec.
